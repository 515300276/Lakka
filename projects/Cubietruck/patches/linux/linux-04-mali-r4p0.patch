From 3740fc03da6d5722f64ccaf61783f0f8b712e79a Mon Sep 17 00:00:00 2001
From: dan-and <github@danand.de>
Date: Tue, 2 Dec 2014 12:57:38 +0100
Subject: [PATCH 1/2] merged with miroslav.bendik r4p0 mali patch


diff --git a/drivers/gpu/mali/Makefile b/drivers/gpu/mali/Makefile
index 9549390..0aef032 100644
--- a/drivers/gpu/mali/Makefile
+++ b/drivers/gpu/mali/Makefile
@@ -2,21 +2,20 @@
 
 ifdef CONFIG_ARCH_SUN7I
 CONFIG:=ca7-virtex820-m400-2
-MALI_PLATFORM_FILE:=platform/${CONFIG}/mali_platform.c
-export MALI_PLATFORM_FILE
 else
 CONFIG:=ca8-virtex820-m400-1
 endif
 
 USING_MMU:=1
-USING_UMP:=1
+USING_UMP:=0
 USING_PMM:=1
 BUILD:=release
-TARGET_PLATFORM:=mali400-pmu
+MALI_PLATFORM_FILES:=platform/sunxi/sunxi.c
+EXTRA_DEFINES:=-DMALI_FAKE_PLATFORM_DEVICE=1
 ifneq ($(CONFIG_TRACEPOINTS),y)
 USING_PROFILING:=0
 export USING_PROFILING
 endif
-export CONFIG USING_MMU USING_UMP USING_PMM BUILD TARGET_PLATFORM
+export CONFIG USING_MMU USING_UMP USING_PMM BUILD MALI_PLATFORM_FILES EXTRA_DEFINES
 
 obj-$(CONFIG_MALI) += ump/ mali/
diff --git a/drivers/gpu/mali/mali/Kbuild b/drivers/gpu/mali/mali/Kbuild
index e37a316..70e09065 100644
--- a/drivers/gpu/mali/mali/Kbuild
+++ b/drivers/gpu/mali/mali/Kbuild
@@ -1,273 +1,208 @@
 #
 # Copyright (C) 2010-2011 ARM Limited. All rights reserved.
-#
+# 
 # This program is free software and is provided to you under the terms of the GNU General Public License version 2
 # as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
-#
+# 
 # A copy of the licence is included with the program, and can also be obtained from Free Software
 # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 #
 
 # This file is called by the Linux build system.
 
-OSKOS=linux
-
 # set up defaults if not defined by the user
-USING_UMP ?= 0
-USING_OS_MEMORY ?= 0
-USING_MALI_PMM_TESTSUITE ?= 0
-OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB ?= 6
-USING_PROFILING ?= 1
-USING_INTERNAL_PROFILING ?= 0
-DISABLE_PP0 ?= 0
-DISABLE_PP1 ?= 0
-DISABLE_PP2 ?= 0
-DISABLE_PP3 ?= 0
 TIMESTAMP ?= default
-BUILD ?= debug
-TARGET_PLATFORM ?= default
-KERNEL_RUNTIME_PM_ENABLED ?= 0
-CONFIG ?= pb-virtex5-m200
+OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB ?= 16
+USING_GPU_UTILIZATION ?= 1
 MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP ?= 0
 MALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED ?= 0
 MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS ?= 0
-
-DEFINES := $(EXTRA_DEFINES)
-
-# Get path to driver source from Linux build system
-DRIVER_DIR=$(src)
+MALI_UPPER_HALF_SCHEDULING ?= 1
+MALI_ENABLE_CPU_CYCLES ?= 0
 
 # For customer releases the Linux Device Drivers will be provided as ARM proprietary and GPL releases:
 # The ARM proprietary product will only include the license/proprietary directory
 # The GPL product will only include the license/gpl directory
-
-ccflags-y += -I$(srctree)/$(DRIVER_DIR)/arch-$(CONFIG)
-
-ifeq ($(wildcard $(srctree)/$(DRIVER_DIR)/linux/license/gpl/*),)
-ccflags-y += -I$(srctree)/$(DRIVER_DIR)/linux/license/proprietary
-# Disable profiling for proprietary
-override USING_PROFILING := 0
-$(warning "USING_PROFILING not supported, disabling.")
+ifeq ($(wildcard $(src)/linux/license/gpl/*),)
+    ccflags-y += -I$(src)/linux/license/proprietary
+    ifeq ($(CONFIG_MALI400_PROFILING),y)
+        $(error Profiling is incompatible with non-GPL license)
+    endif
+    ifeq ($(CONFIG_PM_RUNTIME),y)
+        $(error Runtime PM is incompatible with non-GPL license)
+    endif
+    ifeq ($(CONFIG_DMA_SHARED_BUFFER),y)
+        $(error DMA-BUF is incompatible with non-GPL license)
+    endif
+    $(error Linux Device integration is incompatible with non-GPL license)
 else
-ccflags-y += -I$(srctree)/$(DRIVER_DIR)/linux/license/gpl
-endif
-
-
-ifeq ($(USING_PROFILING),1)
-ifeq ($(USING_INTERNAL_PROFILING),0)
-ifndef CONFIG_TRACEPOINTS
-# Should default to gator profiling, but we dont have the kernel feature required, so disable profiling
-override USING_PROFILING = 0
-$(warning "CONFIG_TRACEPOINTS required for USING_PROFILING")
-endif
-endif
-endif
+    ccflags-y += -I$(src)/linux/license/gpl
+endif
+
+mali-y += \
+	linux/mali_osk_atomics.o \
+	linux/mali_osk_irq.o \
+	linux/mali_osk_wq.o \
+	linux/mali_osk_locks.o \
+	linux/mali_osk_wait_queue.o \
+	linux/mali_osk_low_level_mem.o \
+	linux/mali_osk_math.o \
+	linux/mali_osk_memory.o \
+	linux/mali_osk_misc.o \
+	linux/mali_osk_mali.o \
+	linux/mali_osk_notification.o \
+	linux/mali_osk_time.o \
+	linux/mali_osk_timers.o
+
+mali-y += linux/mali_memory.o linux/mali_memory_os_alloc.o
+mali-y += linux/mali_memory_external.o
+mali-y += linux/mali_memory_block_alloc.o
+
+mali-y += \
+	linux/mali_ukk_mem.o \
+	linux/mali_ukk_gp.o \
+	linux/mali_ukk_pp.o \
+	linux/mali_ukk_core.o \
+	linux/mali_ukk_soft_job.o \
+	linux/mali_ukk_timeline.o
 
-ifeq ($(USING_PROFILING),0)
-# make sure user hasnt selected incompatible flags
-override USING_INTERNAL_PROFILING = 0
-endif
-
-MALI_RELEASE_NAME=$(shell cat $(DRIVER_DIR)/.version 2> /dev/null)
-
-# Check if a Mali Core sub module should be enabled, true or false returned
-submodule_enabled = $(shell gcc $(DEFINES) -E $(srctree)/$(DRIVER_DIR)/arch-$(CONFIG)/config.h | grep type | grep -c $(2))
-
-OSKFILES = \
-	$(OSKOS)/mali_osk_atomics.c \
-	$(OSKOS)/mali_osk_irq.c \
-	$(OSKOS)/mali_osk_locks.c \
-	$(OSKOS)/mali_osk_wait_queue.c \
-	$(OSKOS)/mali_osk_low_level_mem.c \
-	$(OSKOS)/mali_osk_math.c \
-	$(OSKOS)/mali_osk_memory.c \
-	$(OSKOS)/mali_osk_misc.c \
-	$(OSKOS)/mali_osk_mali.c \
-	$(OSKOS)/mali_osk_notification.c \
-	$(OSKOS)/mali_osk_time.c \
-	$(OSKOS)/mali_osk_timers.c
-
-UKKFILES = \
-	$(OSKOS)/mali_ukk_mem.c \
-	$(OSKOS)/mali_ukk_gp.c \
-	$(OSKOS)/mali_ukk_pp.c \
-	$(OSKOS)/mali_ukk_core.c
-
-ifeq ($(USING_PROFILING),1)
-UKKFILES += \
-	$(OSKOS)/mali_ukk_profiling.c
-endif
+# Source files which always are included in a build
+mali-y += \
+	common/mali_kernel_core.o \
+	linux/mali_kernel_linux.o \
+	common/mali_kernel_descriptor_mapping.o \
+	common/mali_session.o \
+	linux/mali_device_pause_resume.o \
+	common/mali_kernel_vsync.o \
+	linux/mali_ukk_vsync.o \
+	linux/mali_kernel_sysfs.o \
+	common/mali_mmu.o \
+	common/mali_mmu_page_directory.o \
+	common/mali_mem_validation.o \
+	common/mali_hw_core.o \
+	common/mali_gp.o \
+	common/mali_pp.o \
+	common/mali_pp_job.o \
+	common/mali_gp_job.o \
+	common/mali_soft_job.o \
+	common/mali_scheduler.o \
+	common/mali_gp_scheduler.o \
+	common/mali_pp_scheduler.o \
+	common/mali_group.o \
+	common/mali_dlbu.o \
+	common/mali_broadcast.o \
+	common/mali_pm.o \
+	common/mali_pmu.o \
+	common/mali_user_settings_db.o \
+	common/mali_kernel_utilization.o \
+	common/mali_l2_cache.o \
+	common/mali_dma.o \
+	common/mali_timeline.o \
+	common/mali_timeline_fence_wait.o \
+	common/mali_timeline_sync_fence.o \
+	common/mali_spinlock_reentrant.o \
+	common/mali_pm_domain.o \
+	linux/mali_osk_pm.o \
+	linux/mali_pmu_power_up_down.o \
+	__malidrv_build_info.o
+
+ifneq ($(MALI_PLATFORM_FILES),)
+	mali-y += $(MALI_PLATFORM_FILES:.c=.o)
+endif
+
+mali-$(CONFIG_MALI400_PROFILING) += linux/mali_ukk_profiling.o
+mali-$(CONFIG_MALI400_PROFILING) += linux/mali_osk_profiling.o
+
+mali-$(CONFIG_MALI400_INTERNAL_PROFILING) += linux/mali_profiling_internal.o timestamp-$(TIMESTAMP)/mali_timestamp.o
+ccflags-$(CONFIG_MALI400_INTERNAL_PROFILING) += -I$(src)/timestamp-$(TIMESTAMP)
+
+mali-$(CONFIG_DMA_SHARED_BUFFER) += linux/mali_memory_dma_buf.o
+mali-$(CONFIG_SYNC) += linux/mali_sync.o
+ccflags-$(CONFIG_SYNC) += -Idrivers/staging/android
+
+mali-$(CONFIG_MALI400_UMP) += linux/mali_memory_ump.o
+
+mali-$(CONFIG_MALI400_POWER_PERFORMANCE_POLICY) += common/mali_power_performance_policy.o
 
-ifeq ($(MALI_PLATFORM_FILE),)
-MALI_PLATFORM_FILE = platform/default/mali_platform.c
-endif
+# Tell the Linux build system from which .o file to create the kernel module
+obj-$(CONFIG_MALI400) := mali.o
 
-SVN_REV := $(MALI_RELEASE_NAME)
+ccflags-y += $(EXTRA_DEFINES)
 
 # Set up our defines, which will be passed to gcc
-DEFINES += -DUSING_OS_MEMORY=$(USING_OS_MEMORY)
-DEFINES += -DUSING_MMU=1
-DEFINES += -DUSING_UMP=$(USING_UMP)
-DEFINES += -D_MALI_OSK_SPECIFIC_INDIRECT_MMAP
-DEFINES += -DMALI_INTERNAL_TIMELINE_PROFILING_ENABLED=$(USING_INTERNAL_PROFILING)
-DEFINES += -DDISABLE_PP0=$(DISABLE_PP0)
-DEFINES += -DDISABLE_PP1=$(DISABLE_PP1)
-DEFINES += -DDISABLE_PP2=$(DISABLE_PP2)
-DEFINES += -DDISABLE_PP3=$(DISABLE_PP3)
-DEFINES += -DMALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP=$(MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP)
-DEFINES += -DMALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED=$(MALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED)
-DEFINES += -DMALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS=$(MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS)
-DEFINES += -DMALI_TIMELINE_PROFILING_ENABLED=$(USING_PROFILING)
-DEFINES += -DMALI_POWER_MGMT_TEST_SUITE=$(USING_MALI_PMM_TESTSUITE)
-ifeq ($(shell test $(SUBLEVEL) -gt 32 -a $(PATCHLEVEL) = 6 -a $(VERSION) = 2 -o $(VERSION) -gt 2 && echo "OK"),OK)
-# MALI_STATE_TRACKING is only supported on Linux kernels from version 2.6.32.
-DEFINES += -DMALI_STATE_TRACKING=1
-else
-DEFINES += -DMALI_STATE_TRACKING=0
-endif
-DEFINES += -DMALI_OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB=$(OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB)
+ccflags-y += -DMALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP=$(MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP)
+ccflags-y += -DMALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED=$(MALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED)
+ccflags-y += -DMALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS=$(MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS)
+ccflags-y += -DMALI_STATE_TRACKING=1
+ccflags-y += -DMALI_OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB=$(OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB)
+ccflags-y += -DUSING_GPU_UTILIZATION=$(USING_GPU_UTILIZATION)
+ccflags-y += -DMALI_ENABLE_CPU_CYCLES=$(MALI_ENABLE_CPU_CYCLES)
 
-MALI_PLATFORM_FILE = platform/$(TARGET_PLATFORM)/mali_platform.c
-
-
-ifdef CONFIG_PM
-ifdef CONFIG_PM_RUNTIME
-	KERNEL_RUNTIME_PM_ENABLED = 1
-endif
+ifeq ($(MALI_UPPER_HALF_SCHEDULING),1)
+	ccflags-y += -DMALI_UPPER_HALF_SCHEDULING
 endif
 
-DEFINES += -DMALI_PMM_RUNTIME_JOB_CONTROL_ON=$(KERNEL_RUNTIME_PM_ENABLED)
-
-ifeq ($(BUILD), debug)
-DEFINES += -DDEBUG
-endif
-DEFINES += -DSVN_REV=$(SVN_REV)
-DEFINES += -DSVN_REV_STRING=\"$(SVN_REV)\"
-
-# Linux has its own mmap cleanup handlers (see mali_kernel_memory.c)
-DEFINES += -DMALI_UKK_HAS_IMPLICIT_MMAP_CLEANUP
-
-ifeq ($(USING_UMP),1)
-	DEFINES += -DMALI_USE_UNIFIED_MEMORY_PROVIDER=1
-	ccflags-y += -I$(DRIVER_DIR)/../ump/include/ump
-else
-	DEFINES += -DMALI_USE_UNIFIED_MEMORY_PROVIDER=0
-endif
+ccflags-$(CONFIG_MALI400_UMP) += -I$(src)/../../ump/include/ump
+ccflags-$(CONFIG_MALI400_DEBUG) += -DDEBUG
 
 # Use our defines when compiling
-ccflags-y += $(DEFINES) -I$(DRIVER_DIR) -I$(DRIVER_DIR)/include -I$(DRIVER_DIR)/common -I$(DRIVER_DIR)/linux -I$(DRIVER_DIR)/platform
-
-# Source files which always are included in a build
-SRC = \
-	common/mali_kernel_core.c \
-	linux/mali_kernel_linux.c \
-	$(OSKOS)/mali_osk_indir_mmap.c \
-	common/mali_kernel_descriptor_mapping.c \
-	common/mali_session.c \
-	common/mali_device_pause_resume.c \
-	common/mali_kernel_vsync.c \
-	linux/mali_ukk_vsync.c \
-	linux/mali_kernel_sysfs.c \
-	common/mali_mmu.c \
-	common/mali_mmu_page_directory.c \
-	common/mali_memory.c \
-	common/mali_kernel_memory_engine.c \
-	common/mali_block_allocator.c \
-	common/mali_kernel_mem_os.c \
-	common/mali_mem_validation.c \
-	common/mali_hw_core.c \
-	common/mali_gp.c \
-	common/mali_pp.c \
-	common/mali_pp_job.c \
-	common/mali_gp_job.c \
-	common/mali_scheduler.c \
-	common/mali_gp_scheduler.c \
-	common/mali_pp_scheduler.c \
-	common/mali_cluster.c \
-	common/mali_group.c \
-	common/mali_dlbu.c \
-	common/mali_pm.c \
-	common/mali_pmu.c \
-	common/mali_user_settings_db.c \
-	$(OSKOS)/mali_osk_pm.c \
-	linux/mali_kernel_pm.c \
-	linux/mali_pmu_power_up_down.c \
-	$(MALI_PLATFORM_FILE) \
-	$(OSKFILES) \
-	$(UKKFILES) \
-	__malidrv_build_info.c
-
-# Selecting files to compile by parsing the config file
-
-ifeq ($(USING_INTERNAL_PROFILING),1)
-PROFILING_BACKEND_SOURCES = \
-    linux/mali_osk_profiling_internal.c \
-    timestamp-$(TIMESTAMP)/mali_timestamp.c
-ccflags-y += -I$(DRIVER_DIR)/timestamp-$(TIMESTAMP)
-else
-ifeq ($(USING_PROFILING),1)
-PROFILING_BACKEND_SOURCES = \
-    linux/mali_osk_profiling_gator.c
-endif
-endif
+ccflags-y += -I$(src) -I$(src)/include -I$(src)/common -I$(src)/linux -I$(src)/platform
 
-# Add the profiling sources
-SRC += $(PROFILING_BACKEND_SOURCES)
+# Get subversion revision number, fall back to only ${MALI_RELEASE_NAME} if no svn info is available
+MALI_RELEASE_NAME=$(shell cat $(src)/.version 2> /dev/null)
 
-ifeq ($(USING_MALI_PMM_TESTSUITE),1)
-ccflags-y += -I$(DRIVER_DIR)/platform/mali_pmu_testing
-endif
+SVN_INFO = (cd $(src); svn info 2>/dev/null)
 
-mali-$(CONFIG_MALI400_GPU_UTILIZATION) += common/mali_kernel_utilization.o
+ifneq ($(shell $(SVN_INFO) 2>/dev/null),)
+# SVN detected
+SVN_REV := $(shell $(SVN_INFO) | grep '^Revision: '| sed -e 's/^Revision: //' 2>/dev/null)
+DRIVER_REV := $(MALI_RELEASE_NAME)-r$(SVN_REV)
+CHANGE_DATE := $(shell $(SVN_INFO) | grep '^Last Changed Date: ' | cut -d: -f2- | cut -b2-)
+CHANGED_REVISION := $(shell $(SVN_INFO) | grep '^Last Changed Rev: ' | cut -d: -f2- | cut -b2-)
+REPO_URL := $(shell $(SVN_INFO) | grep '^URL: ' | cut -d: -f2- | cut -b2-)
 
-ifneq ($(call submodule_enabled, $(DRIVER_DIR), MALI400PP),0)
-	# Mali-400 PP in use
-	ccflags-y += -DUSING_MALI400
-endif
+else # SVN
+GIT_REV := $(shell cd $(src); git describe --always 2>/dev/null)
+ifneq ($(GIT_REV),)
+# Git detected
+DRIVER_REV := $(MALI_RELEASE_NAME)-$(GIT_REV)
+CHANGE_DATE := $(shell cd $(src); git log -1 --format="%ci")
+CHANGED_REVISION := $(GIT_REV)
+REPO_URL := $(shell cd $(src); git describe --all --always 2>/dev/null)
 
-ifneq ($(call submodule_enabled, $(DRIVER_DIR), MALI300PP),0)
-	# Mali-400 PP in use
-	ccflags-y += -DUSING_MALI400
+else # Git
+# No Git or SVN detected
+DRIVER_REV := $(MALI_RELEASE_NAME)
+CHANGE_DATE := $(MALI_RELEASE_NAME)
+CHANGED_REVISION := $(MALI_RELEASE_NAME)
 endif
-
-ifneq ($(call submodule_enabled, $(DRIVER_DIR), MALI200),0)
-	# Mali200 in use
-	ccflags-y += -DUSING_MALI200
 endif
 
-# Always build in support for Mali L2 cache
-SRC += common/mali_l2_cache.c
-
-# Tell the Linux build system to enable building of our .c files
-mali-y += $(SRC:.c=.o)
-# Tell the Linux build system from which .o file to create the kernel module
-obj-$(CONFIG_MALI400) := mali.o
-
+ccflags-y += -DSVN_REV_STRING=\"$(DRIVER_REV)\"
 
 VERSION_STRINGS :=
-VERSION_STRINGS += CONFIG=$(CONFIG)
-VERSION_STRINGS += USING_OS_MEMORY=$(USING_OS_MEMORY)
-VERSION_STRINGS += API_VERSION=$(shell cd $(DRIVER_DIR); grep "\#define _MALI_API_VERSION" $(srctree)/$(DRIVER_DIR)/include/linux/mali/mali_utgard_uk_types.h | cut -d' ' -f 3 )
-VERSION_STRINGS += REPO_URL=$(shell cd $(DRIVER_DIR); (svn info || git svn info || echo 'URL: $(MALI_RELEASE_NAME)') 2>/dev/null | grep '^URL: ' | cut -d: -f2- | cut -b2-)
-VERSION_STRINGS += REVISION=$(SVN_REV)
-VERSION_STRINGS += CHANGED_REVISION=$(shell cd $(DRIVER_DIR); (svn info || git svn info || echo 'Last Changed Rev: $(MALI_RELEASE_NAME)') 2>/dev/null | grep '^Last Changed Rev: ' | cut -d: -f2- | cut -b2-)
-VERSION_STRINGS += CHANGE_DATE=$(shell cd $(DRIVER_DIR); (svn info || git svn info || echo 'Last Changed Date: $(MALI_RELEASE_NAME)') 2>/dev/null | grep '^Last Changed Date: ' | cut -d: -f2- | cut -b2-)
+VERSION_STRINGS += API_VERSION=$(shell cd $(src); grep "\#define _MALI_API_VERSION" $(FILES_PREFIX)include/linux/mali/mali_utgard_uk_types.h | cut -d' ' -f 3 )
+VERSION_STRINGS += REPO_URL=$(REPO_URL)
+VERSION_STRINGS += REVISION=$(DRIVER_REV)
+VERSION_STRINGS += CHANGED_REVISION=$(CHANGED_REVISION)
+VERSION_STRINGS += CHANGE_DATE=$(CHANGE_DATE)
 VERSION_STRINGS += BUILD_DATE=$(shell date)
-
-VERSION_STRINGS += BUILD=$(shell echo $(BUILD) | tr a-z A-Z)
-VERSION_STRINGS += CPU=$(CPU)
-VERSION_STRINGS += USING_UMP=$(USING_UMP)
-VERSION_STRINGS += USING_MALI200=$(call submodule_enabled, $(DRIVER_DIR), MALI200)
-VERSION_STRINGS += USING_MALI400=$(call submodule_enabled, $(DRIVER_DIR), MALI400)
-VERSION_STRINGS += USING_MALI400_L2_CACHE=$(call submodule_enabled, $(DRIVER_DIR), MALI400L2)
-VERSION_STRINGS += USING_GP2=$(call submodule_enabled, $(DRIVER_DIR), MALIGP2)
+ifdef CONFIG_MALI400_DEBUG
+VERSION_STRINGS += BUILD=debug
+else
+VERSION_STRINGS += BUILD=release
+endif
+VERSION_STRINGS += TARGET_PLATFORM=$(TARGET_PLATFORM)
+VERSION_STRINGS += MALI_PLATFORM=$(MALI_PLATFORM)
 VERSION_STRINGS += KDIR=$(KDIR)
-VERSION_STRINGS += MALI_PLATFORM_FILE=$(MALI_PLATFORM_FILE)
 VERSION_STRINGS += OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB=$(OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB)
-VERSION_STRINGS += USING_PROFILING=$(USING_PROFILING)
-VERSION_STRINGS += USING_INTERNAL_PROFILING=$(USING_INTERNAL_PROFILING)
-VERSION_STRINGS += USING_GPU_UTILIZATION=$(CONFIG_MALI400_GPU_UTILIZATION)
+VERSION_STRINGS += USING_UMP=$(CONFIG_MALI400_UMP)
+VERSION_STRINGS += USING_PROFILING=$(CONFIG_MALI400_PROFILING)
+VERSION_STRINGS += USING_INTERNAL_PROFILING=$(CONFIG_MALI400_INTERNAL_PROFILING)
+VERSION_STRINGS += USING_GPU_UTILIZATION=$(USING_GPU_UTILIZATION)
+VERSION_STRINGS += USING_POWER_PERFORMANCE_POLICY=$(CONFIG_POWER_PERFORMANCE_POLICY)
+VERSION_STRINGS += MALI_UPPER_HALF_SCHEDULING=$(MALI_UPPER_HALF_SCHEDULING)
 
 # Create file with Mali driver configuration
-$(DRIVER_DIR)/__malidrv_build_info.c:
-	@echo 'const char *__malidrv_build_info(void) { return "malidrv: $(VERSION_STRINGS)";}' > $(DRIVER_DIR)/__malidrv_build_info.c
+$(src)/__malidrv_build_info.c:
+	@echo 'const char *__malidrv_build_info(void) { return "malidrv: $(VERSION_STRINGS)";}' > $(src)/__malidrv_build_info.c
diff --git a/drivers/gpu/mali/mali/Kconfig b/drivers/gpu/mali/mali/Kconfig
index 62e2830..cdee98b 100644
--- a/drivers/gpu/mali/mali/Kconfig
+++ b/drivers/gpu/mali/mali/Kconfig
@@ -1,29 +1,90 @@
 config MALI400
 	tristate "Mali-300/400/450 support"
 	depends on ARM
-	select FB
+	select DMA_SHARED_BUFFER
 	---help---
-	  This enables support for the Mali-300, Mali-400, and Mali-450 GPUs.
+	  This enables support for the ARM Mali-300, Mali-400, and Mali-450
+	  GPUs.
 
 	  To compile this driver as a module, choose M here: the module will be
 	  called mali.
 
+config MALI450
+	bool "Enable Mali-450 support"
+	depends on MALI400
+	---help---
+	  This enables support for Mali-450 specific features.
+
 config MALI400_DEBUG
 	bool "Enable debug in Mali driver"
 	depends on MALI400
 	---help---
-	  This enabled extra debug checks and messages in the Mali-300/400/450
-	  driver.
+	  This enabled extra debug checks and messages in the Mali driver.
 
 config MALI400_PROFILING
 	bool "Enable Mali profiling"
-	depends on MALI400 && TRACEPOINTS
+	depends on MALI400
+	select TRACEPOINTS
+	default y
 	---help---
 	  This enables gator profiling of Mali GPU events.
 
-config MALI400_GPU_UTILIZATION
-	bool "Enable Mali GPU utilization tracking"
+config MALI400_INTERNAL_PROFILING
+	bool "Enable internal Mali profiling API"
+	depends on MALI400_PROFILING
+	default n
+	---help---
+	  This enables the internal legacy Mali profiling API.
+
+config MALI400_UMP
+	bool "Enable UMP support"
 	depends on MALI400
 	---help---
-	  This enables gathering and processing of the utilization of Mali GPU.
-	  This data can be used as a basis to change GPU operating frequency.
+	  This enables support for the UMP memory sharing API in the Mali driver.
+
+config MALI400_POWER_PERFORMANCE_POLICY
+	bool "Enable Mali power performance policy"
+	depends on ARM
+	default n
+	---help---
+	  This enables support for dynamic performance scaling of Mali with the goal of lowering power consumption.
+
+config MALI_DMA_BUF_MAP_ON_ATTACH
+	bool "Map dma-buf attachments on attach"
+	depends on MALI400 && DMA_SHARED_BUFFER
+	default y
+	---help---
+	  This makes the Mali driver map dma-buf attachments after doing
+	  attach. If this is not set the dma-buf attachments will be mapped for
+	  every time the GPU need to access the buffer.
+
+	  Mapping for each access can cause lower performance.
+
+config MALI_SHARED_INTERRUPTS
+	bool "Support for shared interrupts"
+	depends on MALI400
+	default n
+	---help---
+	  Adds functionality required to properly support shared interrupts.  Without this support,
+	  the device driver will fail during insmod if it detects shared interrupts.  This also
+	  works when the GPU is not using shared interrupts, but might have a slight performance
+	  impact.
+
+config MALI_PMU_PARALLEL_POWER_UP
+	bool "Power up Mali PMU domains in parallel"
+	depends on MALI400
+	default n
+	---help---
+	  This makes the Mali driver power up all PMU power domains in parallel, instead of
+	  powering up domains one by one, with a slight delay in between. Powering on all power
+	  domains at the same time may cause peak currents higher than what some systems can handle.
+	  These systems must not enable this option.
+
+config MALI_QUIET
+	bool "Make Mali driver very quiet"
+	depends on MALI400 && !MALI400_DEBUG
+	default n
+	---help---
+	  This forces the Mali driver to never print any messages.
+
+	  If unsure, say N.
diff --git a/drivers/gpu/mali/mali/Makefile b/drivers/gpu/mali/mali/Makefile
index aa36fbb..945aa35 100644
--- a/drivers/gpu/mali/mali/Makefile
+++ b/drivers/gpu/mali/mali/Makefile
@@ -1,14 +1,20 @@
 #
-# Copyright (C) 2010-2012 ARM Limited. All rights reserved.
-#
+# Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+# 
 # This program is free software and is provided to you under the terms of the GNU General Public License version 2
 # as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
-#
+# 
 # A copy of the licence is included with the program, and can also be obtained from Free Software
 # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 #
 
 USE_UMPV2=0
+USING_PROFILING ?= 0
+USING_INTERNAL_PROFILING ?= 0
+USING_POWER_PERFORMANCE_POLICY ?= 0
+MALI_HEATMAPS_ENABLED ?= 0
+MALI_DMA_BUF_MAP_ON_ATTACH ?= 0
+MALI_PMU_PARALLEL_POWER_UP ?= 0
 
 # The Makefile sets up "arch" based on the CONFIG, creates the version info
 # string and the __malidrv_build_info.c file, and then call the Linux build
@@ -21,18 +27,46 @@ ARCH ?= arm
 OSKOS=linux
 FILES_PREFIX=
 
+check_cc2 = \
+	$(shell if $(1) -S -o /dev/null -xc /dev/null > /dev/null 2>&1; \
+	then \
+		echo "$(2)"; \
+	else \
+		echo "$(3)"; \
+	fi ;)
+
 # This conditional makefile exports the global definition ARM_INTERNAL_BUILD. Customer releases will not include arm_internal.mak
 -include ../../../arm_internal.mak
 
-# Check that required parameters are supplied.
-ifeq ($(CONFIG),)
-$(error "CONFIG must be specified.")
+# Give warning of old config parameters are used
+ifneq ($(CONFIG),)
+$(warning "You have specified the CONFIG variable which is no longer in used. Use TARGET_PLATFORM instead.")
 endif
-ifeq ($(CPU)$(KDIR),)
-$(error "KDIR or CPU must be specified.")
+
+ifneq ($(CPU),)
+$(warning "You have specified the CPU variable which is no longer in used. Use TARGET_PLATFORM instead.")
 endif
 
+# Include the mapping between TARGET_PLATFORM and KDIR + MALI_PLATFORM
+-include MALI_CONFIGURATION
+export KDIR ?= $(KDIR-$(TARGET_PLATFORM))
+export MALI_PLATFORM ?= $(MALI_PLATFORM-$(TARGET_PLATFORM))
+
+ifneq ($(TARGET_PLATFORM),)
+ifeq ($(MALI_PLATFORM),)
+$(error "Invalid TARGET_PLATFORM: $(TARGET_PLATFORM)")
+endif
+endif
+
+# validate lookup result
+ifeq ($(KDIR),)
+$(error No KDIR found for platform $(TARGET_PLATFORM))
+endif
+
+
 ifeq ($(USING_UMP),1)
+export CONFIG_MALI400_UMP=y
+export EXTRA_DEFINES += -DCONFIG_MALI400_UMP=1
 ifeq ($(USE_UMPV2),1)
 UMP_SYMVERS_FILE ?= ../umpv2/Module.symvers
 else
@@ -42,38 +76,85 @@ KBUILD_EXTRA_SYMBOLS = $(realpath $(UMP_SYMVERS_FILE))
 $(warning $(KBUILD_EXTRA_SYMBOLS))
 endif
 
-# Get any user defined KDIR-<names> or maybe even a hardcoded KDIR
--include KDIR_CONFIGURATION
-
 # Define host system directory
 KDIR-$(shell uname -m):=/lib/modules/$(shell uname -r)/build
 
-ifeq ($(ARCH), arm)
-	# when compiling for ARM we're cross compiling
-	export CROSS_COMPILE ?= arm-none-linux-gnueabi-
-endif
-
-# look up KDIR based om CPU selection
-KDIR ?= $(KDIR-$(CPU))
+include $(KDIR)/.config
 
-# validate lookup result
-ifeq ($(KDIR),)
-$(error No KDIR found for platform $(CPU))
+ifeq ($(ARCH), arm)
+# when compiling for ARM we're cross compiling
+export CROSS_COMPILE ?= $(call check_cc2, arm-linux-gnueabi-gcc, arm-linux-gnueabi-, arm-none-linux-gnueabi-)
 endif
 
 # report detected/selected settings
 ifdef ARM_INTERNAL_BUILD
-$(warning Config $(CONFIG))
-$(warning Host CPU $(CPU))
-$(warning OS_MEMORY $(USING_OS_MEMORY))
+$(warning TARGET_PLATFORM $(TARGET_PLATFORM))
+$(warning KDIR $(KDIR))
+$(warning MALI_PLATFORM $(MALI_PLATFORM))
 endif
 
 # Set up build config
 export CONFIG_MALI400=m
+export CONFIG_MALI450=y
+
+export EXTRA_DEFINES += -DCONFIG_MALI400=1
+export EXTRA_DEFINES += -DCONFIG_MALI450=1
+
+ifneq ($(MALI_PLATFORM),)
+export EXTRA_DEFINES += -DMALI_FAKE_PLATFORM_DEVICE=1
+export MALI_PLATFORM_FILES = $(wildcard platform/$(MALI_PLATFORM)/*.c)
+endif
+
+ifeq ($(USING_PROFILING),1)
+ifeq ($(CONFIG_TRACEPOINTS),)
+$(warning CONFIG_TRACEPOINTS required for profiling)
+else
+export CONFIG_MALI400_PROFILING=y
+export EXTRA_DEFINES += -DCONFIG_MALI400_PROFILING=1
+ifeq ($(USING_INTERNAL_PROFILING),1)
+export CONFIG_MALI400_INTERNAL_PROFILING=y
+export EXTRA_DEFINES += -DCONFIG_MALI400_INTERNAL_PROFILING=1
+endif
+ifeq ($(MALI_HEATMAPS_ENABLED),1)
+export MALI_HEATMAPS_ENABLED=y
+export EXTRA_DEFINES += -DCONFIG_MALI400_HEATMAPS_ENABLED
+endif
+endif
+endif
+
+ifeq ($(MALI_DMA_BUF_MAP_ON_ATTACH),1)
+export CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH=y
+export EXTRA_DEFINES += -DCONFIG_MALI_DMA_BUF_MAP_ON_ATTACH
+endif
+
+ifeq ($(MALI_SHARED_INTERRUPTS),1)
+export CONFIG_MALI_SHARED_INTERRUPTS=y
+export EXTRA_DEFINES += -DCONFIG_MALI_SHARED_INTERRUPTS
+endif
+
+ifeq ($(USING_POWER_PERFORMANCE_POLICY),1)
+export CONFIG_MALI400_POWER_PERFORMANCE_POLICY=y
+export EXTRA_DEFINES += -DCONFIG_MALI400_POWER_PERFORMANCE_POLICY
+endif
+
+ifeq ($(MALI_PMU_PARALLEL_POWER_UP),1)
+export CONFIG_MALI_PMU_PARALLEL_POWER_UP=y
+export EXTRA_DEFINES += -DCONFIG_MALI_PMU_PARALLEL_POWER_UP
+endif
+
+ifneq ($(BUILD),release)
+# Debug
+export CONFIG_MALI400_DEBUG=y
+else
+# Release
+ifeq ($(MALI_QUIET),1)
+export CONFIG_MALI_QUIET=y
+export EXTRA_DEFINES += -DCONFIG_MALI_QUIET
+endif
+endif
 
-ifeq ($(USING_GPU_UTILIZATION),1)
-export EXTRA_DEFINES += -DCONFIG_MALI400_GPU_UTILIZATION=1
-export CONFIG_MALI400_GPU_UTILIZATION := y
+ifeq ($(MALI_SKIP_JOBS),1)
+EXTRA_DEFINES += -DPROFILING_SKIP_PP_JOBS=1 -DPROFILING_SKIP_GP_JOBS=1
 endif
 
 all: $(UMP_SYMVERS_FILE)
diff --git a/drivers/gpu/mali/mali/arch-ca7-virtex820-m400-2/config.h b/drivers/gpu/mali/mali/arch-ca7-virtex820-m400-2/config.h
deleted file mode 100644
index 08dfbfb..0000000
--- a/drivers/gpu/mali/mali/arch-ca7-virtex820-m400-2/config.h
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * This confidential and proprietary software may be used only as
- * authorised by a licensing agreement from ARM Limited
- * (C) COPYRIGHT 2008-2010 ARM Limited
- * ALL RIGHTS RESERVED
- * The entire notice above must be reproduced on all authorised
- * copies and copies may only be made to the extent permitted
- * by a licensing agreement from ARM Limited.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the EB platform with ZBT memory enabled */
-
-/* FIXME: mali don't use kernel header, so that we are unable to known which platform to use.
- hardcode the irq to make it work on allwinner a20 platform
-*/
-#define SW_INT_START 32
-#define SW_INT_IRQNO_GPU_GP             (69 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_GPMMU          (70 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_PP0            (71 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_PPMMU0         (72 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_PMU            (73 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_PP1            (74 + SW_INT_START)
-#define SW_INT_IRQNO_GPU_PPMMU1         (75 + SW_INT_START)
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = PMU,
-		.description = "Mali-400 PMU",
-		.base = 0x01C42000,
-		.irq = SW_INT_IRQNO_GPU_PMU,
-		.mmu_id = 0
-	},
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0x01C40000,
-		.irq = SW_INT_IRQNO_GPU_GP,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0x01C48000,
-		.irq = SW_INT_IRQNO_GPU_PP0,
-		.description = "Mali-400 PP0",
-		.mmu_id = 2
-	},
-	{
-		.type = MALI400PP,
-		.base = 0x01C4A000,
-		.irq = SW_INT_IRQNO_GPU_PP1,
-		.description = "Mali-400 PP1",
-		.mmu_id = 3
-	},
-	{
-		.type = MMU,
-		.base = 0x01C43000,
-		.irq = SW_INT_IRQNO_GPU_GPMMU,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0x01C44000,
-		.irq = SW_INT_IRQNO_GPU_PPMMU0,
-		.description = "Mali-400 MMU for PP0",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0x01C45000,
-		.irq = SW_INT_IRQNO_GPU_PPMMU1,
-		.description = "Mali-400 MMU for PP1",
-		.mmu_id = 3
-	},
-	{
-		.type = OS_MEMORY,
-		.description = "OS Memory",
-		.cpu_usage_adjust = 0x40000000, /* PHYS_OFFSET */
-		.alloc_order = 1, /* Lowest preference for this memory */
-		.size = 192 * 1024 * 1024, /* 64 MB */
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_MMU_READABLE | _MALI_MMU_WRITEABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0x01C41000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-ca8-virtex820-m400-1/config.h b/drivers/gpu/mali/mali/arch-ca8-virtex820-m400-1/config.h
deleted file mode 100644
index 3860934..0000000
--- a/drivers/gpu/mali/mali/arch-ca8-virtex820-m400-1/config.h
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * This confidential and proprietary software may be used only as
- * authorised by a licensing agreement from ARM Limited
- * (C) COPYRIGHT 2008-2010 ARM Limited
- * ALL RIGHTS RESERVED
- * The entire notice above must be reproduced on all authorised
- * copies and copies may only be made to the extent permitted
- * by a licensing agreement from ARM Limited.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the EB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = PMU,
-		.description = "Mali-400 PMU",
-		.base = 0x01C42000,
-		.irq = 73,
-		.mmu_id = 0
-	},
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0x01C40000,
-		.irq = 69,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0x01C48000,
-		.irq = 71,
-		.description = "Mali-400 PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0x01C43000,
-		.irq = 70,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0x01C44000,
-		.irq = 72,
-		.description = "Mali-400 MMU for PP",
-		.mmu_id = 2
-	},
-	{
-		.type = OS_MEMORY,
-		.description = "OS Memory",
-		.cpu_usage_adjust = 0x40000000, /* PHYS_OFFSET */
-		.alloc_order = 1, /* Lowest preference for this memory */
-		.size = 192 * 1024 * 1024, /* 64 MB */
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_MMU_READABLE | _MALI_MMU_WRITEABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0x01C41000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m300/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m300/config.h
deleted file mode 100644
index 8e65cae..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m300/config.h
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = PMU,
-		.description = "Mali-300 PMU",
-		.base = 0xC0002000,
-		.irq = -1,
-		.mmu_id = 0
-
-	},
-	{
-		.type = MALI300GP,
-		.description = "Mali-300 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI300PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-300 PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = -1,
-		.description = "Mali-300 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = -1,
-		.description = "Mali-300 MMU for PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI300L2,
-		.base = 0xC0001000,
-		.description = "Mali-300 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-direct/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-direct/config.h
deleted file mode 100644
index a495fda..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-direct/config.h
+++ /dev/null
@@ -1,92 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-
-    	{
-                .type = PMU,
-                .description = "Mali-400 PMU",
-                .base = 0xC0002000,
-                .irq = -1,
-                .mmu_id = 0
-        },
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = -1,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = -1,
-		.description = "Mali-400 MMU for PP",
-		.mmu_id = 2
-	},
-	{
-		.type = OS_MEMORY,
-		.description = "OS Memory",
-		.alloc_order = 10, /* Lowest preference for this memory */
-		.size = 96 * 1024 * 1024, /* 96 MB */
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = 0,
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0x80000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-pmu/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-pmu/config.h
deleted file mode 100644
index e99a041..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1-pmu/config.h
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = PMU,
-		.description = "Mali-400 PMU",
-		.base = 0xC0002000,
-		.irq = -1,
-		.mmu_id = 0
-
-	},
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = -1,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = -1,
-		.description = "Mali-400 MMU for PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1/config.h
deleted file mode 100644
index e0c918b..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-1/config.h
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = -1,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = -1,
-		.description = "Mali-400 MMU for PP",
-		.mmu_id = 2
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-2/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-2/config.h
deleted file mode 100644
index 8264150..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-2/config.h
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000A000,
-		.irq = -1,
-		.description = "Mali-400 PP 1",
-		.mmu_id = 3
-        },
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = -1,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = -1,
-		.description = "Mali-400 MMU for PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0005000,
-		.irq = -1,
-		.description = "Mali-400 MMU for PP 1",
-		.mmu_id = 3
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-3/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-3/config.h
deleted file mode 100644
index 9dbf862..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-3/config.h
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the PB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000A000,
-		.irq = -1,
-		.description = "Mali-400 PP 1",
-		.mmu_id = 3
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000C000,
-		.irq = -1,
-		.description = "Mali-400 PP 2",
-		.mmu_id = 4
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = 102,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0005000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 1",
-		.mmu_id = 3
-	},
-	{
-		.type = MMU,
-		.base = 0xC0006000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 2",
-		.mmu_id = 4
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-4/config.h b/drivers/gpu/mali/mali/arch-pb-virtex5-m400-4/config.h
deleted file mode 100644
index 4fa1e9f..0000000
--- a/drivers/gpu/mali/mali/arch-pb-virtex5-m400-4/config.h
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the EB platform with ZBT memory enabled */
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	{
-		.type = MALI400GP,
-		.description = "Mali-400 GP",
-		.base = 0xC0000000,
-		.irq = -1,
-		.mmu_id = 1
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc0008000,
-		.irq = -1,
-		.description = "Mali-400 PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000A000,
-		.irq = -1,
-		.description = "Mali-400 PP 1",
-		.mmu_id = 3
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000C000,
-		.irq = -1,
-		.description = "Mali-400 PP 2",
-		.mmu_id = 4
-	},
-	{
-		.type = MALI400PP,
-		.base = 0xc000E000,
-		.irq = -1,
-		.description = "Mali-400 PP 3",
-		.mmu_id = 5
-	},
-	{
-		.type = MMU,
-		.base = 0xC0003000,
-		.irq = 102,
-		.description = "Mali-400 MMU for GP",
-		.mmu_id = 1
-	},
-	{
-		.type = MMU,
-		.base = 0xC0004000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 0",
-		.mmu_id = 2
-	},
-	{
-		.type = MMU,
-		.base = 0xC0005000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 1",
-		.mmu_id = 3
-	},
-	{
-		.type = MMU,
-		.base = 0xC0006000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 2",
-		.mmu_id = 4
-	},
-	{
-		.type = MMU,
-		.base = 0xC0007000,
-		.irq = 102,
-		.description = "Mali-400 MMU for PP 3",
-		.mmu_id = 5
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali SDRAM remapped to baseboard",
-		.cpu_usage_adjust = -0x50000000,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0xD0000000,
-		.size = 0x10000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEMORY,
-		.description = "Mali ZBT",
-		.alloc_order = 5, /* Medium preference for this memory */
-		.base = 0xe1000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-	{
-		.type = MALI400L2,
-		.base = 0xC0001000,
-		.description = "Mali-400 L2 cache"
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/arch-ve-virtex6-m450-8/config.h b/drivers/gpu/mali/mali/arch-ve-virtex6-m450-8/config.h
deleted file mode 100644
index 801b6dc..0000000
--- a/drivers/gpu/mali/mali/arch-ve-virtex6-m450-8/config.h
+++ /dev/null
@@ -1,168 +0,0 @@
-/*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __ARCH_CONFIG_H__
-#define __ARCH_CONFIG_H__
-
-/* Configuration for the Versatile Express platform */
-
-#define MALI_BASE_ADDRESS 0xFC040000
-
-static _mali_osk_resource_t arch_configuration [] =
-{
-	/* GP cluster */
-	{
-		.type = MALI400L2,
-		.base = MALI_BASE_ADDRESS + 0x10000,
-		.description = "Mali-450 L2 cache for GP"
-	},
-	{
-		.type = MALI400GP,
-		.description = "Mali-450 GP",
-		.base = MALI_BASE_ADDRESS,
-		.irq = -1,
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x3000,
-		.irq = 70,
-		.description = "Mali-450 MMU for GP",
-	},
-
-	/* PP0-3 cluster */
-	{
-		.type = MALI400L2,
-		.base = MALI_BASE_ADDRESS + 0x1000,
-		.description = "Mali-450 L2 cache for PP0-3"
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0x8000,
-		.irq = 70,
-		.description = "Mali-450 PP0",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x4000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP0",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0xA000,
-		.irq = 70,
-		.description = "Mali-450 PP1",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x5000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP1",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0xC000,
-		.irq = 70,
-		.description = "Mali-450 PP2",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x6000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP2",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0xE000,
-		.irq = 70,
-		.description = "Mali-450 PP3",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x7000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP3",
-	},
-
-	/* PP4-7 cluster */
-	{
-		.type = MALI400L2,
-		.base = MALI_BASE_ADDRESS + 0x11000,
-		.description = "Mali-450 L2 cache for PP4-7"
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0x28000,
-		.irq = 70,
-		.description = "Mali-450 PP4",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x1C000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP4",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0x2A000,
-		.irq = 70,
-		.description = "Mali-450 PP5",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x1D000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP5",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0x2C000,
-		.irq = 70,
-		.description = "Mali-450 PP6",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x1E000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP6",
-	},
-	{
-		.type = MALI400PP,
-		.base = MALI_BASE_ADDRESS + 0x2E000,
-		.irq = 70,
-		.description = "Mali-450 PP7",
-	},
-	{
-		.type = MMU,
-		.base = MALI_BASE_ADDRESS + 0x1F000,
-		.irq = 70,
-		.description = "Mali-450 MMU for PP7",
-	},
-
-	/* Memory */
-	{
-		.type = OS_MEMORY,
-		.description = "Mali OS memory",
-		.cpu_usage_adjust = 0,
-		.alloc_order = 0, /* Highest preference for this memory */
-		.base = 0x0,
-		.size = 256 * 1024 * 1024,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE
-	},
-	{
-		.type = MEM_VALIDATION,
-		.description = "Framebuffer",
-		.base = 0xe0000000,
-		.size = 0x01000000,
-		.flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_WRITEABLE | _MALI_PP_READABLE
-	},
-};
-
-#endif /* __ARCH_CONFIG_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_block_allocator.c b/drivers/gpu/mali/mali/common/mali_block_allocator.c
deleted file mode 100644
index 789d696..0000000
--- a/drivers/gpu/mali/mali/common/mali_block_allocator.c
+++ /dev/null
@@ -1,391 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-#include "mali_kernel_common.h"
-#include "mali_kernel_core.h"
-#include "mali_kernel_memory_engine.h"
-#include "mali_block_allocator.h"
-#include "mali_osk.h"
-
-#define MALI_BLOCK_SIZE (256UL * 1024UL)  /* 256 kB, remember to keep the ()s */
-
-typedef struct block_info
-{
-	struct block_info * next;
-} block_info;
-
-/* The structure used as the handle produced by block_allocator_allocate,
- * and removed by block_allocator_release */
-typedef struct block_allocator_allocation
-{
-	/* The list will be released in reverse order */
-	block_info *last_allocated;
-	mali_allocation_engine * engine;
-	mali_memory_allocation * descriptor;
-	u32 start_offset;
-	u32 mapping_length;
-} block_allocator_allocation;
-
-
-typedef struct block_allocator
-{
-    _mali_osk_lock_t *mutex;
-	block_info * all_blocks;
-	block_info * first_free;
-	u32 base;
-	u32 cpu_usage_adjust;
-	u32 num_blocks;
-} block_allocator;
-
-MALI_STATIC_INLINE u32 get_phys(block_allocator * info, block_info * block);
-static mali_physical_memory_allocation_result block_allocator_allocate(void* ctx, mali_allocation_engine * engine,  mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info);
-static void block_allocator_release(void * ctx, void * handle);
-static mali_physical_memory_allocation_result block_allocator_allocate_page_table_block(void * ctx, mali_page_table_block * block);
-static void block_allocator_release_page_table_block( mali_page_table_block *page_table_block );
-static void block_allocator_destroy(mali_physical_memory_allocator * allocator);
-static u32 block_allocator_stat(mali_physical_memory_allocator * allocator);
-
-mali_physical_memory_allocator * mali_block_allocator_create(u32 base_address, u32 cpu_usage_adjust, u32 size, const char *name)
-{
-	mali_physical_memory_allocator * allocator;
-	block_allocator * info;
-	u32 usable_size;
-	u32 num_blocks;
-
-	usable_size = size & ~(MALI_BLOCK_SIZE - 1);
-	MALI_DEBUG_PRINT(3, ("Mali block allocator create for region starting at 0x%08X length 0x%08X\n", base_address, size));
-	MALI_DEBUG_PRINT(4, ("%d usable bytes\n", usable_size));
-	num_blocks = usable_size / MALI_BLOCK_SIZE;
-	MALI_DEBUG_PRINT(4, ("which becomes %d blocks\n", num_blocks));
-
-	if (usable_size == 0)
-	{
-		MALI_DEBUG_PRINT(1, ("Memory block of size %d is unusable\n", size));
-		return NULL;
-	}
-
-	allocator = _mali_osk_malloc(sizeof(mali_physical_memory_allocator));
-	if (NULL != allocator)
-	{
-		info = _mali_osk_malloc(sizeof(block_allocator));
-		if (NULL != info)
-		{
-            info->mutex = _mali_osk_lock_init( _MALI_OSK_LOCKFLAG_ORDERED, 0, _MALI_OSK_LOCK_ORDER_MEM_INFO);
-            if (NULL != info->mutex)
-            {
-        		info->all_blocks = _mali_osk_malloc(sizeof(block_info) * num_blocks);
-			    if (NULL != info->all_blocks)
-			    {
-				    u32 i;
-				    info->first_free = NULL;
-				    info->num_blocks = num_blocks;
-
-				    info->base = base_address;
-				    info->cpu_usage_adjust = cpu_usage_adjust;
-
-				    for ( i = 0; i < num_blocks; i++)
-				    {
-					    info->all_blocks[i].next = info->first_free;
-					    info->first_free = &info->all_blocks[i];
-				    }
-
-				    allocator->allocate = block_allocator_allocate;
-				    allocator->allocate_page_table_block = block_allocator_allocate_page_table_block;
-				    allocator->destroy = block_allocator_destroy;
-				    allocator->stat = block_allocator_stat;
-				    allocator->ctx = info;
-					allocator->name = name;
-
-				    return allocator;
-			    }
-                _mali_osk_lock_term(info->mutex);
-            }
-			_mali_osk_free(info);
-		}
-		_mali_osk_free(allocator);
-	}
-
-	return NULL;
-}
-
-static void block_allocator_destroy(mali_physical_memory_allocator * allocator)
-{
-	block_allocator * info;
-	MALI_DEBUG_ASSERT_POINTER(allocator);
-	MALI_DEBUG_ASSERT_POINTER(allocator->ctx);
-	info = (block_allocator*)allocator->ctx;
-
-	_mali_osk_free(info->all_blocks);
-    _mali_osk_lock_term(info->mutex);
-	_mali_osk_free(info);
-	_mali_osk_free(allocator);
-}
-
-MALI_STATIC_INLINE u32 get_phys(block_allocator * info, block_info * block)
-{
-	return info->base + ((block - info->all_blocks) * MALI_BLOCK_SIZE);
-}
-
-static mali_physical_memory_allocation_result block_allocator_allocate(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info)
-{
-	block_allocator * info;
-	u32 left;
-	block_info * last_allocated = NULL;
-	mali_physical_memory_allocation_result result = MALI_MEM_ALLOC_NONE;
-	block_allocator_allocation *ret_allocation;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(offset);
-	MALI_DEBUG_ASSERT_POINTER(alloc_info);
-
-	info = (block_allocator*)ctx;
-	left = descriptor->size - *offset;
-	MALI_DEBUG_ASSERT(0 != left);
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW)) return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	ret_allocation = _mali_osk_malloc( sizeof(block_allocator_allocation) );
-
-	if ( NULL == ret_allocation )
-	{
-		/* Failure; try another allocator by returning MALI_MEM_ALLOC_NONE */
-		_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-		return result;
-	}
-
-	ret_allocation->start_offset = *offset;
-	ret_allocation->mapping_length = 0;
-
-	while ((left > 0) && (info->first_free))
-	{
-		block_info * block;
-		u32 phys_addr;
-		u32 padding;
-		u32 current_mapping_size;
-
-		block = info->first_free;
-		info->first_free = info->first_free->next;
-		block->next = last_allocated;
-		last_allocated = block;
-
-		phys_addr = get_phys(info, block);
-
-		padding = *offset & (MALI_BLOCK_SIZE-1);
-
- 		if (MALI_BLOCK_SIZE - padding < left)
-		{
-			current_mapping_size = MALI_BLOCK_SIZE - padding;
-		}
-		else
-		{
-			current_mapping_size = left;
-		}
-
-		if (_MALI_OSK_ERR_OK != mali_allocation_engine_map_physical(engine, descriptor, *offset, phys_addr + padding, info->cpu_usage_adjust, current_mapping_size))
-		{
-			MALI_DEBUG_PRINT(1, ("Mapping of physical memory  failed\n"));
-			result = MALI_MEM_ALLOC_INTERNAL_FAILURE;
-			mali_allocation_engine_unmap_physical(engine, descriptor, ret_allocation->start_offset, ret_allocation->mapping_length, (_mali_osk_mem_mapregion_flags_t)0);
-
-			/* release all memory back to the pool */
-			while (last_allocated)
-			{
-				/* This relinks every block we've just allocated back into the free-list */
-				block = last_allocated->next;
-				last_allocated->next = info->first_free;
-				info->first_free = last_allocated;
-				last_allocated = block;
-			}
-
-			break;
-		}
-
-		*offset += current_mapping_size;
-		left -= current_mapping_size;
-		ret_allocation->mapping_length += current_mapping_size;
-	}
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	if (last_allocated)
-	{
-		if (left) result = MALI_MEM_ALLOC_PARTIAL;
-		else result = MALI_MEM_ALLOC_FINISHED;
-
-		/* Record all the information about this allocation */
-		ret_allocation->last_allocated = last_allocated;
-		ret_allocation->engine = engine;
-		ret_allocation->descriptor = descriptor;
-
-		alloc_info->ctx = info;
-		alloc_info->handle = ret_allocation;
-		alloc_info->release = block_allocator_release;
-	}
-	else
-	{
-		/* Free the allocation information - nothing to be passed back */
-		_mali_osk_free( ret_allocation );
-	}
-
-	return result;
-}
-
-static void block_allocator_release(void * ctx, void * handle)
-{
-	block_allocator * info;
-	block_info * block, * next;
-	block_allocator_allocation *allocation;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(handle);
-
-	info = (block_allocator*)ctx;
-	allocation = (block_allocator_allocation*)handle;
-	block = allocation->last_allocated;
-
-	MALI_DEBUG_ASSERT_POINTER(block);
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW))
-	{
-		MALI_DEBUG_PRINT(1, ("allocator release: Failed to get mutex\n"));
-		return;
-	}
-
-	/* unmap */
-	mali_allocation_engine_unmap_physical(allocation->engine, allocation->descriptor, allocation->start_offset, allocation->mapping_length, (_mali_osk_mem_mapregion_flags_t)0);
-
-	while (block)
-	{
-		MALI_DEBUG_ASSERT(!((block < info->all_blocks) || (block > (info->all_blocks + info->num_blocks))));
-
-		next = block->next;
-
-		/* relink into free-list */
-		block->next = info->first_free;
-		info->first_free = block;
-
-		/* advance the loop */
-		block = next;
-	}
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	_mali_osk_free( allocation );
-}
-
-
-static mali_physical_memory_allocation_result block_allocator_allocate_page_table_block(void * ctx, mali_page_table_block * block)
-{
-	block_allocator * info;
-	mali_physical_memory_allocation_result result = MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(block);
-	info = (block_allocator*)ctx;
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW)) return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	if (NULL != info->first_free)
-	{
-		void * virt;
-		u32 phys;
-		u32 size;
-		block_info * alloc;
-		alloc = info->first_free;
-
-		phys = get_phys(info, alloc); /* Does not modify info or alloc */
-		size = MALI_BLOCK_SIZE; /* Must be multiple of MALI_MMU_PAGE_SIZE */
-		virt = _mali_osk_mem_mapioregion( phys, size, "Mali block allocator page tables" );
-
-		/* Failure of _mali_osk_mem_mapioregion will result in MALI_MEM_ALLOC_INTERNAL_FAILURE,
-		 * because it's unlikely another allocator will be able to map in. */
-
-		if ( NULL != virt )
-		{
-			block->ctx = info; /* same as incoming ctx */
-			block->handle = alloc;
-			block->phys_base = phys;
-			block->size = size;
-			block->release = block_allocator_release_page_table_block;
-			block->mapping = virt;
-
-			info->first_free = alloc->next;
-
-			alloc->next = NULL; /* Could potentially link many blocks together instead */
-
-			result = MALI_MEM_ALLOC_FINISHED;
-		}
-	}
-	else result = MALI_MEM_ALLOC_NONE;
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	return result;
-}
-
-
-static void block_allocator_release_page_table_block( mali_page_table_block *page_table_block )
-{
-	block_allocator * info;
-	block_info * block, * next;
-
-	MALI_DEBUG_ASSERT_POINTER( page_table_block );
-
-	info = (block_allocator*)page_table_block->ctx;
-	block = (block_info*)page_table_block->handle;
-
-	MALI_DEBUG_ASSERT_POINTER(info);
-	MALI_DEBUG_ASSERT_POINTER(block);
-
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW))
-	{
-		MALI_DEBUG_PRINT(1, ("allocator release: Failed to get mutex\n"));
-		return;
-	}
-
-	/* Unmap all the physical memory at once */
-	_mali_osk_mem_unmapioregion( page_table_block->phys_base, page_table_block->size, page_table_block->mapping );
-
-	/** @note This loop handles the case where more than one block_info was linked.
-	 * Probably unnecessary for page table block releasing. */
-	while (block)
-	{
-		next = block->next;
-
-		MALI_DEBUG_ASSERT(!((block < info->all_blocks) || (block > (info->all_blocks + info->num_blocks))));
-
-		block->next = info->first_free;
-		info->first_free = block;
-
-		block = next;
-	}
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-}
-
-static u32 block_allocator_stat(mali_physical_memory_allocator * allocator)
-{
-	block_allocator * info;
-	block_info *block;
-	u32 free_blocks = 0;
-
-	MALI_DEBUG_ASSERT_POINTER(allocator);
-
-	info = (block_allocator*)allocator->ctx;
-	block = info->first_free;
-
-	while(block)
-	{
-		free_blocks++;
-		block = block->next;
-	}
-	return (info->num_blocks - free_blocks) * MALI_BLOCK_SIZE;
-}
diff --git a/drivers/gpu/mali/mali/common/mali_block_allocator.h b/drivers/gpu/mali/mali/common/mali_block_allocator.h
deleted file mode 100644
index 35b9d8f..0000000
--- a/drivers/gpu/mali/mali/common/mali_block_allocator.h
+++ /dev/null
@@ -1,18 +0,0 @@
-/*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_BLOCK_ALLOCATOR_H__
-#define __MALI_BLOCK_ALLOCATOR_H__
-
-#include "mali_kernel_memory_engine.h"
-
-mali_physical_memory_allocator * mali_block_allocator_create(u32 base_address, u32 cpu_usage_adjust, u32 size, const char *name);
-
-#endif /* __MALI_BLOCK_ALLOCATOR_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_cluster.c b/drivers/gpu/mali/mali/common/mali_cluster.c
deleted file mode 100644
index 1afe7ab..0000000
--- a/drivers/gpu/mali/mali/common/mali_cluster.c
+++ /dev/null
@@ -1,218 +0,0 @@
-/*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include "mali_kernel_common.h"
-#include "mali_cluster.h"
-#include "mali_osk.h"
-#include "mali_group.h"
-#include "mali_l2_cache.h"
-#include "mali_scheduler.h"
-
-static struct mali_cluster *mali_global_clusters[MALI_MAX_NUMBER_OF_CLUSTERS] = { NULL, NULL, NULL };
-static u32 mali_global_num_clusters = 0;
-
-/**
- * The structure represents a render cluster
- * A render cluster is defined by all the cores that share the same Mali L2 cache
- */
-struct mali_cluster
-{
-	struct mali_l2_cache_core *l2;
-	u32 number_of_groups;
-	struct mali_group* groups[MALI_MAX_NUMBER_OF_GROUPS_PER_CLUSTER];
-	u32 last_invalidated_id;
-	mali_bool power_is_enabled;
-};
-
-struct mali_cluster *mali_cluster_create(struct mali_l2_cache_core *l2_cache)
-{
-	struct mali_cluster *cluster = NULL;
-
-	if (mali_global_num_clusters >= MALI_MAX_NUMBER_OF_CLUSTERS)
-	{
-		MALI_PRINT_ERROR(("Mali cluster: Too many cluster objects created\n"));
-		return NULL;
-	}
-
-	cluster = _mali_osk_malloc(sizeof(struct mali_cluster));
-	if (NULL != cluster)
-	{
-		_mali_osk_memset(cluster, 0, sizeof(struct mali_cluster));
-		cluster->l2 = l2_cache; /* This cluster now owns this L2 cache object */
-		cluster->last_invalidated_id = 0;
-		cluster->power_is_enabled = MALI_TRUE;
-
-		mali_global_clusters[mali_global_num_clusters] = cluster;
-		mali_global_num_clusters++;
-
-		return cluster;
-	}
-
-	return NULL;
-}
-
-void mali_cluster_power_is_enabled_set(struct mali_cluster * cluster, mali_bool power_is_enabled)
-{
-	cluster->power_is_enabled = power_is_enabled;
-}
-
-mali_bool mali_cluster_power_is_enabled_get(struct mali_cluster * cluster)
-{
-	return cluster->power_is_enabled;
-}
-
-
-void mali_cluster_add_group(struct mali_cluster *cluster, struct mali_group *group)
-{
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	if (cluster->number_of_groups < MALI_MAX_NUMBER_OF_GROUPS_PER_CLUSTER)
-	{
-		/* This cluster now owns the group object */
-		cluster->groups[cluster->number_of_groups] = group;
-		cluster->number_of_groups++;
-	}
-}
-
-void mali_cluster_delete(struct mali_cluster *cluster)
-{
-	u32 i;
-
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	/* Free all the resources we own */
-	for (i = 0; i < cluster->number_of_groups; i++)
-	{
-		mali_group_delete(cluster->groups[i]);
-	}
-
-	if (NULL != cluster->l2)
-	{
-		mali_l2_cache_delete(cluster->l2);
-	}
-
-	for (i = 0; i < mali_global_num_clusters; i++)
-	{
-		if (mali_global_clusters[i] == cluster)
-		{
-			mali_global_clusters[i] = NULL;
-			mali_global_num_clusters--;
-			break;
-		}
-	}
-
-	_mali_osk_free(cluster);
-}
-
-void mali_cluster_reset(struct mali_cluster *cluster)
-{
-	u32 i;
-
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	/* Free all the resources we own */
-	for (i = 0; i < cluster->number_of_groups; i++)
-	{
-		struct mali_group *group = cluster->groups[i];
-
-		mali_group_reset(group);
-	}
-
-	if (NULL != cluster->l2)
-	{
-		mali_l2_cache_reset(cluster->l2);
-	}
-}
-
-struct mali_l2_cache_core* mali_cluster_get_l2_cache_core(struct mali_cluster *cluster)
-{
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-	return cluster->l2;
-}
-
-struct mali_group *mali_cluster_get_group(struct mali_cluster *cluster, u32 index)
-{
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	if (index <  cluster->number_of_groups)
-	{
-		return cluster->groups[index];
-	}
-
-	return NULL;
-}
-
-struct mali_cluster *mali_cluster_get_global_cluster(u32 index)
-{
-	if (MALI_MAX_NUMBER_OF_CLUSTERS > index)
-	{
-		return mali_global_clusters[index];
-	}
-
-	return NULL;
-}
-
-u32 mali_cluster_get_glob_num_clusters(void)
-{
-	return mali_global_num_clusters;
-}
-
-mali_bool mali_cluster_l2_cache_invalidate_all(struct mali_cluster *cluster, u32 id)
-{
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	if (NULL != cluster->l2)
-	{
-		/* If the last cache invalidation was done by a job with a higher id we
-		 * don't have to flush. Since user space will store jobs w/ their
-		 * corresponding memory in sequence (first job #0, then job #1, ...),
-		 * we don't have to flush for job n-1 if job n has already invalidated
-		 * the cache since we know for sure that job n-1's memory was already
-		 * written when job n was started. */
-		if (((s32)id) <= ((s32)cluster->last_invalidated_id))
-		{
-			return MALI_FALSE;
-		}
-		else
-		{
-			cluster->last_invalidated_id = mali_scheduler_get_new_id();
-		}
-
-		mali_l2_cache_invalidate_all(cluster->l2);
-	}
-	return MALI_TRUE;
-}
-
-void mali_cluster_l2_cache_invalidate_all_force(struct mali_cluster *cluster)
-{
-	MALI_DEBUG_ASSERT_POINTER(cluster);
-
-	if (NULL != cluster->l2)
-	{
-		cluster->last_invalidated_id = mali_scheduler_get_new_id();
-		mali_l2_cache_invalidate_all(cluster->l2);
-	}
-}
-
-void mali_cluster_invalidate_pages(u32 *pages, u32 num_pages)
-{
-	u32 i;
-
-	for (i = 0; i < mali_global_num_clusters; i++)
-	{
-		/*additional check for cluster*/
-		if (MALI_TRUE == mali_l2_cache_lock_power_state(mali_global_clusters[i]->l2))
-		{
-			mali_l2_cache_invalidate_pages(mali_global_clusters[i]->l2, pages, num_pages);
-		}
-		mali_l2_cache_unlock_power_state(mali_global_clusters[i]->l2);
-		/*check for failed power locking???*/
-	}
-}
diff --git a/drivers/gpu/mali/mali/common/mali_cluster.h b/drivers/gpu/mali/mali/common/mali_cluster.h
deleted file mode 100644
index a6c6408..0000000
--- a/drivers/gpu/mali/mali/common/mali_cluster.h
+++ /dev/null
@@ -1,44 +0,0 @@
-/*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_CLUSTER_H__
-#define __MALI_CLUSTER_H__
-
-#include "mali_osk.h"
-#include "mali_l2_cache.h"
-
-/* Maximum 1 GP and 4 PP for a cluster (Mali-400 Quad-core) */
-#define MALI_MAX_NUMBER_OF_GROUPS_PER_CLUSTER 5
-#define MALI_MAX_NUMBER_OF_CLUSTERS           3
-
-struct mali_cluster;
-struct mali_group;
-
-struct mali_cluster *mali_cluster_create(struct mali_l2_cache_core *l2_cache);
-void mali_cluster_add_group(struct mali_cluster *cluster, struct mali_group *group);
-void mali_cluster_delete(struct mali_cluster *cluster);
-
-void mali_cluster_power_is_enabled_set(struct mali_cluster * cluster, mali_bool power_is_enabled);
-mali_bool mali_cluster_power_is_enabled_get(struct mali_cluster * cluster);
-
-void mali_cluster_reset(struct mali_cluster *cluster);
-
-struct mali_l2_cache_core* mali_cluster_get_l2_cache_core(struct mali_cluster *cluster);
-struct mali_group *mali_cluster_get_group(struct mali_cluster *cluster, u32 index);
-
-struct mali_cluster *mali_cluster_get_global_cluster(u32 index);
-u32 mali_cluster_get_glob_num_clusters(void);
-
-/*  Returns MALI_TRUE if it did the flush */
-mali_bool mali_cluster_l2_cache_invalidate_all(struct mali_cluster *cluster, u32 id);
-void mali_cluster_l2_cache_invalidate_all_force(struct mali_cluster *cluster);
-void mali_cluster_invalidate_pages(u32 *pages, u32 num_pages);
-
-#endif /* __MALI_CLUSTER_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_device_pause_resume.c b/drivers/gpu/mali/mali/common/mali_device_pause_resume.c
deleted file mode 100644
index 5490c91..0000000
--- a/drivers/gpu/mali/mali/common/mali_device_pause_resume.c
+++ /dev/null
@@ -1,46 +0,0 @@
-/**
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-/**
- * @file mali_device_pause_resume.c
- * Implementation of the Mali pause/resume functionality
- */
-
-#include "mali_gp_scheduler.h"
-#include "mali_pp_scheduler.h"
-#include "mali_pm.h"
-
-void mali_dev_pause(mali_bool *power_is_on)
-{
-	mali_gp_scheduler_suspend();
-	mali_pp_scheduler_suspend();
-
-	/*
-	 * Take and hold the PM lock to be sure we don't change power state as well.
-	 * (it might be unsafe to for instance change frequency if Mali GPU is powered off)
-	 */
-	mali_pm_execute_state_change_lock();
-	if (NULL != power_is_on)
-	{
-		*power_is_on = mali_pm_is_powered_on();
-	}
-}
-
-void mali_dev_resume(void)
-{
-	mali_pm_execute_state_change_unlock();
-	mali_gp_scheduler_resume();
-	mali_pp_scheduler_resume();
-}
-
-/*
-EXPORT_SYMBOL(mali_dev_pause);
-EXPORT_SYMBOL(mali_dev_resume);
-*/
diff --git a/drivers/gpu/mali/mali/common/mali_device_pause_resume.h b/drivers/gpu/mali/mali/common/mali_device_pause_resume.h
deleted file mode 100644
index 4d9278e..0000000
--- a/drivers/gpu/mali/mali/common/mali_device_pause_resume.h
+++ /dev/null
@@ -1,31 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_DEVICE_PAUSE_RESUME_H__
-#define __MALI_DEVICE_PAUSE_RESUME_H__
-
-#include "mali_osk.h"
-
-/**
- * Pause the scheduling and power state changes of Mali device driver.
- * mali_dev_resume() must always be called as soon as possible after this function
- * in order to resume normal operation of the Mali driver.
- *
- * @param power_is_on Receives the power current status of Mali GPU. MALI_TRUE if GPU is powered on
- */
-void mali_dev_pause(mali_bool *power_is_on);
-
-/**
- * Resume scheduling and allow power changes in Mali device driver.
- * This must always be called after mali_dev_pause().
- */
-void mali_dev_resume(void);
-
-#endif /* __MALI_DEVICE_PAUSE_RESUME_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_dlbu.c b/drivers/gpu/mali/mali/common/mali_dlbu.c
old mode 100644
new mode 100755
index ae3612e..f70a5c7
--- a/drivers/gpu/mali/mali/common/mali_dlbu.c
+++ b/drivers/gpu/mali/mali/common/mali_dlbu.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -21,9 +21,7 @@
 #define MALI_DLBU_SIZE 0x400
 
 u32 mali_dlbu_phys_addr = 0;
-static mali_io_address mali_dlbu_cpu_addr = 0;
-
-static u32 mali_dlbu_tile_position;
+static mali_io_address mali_dlbu_cpu_addr = NULL;
 
 /**
  * DLBU register numbers
@@ -32,40 +30,39 @@ static u32 mali_dlbu_tile_position;
  */
 typedef enum mali_dlbu_register {
 	MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR = 0x0000, /**< Master tile list physical base address;
-	                                                     31:12 Physical address to the page used for the DLBU
-	                                                     0 DLBU enable - set this bit to 1 enables the AXI bus
-	                                                     between PPs and L2s, setting to 0 disables the router and
-	                                                     no further transactions are sent to DLBU */
+                                                             31:12 Physical address to the page used for the DLBU
+                                                             0 DLBU enable - set this bit to 1 enables the AXI bus
+                                                             between PPs and L2s, setting to 0 disables the router and
+                                                             no further transactions are sent to DLBU */
 	MALI_DLBU_REGISTER_MASTER_TLLIST_VADDR     = 0x0004, /**< Master tile list virtual base address;
-	                                                     31:12 Virtual address to the page used for the DLBU */
-	MALI_DLBU_REGISTER_TLLIST_VBASEADDR        = 0x0008, /**< Tile list virtual base address;
-	                                                     31:12 Virtual address to the tile list. This address is used when
-	                                                     calculating the call address sent to PP.*/
-	MALI_DLBU_REGISTER_FB_DIM                  = 0x000C, /**< Framebuffer dimension;
-	                                                     23:16 Number of tiles in Y direction-1
-	                                                     7:0 Number of tiles in X direction-1 */
-	MALI_DLBU_REGISTER_TLLIST_CONF             = 0x0010, /**< Tile list configuration;
-	                                                     29:28 select the size of each allocated block: 0=128 bytes, 1=256, 2=512, 3=1024
-	                                                     21:16 2^n number of tiles to be binned to one tile list in Y direction
-	                                                     5:0 2^n number of tiles to be binned to one tile list in X direction */
-	MALI_DLBU_REGISTER_START_TILE_POS          = 0x0014, /**< Start tile positions;
-	                                                     31:24 start position in Y direction for group 1
-	                                                     23:16 start position in X direction for group 1
-	                                                     15:8 start position in Y direction for group 0
-	                                                     7:0 start position in X direction for group 0 */
-	MALI_DLBU_REGISTER_PP_ENABLE_MASK          = 0x0018, /**< PP enable mask;
-	                                                     7 enable PP7 for load balancing
-	                                                     6 enable PP6 for load balancing
-	                                                     5 enable PP5 for load balancing
-	                                                     4 enable PP4 for load balancing
-	                                                     3 enable PP3 for load balancing
-	                                                     2 enable PP2 for load balancing
-	                                                     1 enable PP1 for load balancing
-	                                                     0 enable PP0 for load balancing */
+                                                             31:12 Virtual address to the page used for the DLBU */
+	MALI_DLBU_REGISTER_TLLIST_VBASEADDR     = 0x0008, /**< Tile list virtual base address;
+                                                             31:12 Virtual address to the tile list. This address is used when
+                                                             calculating the call address sent to PP.*/
+	MALI_DLBU_REGISTER_FB_DIM                 = 0x000C, /**< Framebuffer dimension;
+                                                             23:16 Number of tiles in Y direction-1
+                                                             7:0 Number of tiles in X direction-1 */
+	MALI_DLBU_REGISTER_TLLIST_CONF       = 0x0010, /**< Tile list configuration;
+                                                             29:28 select the size of each allocated block: 0=128 bytes, 1=256, 2=512, 3=1024
+                                                             21:16 2^n number of tiles to be binned to one tile list in Y direction
+                                                             5:0 2^n number of tiles to be binned to one tile list in X direction */
+	MALI_DLBU_REGISTER_START_TILE_POS         = 0x0014, /**< Start tile positions;
+                                                             31:24 start position in Y direction for group 1
+                                                             23:16 start position in X direction for group 1
+                                                             15:8 start position in Y direction for group 0
+                                                             7:0 start position in X direction for group 0 */
+	MALI_DLBU_REGISTER_PP_ENABLE_MASK         = 0x0018, /**< PP enable mask;
+                                                             7 enable PP7 for load balancing
+                                                             6 enable PP6 for load balancing
+                                                             5 enable PP5 for load balancing
+                                                             4 enable PP4 for load balancing
+                                                             3 enable PP3 for load balancing
+                                                             2 enable PP2 for load balancing
+                                                             1 enable PP1 for load balancing
+                                                             0 enable PP0 for load balancing */
 } mali_dlbu_register;
 
-typedef enum
-{
+typedef enum {
 	PP0ENABLE = 0,
 	PP1ENABLE,
 	PP2ENABLE,
@@ -76,20 +73,18 @@ typedef enum
 	PP7ENABLE
 } mali_dlbu_pp_enable;
 
-struct mali_dlbu_core
-{
+struct mali_dlbu_core {
 	struct mali_hw_core     hw_core;           /**< Common for all HW cores */
 	u32                     pp_cores_mask;     /**< This is a mask for the PP cores whose operation will be controlled by LBU
-	                                              see MALI_DLBU_REGISTER_PP_ENABLE_MASK register */
+                                                      see MALI_DLBU_REGISTER_PP_ENABLE_MASK register */
 };
 
 _mali_osk_errcode_t mali_dlbu_initialize(void)
 {
 
-	MALI_DEBUG_PRINT(2, ("Dynamic Load Balancing Unit initializing\n"));
+	MALI_DEBUG_PRINT(2, ("Mali DLBU: Initializing\n"));
 
-	if (_MALI_OSK_ERR_OK == mali_mmu_get_table_page(&mali_dlbu_phys_addr, &mali_dlbu_cpu_addr))
-	{
+	if (_MALI_OSK_ERR_OK == mali_mmu_get_table_page(&mali_dlbu_phys_addr, &mali_dlbu_cpu_addr)) {
 		MALI_SUCCESS;
 	}
 
@@ -100,24 +95,20 @@ void mali_dlbu_terminate(void)
 {
 	MALI_DEBUG_PRINT(3, ("Mali DLBU: terminating\n"));
 
-	mali_mmu_release_table_page(mali_dlbu_phys_addr);
+	mali_mmu_release_table_page(mali_dlbu_phys_addr, mali_dlbu_cpu_addr);
 }
 
-struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t * resource)
+struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t *resource)
 {
 	struct mali_dlbu_core *core = NULL;
 
 	MALI_DEBUG_PRINT(2, ("Mali DLBU: Creating Mali dynamic load balancing unit: %s\n", resource->description));
 
 	core = _mali_osk_malloc(sizeof(struct mali_dlbu_core));
-	if (NULL != core)
-	{
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALI_DLBU_SIZE))
-		{
-			if (_MALI_OSK_ERR_OK == mali_dlbu_reset(core))
-			{
-				mali_hw_core_register_write(&core->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_VADDR, MALI_DLB_VIRT_ADDR);
-
+	if (NULL != core) {
+		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALI_DLBU_SIZE)) {
+			core->pp_cores_mask = 0;
+			if (_MALI_OSK_ERR_OK == mali_dlbu_reset(core)) {
 				return core;
 			}
 			MALI_PRINT_ERROR(("Failed to reset DLBU %s\n", core->hw_core.description));
@@ -125,9 +116,7 @@ struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t * resource)
 		}
 
 		_mali_osk_free(core);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Mali DLBU: Failed to allocate memory for DLBU core\n"));
 	}
 
@@ -136,150 +125,85 @@ struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t * resource)
 
 void mali_dlbu_delete(struct mali_dlbu_core *dlbu)
 {
+	MALI_DEBUG_ASSERT_POINTER(dlbu);
+
 	mali_dlbu_reset(dlbu);
 	mali_hw_core_delete(&dlbu->hw_core);
 	_mali_osk_free(dlbu);
 }
 
-void mali_dlbu_enable(struct mali_dlbu_core *dlbu)
-{
-	u32 wval = mali_hw_core_register_read(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR);
-
-	wval |= 0x1;
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR, wval);
-}
-
-void mali_dlbu_disable(struct mali_dlbu_core *dlbu)
-{
-	u32 wval = mali_hw_core_register_read(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR);
-
-	wval |= (wval & 0xFFFFFFFE);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR, wval);
-}
-
-_mali_osk_errcode_t mali_dlbu_enable_pp_core(struct mali_dlbu_core *dlbu, u32 pp_core_enable, u32 val)
-{
-	u32 wval = mali_hw_core_register_read(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK);
-
-	if((pp_core_enable < mali_pp_get_glob_num_pp_cores()) && ((0 == val) || (1 == val))) /* check for valid input parameters */
-	{
-		if (val == 1)
-		{
-			val = (wval | (pp_core_enable <<= 0x1));
-		}
-		if (val == 0)
-		{
-			val = (wval & ~(pp_core_enable << 0x1));
-		}
-		wval |= val;
-		mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, wval);
-		dlbu->pp_cores_mask = wval;
-
-		return _MALI_OSK_ERR_OK;
-	}
-
-	return _MALI_OSK_ERR_FAULT;
-}
-
-void mali_dlbu_enable_all_pp_cores(struct mali_dlbu_core *dlbu)
-{
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, dlbu->pp_cores_mask);
-}
-
-void mali_dlbu_disable_all_pp_cores(struct mali_dlbu_core *dlbu)
-{
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, 0x0);
-}
-
-void mali_dlbu_setup(struct mali_dlbu_core *dlbu, u8 fb_xdim, u8 fb_ydim, u8 xtilesize, u8 ytilesize, u8 blocksize, u8 xgr0, u8 ygr0, u8 xgr1, u8 ygr1)
-{
-	u32 wval = 0x0;
-
-	/* write the framebuffer dimensions */
-	wval = (16 << (u32)fb_ydim) | (u32)fb_xdim;
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_FB_DIM, wval);
-
-	/* write the tile list configuration */
-	wval = 0x0;
-	wval = (28 << (u32)blocksize) | (16 << (u32)ytilesize) | ((u32)xtilesize);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_TLLIST_CONF, wval);
-
-	/* write the start tile position */
-	wval = 0x0;
-	wval = (24 << (u32)ygr1 | (16 << (u32)xgr1) | 8 << (u32)ygr0) | (u32)xgr0;
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_START_TILE_POS, wval);
-}
-
 _mali_osk_errcode_t mali_dlbu_reset(struct mali_dlbu_core *dlbu)
 {
+	u32 dlbu_registers[7];
 	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
 	MALI_DEBUG_ASSERT_POINTER(dlbu);
 
 	MALI_DEBUG_PRINT(4, ("Mali DLBU: mali_dlbu_reset: %s\n", dlbu->hw_core.description));
 
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR, mali_dlbu_phys_addr);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_TLLIST_VBASEADDR, 0x00);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_FB_DIM, 0x00);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_TLLIST_CONF, 0x00);
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_START_TILE_POS, 0x00);
+	dlbu_registers[0] = mali_dlbu_phys_addr | 1; /* bit 0 enables the whole core */
+	dlbu_registers[1] = MALI_DLBU_VIRT_ADDR;
+	dlbu_registers[2] = 0;
+	dlbu_registers[3] = 0;
+	dlbu_registers[4] = 0;
+	dlbu_registers[5] = 0;
+	dlbu_registers[6] = dlbu->pp_cores_mask;
 
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, dlbu->pp_cores_mask);
+	/* write reset values to core registers */
+	mali_hw_core_register_write_array_relaxed(&dlbu->hw_core, MALI_DLBU_REGISTER_MASTER_TLLIST_PHYS_ADDR, dlbu_registers, 7);
 
 	err = _MALI_OSK_ERR_OK;
 
 	return err;
 }
 
-_mali_osk_errcode_t mali_dlbu_add_group(struct mali_dlbu_core *dlbu, struct mali_group *group)
+void mali_dlbu_update_mask(struct mali_dlbu_core *dlbu)
 {
-	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
-	u32 wval, rval;
-	struct mali_pp_core *pp_core = mali_group_get_pp_core(group);
-
-	/* find the core id and set the mask */
-
-	if (NULL != pp_core)
-	{
-		wval = mali_pp_core_get_id(pp_core);
-		rval = mali_hw_core_register_read(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK);
-		mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, (wval << 0x1) | rval);
-		err = _MALI_OSK_ERR_OK;
-	}
+	MALI_DEBUG_ASSERT_POINTER(dlbu);
 
-	return err;
+	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_PP_ENABLE_MASK, dlbu->pp_cores_mask);
 }
 
-void mali_dlbu_set_tllist_base_address(struct mali_dlbu_core *dlbu, u32 val)
+void mali_dlbu_add_group(struct mali_dlbu_core *dlbu, struct mali_group *group)
 {
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_TLLIST_VBASEADDR, val);
+	struct mali_pp_core *pp_core;
+	u32 bcast_id;
+
+	MALI_DEBUG_ASSERT_POINTER(dlbu);
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	pp_core = mali_group_get_pp_core(group);
+	bcast_id = mali_pp_core_get_bcast_id(pp_core);
+
+	dlbu->pp_cores_mask |= bcast_id;
+	MALI_DEBUG_PRINT(3, ("Mali DLBU: Adding core[%d] New mask= 0x%02x\n", bcast_id , dlbu->pp_cores_mask));
 }
 
-void mali_dlbu_pp_jobs_stop(struct mali_dlbu_core *dlbu)
+/* Remove a group from the DLBU */
+void mali_dlbu_remove_group(struct mali_dlbu_core *dlbu, struct mali_group *group)
 {
-	/* this function to implement (see documentation):
-	 * 1) clear all bits in the enable register
-	 * 2) wait until all PPs have finished - mali_pp_scheduler.c code - this done in interrupts call?
-	 * 3) read the current tile position registers to get current tile positions -
-	 * note that current tile position register is the same as start tile position - perhaps the name should be changed!!! */
+	struct mali_pp_core *pp_core;
+	u32 bcast_id;
 
-	/* 1) */
-	mali_dlbu_disable_all_pp_cores(dlbu);
+	MALI_DEBUG_ASSERT_POINTER(dlbu);
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	pp_core = mali_group_get_pp_core(group);
+	bcast_id = mali_pp_core_get_bcast_id(pp_core);
 
-	/* 3) */
-	mali_dlbu_tile_position = mali_hw_core_register_read(&dlbu->hw_core, MALI_DLBU_REGISTER_START_TILE_POS);
+	dlbu->pp_cores_mask &= ~bcast_id;
+	MALI_DEBUG_PRINT(3, ("Mali DLBU: Removing core[%d] New mask= 0x%02x\n", bcast_id, dlbu->pp_cores_mask));
 }
 
-void mali_dlbu_pp_jobs_restart(struct mali_dlbu_core *dlbu)
+/* Configure the DLBU for \a job. This needs to be done before the job is started on the groups in the DLBU. */
+void mali_dlbu_config_job(struct mali_dlbu_core *dlbu, struct mali_pp_job *job)
 {
-	/* this function to implement (see the document):
-	 * 1) configure the dynamic load balancing unit as normal
-	 * 2) set the current tile position registers as read when stopping the job
-	 * 3) configure the PPs to start the job as normal - done by another part of the system - scheduler */
+	u32 *registers;
+	MALI_DEBUG_ASSERT(job);
+	registers = mali_pp_job_get_dlbu_registers(job);
+	MALI_DEBUG_PRINT(4, ("Mali DLBU: Starting job\n"));
 
-	/* 1) */
-	mali_dlbu_reset(dlbu);
-	/* ++ setup the needed values - see this */
+	/* Writing 4 registers:
+	 * DLBU registers except the first two (written once at DLBU initialisation / reset) and the PP_ENABLE_MASK register */
+	mali_hw_core_register_write_array_relaxed(&dlbu->hw_core, MALI_DLBU_REGISTER_TLLIST_VBASEADDR, registers, 4);
 
-	/* 2)  */
-	mali_hw_core_register_write(&dlbu->hw_core, MALI_DLBU_REGISTER_START_TILE_POS, mali_dlbu_tile_position);
 }
diff --git a/drivers/gpu/mali/mali/common/mali_dlbu.h b/drivers/gpu/mali/mali/common/mali_dlbu.h
old mode 100644
new mode 100755
index e86dcd6..b77657b
--- a/drivers/gpu/mali/mali/common/mali_dlbu.h
+++ b/drivers/gpu/mali/mali/common/mali_dlbu.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,10 +11,12 @@
 #ifndef __MALI_DLBU_H__
 #define __MALI_DLBU_H__
 
+#define MALI_DLBU_VIRT_ADDR 0xFFF00000 /* master tile virtual address fixed at this value and mapped into every session */
+
 #include "mali_osk.h"
-#include "mali_group.h"
 
-#define MALI_DLB_VIRT_ADDR 0xFFF00000 /* master tile virtual address fixed at this value and mapped into every session */
+struct mali_pp_job;
+struct mali_group;
 
 extern u32 mali_dlbu_phys_addr;
 
@@ -23,23 +25,22 @@ struct mali_dlbu_core;
 _mali_osk_errcode_t mali_dlbu_initialize(void);
 void mali_dlbu_terminate(void);
 
-struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t * resource);
+struct mali_dlbu_core *mali_dlbu_create(const _mali_osk_resource_t *resource);
 void mali_dlbu_delete(struct mali_dlbu_core *dlbu);
 
-void mali_dlbu_enable(struct mali_dlbu_core *dlbu);
-void mali_dlbu_disable(struct mali_dlbu_core *dlbu);
-
-_mali_osk_errcode_t mali_dlbu_enable_pp_core(struct mali_dlbu_core *dlbu, u32 pp_core_enable, u32 val);
-void mali_dlbu_enable_all_pp_cores(struct mali_dlbu_core *dlbu);
-void mali_dlbu_disable_all_pp_cores(struct mali_dlbu_core *dlbu);
-
 _mali_osk_errcode_t mali_dlbu_reset(struct mali_dlbu_core *dlbu);
-void mali_dlbu_setup(struct mali_dlbu_core *dlbu, u8 fb_xdim, u8 fb_ydim, u8 xtilesize, u8 ytilesize, u8 blocksize, u8 xgr0, u8 ygr0, u8 xgr1, u8 ygr1);
 
-_mali_osk_errcode_t mali_dlbu_add_group(struct mali_dlbu_core *dlbu, struct mali_group *group);
-void mali_dlbu_set_tllist_base_address(struct mali_dlbu_core *dlbu, u32 val);
+void mali_dlbu_add_group(struct mali_dlbu_core *dlbu, struct mali_group *group);
+void mali_dlbu_remove_group(struct mali_dlbu_core *dlbu, struct mali_group *group);
+
+/** @brief Called to update HW after DLBU state changed
+ *
+ * This function must be called after \a mali_dlbu_add_group or \a
+ * mali_dlbu_remove_group to write the updated mask to hardware, unless the
+ * same is accomplished by calling \a mali_dlbu_reset.
+ */
+void mali_dlbu_update_mask(struct mali_dlbu_core *dlbu);
 
-void mali_dlbu_pp_jobs_stop(struct mali_dlbu_core *dlbu);
-void mali_dlbu_pp_jobs_restart(struct mali_dlbu_core *dlbu);
+void mali_dlbu_config_job(struct mali_dlbu_core *dlbu, struct mali_pp_job *job);
 
 #endif /* __MALI_DLBU_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_gp.c b/drivers/gpu/mali/mali/common/mali_gp.c
old mode 100644
new mode 100755
index 15008c8..1e633f2
--- a/drivers/gpu/mali/mali/common/mali_gp.c
+++ b/drivers/gpu/mali/mali/common/mali_gp.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -15,104 +15,59 @@
 #include "regs/mali_gp_regs.h"
 #include "mali_kernel_common.h"
 #include "mali_kernel_core.h"
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 #include "mali_osk_profiling.h"
 #endif
 
-/**
- * Definition of the GP core struct
- * Used to track a GP core in the system.
- */
-struct mali_gp_core
-{
-	struct mali_hw_core  hw_core;           /**< Common for all HW cores */
-	struct mali_group   *group;             /**< Parent group for this core */
-	_mali_osk_irq_t     *irq;               /**< IRQ handler */
-	struct mali_gp_job  *running_job;       /**< Current running job */
-	_mali_osk_timer_t   *timeout_timer;     /**< timeout timer for this core */
-	u32                  timeout_job_id;    /**< job id for the timed out job - relevant only if gp_core_timed_out == MALI_TRUE */
-	mali_bool            core_timed_out;    /**< if MALI_TRUE, this gp core has timed out; if MALI_FALSE, no timeout on this gp core */
-	u32                  counter_src0;      /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
-	u32                  counter_src1;      /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
-	u32                  counter_src0_used; /**< The selected performance counter 0 when a job is running */
-	u32                  counter_src1_used; /**< The selected performance counter 1 when a job is running */
-};
-
 static struct mali_gp_core *mali_global_gp_core = NULL;
 
 /* Interrupt handlers */
-static _mali_osk_errcode_t mali_gp_upper_half(void *data);
-static void mali_gp_bottom_half(void *data);
 static void mali_gp_irq_probe_trigger(void *data);
 static _mali_osk_errcode_t mali_gp_irq_probe_ack(void *data);
-static void mali_gp_post_process_job(struct mali_gp_core *core, mali_bool suspend);
-static void mali_gp_timeout(void *data);
 
-struct mali_gp_core *mali_gp_create(const _mali_osk_resource_t * resource, struct mali_group *group)
+struct mali_gp_core *mali_gp_create(const _mali_osk_resource_t *resource, struct mali_group *group)
 {
-	struct mali_gp_core* core = NULL;
+	struct mali_gp_core *core = NULL;
 
 	MALI_DEBUG_ASSERT(NULL == mali_global_gp_core);
 	MALI_DEBUG_PRINT(2, ("Mali GP: Creating Mali GP core: %s\n", resource->description));
 
 	core = _mali_osk_malloc(sizeof(struct mali_gp_core));
-	if (NULL != core)
-	{
-		core->group = group;
-		core->running_job = NULL;
-		core->counter_src0 = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src1 = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src0_used = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src1_used = MALI_HW_CORE_NO_COUNTER;
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALIGP2_REGISTER_ADDRESS_SPACE_SIZE))
-		{
+	if (NULL != core) {
+		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALIGP2_REGISTER_ADDRESS_SPACE_SIZE)) {
 			_mali_osk_errcode_t ret;
 
-			mali_group_lock(group);
 			ret = mali_gp_reset(core);
-			mali_group_unlock(group);
-
-			if (_MALI_OSK_ERR_OK == ret)
-			{
-				/* Setup IRQ handlers (which will do IRQ probing if needed) */
-				core->irq = _mali_osk_irq_init(resource->irq,
-				                               mali_gp_upper_half,
-				                               mali_gp_bottom_half,
-				                               mali_gp_irq_probe_trigger,
-				                               mali_gp_irq_probe_ack,
-				                               core,
-				                               "mali_gp_irq_handlers");
-				if (NULL != core->irq)
-				{
-					/* Initialise the timeout timer */
-					core->timeout_timer = _mali_osk_timer_init();
-					if(NULL != core->timeout_timer)
-					{
-						_mali_osk_timer_setcallback(core->timeout_timer, mali_gp_timeout, (void *)core);
+
+			if (_MALI_OSK_ERR_OK == ret) {
+				ret = mali_group_add_gp_core(group, core);
+				if (_MALI_OSK_ERR_OK == ret) {
+					/* Setup IRQ handlers (which will do IRQ probing if needed) */
+					core->irq = _mali_osk_irq_init(resource->irq,
+								       mali_group_upper_half_gp,
+								       group,
+								       mali_gp_irq_probe_trigger,
+								       mali_gp_irq_probe_ack,
+								       core,
+								       resource->description);
+					if (NULL != core->irq) {
 						MALI_DEBUG_PRINT(4, ("Mali GP: set global gp core from 0x%08X to 0x%08X\n", mali_global_gp_core, core));
 						mali_global_gp_core = core;
 
 						return core;
+					} else {
+						MALI_PRINT_ERROR(("Mali GP: Failed to setup interrupt handlers for GP core %s\n", core->hw_core.description));
 					}
-					else
-					{
-						MALI_PRINT_ERROR(("Failed to setup timeout timer for GP core %s\n", core->hw_core.description));
-						/* Release IRQ handlers */
-						_mali_osk_irq_term(core->irq);
-					}
-				}
-				else
-				{
-					MALI_PRINT_ERROR(("Failed to setup interrupt handlers for GP core %s\n", core->hw_core.description));
+					mali_group_remove_gp_core(group);
+				} else {
+					MALI_PRINT_ERROR(("Mali GP: Failed to add core %s to group\n", core->hw_core.description));
 				}
 			}
 			mali_hw_core_delete(&core->hw_core);
 		}
 
 		_mali_osk_free(core);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Failed to allocate memory for GP core\n"));
 	}
 
@@ -123,7 +78,6 @@ void mali_gp_delete(struct mali_gp_core *core)
 {
 	MALI_DEBUG_ASSERT_POINTER(core);
 
-	_mali_osk_timer_term(core->timeout_timer);
 	_mali_osk_irq_term(core->irq);
 	mali_hw_core_delete(&core->hw_core);
 	mali_global_gp_core = NULL;
@@ -140,7 +94,6 @@ void mali_gp_stop_bus(struct mali_gp_core *core)
 _mali_osk_errcode_t mali_gp_stop_bus_wait(struct mali_gp_core *core)
 {
 	int i;
-	const int request_loop_count = 20;
 
 	MALI_DEBUG_ASSERT_POINTER(core);
 
@@ -148,17 +101,13 @@ _mali_osk_errcode_t mali_gp_stop_bus_wait(struct mali_gp_core *core)
 	mali_gp_stop_bus(core);
 
 	/* Wait for bus to be stopped */
-	for (i = 0; i < request_loop_count; i++)
-	{
-		if (mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS) & MALIGP2_REG_VAL_STATUS_BUS_STOPPED)
-		{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
+		if (mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS) & MALIGP2_REG_VAL_STATUS_BUS_STOPPED) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(10);
 	}
 
-	if (request_loop_count == i)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Mali GP: Failed to stop bus on %s\n", core->hw_core.description));
 		return _MALI_OSK_ERR_FAULT;
 	}
@@ -167,7 +116,6 @@ _mali_osk_errcode_t mali_gp_stop_bus_wait(struct mali_gp_core *core)
 
 void mali_gp_hard_reset(struct mali_gp_core *core)
 {
-	const int reset_finished_loop_count = 15;
 	const u32 reset_wait_target_register = MALIGP2_REG_ADDR_MGMT_WRITE_BOUND_LOW;
 	const u32 reset_invalid_value = 0xC0FFE000;
 	const u32 reset_check_value = 0xC01A0000;
@@ -176,25 +124,19 @@ void mali_gp_hard_reset(struct mali_gp_core *core)
 
 	MALI_DEBUG_ASSERT_POINTER(core);
 	MALI_DEBUG_PRINT(4, ("Mali GP: Hard reset of core %s\n", core->hw_core.description));
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	mali_gp_post_process_job(core, MALI_FALSE);
 
 	mali_hw_core_register_write(&core->hw_core, reset_wait_target_register, reset_invalid_value);
 
 	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALIGP2_REG_VAL_CMD_RESET);
 
-	for (i = 0; i < reset_finished_loop_count; i++)
-	{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
 		mali_hw_core_register_write(&core->hw_core, reset_wait_target_register, reset_check_value);
-		if (reset_check_value == mali_hw_core_register_read(&core->hw_core, reset_wait_target_register))
-		{
+		if (reset_check_value == mali_hw_core_register_read(&core->hw_core, reset_wait_target_register)) {
 			break;
 		}
 	}
 
-	if (i == reset_finished_loop_count)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Mali GP: The hard reset loop didn't work, unable to recover\n"));
 	}
 
@@ -205,67 +147,37 @@ void mali_gp_hard_reset(struct mali_gp_core *core)
 
 }
 
-_mali_osk_errcode_t mali_gp_reset(struct mali_gp_core *core)
+void mali_gp_reset_async(struct mali_gp_core *core)
 {
-	int i;
-	const int request_loop_count = 20;
-
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_DEBUG_PRINT(4, ("Mali GP: Reset of core %s\n", core->hw_core.description));
-	MALI_ASSERT_GROUP_LOCKED(core->group);
 
-	mali_gp_post_process_job(core, MALI_FALSE);
+	MALI_DEBUG_PRINT(4, ("Mali GP: Reset of core %s\n", core->hw_core.description));
 
 	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, 0); /* disable the IRQs */
+	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, MALI400GP_REG_VAL_IRQ_RESET_COMPLETED);
+	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALI400GP_REG_VAL_CMD_SOFT_RESET);
 
-#if defined(USING_MALI200)
-
-	/* On Mali-200, stop the  bus, then do a hard reset of the core */
-
-	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALIGP2_REG_VAL_CMD_STOP_BUS);
-
-	for (i = 0; i < request_loop_count; i++)
-	{
-		if (mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS) & MALIGP2_REG_VAL_STATUS_BUS_STOPPED)
-		{
-			break;
-		}
-		_mali_osk_time_ubusydelay(10);
-	}
-
-	if (request_loop_count == i)
-	{
-		MALI_PRINT_ERROR(("Mali GP: Failed to stop bus for core %s, unable to recover\n", core->hw_core.description));
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	/* the bus was stopped OK, do the hard reset */
-	mali_gp_hard_reset(core);
-
-#elif defined(USING_MALI400)
+}
 
-	/* Mali-300 and Mali-400 have a safe reset command which we use */
+_mali_osk_errcode_t mali_gp_reset_wait(struct mali_gp_core *core)
+{
+	int i;
+	u32 rawstat = 0;
 
-	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, MALI400GP_REG_VAL_IRQ_RESET_COMPLETED);
-	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALI400GP_REG_VAL_CMD_SOFT_RESET);
+	MALI_DEBUG_ASSERT_POINTER(core);
 
-	for (i = 0; i < request_loop_count; i++)
-	{
-		if (mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT) & MALI400GP_REG_VAL_IRQ_RESET_COMPLETED)
-		{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
+		rawstat = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT);
+		if (rawstat & MALI400GP_REG_VAL_IRQ_RESET_COMPLETED) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(10);
 	}
 
-	if (request_loop_count == i)
-	{
-		MALI_PRINT_ERROR(("Mali GP: Failed to reset core %s, unable to recover\n", core->hw_core.description));
+	if (i == MALI_REG_POLL_COUNT_FAST) {
+		MALI_PRINT_ERROR(("Mali GP: Failed to reset core %s, rawstat: 0x%08x\n",
+				  core->hw_core.description, rawstat));
 		return _MALI_OSK_ERR_FAULT;
 	}
-#else
-#error "no supported mali core defined"
-#endif
 
 	/* Re-enable interrupts */
 	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, MALIGP2_REG_VAL_IRQ_MASK_ALL);
@@ -274,23 +186,26 @@ _mali_osk_errcode_t mali_gp_reset(struct mali_gp_core *core)
 	return _MALI_OSK_ERR_OK;
 }
 
+_mali_osk_errcode_t mali_gp_reset(struct mali_gp_core *core)
+{
+	mali_gp_reset_async(core);
+	return mali_gp_reset_wait(core);
+}
+
 void mali_gp_job_start(struct mali_gp_core *core, struct mali_gp_job *job)
 {
 	u32 startcmd = 0;
 	u32 *frame_registers = mali_gp_job_get_frame_registers(job);
-	core->counter_src0_used = core->counter_src0;
-	core->counter_src1_used = core->counter_src1;
+	u32 counter_src0 = mali_gp_job_get_perf_counter_src0(job);
+	u32 counter_src1 = mali_gp_job_get_perf_counter_src1(job);
 
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_ASSERT_GROUP_LOCKED(core->group);
 
-	if (mali_gp_job_has_vs_job(job))
-	{
+	if (mali_gp_job_has_vs_job(job)) {
 		startcmd |= (u32) MALIGP2_REG_VAL_CMD_START_VS;
 	}
 
-	if (mali_gp_job_has_plbu_job(job))
-	{
+	if (mali_gp_job_has_plbu_job(job)) {
 		startcmd |= (u32) MALIGP2_REG_VAL_CMD_START_PLBU;
 	}
 
@@ -298,66 +213,45 @@ void mali_gp_job_start(struct mali_gp_core *core, struct mali_gp_job *job)
 
 	mali_hw_core_register_write_array_relaxed(&core->hw_core, MALIGP2_REG_ADDR_MGMT_VSCL_START_ADDR, frame_registers, MALIGP2_NUM_REGS_FRAME);
 
-	/* This selects which performance counters we are reading */
-	if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used || MALI_HW_CORE_NO_COUNTER != core->counter_src0_used)
-	{
-		/* global_config has enabled HW counters, this will override anything specified by user space */
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used)
-		{
-			mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_SRC, core->counter_src0_used);
-			mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
-		}
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src1_used)
-		{
-			mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_SRC, core->counter_src1_used);
-			mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
-		}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src0) {
+		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_SRC, counter_src0);
+		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
 	}
-	else
-	{
-		/* Use HW counters from job object, if any */
-		u32 perf_counter_flag = mali_gp_job_get_perf_counter_flag(job);
-		if (0 != perf_counter_flag)
-		{
-			if (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE)
-			{
-				core->counter_src0_used = mali_gp_job_get_perf_counter_src0(job);
-				mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_SRC, core->counter_src0_used);
-				mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
-			}
-
-			if (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE)
-			{
-				core->counter_src1_used = mali_gp_job_get_perf_counter_src1(job);
-				mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_SRC, core->counter_src1_used);
-				mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
-			}
-		}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src1) {
+		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_SRC, counter_src1);
+		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALIGP2_REG_VAL_PERF_CNT_ENABLE);
 	}
 
 	MALI_DEBUG_PRINT(3, ("Mali GP: Starting job (0x%08x) on core %s with command 0x%08X\n", job, core->hw_core.description, startcmd));
 
-	/* Barrier to make sure the previous register write is finished */
-	_mali_osk_write_mem_barrier();
-
-	/* This is the command that starts the core. */
-	mali_hw_core_register_write_relaxed(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, startcmd);
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALIGP2_REG_VAL_CMD_UPDATE_PLBU_ALLOC);
 
 	/* Barrier to make sure the previous register write is finished */
 	_mali_osk_write_mem_barrier();
 
-	/* Setup the timeout timer value and save the job id for the job running on the gp core */
+	/* This is the command that starts the core.
+	 *
+	 * Don't actually run the job if PROFILING_SKIP_PP_JOBS are set, just
+	 * force core to assert the completion interrupt.
+	 */
+#if !defined(PROFILING_SKIP_GP_JOBS)
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, startcmd);
+#else
+	{
+		u32 bits = 0;
 
-	_mali_osk_timer_add(core->timeout_timer, _mali_osk_time_mstoticks(mali_max_job_runtime));
-	core->timeout_job_id = mali_gp_job_get_id(job);
+		if (mali_gp_job_has_vs_job(job))
+			bits = MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST;
+		if (mali_gp_job_has_plbu_job(job))
+			bits |= MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST;
 
-#if MALI_TIMELINE_PROFILING_ENABLED
-	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE | MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0) | MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH,
-	                          job->frame_builder_id, job->flush_id, 0, 0, 0);
-	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START|MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0), job->pid, job->tid, 0, 0, 0);
+		mali_hw_core_register_write_relaxed(&core->hw_core,
+						    MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT, bits);
+	}
 #endif
 
-	core->running_job = job;
+	/* Barrier to make sure the previous register write is finished */
+	_mali_osk_write_mem_barrier();
 }
 
 void mali_gp_resume_with_new_heap(struct mali_gp_core *core, u32 start_addr, u32 end_addr)
@@ -365,12 +259,10 @@ void mali_gp_resume_with_new_heap(struct mali_gp_core *core, u32 start_addr, u32
 	u32 irq_readout;
 
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_ASSERT_GROUP_LOCKED(core->group);
 
 	irq_readout = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT);
 
-	if (irq_readout & MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM)
-	{
+	if (irq_readout & MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM) {
 		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, (MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM | MALIGP2_REG_VAL_IRQ_HANG));
 		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_USED); /* re-enable interrupts */
 		mali_hw_core_register_write_relaxed(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PLBU_ALLOC_START_ADDR, start_addr);
@@ -380,10 +272,6 @@ void mali_gp_resume_with_new_heap(struct mali_gp_core *core, u32 start_addr, u32
 
 		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_CMD, MALIGP2_REG_VAL_CMD_UPDATE_PLBU_ALLOC);
 		_mali_osk_write_mem_barrier();
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_RESUME|MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0), 0, 0, 0, 0, 0);
-#endif
 	}
 	/*
 	 * else: core has been reset between PLBU_OUT_OF_MEM interrupt and this new heap response.
@@ -391,180 +279,23 @@ void mali_gp_resume_with_new_heap(struct mali_gp_core *core, u32 start_addr, u32
 	 */
 }
 
-void mali_gp_abort_job(struct mali_gp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	if (_MALI_OSK_ERR_FAULT != mali_gp_reset(core))
-	{
-		_mali_osk_timer_del(core->timeout_timer);
-	}
-}
-
 u32 mali_gp_core_get_version(struct mali_gp_core *core)
 {
 	MALI_DEBUG_ASSERT_POINTER(core);
 	return mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_VERSION);
 }
 
-mali_bool mali_gp_core_set_counter_src0(struct mali_gp_core *core, u32 counter)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-
-	core->counter_src0 = counter;
-	return MALI_TRUE;
-}
-
-mali_bool mali_gp_core_set_counter_src1(struct mali_gp_core *core, u32 counter)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-
-	core->counter_src1 = counter;
-	return MALI_TRUE;
-}
-
-u32 mali_gp_core_get_counter_src0(struct mali_gp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	return core->counter_src0;
-}
-
-u32 mali_gp_core_get_counter_src1(struct mali_gp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	return core->counter_src1;
-}
-
 struct mali_gp_core *mali_gp_get_global_gp_core(void)
 {
 	return mali_global_gp_core;
 }
 
 /* ------------- interrupt handling below ------------------ */
-static _mali_osk_errcode_t mali_gp_upper_half(void *data)
-{
-	struct mali_gp_core *core = (struct mali_gp_core *)data;
-	u32 irq_readout;
-
-	irq_readout = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_STAT);
-	if (MALIGP2_REG_VAL_IRQ_MASK_NONE != irq_readout)
-	{
-		/* Mask out all IRQs from this core until IRQ is handled */
-		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_NONE);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE|MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0)|MALI_PROFILING_EVENT_REASON_SINGLE_HW_INTERRUPT, irq_readout, 0, 0, 0, 0);
-#endif
-
-		/* We do need to handle this in a bottom half */
-		_mali_osk_irq_schedulework(core->irq);
-		return _MALI_OSK_ERR_OK;
-	}
-
-	return _MALI_OSK_ERR_FAULT;
-}
-
-static void mali_gp_bottom_half(void *data)
-{
-	struct mali_gp_core *core = (struct mali_gp_core *)data;
-	u32 irq_readout;
-	u32 irq_errors;
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-#if 0  /* Bottom half TLP logging is currently not supported */
-	_mali_osk_profiling_add_event( MALI_PROFILING_EVENT_TYPE_START| MALI_PROFILING_EVENT_CHANNEL_SOFTWARE ,  _mali_osk_get_pid(), _mali_osk_get_tid()+11000, 0, 0, 0);
-#endif
-#endif
-
-	mali_group_lock(core->group); /* Group lock grabbed in core handlers, but released in common group handler */
-
-	if ( MALI_FALSE == mali_group_power_is_on(core->group) )
-	{
-		MALI_PRINT_ERROR(("Interrupt bottom half of %s when core is OFF.", core->hw_core.description));
-		mali_group_unlock(core->group);
-		return;
-	}
-
-	irq_readout = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT) & MALIGP2_REG_VAL_IRQ_MASK_USED;
-	MALI_DEBUG_PRINT(4, ("Mali GP: Bottom half IRQ 0x%08X from core %s\n", irq_readout, core->hw_core.description));
-
-	if (irq_readout & (MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST|MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST))
-	{
-		u32 core_status = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS);
-		if (0 == (core_status & MALIGP2_REG_VAL_STATUS_MASK_ACTIVE))
-		{
-			mali_gp_post_process_job(core, MALI_FALSE);
-			MALI_DEBUG_PRINT(4, ("Mali GP: Job completed, calling group handler\n"));
-			mali_group_bottom_half(core->group, GROUP_EVENT_GP_JOB_COMPLETED); /* Will release group lock */
-			return;
-		}
-	}
-
-	/*
-	 * Now lets look at the possible error cases (IRQ indicating error or timeout)
-	 * END_CMD_LST, HANG and PLBU_OOM interrupts are not considered error.
-	 */
-	irq_errors = irq_readout & ~(MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST|MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST|MALIGP2_REG_VAL_IRQ_HANG|MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM);
-	if (0 != irq_errors)
-	{
-		mali_gp_post_process_job(core, MALI_FALSE);
-		MALI_PRINT_ERROR(("Mali GP: Unknown interrupt 0x%08X from core %s, aborting job\n", irq_readout, core->hw_core.description));
-		mali_group_bottom_half(core->group, GROUP_EVENT_GP_JOB_FAILED); /* Will release group lock */
-		return;
-	}
-	else if (MALI_TRUE == core->core_timed_out) /* SW timeout */
-	{
-		if (core->timeout_job_id == mali_gp_job_get_id(core->running_job))
-		{
-			mali_gp_post_process_job(core, MALI_FALSE);
-			MALI_DEBUG_PRINT(2, ("Mali GP: Job %d timed out\n", mali_gp_job_get_id(core->running_job)));
-			mali_group_bottom_half(core->group, GROUP_EVENT_GP_JOB_TIMED_OUT);
-		}
-		core->core_timed_out = MALI_FALSE;
-		return;
-	}
-	else if (irq_readout & MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM)
-	{
-		/* GP wants more memory in order to continue.
-		 *
-		 * This must be handled prior to HANG because this actually can
-		 * generate a HANG while waiting for more memory.
-		 * And it must be handled before the completion interrupts,
-		 * since the PLBU can run out of memory after VS is complete;
-		 * in which case the OOM must be handled before to complete the
-		 * PLBU work.
-		 */
-		mali_gp_post_process_job(core, MALI_TRUE);
-		MALI_DEBUG_PRINT(3, ("Mali GP: PLBU needs more heap memory\n"));
-		mali_group_bottom_half(core->group, GROUP_EVENT_GP_OOM); /* Will release group lock */
-		return;
-	}
-	else if (irq_readout & MALIGP2_REG_VAL_IRQ_HANG)
-	{
-		/* Just ignore hang interrupts, the job timer will detect hanging jobs anyways */
-		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, MALIGP2_REG_VAL_IRQ_HANG);
-	}
-
-	/*
-	 * The only way to get here is if we got a HANG interrupt, which we ignore, or only one of two needed END_CMD_LST interrupts.
-	 * Re-enable interrupts and let core continue to run.
-	 */
-	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_USED);
-	mali_group_unlock(core->group);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-#if 0  /* Bottom half TLP logging is currently not supported */
-	_mali_osk_profiling_add_event( MALI_PROFILING_EVENT_TYPE_STOP| MALI_PROFILING_EVENT_CHANNEL_SOFTWARE ,  _mali_osk_get_pid(), _mali_osk_get_tid()+11000, 0, 0, 0);
-#endif
-#endif
-}
-
 static void mali_gp_irq_probe_trigger(void *data)
 {
 	struct mali_gp_core *core = (struct mali_gp_core *)data;
 
-	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_USED);     /* @@@@ This should not be needed */
+	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_USED);
 	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT, MALIGP2_REG_VAL_CMD_FORCE_HANG);
 	_mali_osk_mem_barrier();
 }
@@ -575,8 +306,7 @@ static _mali_osk_errcode_t mali_gp_irq_probe_ack(void *data)
 	u32 irq_readout;
 
 	irq_readout = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_STAT);
-	if (MALIGP2_REG_VAL_IRQ_FORCE_HANG & irq_readout)
-	{
+	if (MALIGP2_REG_VAL_IRQ_FORCE_HANG & irq_readout) {
 		mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_CLEAR, MALIGP2_REG_VAL_IRQ_FORCE_HANG);
 		_mali_osk_mem_barrier();
 		return _MALI_OSK_ERR_OK;
@@ -586,108 +316,40 @@ static _mali_osk_errcode_t mali_gp_irq_probe_ack(void *data)
 }
 
 /* ------ local helper functions below --------- */
-
-static void mali_gp_post_process_job(struct mali_gp_core *core, mali_bool suspend)
+#if MALI_STATE_TRACKING
+u32 mali_gp_dump_state(struct mali_gp_core *core, char *buf, u32 size)
 {
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	if (NULL != core->running_job)
-	{
-		u32 val0 = 0;
-		u32 val1 = 0;
-#if MALI_TIMELINE_PROFILING_ENABLED
-		u32 event_id;
-#endif
+	int n = 0;
 
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used)
-		{
-			val0 = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_VALUE);
-			if (mali_gp_job_get_perf_counter_flag(core->running_job) &&
-			    _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE && mali_gp_job_get_perf_counter_src0(core->running_job) == core->counter_src0_used)
-			{
-				/* We retrieved the counter that user space asked for, so return the value through the job object */
-				mali_gp_job_set_perf_counter_value0(core->running_job, val0);
-			}
-			else
-			{
-				/* User space asked for a counter, but this is not what we retrived (overridden by counter src set on core) */
-				mali_gp_job_set_perf_counter_value0(core->running_job, MALI_HW_CORE_INVALID_VALUE);
-			}
+	n += _mali_osk_snprintf(buf + n, size - n, "\tGP: %s\n", core->hw_core.description);
 
-#if MALI_TIMELINE_PROFILING_ENABLED
-			_mali_osk_profiling_report_hw_counter(COUNTER_VP_C0, val0);
+	return n;
+}
 #endif
 
-		}
+void mali_gp_update_performance_counters(struct mali_gp_core *core, struct mali_gp_job *job, mali_bool suspend)
+{
+	u32 val0 = 0;
+	u32 val1 = 0;
+	u32 counter_src0 = mali_gp_job_get_perf_counter_src0(job);
+	u32 counter_src1 = mali_gp_job_get_perf_counter_src1(job);
 
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src1_used)
-		{
-			val1 = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_VALUE);
-			if (mali_gp_job_get_perf_counter_flag(core->running_job) &&
-			    _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE && mali_gp_job_get_perf_counter_src1(core->running_job) == core->counter_src1_used)
-			{
-				/* We retrieved the counter that user space asked for, so return the value through the job object */
-				mali_gp_job_set_perf_counter_value1(core->running_job, val1);
-			}
-			else
-			{
-				/* User space asked for a counter, but this is not what we retrieved (overridden by counter src set on core) */
-				mali_gp_job_set_perf_counter_value1(core->running_job, MALI_HW_CORE_INVALID_VALUE);
-			}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src0) {
+		val0 = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_0_VALUE);
+		mali_gp_job_set_perf_counter_value0(job, val0);
 
-#if MALI_TIMELINE_PROFILING_ENABLED
-			_mali_osk_profiling_report_hw_counter(COUNTER_VP_C1, val1);
+#if defined(CONFIG_MALI400_PROFILING)
+		_mali_osk_profiling_report_hw_counter(COUNTER_VP_0_C0, val0);
 #endif
-		}
 
-#if MALI_TIMELINE_PROFILING_ENABLED
-		if (MALI_TRUE == suspend)
-		{
-			event_id = MALI_PROFILING_EVENT_TYPE_SUSPEND|MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0);
-		}
-		else
-		{
-			event_id = MALI_PROFILING_EVENT_TYPE_STOP|MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0);
-		}
-		_mali_osk_profiling_add_event(event_id, val0, val1, core->counter_src0_used | (core->counter_src1_used << 8), 0, 0);
-#endif
-
-		mali_gp_job_set_current_heap_addr(core->running_job,
-		                                  mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PLBU_ALLOC_START_ADDR));
-
-		if (MALI_TRUE != suspend)
-		{
-			/* We are no longer running a job... */
-			core->running_job = NULL;
-			_mali_osk_timer_del(core->timeout_timer);
-		}
 	}
-}
-
-/* callback function for gp core timeout */
-static void mali_gp_timeout(void *data)
-{
-	struct mali_gp_core * core = ((struct mali_gp_core *)data);
 
-	MALI_DEBUG_PRINT(3, ("Mali GP: TIMEOUT callback \n"));
-	core->core_timed_out = MALI_TRUE;
-	_mali_osk_irq_schedulework(core->irq);
-}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src1) {
+		val1 = mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PERF_CNT_1_VALUE);
+		mali_gp_job_set_perf_counter_value1(job, val1);
 
-#if 0
-void mali_gp_print_state(struct mali_gp_core *core)
-{
-	MALI_DEBUG_PRINT(2, ("Mali GP: State: 0x%08x\n", mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS) ));
-}
+#if defined(CONFIG_MALI400_PROFILING)
+		_mali_osk_profiling_report_hw_counter(COUNTER_VP_0_C1, val1);
 #endif
-
-#if MALI_STATE_TRACKING
-u32 mali_gp_dump_state(struct mali_gp_core *core, char *buf, u32 size)
-{
-	int n = 0;
-
-	n += _mali_osk_snprintf(buf + n, size - n, "\tGP: %s\n", core->hw_core.description);
-
-	return n;
+	}
 }
-#endif
diff --git a/drivers/gpu/mali/mali/common/mali_gp.h b/drivers/gpu/mali/mali/common/mali_gp.h
old mode 100644
new mode 100755
index da5293b..ee5a44d
--- a/drivers/gpu/mali/mali/common/mali_gp.h
+++ b/drivers/gpu/mali/mali/common/mali_gp.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,34 +13,81 @@
 
 #include "mali_osk.h"
 #include "mali_gp_job.h"
+#include "mali_hw_core.h"
+#include "regs/mali_gp_regs.h"
 
-struct mali_gp_core;
 struct mali_group;
 
+/**
+ * Definition of the GP core struct
+ * Used to track a GP core in the system.
+ */
+struct mali_gp_core {
+	struct mali_hw_core  hw_core;           /**< Common for all HW cores */
+	_mali_osk_irq_t     *irq;               /**< IRQ handler */
+};
+
 _mali_osk_errcode_t mali_gp_initialize(void);
 void mali_gp_terminate(void);
 
-struct mali_gp_core *mali_gp_create(const _mali_osk_resource_t * resource, struct mali_group *group);
+struct mali_gp_core *mali_gp_create(const _mali_osk_resource_t *resource, struct mali_group *group);
 void mali_gp_delete(struct mali_gp_core *core);
 
 void mali_gp_stop_bus(struct mali_gp_core *core);
 _mali_osk_errcode_t mali_gp_stop_bus_wait(struct mali_gp_core *core);
+void mali_gp_reset_async(struct mali_gp_core *core);
+_mali_osk_errcode_t mali_gp_reset_wait(struct mali_gp_core *core);
 void mali_gp_hard_reset(struct mali_gp_core *core);
 _mali_osk_errcode_t mali_gp_reset(struct mali_gp_core *core);
 
 void mali_gp_job_start(struct mali_gp_core *core, struct mali_gp_job *job);
 void mali_gp_resume_with_new_heap(struct mali_gp_core *core, u32 start_addr, u32 end_addr);
 
-void mali_gp_abort_job(struct mali_gp_core *core);
-
 u32 mali_gp_core_get_version(struct mali_gp_core *core);
 
-mali_bool mali_gp_core_set_counter_src0(struct mali_gp_core *core, u32 counter);
-mali_bool mali_gp_core_set_counter_src1(struct mali_gp_core *core, u32 counter);
-u32 mali_gp_core_get_counter_src0(struct mali_gp_core *core);
-u32 mali_gp_core_get_counter_src1(struct mali_gp_core *core);
 struct mali_gp_core *mali_gp_get_global_gp_core(void);
 
 u32 mali_gp_dump_state(struct mali_gp_core *core, char *buf, u32 size);
 
+void mali_gp_update_performance_counters(struct mali_gp_core *core, struct mali_gp_job *job, mali_bool suspend);
+
+/*** Accessor functions ***/
+MALI_STATIC_INLINE const char *mali_gp_get_hw_core_desc(struct mali_gp_core *core)
+{
+	return core->hw_core.description;
+}
+
+/*** Register reading/writing functions ***/
+MALI_STATIC_INLINE u32 mali_gp_get_int_stat(struct mali_gp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_STAT);
+}
+
+MALI_STATIC_INLINE void mali_gp_mask_all_interrupts(struct mali_gp_core *core)
+{
+	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK, MALIGP2_REG_VAL_IRQ_MASK_NONE);
+}
+
+MALI_STATIC_INLINE u32 mali_gp_read_rawstat(struct mali_gp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_RAWSTAT) & MALIGP2_REG_VAL_IRQ_MASK_USED;
+}
+
+MALI_STATIC_INLINE u32 mali_gp_read_core_status(struct mali_gp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_STATUS);
+}
+
+MALI_STATIC_INLINE void mali_gp_enable_interrupts(struct mali_gp_core *core, u32 irq_exceptions)
+{
+	/* Enable all interrupts, except those specified in irq_exceptions */
+	mali_hw_core_register_write(&core->hw_core, MALIGP2_REG_ADDR_MGMT_INT_MASK,
+				    MALIGP2_REG_VAL_IRQ_MASK_USED & ~irq_exceptions);
+}
+
+MALI_STATIC_INLINE u32 mali_gp_read_plbu_alloc_start_addr(struct mali_gp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALIGP2_REG_ADDR_MGMT_PLBU_ALLOC_START_ADDR);
+}
+
 #endif /* __MALI_GP_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_gp_job.c b/drivers/gpu/mali/mali/common/mali_gp_job.c
old mode 100644
new mode 100755
index 2c35b82..1d3d942
--- a/drivers/gpu/mali/mali/common/mali_gp_job.c
+++ b/drivers/gpu/mali/mali/common/mali_gp_job.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,29 +13,64 @@
 #include "mali_osk_list.h"
 #include "mali_uk_types.h"
 
-struct mali_gp_job *mali_gp_job_create(struct mali_session_data *session, _mali_uk_gp_start_job_s *args, u32 id)
+static u32 gp_counter_src0 = MALI_HW_CORE_NO_COUNTER;      /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
+static u32 gp_counter_src1 = MALI_HW_CORE_NO_COUNTER;           /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
+
+struct mali_gp_job *mali_gp_job_create(struct mali_session_data *session, _mali_uk_gp_start_job_s *uargs, u32 id, struct mali_timeline_tracker *pp_tracker)
 {
 	struct mali_gp_job *job;
+	u32 perf_counter_flag;
 
 	job = _mali_osk_malloc(sizeof(struct mali_gp_job));
-	if (NULL != job)
-	{
+	if (NULL != job) {
+		job->finished_notification = _mali_osk_notification_create(_MALI_NOTIFICATION_GP_FINISHED, sizeof(_mali_uk_gp_job_finished_s));
+		if (NULL == job->finished_notification) {
+			_mali_osk_free(job);
+			return NULL;
+		}
+
+		job->oom_notification = _mali_osk_notification_create(_MALI_NOTIFICATION_GP_STALLED, sizeof(_mali_uk_gp_job_suspended_s));
+		if (NULL == job->oom_notification) {
+			_mali_osk_notification_delete(job->finished_notification);
+			_mali_osk_free(job);
+			return NULL;
+		}
+
+		if (0 != _mali_osk_copy_from_user(&job->uargs, uargs, sizeof(_mali_uk_gp_start_job_s))) {
+			_mali_osk_notification_delete(job->finished_notification);
+			_mali_osk_notification_delete(job->oom_notification);
+			_mali_osk_free(job);
+			return NULL;
+		}
+
+		perf_counter_flag = mali_gp_job_get_perf_counter_flag(job);
+
+		/* case when no counters came from user space
+		 * so pass the debugfs / DS-5 provided global ones to the job object */
+		if (!((perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE) ||
+		      (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE))) {
+			mali_gp_job_set_perf_counter_src0(job, mali_gp_job_get_gp_counter_src0());
+			mali_gp_job_set_perf_counter_src1(job, mali_gp_job_get_gp_counter_src1());
+		}
+
 		_mali_osk_list_init(&job->list);
 		job->session = session;
 		job->id = id;
-		job->user_id = args->user_job_ptr;
-		_mali_osk_memcpy(job->frame_registers, args->frame_registers, sizeof(job->frame_registers));
-		job->heap_current_addr = args->frame_registers[4];
-		job->perf_counter_flag = args->perf_counter_flag;
-		job->perf_counter_src0 = args->perf_counter_src0;
-		job->perf_counter_src1 = args->perf_counter_src1;
+		job->heap_current_addr = job->uargs.frame_registers[4];
 		job->perf_counter_value0 = 0;
 		job->perf_counter_value1 = 0;
-
 		job->pid = _mali_osk_get_pid();
 		job->tid = _mali_osk_get_tid();
-		job->frame_builder_id = args->frame_builder_id;
-		job->flush_id = args->flush_id;
+
+		job->pp_tracker = pp_tracker;
+		if (NULL != job->pp_tracker) {
+			/* Take a reference on PP job's tracker that will be released when the GP
+			   job is done. */
+			mali_timeline_system_tracker_get(session->timeline_system, pp_tracker);
+		}
+
+		mali_timeline_tracker_init(&job->tracker, MALI_TIMELINE_TRACKER_GP, NULL, job);
+		mali_timeline_fence_copy_uk_fence(&(job->tracker.fence), &(job->uargs.fence));
 
 		return job;
 	}
@@ -45,5 +80,52 @@ struct mali_gp_job *mali_gp_job_create(struct mali_session_data *session, _mali_
 
 void mali_gp_job_delete(struct mali_gp_job *job)
 {
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT(NULL == job->pp_tracker);
+
+	/* de-allocate the pre-allocated oom notifications */
+	if (NULL != job->oom_notification) {
+		_mali_osk_notification_delete(job->oom_notification);
+		job->oom_notification = NULL;
+	}
+	if (NULL != job->finished_notification) {
+		_mali_osk_notification_delete(job->finished_notification);
+		job->finished_notification = NULL;
+	}
+
 	_mali_osk_free(job);
 }
+
+u32 mali_gp_job_get_gp_counter_src0(void)
+{
+	return gp_counter_src0;
+}
+
+void mali_gp_job_set_gp_counter_src0(u32 counter)
+{
+	gp_counter_src0 = counter;
+}
+
+u32 mali_gp_job_get_gp_counter_src1(void)
+{
+	return gp_counter_src1;
+}
+
+void mali_gp_job_set_gp_counter_src1(u32 counter)
+{
+	gp_counter_src1 = counter;
+}
+
+mali_scheduler_mask mali_gp_job_signal_pp_tracker(struct mali_gp_job *job, mali_bool success)
+{
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	if (NULL != job->pp_tracker) {
+		schedule_mask |= mali_timeline_system_tracker_put(job->session->timeline_system, job->pp_tracker, MALI_FALSE == success);
+		job->pp_tracker = NULL;
+	}
+
+	return schedule_mask;
+}
diff --git a/drivers/gpu/mali/mali/common/mali_gp_job.h b/drivers/gpu/mali/mali/common/mali_gp_job.h
old mode 100644
new mode 100755
index 4a51f8e..f404089
--- a/drivers/gpu/mali/mali/common/mali_gp_job.h
+++ b/drivers/gpu/mali/mali/common/mali_gp_job.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -15,57 +15,77 @@
 #include "mali_osk_list.h"
 #include "mali_uk_types.h"
 #include "mali_session.h"
+#include "mali_timeline.h"
+#include "mali_scheduler_types.h"
 
 /**
- * The structure represends a GP job, including all sub-jobs
- * (This struct unfortunatly needs to be public because of how the _mali_osk_list_*
+ * The structure represents a GP job, including all sub-jobs
+ * (This struct unfortunately needs to be public because of how the _mali_osk_list_*
  * mechanism works)
  */
-struct mali_gp_job
-{
+struct mali_gp_job {
 	_mali_osk_list_t list;                             /**< Used to link jobs together in the scheduler queue */
 	struct mali_session_data *session;                 /**< Session which submitted this job */
-	u32 id;                                            /**< identifier for this job in kernel space (sequential numbering) */
-	u32 user_id;                                       /**< identifier for the job in user space */
-	u32 frame_registers[MALIGP2_NUM_REGS_FRAME];       /**< core specific registers associated with this job, see ARM DDI0415A */
+	_mali_uk_gp_start_job_s uargs;                     /**< Arguments from user space */
+	u32 id;                                            /**< Identifier for this job in kernel space (sequential numbering) */
+	u32 cache_order;                                   /**< Cache order used for L2 cache flushing (sequential numbering) */
 	u32 heap_current_addr;                             /**< Holds the current HEAP address when the job has completed */
-	u32 perf_counter_flag;                             /**< bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
-	u32 perf_counter_src0;                             /**< source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
-	u32 perf_counter_src1;                             /**< source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
 	u32 perf_counter_value0;                           /**< Value of performance counter 0 (to be returned to user space) */
 	u32 perf_counter_value1;                           /**< Value of performance counter 1 (to be returned to user space) */
 	u32 pid;                                           /**< Process ID of submitting process */
 	u32 tid;                                           /**< Thread ID of submitting thread */
-	u32 frame_builder_id;                              /**< id of the originating frame builder */
-	u32 flush_id;                                      /**< flush id within the originating frame builder */
+	_mali_osk_notification_t *finished_notification;   /**< Notification sent back to userspace on job complete */
+	_mali_osk_notification_t *oom_notification;        /**< Notification sent back to userspace on OOM */
+	struct mali_timeline_tracker tracker;              /**< Timeline tracker for this job */
+	struct mali_timeline_tracker *pp_tracker;          /**< Pointer to Timeline tracker for PP job that depends on this job. */
 };
 
-struct mali_gp_job *mali_gp_job_create(struct mali_session_data *session, _mali_uk_gp_start_job_s *args, u32 id);
+struct mali_gp_job *mali_gp_job_create(struct mali_session_data *session, _mali_uk_gp_start_job_s *uargs, u32 id, struct mali_timeline_tracker *pp_tracker);
 void mali_gp_job_delete(struct mali_gp_job *job);
 
+u32 mali_gp_job_get_gp_counter_src0(void);
+void mali_gp_job_set_gp_counter_src0(u32 counter);
+u32 mali_gp_job_get_gp_counter_src1(void);
+void mali_gp_job_set_gp_counter_src1(u32 counter);
+
 MALI_STATIC_INLINE u32 mali_gp_job_get_id(struct mali_gp_job *job)
 {
 	return (NULL == job) ? 0 : job->id;
 }
 
+MALI_STATIC_INLINE u32 mali_gp_job_get_cache_order(struct mali_gp_job *job)
+{
+	return (NULL == job) ? 0 : job->cache_order;
+}
+
 MALI_STATIC_INLINE u32 mali_gp_job_get_user_id(struct mali_gp_job *job)
 {
-	return job->user_id;
+	return job->uargs.user_job_ptr;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_frame_builder_id(struct mali_gp_job *job)
 {
-	return job->frame_builder_id;
+	return job->uargs.frame_builder_id;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_flush_id(struct mali_gp_job *job)
 {
-	return job->flush_id;
+	return job->uargs.flush_id;
 }
 
-MALI_STATIC_INLINE u32* mali_gp_job_get_frame_registers(struct mali_gp_job *job)
+MALI_STATIC_INLINE u32 mali_gp_job_get_pid(struct mali_gp_job *job)
 {
-	return job->frame_registers;
+	return job->pid;
+}
+
+MALI_STATIC_INLINE u32 mali_gp_job_get_tid(struct mali_gp_job *job)
+{
+	return job->tid;
+}
+
+MALI_STATIC_INLINE u32 *mali_gp_job_get_frame_registers(struct mali_gp_job *job)
+{
+	return job->uargs.frame_registers;
 }
 
 MALI_STATIC_INLINE struct mali_session_data *mali_gp_job_get_session(struct mali_gp_job *job)
@@ -75,12 +95,12 @@ MALI_STATIC_INLINE struct mali_session_data *mali_gp_job_get_session(struct mali
 
 MALI_STATIC_INLINE mali_bool mali_gp_job_has_vs_job(struct mali_gp_job *job)
 {
-	return (job->frame_registers[0] != job->frame_registers[1]) ? MALI_TRUE : MALI_FALSE;
+	return (job->uargs.frame_registers[0] != job->uargs.frame_registers[1]) ? MALI_TRUE : MALI_FALSE;
 }
 
 MALI_STATIC_INLINE mali_bool mali_gp_job_has_plbu_job(struct mali_gp_job *job)
 {
-	return (job->frame_registers[2] != job->frame_registers[3]) ? MALI_TRUE : MALI_FALSE;
+	return (job->uargs.frame_registers[2] != job->uargs.frame_registers[3]) ? MALI_TRUE : MALI_FALSE;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_current_heap_addr(struct mali_gp_job *job)
@@ -95,17 +115,17 @@ MALI_STATIC_INLINE void mali_gp_job_set_current_heap_addr(struct mali_gp_job *jo
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_perf_counter_flag(struct mali_gp_job *job)
 {
-	return job->perf_counter_flag;
+	return job->uargs.perf_counter_flag;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_perf_counter_src0(struct mali_gp_job *job)
 {
-	return job->perf_counter_src0;
+	return job->uargs.perf_counter_src0;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_perf_counter_src1(struct mali_gp_job *job)
 {
-	return job->perf_counter_src1;
+	return job->uargs.perf_counter_src1;
 }
 
 MALI_STATIC_INLINE u32 mali_gp_job_get_perf_counter_value0(struct mali_gp_job *job)
@@ -118,6 +138,16 @@ MALI_STATIC_INLINE u32 mali_gp_job_get_perf_counter_value1(struct mali_gp_job *j
 	return job->perf_counter_value1;
 }
 
+MALI_STATIC_INLINE void mali_gp_job_set_perf_counter_src0(struct mali_gp_job *job, u32 src)
+{
+	job->uargs.perf_counter_src0 = src;
+}
+
+MALI_STATIC_INLINE void mali_gp_job_set_perf_counter_src1(struct mali_gp_job *job, u32 src)
+{
+	job->uargs.perf_counter_src1 = src;
+}
+
 MALI_STATIC_INLINE void mali_gp_job_set_perf_counter_value0(struct mali_gp_job *job, u32 value)
 {
 	job->perf_counter_value0 = value;
@@ -128,4 +158,29 @@ MALI_STATIC_INLINE void mali_gp_job_set_perf_counter_value1(struct mali_gp_job *
 	job->perf_counter_value1 = value;
 }
 
+/**
+ * Returns MALI_TRUE if first job is after the second job, ordered by job ID.
+ *
+ * @param first First job.
+ * @param second Second job.
+ * @return MALI_TRUE if first job should be ordered after the second job, MALI_FALSE if not.
+ */
+MALI_STATIC_INLINE mali_bool mali_gp_job_is_after(struct mali_gp_job *first, struct mali_gp_job *second)
+{
+	/* A span is used to handle job ID wrapping. */
+	return (mali_gp_job_get_id(first) - mali_gp_job_get_id(second)) < MALI_SCHEDULER_JOB_ID_SPAN;
+}
+
+/**
+ * Release reference on tracker for PP job that depends on this GP job.
+ *
+ * @note If GP job has a reference on tracker, this function MUST be called before the GP job is
+ * deleted.
+ *
+ * @param job GP job that is done.
+ * @param success MALI_TRUE if job completed successfully, MALI_FALSE if not.
+ * @return A scheduling bitmask indicating whether scheduling needs to be done.
+ */
+mali_scheduler_mask mali_gp_job_signal_pp_tracker(struct mali_gp_job *job, mali_bool success);
+
 #endif /* __MALI_GP_JOB_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_gp_scheduler.c b/drivers/gpu/mali/mali/common/mali_gp_scheduler.c
old mode 100644
new mode 100755
index fc64075..ff973f8
--- a/drivers/gpu/mali/mali/common/mali_gp_scheduler.c
+++ b/drivers/gpu/mali/mali/common/mali_gp_scheduler.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,17 +16,22 @@
 #include "mali_gp.h"
 #include "mali_gp_job.h"
 #include "mali_group.h"
-#include "mali_cluster.h"
+#include "mali_timeline.h"
+#include "mali_osk_profiling.h"
+#include "mali_kernel_utilization.h"
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+#include <linux/sched.h>
+#include <trace/events/gpu.h>
+#endif
 
-enum mali_gp_slot_state
-{
+enum mali_gp_slot_state {
 	MALI_GP_SLOT_STATE_IDLE,
 	MALI_GP_SLOT_STATE_WORKING,
+	MALI_GP_SLOT_STATE_DISABLED,
 };
 
 /* A render slot is an entity which jobs can be scheduled onto */
-struct mali_gp_slot
-{
+struct mali_gp_slot {
 	struct mali_group *group;
 	/*
 	 * We keep track of the state here as well as in the group object
@@ -37,216 +42,267 @@ struct mali_gp_slot
 };
 
 static u32 gp_version = 0;
-static _MALI_OSK_LIST_HEAD(job_queue);                          /* List of jobs with some unscheduled work */
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(job_queue);      /* List of unscheduled jobs. */
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(job_queue_high); /* List of unscheduled high priority jobs. */
 static struct mali_gp_slot slot;
 
 /* Variables to allow safe pausing of the scheduler */
 static _mali_osk_wait_queue_t *gp_scheduler_working_wait_queue = NULL;
 static u32 pause_count = 0;
 
-static mali_bool mali_gp_scheduler_is_suspended(void);
+static mali_bool mali_gp_scheduler_is_suspended(void *data);
+static void mali_gp_scheduler_job_queued(void);
+static void mali_gp_scheduler_job_completed(void);
 
-static _mali_osk_lock_t *gp_scheduler_lock = NULL;
-/* Contains tid of thread that locked the scheduler or 0, if not locked */
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+static _mali_osk_spinlock_irq_t *gp_scheduler_lock = NULL;
+#else
+static _mali_osk_spinlock_t *gp_scheduler_lock = NULL;
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 
 _mali_osk_errcode_t mali_gp_scheduler_initialize(void)
 {
+	u32 num_groups;
 	u32 i;
+	_mali_osk_errcode_t ret = _MALI_OSK_ERR_OK;
 
-	_MALI_OSK_INIT_LIST_HEAD(&job_queue);
-
-	gp_scheduler_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_SCHEDULER);
-	gp_scheduler_working_wait_queue = _mali_osk_wait_queue_init();
-
-	if (NULL == gp_scheduler_lock)
-	{
-		return _MALI_OSK_ERR_NOMEM;
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	gp_scheduler_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER);
+#else
+	gp_scheduler_lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
+	if (NULL == gp_scheduler_lock) {
+		ret = _MALI_OSK_ERR_NOMEM;
+		goto cleanup;
 	}
 
-	if (NULL == gp_scheduler_working_wait_queue)
-	{
-		_mali_osk_lock_term(gp_scheduler_lock);
-		return _MALI_OSK_ERR_NOMEM;
+	gp_scheduler_working_wait_queue = _mali_osk_wait_queue_init();
+	if (NULL == gp_scheduler_working_wait_queue) {
+		ret = _MALI_OSK_ERR_NOMEM;
+		goto cleanup;
 	}
 
 	/* Find all the available GP cores */
-	for (i = 0; i < mali_cluster_get_glob_num_clusters(); i++)
-	{
-		u32 group_id = 0;
-		struct mali_cluster *curr_cluster = mali_cluster_get_global_cluster(i);
-		struct mali_group *group = mali_cluster_get_group(curr_cluster, group_id);
-		while (NULL != group)
-		{
+	num_groups = mali_group_get_glob_num_groups();
+	for (i = 0; i < num_groups; i++) {
+		struct mali_group *group = mali_group_get_glob_group(i);
+		MALI_DEBUG_ASSERT(NULL != group);
+		if (NULL != group) {
 			struct mali_gp_core *gp_core = mali_group_get_gp_core(group);
-			if (NULL != gp_core)
-			{
-				if (0 == gp_version)
-				{
+			if (NULL != gp_core) {
+				if (0 == gp_version) {
 					/* Retrieve GP version */
 					gp_version = mali_gp_core_get_version(gp_core);
 				}
 				slot.group = group;
 				slot.state = MALI_GP_SLOT_STATE_IDLE;
-				break; /* There are only one GP, no point in looking for more */
+				break; /* There is only one GP, no point in looking for more */
 			}
-			group_id++;
-			group = mali_cluster_get_group(curr_cluster, group_id);
+		} else {
+			ret = _MALI_OSK_ERR_ITEM_NOT_FOUND;
+			goto cleanup;
 		}
 	}
 
 	return _MALI_OSK_ERR_OK;
+
+cleanup:
+	if (NULL != gp_scheduler_working_wait_queue) {
+		_mali_osk_wait_queue_term(gp_scheduler_working_wait_queue);
+		gp_scheduler_working_wait_queue = NULL;
+	}
+
+	if (NULL != gp_scheduler_lock) {
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+		_mali_osk_spinlock_irq_term(gp_scheduler_lock);
+#else
+		_mali_osk_spinlock_term(gp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
+		gp_scheduler_lock = NULL;
+	}
+
+	return ret;
 }
 
 void mali_gp_scheduler_terminate(void)
 {
+	MALI_DEBUG_ASSERT(MALI_GP_SLOT_STATE_IDLE     == slot.state
+			  || MALI_GP_SLOT_STATE_DISABLED == slot.state);
+	MALI_DEBUG_ASSERT_POINTER(slot.group);
+	mali_group_delete(slot.group);
+
 	_mali_osk_wait_queue_term(gp_scheduler_working_wait_queue);
-	_mali_osk_lock_term(gp_scheduler_lock);
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_term(gp_scheduler_lock);
+#else
+	_mali_osk_spinlock_term(gp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 }
 
 MALI_STATIC_INLINE void mali_gp_scheduler_lock(void)
 {
-	if(_MALI_OSK_ERR_OK != _mali_osk_lock_wait(gp_scheduler_lock, _MALI_OSK_LOCKMODE_RW))
-	{
-		/* Non-interruptable lock failed: this should never happen. */
-		MALI_DEBUG_ASSERT(0);
-	}
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_lock(gp_scheduler_lock);
+#else
+	_mali_osk_spinlock_lock(gp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 	MALI_DEBUG_PRINT(5, ("Mali GP scheduler: GP scheduler lock taken\n"));
 }
 
 MALI_STATIC_INLINE void mali_gp_scheduler_unlock(void)
 {
 	MALI_DEBUG_PRINT(5, ("Mali GP scheduler: Releasing GP scheduler lock\n"));
-	_mali_osk_lock_signal(gp_scheduler_lock, _MALI_OSK_LOCKMODE_RW);
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_unlock(gp_scheduler_lock);
+#else
+	_mali_osk_spinlock_unlock(gp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 }
 
-#ifdef DEBUG
-MALI_STATIC_INLINE void mali_gp_scheduler_assert_locked(void)
-{
-	MALI_DEBUG_ASSERT_LOCK_HELD(gp_scheduler_lock);
-}
-#define MALI_ASSERT_GP_SCHEDULER_LOCKED() mali_gp_scheduler_assert_locked()
+#if defined(DEBUG)
+#define MALI_ASSERT_GP_SCHEDULER_LOCKED() MALI_DEBUG_ASSERT_LOCK_HELD(gp_scheduler_lock)
 #else
-#define MALI_ASSERT_GP_SCHEDULER_LOCKED()
-#endif
+#define MALI_ASSERT_GP_SCHEDULER_LOCKED() do {} while (0)
+#endif /* defined(DEBUG) */
 
-static void mali_gp_scheduler_schedule(void)
+/* Group and scheduler must be locked when entering this function.  Both will be unlocked before
+ * exiting. */
+static void mali_gp_scheduler_schedule_internal_and_unlock(void)
 {
-	struct mali_gp_job *job;
+	struct mali_gp_job *job = NULL;
 
-	MALI_ASSERT_GP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT_LOCK_HELD(slot.group->lock);
+	MALI_DEBUG_ASSERT_LOCK_HELD(gp_scheduler_lock);
 
-	if (0 < pause_count || MALI_GP_SLOT_STATE_IDLE != slot.state || _mali_osk_list_empty(&job_queue))
-	{
+	if (0 < pause_count || MALI_GP_SLOT_STATE_IDLE != slot.state ||
+	    (_mali_osk_list_empty(&job_queue) && _mali_osk_list_empty(&job_queue_high))) {
+		mali_gp_scheduler_unlock();
+		mali_group_unlock(slot.group);
 		MALI_DEBUG_PRINT(4, ("Mali GP scheduler: Nothing to schedule (paused=%u, idle slots=%u)\n",
-		                     pause_count, MALI_GP_SLOT_STATE_IDLE == slot.state ? 1 : 0));
+				     pause_count, MALI_GP_SLOT_STATE_IDLE == slot.state ? 1 : 0));
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+		trace_gpu_sched_switch(mali_gp_get_hw_core_desc(group->gp_core), sched_clock(), 0, 0, 0);
+#endif
 		return; /* Nothing to do, so early out */
 	}
 
-	job = _MALI_OSK_LIST_ENTRY(job_queue.next, struct mali_gp_job, list);
+	/* Get next job in queue */
+	if (!_mali_osk_list_empty(&job_queue_high)) {
+		job = _MALI_OSK_LIST_ENTRY(job_queue_high.next, struct mali_gp_job, list);
+	} else {
+		MALI_DEBUG_ASSERT(!_mali_osk_list_empty(&job_queue));
+		job = _MALI_OSK_LIST_ENTRY(job_queue.next, struct mali_gp_job, list);
+	}
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	/* Remove the job from queue */
+	_mali_osk_list_del(&job->list);
+
+	/* Mark slot as busy */
+	slot.state = MALI_GP_SLOT_STATE_WORKING;
+
+	mali_gp_scheduler_unlock();
 
 	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Starting job %u (0x%08X)\n", mali_gp_job_get_id(job), job));
-	if (_MALI_OSK_ERR_OK == mali_group_start_gp_job(slot.group, job))
-	{
-		/* Mark slot as busy */
-		slot.state = MALI_GP_SLOT_STATE_WORKING;
 
-		/* Remove from queue of unscheduled jobs */
-		_mali_osk_list_del(&job->list);
-	}
-	else
-	{
-		MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Failed to start GP job\n"));
-	}
+	mali_group_start_gp_job(slot.group, job);
+	mali_group_unlock(slot.group);
 }
 
-static void mali_gp_scheduler_return_job_to_user(struct mali_gp_job *job, mali_bool success)
+void mali_gp_scheduler_schedule(void)
 {
-	_mali_osk_notification_t *notobj = _mali_osk_notification_create(_MALI_NOTIFICATION_GP_FINISHED, sizeof(_mali_uk_gp_job_finished_s));
-	if (NULL != notobj)
-	{
-		_mali_uk_gp_job_finished_s *jobres = notobj->result_buffer;
-		_mali_osk_memset(jobres, 0, sizeof(_mali_uk_gp_job_finished_s)); /* @@@@ can be removed once we initialize all members in this struct */
-		jobres->user_job_ptr = mali_gp_job_get_user_id(job);
-		if (MALI_TRUE == success)
-		{
-			jobres->status = _MALI_UK_JOB_STATUS_END_SUCCESS;
-		}
-		else
-		{
-			jobres->status = _MALI_UK_JOB_STATUS_END_UNKNOWN_ERR;
-		}
+	mali_group_lock(slot.group);
+	mali_gp_scheduler_lock();
 
-		jobres->heap_current_addr = mali_gp_job_get_current_heap_addr(job);
-		jobres->perf_counter0 = mali_gp_job_get_perf_counter_value0(job);
-		jobres->perf_counter1 = mali_gp_job_get_perf_counter_value1(job);
+	mali_gp_scheduler_schedule_internal_and_unlock();
+}
 
-		mali_session_send_notification(mali_gp_job_get_session(job), notobj);
-	}
-	else
-	{
-		MALI_PRINT_ERROR(("Mali GP scheduler: Unable to allocate notification object\n"));
+static void mali_gp_scheduler_return_job_to_user(struct mali_gp_job *job, mali_bool success)
+{
+	_mali_uk_gp_job_finished_s *jobres = job->finished_notification->result_buffer;
+	_mali_osk_memset(jobres, 0, sizeof(_mali_uk_gp_job_finished_s)); /* @@@@ can be removed once we initialize all members in this struct */
+	jobres->user_job_ptr = mali_gp_job_get_user_id(job);
+	if (MALI_TRUE == success) {
+		jobres->status = _MALI_UK_JOB_STATUS_END_SUCCESS;
+	} else {
+		jobres->status = _MALI_UK_JOB_STATUS_END_UNKNOWN_ERR;
 	}
 
+	jobres->heap_current_addr = mali_gp_job_get_current_heap_addr(job);
+	jobres->perf_counter0 = mali_gp_job_get_perf_counter_value0(job);
+	jobres->perf_counter1 = mali_gp_job_get_perf_counter_value1(job);
+
+	mali_session_send_notification(mali_gp_job_get_session(job), job->finished_notification);
+	job->finished_notification = NULL;
+
 	mali_gp_job_delete(job);
+	mali_gp_scheduler_job_completed();
 }
 
-
-void mali_gp_scheduler_do_schedule(void)
+/* Group must be locked when entering this function.  Will be unlocked before exiting. */
+void mali_gp_scheduler_job_done(struct mali_group *group, struct mali_gp_job *job, mali_bool success)
 {
-	mali_gp_scheduler_lock();
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
 
-	mali_gp_scheduler_schedule();
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_POINTER(job);
 
-	mali_gp_scheduler_unlock();
-}
+	MALI_DEBUG_ASSERT_LOCK_HELD(group->lock);
+	MALI_DEBUG_ASSERT(slot.group == group);
 
-void mali_gp_scheduler_job_done(struct mali_group *group, struct mali_gp_job *job, mali_bool success)
-{
 	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Job %u (0x%08X) completed (%s)\n", mali_gp_job_get_id(job), job, success ? "success" : "failure"));
 
+	/* Release tracker. */
+	schedule_mask |= mali_timeline_tracker_release(&job->tracker);
+
+	/* Signal PP job. */
+	schedule_mask |= mali_gp_job_signal_pp_tracker(job, success);
+
 	mali_gp_scheduler_lock();
 
 	/* Mark slot as idle again */
 	slot.state = MALI_GP_SLOT_STATE_IDLE;
 
 	/* If paused, then this was the last job, so wake up sleeping workers */
-	if (pause_count > 0)
-	{
+	if (pause_count > 0) {
 		_mali_osk_wait_queue_wake_up(gp_scheduler_working_wait_queue);
 	}
-	else
-	{
-		mali_gp_scheduler_schedule();
-	}
 
-	mali_gp_scheduler_unlock();
+	/* Schedule any queued GP jobs on this group. */
+	mali_gp_scheduler_schedule_internal_and_unlock();
+
+	/* GP is now scheduled, removing it from the mask. */
+	schedule_mask &= ~MALI_SCHEDULER_MASK_GP;
 
+	if (MALI_SCHEDULER_MASK_EMPTY != schedule_mask) {
+		/* Releasing the tracker activated other jobs that need scheduling. */
+		mali_scheduler_schedule_from_mask(schedule_mask, MALI_FALSE);
+	}
+
+	/* Sends the job end message to user space and free the job object */
 	mali_gp_scheduler_return_job_to_user(job, success);
 }
 
 void mali_gp_scheduler_oom(struct mali_group *group, struct mali_gp_job *job)
 {
-	_mali_osk_notification_t *notobj;
-
-	notobj = _mali_osk_notification_create(_MALI_NOTIFICATION_GP_STALLED, sizeof(_mali_uk_gp_job_suspended_s));
+	_mali_uk_gp_job_suspended_s *jobres;
+	_mali_osk_notification_t *notification;
 
-	if (NULL != notobj)
-	{
-		_mali_uk_gp_job_suspended_s * jobres;
-
-		mali_gp_scheduler_lock();
+	mali_gp_scheduler_lock();
 
-		jobres = (_mali_uk_gp_job_suspended_s *)notobj->result_buffer;
+	notification = job->oom_notification;
+	job->oom_notification = NULL;
+	slot.returned_cookie = mali_gp_job_get_id(job);
 
-		jobres->user_job_ptr = mali_gp_job_get_user_id(job);
-		jobres->reason = _MALIGP_JOB_SUSPENDED_OUT_OF_MEMORY;
-		jobres->cookie = mali_gp_job_get_id(job);
-		slot.returned_cookie = jobres->cookie;
+	jobres = (_mali_uk_gp_job_suspended_s *)notification->result_buffer;
+	jobres->user_job_ptr = mali_gp_job_get_user_id(job);
+	jobres->cookie = mali_gp_job_get_id(job);
 
-		mali_session_send_notification(mali_gp_job_get_session(job), notobj);
+	mali_gp_scheduler_unlock();
 
-		mali_gp_scheduler_unlock();
-	}
+	mali_session_send_notification(mali_gp_job_get_session(job), notification);
 
 	/*
 	* If this function failed, then we could return the job to user space right away,
@@ -261,53 +317,61 @@ void mali_gp_scheduler_suspend(void)
 	pause_count++; /* Increment the pause_count so that no more jobs will be scheduled */
 	mali_gp_scheduler_unlock();
 
-	_mali_osk_wait_queue_wait_event(gp_scheduler_working_wait_queue, mali_gp_scheduler_is_suspended);
+	_mali_osk_wait_queue_wait_event(gp_scheduler_working_wait_queue, mali_gp_scheduler_is_suspended, NULL);
 }
 
 void mali_gp_scheduler_resume(void)
 {
 	mali_gp_scheduler_lock();
 	pause_count--; /* Decrement pause_count to allow scheduling again (if it reaches 0) */
-	if (0 == pause_count)
-	{
+	mali_gp_scheduler_unlock();
+	if (0 == pause_count) {
 		mali_gp_scheduler_schedule();
 	}
-	mali_gp_scheduler_unlock();
 }
 
-_mali_osk_errcode_t _mali_ukk_gp_start_job(_mali_uk_gp_start_job_s *args)
+mali_timeline_point mali_gp_scheduler_submit_job(struct mali_session_data *session, struct mali_gp_job *job)
+{
+	mali_timeline_point point;
+
+	MALI_DEBUG_ASSERT_POINTER(session);
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	/* We hold a PM reference for every job we hold queued (and running) */
+	_mali_osk_pm_dev_ref_add();
+
+	/* Add job to Timeline system. */
+	point = mali_timeline_system_add_tracker(session->timeline_system, &job->tracker, MALI_TIMELINE_GP);
+
+	return point;
+}
+
+_mali_osk_errcode_t _mali_ukk_gp_start_job(void *ctx, _mali_uk_gp_start_job_s *uargs)
 {
 	struct mali_session_data *session;
 	struct mali_gp_job *job;
+	mali_timeline_point point;
+	u32 __user *timeline_point_ptr = NULL;
 
-	MALI_DEBUG_ASSERT_POINTER(args);
-
-	if (NULL == args->ctx)
-	{
-		return _MALI_OSK_ERR_INVALID_ARGS;
-	}
+	MALI_DEBUG_ASSERT_POINTER(uargs);
+	MALI_DEBUG_ASSERT_POINTER(ctx);
 
-	session = (struct mali_session_data*)args->ctx;
-	if (NULL == session)
-	{
-		return _MALI_OSK_ERR_FAULT;
-	}
+	session = (struct mali_session_data *)ctx;
 
-	job = mali_gp_job_create(session, args, mali_scheduler_get_new_id());
-	if (NULL == job)
-	{
+	job = mali_gp_job_create(session, uargs, mali_scheduler_get_new_id(), NULL);
+	if (NULL == job) {
+		MALI_PRINT_ERROR(("Failed to create GP job.\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
-	mali_gp_scheduler_lock();
-
-	_mali_osk_list_addtail(&job->list, &job_queue);
-
-	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Job %u (0x%08X) queued\n", mali_gp_job_get_id(job), job));
+	timeline_point_ptr = (u32 __user *) job->uargs.timeline_point_ptr;
 
-	mali_gp_scheduler_schedule();
+	point = mali_gp_scheduler_submit_job(session, job);
 
-	mali_gp_scheduler_unlock();
+	if (0 != _mali_osk_put_user(((u32) point), timeline_point_ptr)) {
+		/* Let user space know that something failed after the job was started. */
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
+	}
 
 	return _MALI_OSK_ERR_OK;
 }
@@ -331,90 +395,106 @@ _mali_osk_errcode_t _mali_ukk_get_gp_core_version(_mali_uk_get_gp_core_version_s
 _mali_osk_errcode_t _mali_ukk_gp_suspend_response(_mali_uk_gp_suspend_response_s *args)
 {
 	struct mali_session_data *session;
-	_mali_osk_errcode_t ret = _MALI_OSK_ERR_FAULT;
+	struct mali_gp_job *resumed_job;
+	_mali_osk_notification_t *new_notification = NULL;
 
 	MALI_DEBUG_ASSERT_POINTER(args);
 
-	if (NULL == args->ctx)
-	{
+	if (NULL == args->ctx) {
 		return _MALI_OSK_ERR_INVALID_ARGS;
 	}
 
-	session = (struct mali_session_data*)args->ctx;
-	if (NULL == session)
-	{
+	session = (struct mali_session_data *)args->ctx;
+	if (NULL == session) {
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	mali_gp_scheduler_lock();
+	if (_MALIGP_JOB_RESUME_WITH_NEW_HEAP == args->code) {
+		new_notification = _mali_osk_notification_create(_MALI_NOTIFICATION_GP_STALLED, sizeof(_mali_uk_gp_job_suspended_s));
 
-	/* Make sure that the cookie returned by user space is the same as we provided in the first place */
-	if (args->cookie != slot.returned_cookie)
-	{
-		MALI_DEBUG_PRINT(2, ("Mali GP scheduler: Got an illegal cookie from user space, expected %u but got %u (job id)\n", slot.returned_cookie, args->cookie)) ;
-		mali_gp_scheduler_unlock();
-		return _MALI_OSK_ERR_FAULT;
+		if (NULL == new_notification) {
+			MALI_PRINT_ERROR(("Mali GP scheduler: Failed to allocate notification object. Will abort GP job.\n"));
+			mali_group_lock(slot.group);
+			mali_group_abort_gp_job(slot.group, args->cookie);
+			mali_group_unlock(slot.group);
+			return _MALI_OSK_ERR_FAULT;
+		}
 	}
 
-	mali_gp_scheduler_unlock();
-
-	switch (args->code)
-	{
-		case _MALIGP_JOB_RESUME_WITH_NEW_HEAP:
-			MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Resuming job %u with new heap; 0x%08X - 0x%08X\n", args->cookie, args->arguments[0], args->arguments[1]));
-			mali_group_resume_gp_with_new_heap(slot.group, args->cookie, args->arguments[0], args->arguments[1]);
-			ret = _MALI_OSK_ERR_OK;
-			break;
+	mali_group_lock(slot.group);
 
-		case _MALIGP_JOB_ABORT:
-			MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Aborting job %u, no new heap provided\n", args->cookie));
-			mali_group_abort_gp_job(slot.group, args->cookie);
-			ret = _MALI_OSK_ERR_OK;
-			break;
+	if (_MALIGP_JOB_RESUME_WITH_NEW_HEAP == args->code) {
+		MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Resuming job %u with new heap; 0x%08X - 0x%08X\n", args->cookie, args->arguments[0], args->arguments[1]));
 
-		default:
-			MALI_PRINT_ERROR(("Mali GP scheduler: Wrong suspend response from user space\n"));
-			ret = _MALI_OSK_ERR_FAULT;
-			break;
+		resumed_job = mali_group_resume_gp_with_new_heap(slot.group, args->cookie, args->arguments[0], args->arguments[1]);
+		if (NULL != resumed_job) {
+			resumed_job->oom_notification = new_notification;
+			mali_group_unlock(slot.group);
+			return _MALI_OSK_ERR_OK;
+		} else {
+			mali_group_unlock(slot.group);
+			_mali_osk_notification_delete(new_notification);
+			return _MALI_OSK_ERR_FAULT;
+		}
 	}
 
-    return ret;
-
+	MALI_DEBUG_PRINT(2, ("Mali GP scheduler: Aborting job %u, no new heap provided\n", args->cookie));
+	mali_group_abort_gp_job(slot.group, args->cookie);
+	mali_group_unlock(slot.group);
+	return _MALI_OSK_ERR_OK;
 }
 
 void mali_gp_scheduler_abort_session(struct mali_session_data *session)
 {
 	struct mali_gp_job *job, *tmp;
+	_MALI_OSK_LIST_HEAD_STATIC_INIT(removed_jobs);
+
+	MALI_DEBUG_ASSERT_POINTER(session);
+	MALI_DEBUG_ASSERT(session->is_aborting);
+
+	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Aborting all jobs from session 0x%08X.\n", session));
 
 	mali_gp_scheduler_lock();
-	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Aborting all jobs from session 0x%08x\n", session));
-
-	/* Check queue for jobs and remove */
-	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &job_queue, struct mali_gp_job, list)
-	{
-		if (mali_gp_job_get_session(job) == session)
-		{
-			MALI_DEBUG_PRINT(4, ("Mali GP scheduler: Removing GP job 0x%08x from queue\n", job));
-			_mali_osk_list_del(&(job->list));
-			mali_gp_job_delete(job);
+
+	/* Find all jobs from the aborting session. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &job_queue, struct mali_gp_job, list) {
+		if (job->session == session) {
+			MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Removing job %u (0x%08X) from queue.\n", mali_gp_job_get_id(job), job));
+			_mali_osk_list_move(&job->list, &removed_jobs);
+		}
+	}
+
+	/* Find all high priority jobs from the aborting session. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &job_queue_high, struct mali_gp_job, list) {
+		if (job->session == session) {
+			MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Removing job %u (0x%08X) from queue.\n", mali_gp_job_get_id(job), job));
+			_mali_osk_list_move(&job->list, &removed_jobs);
 		}
 	}
 
 	mali_gp_scheduler_unlock();
 
-	/* Abort running jobs from this session. It is safe to do this outside
-	 * the scheduler lock as there is only one GP core, and the queue has
-	 * already been emptied, as long as there are no new jobs coming in
-	 * from user space. */
+	/* Release and delete all found jobs from the aborting session. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &removed_jobs, struct mali_gp_job, list) {
+		mali_timeline_tracker_release(&job->tracker);
+		mali_gp_job_signal_pp_tracker(job, MALI_FALSE);
+		mali_gp_job_delete(job);
+		mali_gp_scheduler_job_completed();
+	}
+
+	/* Abort any running jobs from the session. */
 	mali_group_abort_session(slot.group, session);
 }
 
-static mali_bool mali_gp_scheduler_is_suspended(void)
+static mali_bool mali_gp_scheduler_is_suspended(void *data)
 {
 	mali_bool ret;
 
+	/* This callback does not use the data pointer. */
+	MALI_IGNORE(data);
+
 	mali_gp_scheduler_lock();
-	ret = pause_count > 0 && slot.state == MALI_GP_SLOT_STATE_IDLE;
+	ret = pause_count > 0 && (slot.state == MALI_GP_SLOT_STATE_IDLE || slot.state == MALI_GP_SLOT_STATE_DISABLED);
 	mali_gp_scheduler_unlock();
 
 	return ret;
@@ -428,11 +508,196 @@ u32 mali_gp_scheduler_dump_state(char *buf, u32 size)
 
 	n += _mali_osk_snprintf(buf + n, size - n, "GP\n");
 	n += _mali_osk_snprintf(buf + n, size - n, "\tQueue is %s\n", _mali_osk_list_empty(&job_queue) ? "empty" : "not empty");
+	n += _mali_osk_snprintf(buf + n, size - n, "\tHigh priority queue is %s\n", _mali_osk_list_empty(&job_queue_high) ? "empty" : "not empty");
 
 	n += mali_group_dump_state(slot.group, buf + n, size - n);
-	n += _mali_osk_snprintf(buf + n, size - n, "\t\tState: %d\n", mali_group_gp_state(slot.group));
 	n += _mali_osk_snprintf(buf + n, size - n, "\n");
 
 	return n;
 }
 #endif
+
+void mali_gp_scheduler_reset_all_groups(void)
+{
+	if (NULL != slot.group) {
+		mali_group_lock(slot.group);
+		mali_group_reset(slot.group);
+		mali_group_unlock(slot.group);
+	}
+}
+
+void mali_gp_scheduler_zap_all_active(struct mali_session_data *session)
+{
+	if (NULL != slot.group) {
+		mali_group_zap_session(slot.group, session);
+	}
+}
+
+void mali_gp_scheduler_enable_group(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(slot.group == group);
+	MALI_DEBUG_PRINT(2, ("Mali GP scheduler: enabling gp group %p\n", group));
+
+	mali_group_lock(group);
+
+	if (MALI_GROUP_STATE_DISABLED != group->state) {
+		mali_group_unlock(group);
+		MALI_DEBUG_PRINT(2, ("Mali GP scheduler: gp group %p already enabled\n", group));
+		return;
+	}
+
+	mali_gp_scheduler_lock();
+
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_DISABLED == group->state);
+	MALI_DEBUG_ASSERT(MALI_GP_SLOT_STATE_DISABLED == slot.state);
+	slot.state = MALI_GP_SLOT_STATE_IDLE;
+	group->state = MALI_GROUP_STATE_IDLE;
+
+	mali_group_power_on_group(group);
+	mali_group_reset(group);
+
+	/* Pick up any jobs that might have been queued while the GP group was disabled. */
+	mali_gp_scheduler_schedule_internal_and_unlock();
+}
+
+void mali_gp_scheduler_disable_group(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(slot.group == group);
+	MALI_DEBUG_PRINT(2, ("Mali GP scheduler: disabling gp group %p\n", group));
+
+	mali_gp_scheduler_suspend();
+	mali_group_lock(group);
+	mali_gp_scheduler_lock();
+
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE     == group->state
+			  || MALI_GROUP_STATE_DISABLED == group->state);
+
+	if (MALI_GROUP_STATE_DISABLED == group->state) {
+		MALI_DEBUG_ASSERT(MALI_GP_SLOT_STATE_DISABLED == slot.state);
+		MALI_DEBUG_PRINT(2, ("Mali GP scheduler: gp group %p already disabled\n", group));
+	} else {
+		MALI_DEBUG_ASSERT(MALI_GP_SLOT_STATE_IDLE == slot.state);
+		slot.state = MALI_GP_SLOT_STATE_DISABLED;
+		group->state = MALI_GROUP_STATE_DISABLED;
+
+		mali_group_power_off_group(group, MALI_TRUE);
+	}
+
+	mali_gp_scheduler_unlock();
+	mali_group_unlock(group);
+	mali_gp_scheduler_resume();
+}
+
+static mali_scheduler_mask mali_gp_scheduler_queue_job(struct mali_gp_job *job)
+{
+	_mali_osk_list_t *queue = NULL;
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+	struct mali_gp_job *iter, *tmp;
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT_POINTER(job->session);
+
+	MALI_DEBUG_ASSERT_LOCK_HELD(gp_scheduler_lock);
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_SINGLE_SW_GP_ENQUEUE, job->pid, job->tid, job->uargs.frame_builder_id, job->uargs.flush_id, 0);
+
+	job->cache_order = mali_scheduler_get_new_cache_order();
+
+	/* Determine which queue the job should be added to. */
+	if (job->session->use_high_priority_job_queue) {
+		queue = &job_queue_high;
+	} else {
+		queue = &job_queue;
+	}
+
+	/* Find position in queue where job should be added. */
+	_MALI_OSK_LIST_FOREACHENTRY_REVERSE(iter, tmp, queue, struct mali_gp_job, list) {
+		if (mali_gp_job_is_after(job, iter)) {
+			break;
+		}
+	}
+
+	/* Add job to queue. */
+	_mali_osk_list_add(&job->list, &iter->list);
+
+	/* Set schedule bitmask if the GP core is idle. */
+	if (MALI_GP_SLOT_STATE_IDLE == slot.state) {
+		schedule_mask |= MALI_SCHEDULER_MASK_GP;
+	}
+
+	mali_gp_scheduler_job_queued();
+
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+	trace_gpu_job_enqueue(mali_gp_job_get_tid(job), mali_gp_job_get_id(job), "GP");
+#endif
+
+	MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Job %u (0x%08X) queued\n", mali_gp_job_get_id(job), job));
+
+	return schedule_mask;
+}
+
+mali_scheduler_mask mali_gp_scheduler_activate_job(struct mali_gp_job *job)
+{
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT_POINTER(job->session);
+
+	MALI_DEBUG_PRINT(4, ("Mali GP scheduler: Timeline activation for job %u (0x%08X).\n", mali_gp_job_get_id(job), job));
+
+	mali_gp_scheduler_lock();
+
+	if (unlikely(job->session->is_aborting)) {
+		/* Before checking if the session is aborting, the scheduler must be locked. */
+		MALI_DEBUG_ASSERT_LOCK_HELD(gp_scheduler_lock);
+
+		MALI_DEBUG_PRINT(3, ("Mali GP scheduler: Job %u (0x%08X) activated while session is aborting.\n", mali_gp_job_get_id(job), job));
+
+		/* This job should not be on any list. */
+		MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->list));
+
+		mali_gp_scheduler_unlock();
+
+		/* Release tracker and delete job. */
+		mali_timeline_tracker_release(&job->tracker);
+		mali_gp_job_signal_pp_tracker(job, MALI_FALSE);
+		mali_gp_job_delete(job);
+
+		/* Release the PM ref taken in mali_gp_scheduler_submit_job */
+		_mali_osk_pm_dev_ref_dec();
+
+		/* Since we are aborting we ignore the scheduler mask. */
+		return MALI_SCHEDULER_MASK_EMPTY;
+	}
+
+	/* GP job is ready to run, queue it. */
+	schedule_mask = mali_gp_scheduler_queue_job(job);
+
+	mali_gp_scheduler_unlock();
+
+	return schedule_mask;
+}
+
+static void mali_gp_scheduler_job_queued(void)
+{
+	if (mali_utilization_enabled()) {
+		/*
+		 * We cheat a little bit by counting the PP as busy from the time a GP job is queued.
+		 * This will be fine because we only loose the tiny idle gap between jobs, but
+		 * we will instead get less utilization work to do (less locks taken)
+		 */
+		mali_utilization_gp_start();
+	}
+}
+
+static void mali_gp_scheduler_job_completed(void)
+{
+	/* Release the PM reference we got in the mali_gp_scheduler_job_queued() function */
+	_mali_osk_pm_dev_ref_dec();
+
+	if (mali_utilization_enabled()) {
+		mali_utilization_gp_end();
+	}
+}
diff --git a/drivers/gpu/mali/mali/common/mali_gp_scheduler.h b/drivers/gpu/mali/mali/common/mali_gp_scheduler.h
old mode 100644
new mode 100755
index a20f1f8..84a096c
--- a/drivers/gpu/mali/mali/common/mali_gp_scheduler.h
+++ b/drivers/gpu/mali/mali/common/mali_gp_scheduler.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,19 +12,90 @@
 #define __MALI_GP_SCHEDULER_H__
 
 #include "mali_osk.h"
-#include "mali_cluster.h"
 #include "mali_gp_job.h"
+#include "mali_group.h"
 
 _mali_osk_errcode_t mali_gp_scheduler_initialize(void);
 void mali_gp_scheduler_terminate(void);
 
-void mali_gp_scheduler_do_schedule(void);
 void mali_gp_scheduler_job_done(struct mali_group *group, struct mali_gp_job *job, mali_bool success);
 void mali_gp_scheduler_oom(struct mali_group *group, struct mali_gp_job *job);
-void mali_gp_scheduler_abort_session(struct mali_session_data *session);
 u32 mali_gp_scheduler_dump_state(char *buf, u32 size);
 
 void mali_gp_scheduler_suspend(void);
 void mali_gp_scheduler_resume(void);
 
+/**
+ * @brief Abort all running and queued GP jobs from session.
+ *
+* This functions aborts all GP jobs from the specified session. Queued jobs are removed from the
+* queue and jobs currently running on a core will be aborted.
+ *
+ * @param session Session that is aborting.
+ */
+void mali_gp_scheduler_abort_session(struct mali_session_data *session);
+
+/**
+ * @brief Reset all groups
+ *
+ * This function resets all groups known by the GP scheuduler. This must be
+ * called after the Mali HW has been powered on in order to reset the HW.
+ */
+void mali_gp_scheduler_reset_all_groups(void);
+
+/**
+ * @brief Zap TLB on all groups with \a session active
+ *
+ * The scheculer will zap the session on all groups it owns.
+ */
+void mali_gp_scheduler_zap_all_active(struct mali_session_data *session);
+
+/**
+ * @brief Re-enable a group that has been disabled with mali_gp_scheduler_disable_group
+ *
+ * If a Mali PMU is present, the group will be powered back on and added back
+ * into the GP scheduler.
+ *
+ * @param group Pointer to the group to enable
+ */
+void mali_gp_scheduler_enable_group(struct mali_group *group);
+
+/**
+ * @brief Disable a group
+ *
+ * The group will be taken out of the GP scheduler and powered off, if a Mali
+ * PMU is present.
+ *
+ * @param group Pointer to the group to disable
+ */
+void mali_gp_scheduler_disable_group(struct mali_group *group);
+
+/**
+ * @brief Used by the Timeline system to queue a GP job.
+ *
+ * @note @ref mali_scheduler_schedule_from_mask() should be called if this function returns non-zero.
+ *
+ * @param job The GP job that is being activated.
+ *
+ * @return A scheduling bitmask that can be used to decide if scheduling is necessary after this
+ * call.
+ */
+mali_scheduler_mask mali_gp_scheduler_activate_job(struct mali_gp_job *job);
+
+/**
+ * @brief Schedule queued jobs on idle cores.
+ */
+void mali_gp_scheduler_schedule(void);
+
+/**
+ * @brief Submit a GP job to the GP scheduler.
+ *
+ * This will add the GP job to the Timeline system.
+ *
+ * @param session Session this job belongs to.
+ * @param job GP job that will be submitted
+ * @return Point on GP timeline for job.
+ */
+mali_timeline_point mali_gp_scheduler_submit_job(struct mali_session_data *session, struct mali_gp_job *job);
+
 #endif /* __MALI_GP_SCHEDULER_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_group.c b/drivers/gpu/mali/mali/common/mali_group.c
old mode 100644
new mode 100755
index 94c5643..922f012
--- a/drivers/gpu/mali/mali/common/mali_group.c
+++ b/drivers/gpu/mali/mali/common/mali_group.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,13 +11,33 @@
 #include "mali_kernel_common.h"
 #include "mali_group.h"
 #include "mali_osk.h"
-#include "mali_cluster.h"
+#include "mali_l2_cache.h"
 #include "mali_gp.h"
 #include "mali_pp.h"
 #include "mali_mmu.h"
-#include "mali_gp_scheduler.h"
-#include "mali_pp_scheduler.h"
+#include "mali_dlbu.h"
+#include "mali_broadcast.h"
+#include "mali_scheduler.h"
+#include "mali_osk_profiling.h"
+#include "mali_pm_domain.h"
 #include "mali_pm.h"
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+#include <linux/sched.h>
+#include <trace/events/gpu.h>
+#endif
+
+
+static void mali_group_bottom_half_mmu(void *data);
+static void mali_group_bottom_half_gp(void *data);
+static void mali_group_bottom_half_pp(void *data);
+
+static void mali_group_timeout(void *data);
+static void mali_group_reset_pp(struct mali_group *group);
+static void mali_group_reset_mmu(struct mali_group *group);
+
+#if defined(CONFIG_MALI400_PROFILING)
+static void mali_group_report_l2_cache_counters_per_core(struct mali_group *group, u32 core_num);
+#endif /* #if defined(CONFIG_MALI400_PROFILING) */
 
 /*
  * The group object is the most important object in the device driver,
@@ -31,65 +51,39 @@
  * GP/PP lock first, then group lock(s).
  */
 
-/**
- * The structure represents a render group
- * A render group is defined by all the cores that share the same Mali MMU
- */
-
-struct mali_group
-{
-	struct mali_cluster *cluster;
-
-	struct mali_mmu_core *mmu;
-	struct mali_session_data *session;
-	int page_dir_ref_count;
-	mali_bool power_is_on;
-#if defined(USING_MALI200)
-	mali_bool pagedir_activation_failed;
-#endif
-
-	struct mali_gp_core         *gp_core;
-	enum mali_group_core_state  gp_state;
-	struct mali_gp_job          *gp_running_job;
-
-	struct mali_pp_core         *pp_core;
-	enum mali_group_core_state  pp_state;
-	struct mali_pp_job          *pp_running_job;
-	u32                         pp_running_sub_job;
-
-	_mali_osk_lock_t *lock;
-};
-
-static struct mali_group *mali_global_groups[MALI_MAX_NUMBER_OF_GROUPS];
+static struct mali_group *mali_global_groups[MALI_MAX_NUMBER_OF_GROUPS] = { NULL, };
 static u32 mali_global_num_groups = 0;
 
-enum mali_group_activate_pd_status
-{
-	MALI_GROUP_ACTIVATE_PD_STATUS_FAILED,
-	MALI_GROUP_ACTIVATE_PD_STATUS_OK_KEPT_PD,
-	MALI_GROUP_ACTIVATE_PD_STATUS_OK_SWITCHED_PD,
-};
+/* timer related */
+int mali_max_job_runtime = MALI_MAX_JOB_RUNTIME_DEFAULT;
 
 /* local helper functions */
-static enum mali_group_activate_pd_status mali_group_activate_page_directory(struct mali_group *group, struct mali_session_data *session);
-static void mali_group_deactivate_page_directory(struct mali_group *group, struct mali_session_data *session);
+static void mali_group_activate_page_directory(struct mali_group *group, struct mali_session_data *session);
+static void mali_group_remove_session_if_unused(struct mali_group *group, struct mali_session_data *session);
 static void mali_group_recovery_reset(struct mali_group *group);
-static void mali_group_complete_jobs(struct mali_group *group, mali_bool complete_gp, mali_bool complete_pp, bool success);
+static void mali_group_mmu_page_fault_and_unlock(struct mali_group *group);
+
+static void mali_group_post_process_job_pp(struct mali_group *group);
+static void mali_group_post_process_job_gp(struct mali_group *group, mali_bool suspend);
 
 void mali_group_lock(struct mali_group *group)
 {
-	if(_MALI_OSK_ERR_OK != _mali_osk_lock_wait(group->lock, _MALI_OSK_LOCKMODE_RW))
-	{
-		/* Non-interruptable lock failed: this should never happen. */
-		MALI_DEBUG_ASSERT(0);
-	}
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_lock(group->lock);
+#else
+	_mali_osk_spinlock_lock(group->lock);
+#endif
 	MALI_DEBUG_PRINT(5, ("Mali group: Group lock taken 0x%08X\n", group));
 }
 
 void mali_group_unlock(struct mali_group *group)
 {
 	MALI_DEBUG_PRINT(5, ("Mali group: Releasing group lock 0x%08X\n", group));
-	_mali_osk_lock_signal(group->lock, _MALI_OSK_LOCKMODE_RW);
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_unlock(group->lock);
+#else
+	_mali_osk_spinlock_unlock(group->lock);
+#endif
 }
 
 #ifdef DEBUG
@@ -100,38 +94,54 @@ void mali_group_assert_locked(struct mali_group *group)
 #endif
 
 
-struct mali_group *mali_group_create(struct mali_cluster *cluster, struct mali_mmu_core *mmu)
+struct mali_group *mali_group_create(struct mali_l2_cache_core *core, struct mali_dlbu_core *dlbu, struct mali_bcast_unit *bcast)
 {
 	struct mali_group *group = NULL;
 
-	if (mali_global_num_groups >= MALI_MAX_NUMBER_OF_GROUPS)
-	{
+	if (mali_global_num_groups >= MALI_MAX_NUMBER_OF_GROUPS) {
 		MALI_PRINT_ERROR(("Mali group: Too many group objects created\n"));
 		return NULL;
 	}
 
-	group = _mali_osk_malloc(sizeof(struct mali_group));
-	if (NULL != group)
-	{
-		_mali_osk_memset(group, 0, sizeof(struct mali_group));
-		group->lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ |_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_GROUP);
-		if (NULL != group->lock)
-		{
-			group->cluster = cluster;
-			group->mmu = mmu; /* This group object now owns the MMU object */
-			group->session = NULL;
-			group->page_dir_ref_count = 0;
-			group->power_is_on = MALI_TRUE;
+	group = _mali_osk_calloc(1, sizeof(struct mali_group));
+	if (NULL != group) {
+		group->timeout_timer = _mali_osk_timer_init();
 
-			group->gp_state = MALI_GROUP_CORE_STATE_IDLE;
-			group->pp_state = MALI_GROUP_CORE_STATE_IDLE;
-#if defined(USING_MALI200)
-			group->pagedir_activation_failed = MALI_FALSE;
+		if (NULL != group->timeout_timer) {
+			_mali_osk_lock_order_t order;
+			_mali_osk_timer_setcallback(group->timeout_timer, mali_group_timeout, (void *)group);
+
+			if (NULL != dlbu) {
+				order = _MALI_OSK_LOCK_ORDER_GROUP_VIRTUAL;
+			} else {
+				order = _MALI_OSK_LOCK_ORDER_GROUP;
+			}
+
+#ifdef MALI_UPPER_HALF_SCHEDULING
+			group->lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, order);
+#else
+			group->lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, order);
 #endif
-			mali_global_groups[mali_global_num_groups] = group;
-			mali_global_num_groups++;
 
-			return group;
+			if (NULL != group->lock) {
+				group->l2_cache_core[0] = core;
+				group->session = NULL;
+				group->power_is_on = MALI_TRUE;
+				group->state = MALI_GROUP_STATE_IDLE;
+				_mali_osk_list_init(&group->group_list);
+				_mali_osk_list_init(&group->pp_scheduler_list);
+				group->parent_group = NULL;
+				group->l2_cache_core_ref_count[0] = 0;
+				group->l2_cache_core_ref_count[1] = 0;
+				group->bcast_core = bcast;
+				group->dlbu_core = dlbu;
+
+				mali_global_groups[mali_global_num_groups] = group;
+				mali_global_num_groups++;
+
+				return group;
+			}
+			_mali_osk_timer_term(group->timeout_timer);
 		}
 		_mali_osk_free(group);
 	}
@@ -139,703 +149,1900 @@ struct mali_group *mali_group_create(struct mali_cluster *cluster, struct mali_m
 	return NULL;
 }
 
-void mali_group_add_gp_core(struct mali_group *group, struct mali_gp_core* gp_core)
+_mali_osk_errcode_t mali_group_add_mmu_core(struct mali_group *group, struct mali_mmu_core *mmu_core)
+{
+	/* This group object now owns the MMU core object */
+	group->mmu = mmu_core;
+	group->bottom_half_work_mmu = _mali_osk_wq_create_work(mali_group_bottom_half_mmu, group);
+	if (NULL == group->bottom_half_work_mmu) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+	return _MALI_OSK_ERR_OK;
+}
+
+void mali_group_remove_mmu_core(struct mali_group *group)
+{
+	/* This group object no longer owns the MMU core object */
+	group->mmu = NULL;
+	if (NULL != group->bottom_half_work_mmu) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_mmu);
+	}
+}
+
+_mali_osk_errcode_t mali_group_add_gp_core(struct mali_group *group, struct mali_gp_core *gp_core)
 {
 	/* This group object now owns the GP core object */
 	group->gp_core = gp_core;
+	group->bottom_half_work_gp = _mali_osk_wq_create_work(mali_group_bottom_half_gp, group);
+	if (NULL == group->bottom_half_work_gp) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+	return _MALI_OSK_ERR_OK;
+}
+
+void mali_group_remove_gp_core(struct mali_group *group)
+{
+	/* This group object no longer owns the GP core object */
+	group->gp_core = NULL;
+	if (NULL != group->bottom_half_work_gp) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_gp);
+	}
 }
 
-void mali_group_add_pp_core(struct mali_group *group, struct mali_pp_core* pp_core)
+_mali_osk_errcode_t mali_group_add_pp_core(struct mali_group *group, struct mali_pp_core *pp_core)
 {
 	/* This group object now owns the PP core object */
 	group->pp_core = pp_core;
+	group->bottom_half_work_pp = _mali_osk_wq_create_work(mali_group_bottom_half_pp, group);
+	if (NULL == group->bottom_half_work_pp) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+	return _MALI_OSK_ERR_OK;
+}
+
+void mali_group_remove_pp_core(struct mali_group *group)
+{
+	/* This group object no longer owns the PP core object */
+	group->pp_core = NULL;
+	if (NULL != group->bottom_half_work_pp) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_pp);
+	}
+}
+
+void mali_group_set_pm_domain(struct mali_group *group, struct mali_pm_domain *domain)
+{
+	group->pm_domain = domain;
 }
 
 void mali_group_delete(struct mali_group *group)
 {
 	u32 i;
 
+	MALI_DEBUG_PRINT(4, ("Deleting group %p\n", group));
+
+	MALI_DEBUG_ASSERT(NULL == group->parent_group);
+
 	/* Delete the resources that this group owns */
-	if (NULL != group->gp_core)
-	{
+	if (NULL != group->gp_core) {
 		mali_gp_delete(group->gp_core);
 	}
 
-	if (NULL != group->pp_core)
-	{
+	if (NULL != group->pp_core) {
 		mali_pp_delete(group->pp_core);
 	}
 
-	if (NULL != group->mmu)
-	{
+	if (NULL != group->mmu) {
 		mali_mmu_delete(group->mmu);
 	}
 
-	for (i = 0; i < mali_global_num_groups; i++)
-	{
-		if (mali_global_groups[i] == group)
-		{
-			mali_global_groups[i] = NULL;
-			mali_global_num_groups--;
-			break;
+	if (mali_group_is_virtual(group)) {
+		/* Remove all groups from virtual group */
+		struct mali_group *child;
+		struct mali_group *temp;
+
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			child->parent_group = NULL;
+			mali_group_delete(child);
+		}
+
+		mali_dlbu_delete(group->dlbu_core);
+
+		if (NULL != group->bcast_core) {
+			mali_bcast_unit_delete(group->bcast_core);
 		}
 	}
 
-	_mali_osk_lock_term(group->lock);
+	for (i = 0; i < mali_global_num_groups; i++) {
+		if (mali_global_groups[i] == group) {
+			mali_global_groups[i] = NULL;
+			mali_global_num_groups--;
 
-	_mali_osk_free(group);
-}
+			if (i != mali_global_num_groups) {
+				/* We removed a group from the middle of the array -- move the last
+				 * group to the current position to close the gap */
+				mali_global_groups[i] = mali_global_groups[mali_global_num_groups];
+				mali_global_groups[mali_global_num_groups] = NULL;
+			}
 
-/* Called from mali_cluster_reset() when the system is re-turned on */
-void mali_group_reset(struct mali_group *group)
-{
-	mali_group_lock(group);
+			break;
+		}
+	}
 
-	group->session = NULL;
+	if (NULL != group->timeout_timer) {
+		_mali_osk_timer_del(group->timeout_timer);
+		_mali_osk_timer_term(group->timeout_timer);
+	}
 
-	if (NULL != group->mmu)
-	{
-		mali_mmu_reset(group->mmu);
+	if (NULL != group->bottom_half_work_mmu) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_mmu);
 	}
 
-	if (NULL != group->gp_core)
-	{
-		mali_gp_reset(group->gp_core);
+	if (NULL != group->bottom_half_work_gp) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_gp);
 	}
 
-	if (NULL != group->pp_core)
-	{
-		mali_pp_reset(group->pp_core);
+	if (NULL != group->bottom_half_work_pp) {
+		_mali_osk_wq_delete_work(group->bottom_half_work_pp);
 	}
 
-	mali_group_unlock(group);
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_term(group->lock);
+#else
+	_mali_osk_spinlock_term(group->lock);
+#endif
+	_mali_osk_free(group);
 }
 
-struct mali_gp_core* mali_group_get_gp_core(struct mali_group *group)
+MALI_DEBUG_CODE(static void mali_group_print_virtual(struct mali_group *vgroup)
 {
-	return group->gp_core;
-}
+	u32 i;
+	struct mali_group *group;
+	struct mali_group *temp;
 
-struct mali_pp_core* mali_group_get_pp_core(struct mali_group *group)
-{
-	return group->pp_core;
-}
+	MALI_DEBUG_PRINT(4, ("Virtual group %p\n", vgroup));
+	MALI_DEBUG_PRINT(4, ("l2_cache_core[0] = %p, ref = %d\n", vgroup->l2_cache_core[0], vgroup->l2_cache_core_ref_count[0]));
+	MALI_DEBUG_PRINT(4, ("l2_cache_core[1] = %p, ref = %d\n", vgroup->l2_cache_core[1], vgroup->l2_cache_core_ref_count[1]));
+
+	i = 0;
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &vgroup->group_list, struct mali_group, group_list) {
+		MALI_DEBUG_PRINT(4, ("[%d] %p, l2_cache_core[0] = %p\n", i, group, group->l2_cache_core[0]));
+		i++;
+	}
+})
 
-_mali_osk_errcode_t mali_group_start_gp_job(struct mali_group *group, struct mali_gp_job *job)
+/**
+ * @brief Add child group to virtual group parent
+ *
+ * Before calling this function, child must have it's state set to JOINING_VIRTUAL
+ * to ensure it's not touched during the transition period. When this function returns,
+ * child's state will be IN_VIRTUAL.
+ */
+void mali_group_add_group(struct mali_group *parent, struct mali_group *child, mali_bool update_hw)
 {
-	struct mali_session_data *session;
-	enum mali_group_activate_pd_status activate_status;
+	mali_bool found;
+	u32 i;
+	struct mali_session_data *child_session;
 
-	MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->gp_state);
+	MALI_DEBUG_PRINT(3, ("Adding group %p to virtual group %p\n", child, parent));
 
-	mali_pm_core_event(MALI_CORE_EVENT_GP_START);
+	MALI_ASSERT_GROUP_LOCKED(parent);
 
-	session = mali_gp_job_get_session(job);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(parent));
+	MALI_DEBUG_ASSERT(!mali_group_is_virtual(child));
+	MALI_DEBUG_ASSERT(NULL == child->parent_group);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_JOINING_VIRTUAL == child->state);
 
-	mali_group_lock(group);
+	_mali_osk_list_addtail(&child->group_list, &parent->group_list);
 
-	mali_cluster_l2_cache_invalidate_all(group->cluster, mali_gp_job_get_id(job));
+	child->state = MALI_GROUP_STATE_IN_VIRTUAL;
+	child->parent_group = parent;
 
-	activate_status = mali_group_activate_page_directory(group, session);
-	if (MALI_GROUP_ACTIVATE_PD_STATUS_FAILED != activate_status)
-	{
-		/* if session is NOT kept Zapping is done as part of session switch */
-		if (MALI_GROUP_ACTIVATE_PD_STATUS_OK_KEPT_PD == activate_status)
-		{
-			mali_mmu_zap_tlb_without_stall(group->mmu);
-		}
-		mali_gp_job_start(group->gp_core, job);
-		group->gp_running_job = job;
-		group->gp_state = MALI_GROUP_CORE_STATE_WORKING;
+	MALI_DEBUG_ASSERT_POINTER(child->l2_cache_core[0]);
 
-		mali_group_unlock(group);
+	MALI_DEBUG_PRINT(4, ("parent->l2_cache_core: [0] = %p, [1] = %p\n", parent->l2_cache_core[0], parent->l2_cache_core[1]));
+	MALI_DEBUG_PRINT(4, ("child->l2_cache_core: [0] = %p, [1] = %p\n", child->l2_cache_core[0], child->l2_cache_core[1]));
 
-		return _MALI_OSK_ERR_OK;
+	/* Keep track of the L2 cache cores of child groups */
+	found = MALI_FALSE;
+	for (i = 0; i < 2; i++) {
+		if (parent->l2_cache_core[i] == child->l2_cache_core[0]) {
+			MALI_DEBUG_ASSERT(parent->l2_cache_core_ref_count[i] > 0);
+			parent->l2_cache_core_ref_count[i]++;
+			found = MALI_TRUE;
+		}
 	}
 
-#if defined(USING_MALI200)
-	group->pagedir_activation_failed = MALI_TRUE;
-#endif
-
-	mali_group_unlock(group);
+	if (!found) {
+		/* First time we see this L2 cache, add it to our list */
+		i = (NULL == parent->l2_cache_core[0]) ? 0 : 1;
 
-	mali_pm_core_event(MALI_CORE_EVENT_GP_STOP); /* Failed to start, so "cancel" the MALI_CORE_EVENT_GP_START */
-	return _MALI_OSK_ERR_FAULT;
-}
+		MALI_DEBUG_PRINT(4, ("First time we see l2_cache %p. Adding to [%d] = %p\n", child->l2_cache_core[0], i, parent->l2_cache_core[i]));
 
-_mali_osk_errcode_t mali_group_start_pp_job(struct mali_group *group, struct mali_pp_job *job, u32 sub_job)
-{
-	struct mali_session_data *session;
-	enum mali_group_activate_pd_status activate_status;
+		MALI_DEBUG_ASSERT(NULL == parent->l2_cache_core[i]);
 
-	MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->pp_state);
+		parent->l2_cache_core[i] = child->l2_cache_core[0];
+		parent->l2_cache_core_ref_count[i]++;
+	}
 
-	mali_pm_core_event(MALI_CORE_EVENT_PP_START);
+	/* Update Broadcast Unit and DLBU */
+	mali_bcast_add_group(parent->bcast_core, child);
+	mali_dlbu_add_group(parent->dlbu_core, child);
 
-	session = mali_pp_job_get_session(job);
+	child_session = child->session;
+	child->session = NULL;
 
-	mali_group_lock(group);
+	/* Above this comment, only software state is updated and the HW is not
+	 * touched. Now, check if Mali is powered and skip the rest if it isn't
+	 * powered.
+	 */
 
-	mali_cluster_l2_cache_invalidate_all(group->cluster, mali_pp_job_get_id(job));
+	if (!update_hw) {
+		MALI_DEBUG_CODE(mali_group_print_virtual(parent));
+		return;
+	}
 
-	activate_status = mali_group_activate_page_directory(group, session);
-	if (MALI_GROUP_ACTIVATE_PD_STATUS_FAILED != activate_status)
-	{
-		/* if session is NOT kept Zapping is done as part of session switch */
-		if (MALI_GROUP_ACTIVATE_PD_STATUS_OK_KEPT_PD == activate_status)
-		{
-			MALI_DEBUG_PRINT(3, ("PP starting job PD_Switch 0 Flush 1 Zap 1\n"));
-			mali_mmu_zap_tlb_without_stall(group->mmu);
+	/* Update MMU */
+	if (parent->session == child_session) {
+		mali_mmu_zap_tlb(child->mmu);
+	} else {
+		if (NULL == parent->session) {
+			mali_mmu_activate_empty_page_directory(child->mmu);
+		} else {
+			mali_mmu_activate_page_directory(child->mmu, mali_session_get_page_directory(parent->session));
 		}
-		mali_pp_job_start(group->pp_core, job, sub_job);
-		group->pp_running_job = job;
-		group->pp_running_sub_job = sub_job;
-		group->pp_state = MALI_GROUP_CORE_STATE_WORKING;
+	}
 
-		mali_group_unlock(group);
+	mali_dlbu_update_mask(parent->dlbu_core);
 
-		return _MALI_OSK_ERR_OK;
-	}
+	/* Start job on child when parent is active */
+	if (NULL != parent->pp_running_job) {
+		struct mali_pp_job *job = parent->pp_running_job;
+		u32 subjob = -1;
 
-#if defined(USING_MALI200)
-	group->pagedir_activation_failed = MALI_TRUE;
-#endif
+		if (mali_pp_job_is_with_dlbu(parent->pp_running_job)) {
+			subjob = mali_pp_core_get_id(child->pp_core);
+		}
 
-	mali_group_unlock(group);
+		/* Take the next unstarted sub job directly without scheduler lock should be
+		 * safe here. Because: 1) Virtual group is the only consumer of this job.
+		 * 2) Taking next unstarted sub job doesn't do any change to the job queue itself
+		 */
+		if (mali_pp_job_has_unstarted_sub_jobs(job)) {
+			subjob = mali_pp_job_get_first_unstarted_sub_job(job);
+			mali_pp_job_mark_sub_job_started(job, subjob);
+		}
 
-	mali_pm_core_event(MALI_CORE_EVENT_PP_STOP); /* Failed to start, so "cancel" the MALI_CORE_EVENT_PP_START */
-	return _MALI_OSK_ERR_FAULT;
+		if (-1 != subjob) {
+			MALI_DEBUG_PRINT(3, ("Group %x joining running job %d on virtual group %x\n",
+					     child, mali_pp_job_get_id(job), parent));
+			MALI_DEBUG_ASSERT(MALI_GROUP_STATE_WORKING == parent->state);
+			/* Reset broadcast unit only when it will help run subjob */
+			mali_bcast_reset(parent->bcast_core);
+
+			mali_group_start_job_on_group(child, job, subjob);
+
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(child->pp_core)) |
+						      MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH,
+						      mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job), 0, 0, 0);
+
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(child->pp_core)) |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_HW_VIRTUAL,
+						      mali_pp_job_get_pid(job), mali_pp_job_get_tid(job), 0, 0, 0);
+#if defined(CONFIG_MALI400_PROFILING)
+			trace_mali_core_active(mali_pp_job_get_pid(job), 1 /* active */, 0 /* PP */, mali_pp_core_get_id(child->pp_core),
+					       mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job));
+#endif
+		}
+	}
+
+	MALI_DEBUG_CODE(mali_group_print_virtual(parent);)
 }
 
-void mali_group_resume_gp_with_new_heap(struct mali_group *group, u32 job_id, u32 start_addr, u32 end_addr)
+/**
+ * @brief Remove child group from virtual group parent
+ *
+ * After the child is removed, it's state will be LEAVING_VIRTUAL and must be set
+ * to IDLE before it can be used.
+ */
+void mali_group_remove_group(struct mali_group *parent, struct mali_group *child)
 {
-	mali_group_lock(group);
+	u32 i;
 
-	if (group->gp_state != MALI_GROUP_CORE_STATE_OOM ||
-	    mali_gp_job_get_id(group->gp_running_job) != job_id)
-	{
-		mali_group_unlock(group);
-		return; /* Illegal request or job has already been aborted */
-	}
+	MALI_ASSERT_GROUP_LOCKED(parent);
 
-	mali_cluster_l2_cache_invalidate_all_force(group->cluster);
-	mali_mmu_zap_tlb_without_stall(group->mmu);
+	MALI_DEBUG_PRINT(3, ("Removing group %p from virtual group %p\n", child, parent));
 
-	mali_gp_resume_with_new_heap(group->gp_core, start_addr, end_addr);
-	group->gp_state = MALI_GROUP_CORE_STATE_WORKING;
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(parent));
+	MALI_DEBUG_ASSERT(!mali_group_is_virtual(child));
+	MALI_DEBUG_ASSERT(parent == child->parent_group);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IN_VIRTUAL == child->state);
+	/* Removing groups while running is not yet supported. */
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE == parent->state);
 
-	mali_group_unlock(group);
-}
+	mali_group_lock(child);
 
-void mali_group_abort_gp_job(struct mali_group *group, u32 job_id)
-{
-	mali_group_lock(group);
+	/* Update Broadcast Unit and DLBU */
+	mali_bcast_remove_group(parent->bcast_core, child);
+	mali_dlbu_remove_group(parent->dlbu_core, child);
 
-	if (group->gp_state == MALI_GROUP_CORE_STATE_IDLE ||
-	    mali_gp_job_get_id(group->gp_running_job) != job_id)
-	{
-		mali_group_unlock(group);
-		return; /* No need to cancel or job has already been aborted or completed */
+	/* Update HW only if power is on */
+	if (mali_pm_is_power_on()) {
+		mali_bcast_reset(parent->bcast_core);
+		mali_dlbu_update_mask(parent->dlbu_core);
 	}
 
-	mali_group_complete_jobs(group, MALI_TRUE, MALI_FALSE, MALI_FALSE); /* Will release group lock */
-}
+	_mali_osk_list_delinit(&child->group_list);
 
-void mali_group_abort_pp_job(struct mali_group *group, u32 job_id)
-{
-	mali_group_lock(group);
+	child->session = parent->session;
+	child->parent_group = NULL;
+	child->state = MALI_GROUP_STATE_LEAVING_VIRTUAL;
 
-	if (group->pp_state == MALI_GROUP_CORE_STATE_IDLE ||
-	    mali_pp_job_get_id(group->pp_running_job) != job_id)
-	{
-		mali_group_unlock(group);
-		return; /* No need to cancel or job has already been aborted or completed */
+	/* Keep track of the L2 cache cores of child groups */
+	i = (child->l2_cache_core[0] == parent->l2_cache_core[0]) ? 0 : 1;
+
+	MALI_DEBUG_ASSERT(child->l2_cache_core[0] == parent->l2_cache_core[i]);
+
+	parent->l2_cache_core_ref_count[i]--;
+
+	if (parent->l2_cache_core_ref_count[i] == 0) {
+		parent->l2_cache_core[i] = NULL;
 	}
 
-	mali_group_complete_jobs(group, MALI_FALSE, MALI_TRUE, MALI_FALSE); /* Will release group lock */
+	MALI_DEBUG_CODE(mali_group_print_virtual(parent));
+
+	mali_group_unlock(child);
 }
 
-void mali_group_abort_session(struct mali_group *group, struct mali_session_data *session)
+struct mali_group *mali_group_acquire_group(struct mali_group *parent)
 {
-	struct mali_gp_job *gp_job;
-	struct mali_pp_job *pp_job;
-	u32 gp_job_id = 0;
-	u32 pp_job_id = 0;
-	mali_bool abort_pp = MALI_FALSE;
-	mali_bool abort_gp = MALI_FALSE;
+	struct mali_group *child;
 
-	mali_group_lock(group);
+	MALI_ASSERT_GROUP_LOCKED(parent);
 
-	gp_job = group->gp_running_job;
-	pp_job = group->pp_running_job;
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(parent));
+	MALI_DEBUG_ASSERT(!_mali_osk_list_empty(&parent->group_list));
 
-	if (gp_job && mali_gp_job_get_session(gp_job) == session)
-	{
-		MALI_DEBUG_PRINT(4, ("Aborting GP job 0x%08x from session 0x%08x\n", gp_job, session));
+	child = _MALI_OSK_LIST_ENTRY(parent->group_list.prev, struct mali_group, group_list);
 
-		gp_job_id = mali_gp_job_get_id(gp_job);
-		abort_gp = MALI_TRUE;
-	}
+	mali_group_remove_group(parent, child);
 
-	if (pp_job && mali_pp_job_get_session(pp_job) == session)
-	{
-		MALI_DEBUG_PRINT(4, ("Mali group: Aborting PP job 0x%08x from session 0x%08x\n", pp_job, session));
+	return child;
+}
 
-		pp_job_id = mali_pp_job_get_id(pp_job);
-		abort_pp = MALI_TRUE;
+void mali_group_reset(struct mali_group *group)
+{
+	/*
+	 * This function should not be used to abort jobs,
+	 * currently only called during insmod and PM resume
+	 */
+	MALI_DEBUG_ASSERT_LOCK_HELD(group->lock);
+	MALI_DEBUG_ASSERT(NULL == group->gp_running_job);
+	MALI_DEBUG_ASSERT(NULL == group->pp_running_job);
+
+	group->session = NULL;
+
+	if (NULL != group->dlbu_core) {
+		mali_dlbu_reset(group->dlbu_core);
 	}
 
-	mali_group_unlock(group);
+	if (NULL != group->bcast_core) {
+		mali_bcast_reset(group->bcast_core);
+	}
 
-	/* These functions takes and releases the group lock */
-	if (0 != abort_gp)
-	{
-		mali_group_abort_gp_job(group, gp_job_id);
+	if (NULL != group->mmu) {
+		mali_group_reset_mmu(group);
 	}
-	if (0 != abort_pp)
-	{
-		mali_group_abort_pp_job(group, pp_job_id);
+
+	if (NULL != group->gp_core) {
+		mali_gp_reset(group->gp_core);
 	}
 
-	mali_group_lock(group);
-	mali_group_remove_session_if_unused(group, session);
-	mali_group_unlock(group);
+	if (NULL != group->pp_core) {
+		mali_group_reset_pp(group);
+	}
 }
 
-enum mali_group_core_state mali_group_gp_state(struct mali_group *group)
+/* This function is called before running a job on virtual group
+ * Remove some child group from the bcast mask necessarily
+ * Set child groups particular registers respectively etc
+ */
+static void mali_group_job_prepare_virtual(struct mali_group *group, struct mali_pp_job *job,
+		u32 first_subjob, u32 last_subjob)
 {
-	return group->gp_state;
-}
+	struct mali_group *child;
+	struct mali_group *temp;
+	u32 subjob = first_subjob;
 
-enum mali_group_core_state mali_group_pp_state(struct mali_group *group)
-{
-	return group->pp_state;
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT(mali_pp_job_is_virtual_group_job(job));
+
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(group));
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	MALI_DEBUG_ASSERT(first_subjob <= last_subjob);
+
+	/* Set each core specific registers:
+	 * 1. Renderer List Address
+	 * 2. Fragment Shader Stack Address
+	 * Other general registers are set through Broadcast Unit in one go.
+	 * Note: for Addtional temporary unused group core in virtual group
+	 * we need to remove it from Broadcast Unit before start the job in
+	 * this virtual group, otherwise, we may never get Frame_end interrupt.
+	 */
+	if (!mali_pp_job_is_with_dlbu(job)) {
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			if (subjob <= last_subjob) {
+				/* Write specific Renderer List Address for each group */
+				mali_pp_write_addr_renderer_list(child->pp_core, job, subjob);
+				/* Write specific stack address for each child group */
+				mali_pp_write_addr_stack(child->pp_core, job, subjob);
+				subjob++;
+				MALI_DEBUG_PRINT(4, ("Mali Virtual Group: Virtual group job %u (0x%08X) part %u/%u started.\n",
+						     mali_pp_job_get_id(job), job, subjob,
+						     mali_pp_job_get_sub_job_count(job)));
+			} else {
+				/* Some physical group are just redundant for this run
+				 * remove it from broadcast
+				 */
+				mali_bcast_remove_group(group->bcast_core, child);
+				MALI_DEBUG_PRINT(4, ("Mali Virtual Group: Remained PP group %0x remove from bcast_core\n", (int)child));
+			}
+		}
+
+		/* Reset broadcast */
+		mali_bcast_reset(group->bcast_core);
+	} else {
+		/* Write stack address for each child group */
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			mali_pp_write_addr_stack(child->pp_core, job, child->pp_core->core_id);
+			mali_bcast_add_group(group->bcast_core, child);
+		}
+
+		/* Reset broadcast */
+		mali_bcast_reset(group->bcast_core);
+
+		mali_dlbu_config_job(group->dlbu_core, job);
+
+		/* Write Renderer List Address for each child group */
+		mali_pp_write_addr_renderer_list(group->pp_core, job, 0);
+
+		MALI_DEBUG_PRINT(4, ("Mali Virtual Group: Virtual job %u (0x%08X) part %u/%u started (from schedule).\n",
+				     mali_pp_job_get_id(job), job, 1,
+				     mali_pp_job_get_sub_job_count(job)));
+	}
 }
 
-/* group lock need to be taken before calling mali_group_bottom_half */
-void mali_group_bottom_half(struct mali_group *group, enum mali_group_event_t event)
+/* Call this function to make sure group->group_list are consistent with the group->broad_core mask */
+void mali_group_non_dlbu_job_done_virtual(struct mali_group *group)
 {
+	struct mali_group *child, *temp;
+
 	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(group));
 
-	switch (event)
-	{
-		case GROUP_EVENT_PP_JOB_COMPLETED:
-			mali_group_complete_jobs(group, MALI_FALSE, MALI_TRUE, MALI_TRUE); /* PP job SUCCESS */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_PP_JOB_FAILED:
-			mali_group_complete_jobs(group, MALI_FALSE, MALI_TRUE, MALI_FALSE); /* PP job FAIL */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_PP_JOB_TIMED_OUT:
-			mali_group_complete_jobs(group, MALI_FALSE, MALI_TRUE, MALI_FALSE); /* PP job TIMEOUT */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_GP_JOB_COMPLETED:
-			mali_group_complete_jobs(group, MALI_TRUE, MALI_FALSE, MALI_TRUE); /* GP job SUCCESS */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_GP_JOB_FAILED:
-			mali_group_complete_jobs(group, MALI_TRUE, MALI_FALSE, MALI_FALSE); /* GP job FAIL */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_GP_JOB_TIMED_OUT:
-			mali_group_complete_jobs(group, MALI_TRUE, MALI_FALSE, MALI_FALSE); /* GP job TIMEOUT */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		case GROUP_EVENT_GP_OOM:
-			group->gp_state = MALI_GROUP_CORE_STATE_OOM;
-			mali_group_unlock(group); /* Nothing to do on the HW side, so just release group lock right away */
-			mali_gp_scheduler_oom(group, group->gp_running_job);
-			break;
-		case GROUP_EVENT_MMU_PAGE_FAULT:
-			mali_group_complete_jobs(group, MALI_TRUE, MALI_TRUE, MALI_FALSE); /* GP and PP job FAIL */
-			/* group lock is released by mali_group_complete_jobs() call above */
-			break;
-		default:
-			break;
+	_MALI_OSK_LIST_FOREACHENTRY(child, temp,
+				    &group->group_list, struct mali_group, group_list) {
+		mali_bcast_add_group(group->bcast_core, child);
 	}
+
+	MALI_DEBUG_PRINT(3, ("Mali group: New physical groups added in virtual group at non dlbu job done"));
+	/**
+	 * When new physical groups added in the virtual groups, they may have different
+	 * page directory with the virtual group. Here just activate the empty page directory
+	 * for the virtual group to avoid potential inconsistent page directory.
+	 */
+	mali_mmu_activate_empty_page_directory(group->mmu);
+	group->session = NULL;
 }
 
-struct mali_mmu_core *mali_group_get_mmu(struct mali_group *group)
+struct mali_gp_core *mali_group_get_gp_core(struct mali_group *group)
 {
-	return group->mmu;
+	return group->gp_core;
 }
 
-struct mali_session_data *mali_group_get_session(struct mali_group *group)
+struct mali_pp_core *mali_group_get_pp_core(struct mali_group *group)
 {
-	return group->session;
+	return group->pp_core;
 }
 
-struct mali_group *mali_group_get_glob_group(u32 index)
+void mali_group_start_gp_job(struct mali_group *group, struct mali_gp_job *job)
 {
-	if(mali_global_num_groups > index)
-	{
-		return mali_global_groups[index];
+	struct mali_session_data *session;
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE == group->state);
+
+	session = mali_gp_job_get_session(job);
+
+	if (NULL != group->l2_cache_core[0]) {
+		mali_l2_cache_invalidate_conditional(group->l2_cache_core[0], mali_gp_job_get_cache_order(job));
 	}
 
-	return NULL;
-}
+	mali_group_activate_page_directory(group, session);
 
-u32 mali_group_get_glob_num_groups(void)
-{
-	return mali_global_num_groups;
+	mali_gp_job_start(group->gp_core, job);
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE |
+				      MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0) |
+				      MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH,
+				      mali_gp_job_get_frame_builder_id(job), mali_gp_job_get_flush_id(job), 0, 0, 0);
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+				      MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0),
+				      mali_gp_job_get_pid(job), mali_gp_job_get_tid(job), 0, 0, 0);
+
+#if defined(CONFIG_MALI400_PROFILING)
+	trace_mali_core_active(mali_gp_job_get_pid(job), 1 /* active */, 1 /* GP */,  0 /* core */,
+			       mali_gp_job_get_frame_builder_id(job), mali_gp_job_get_flush_id(job));
+#endif
+
+#if defined(CONFIG_MALI400_PROFILING)
+	if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+	    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0])))
+		mali_group_report_l2_cache_counters_per_core(group, 0);
+#endif /* #if defined(CONFIG_MALI400_PROFILING) */
+
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+	trace_gpu_sched_switch(mali_gp_get_hw_core_desc(group->gp_core), sched_clock(),
+			       mali_gp_job_get_pid(job), 0, mali_gp_job_get_id(job));
+#endif
+
+	group->gp_running_job = job;
+	group->state = MALI_GROUP_STATE_WORKING;
+
+	/* Setup the timeout timer value and save the job id for the job running on the gp core */
+	_mali_osk_timer_mod(group->timeout_timer, _mali_osk_time_mstoticks(mali_max_job_runtime));
 }
 
-/* Used to check if scheduler for the other core type needs to be called on job completion.
- *
- * Used only for Mali-200, where job start may fail if the only MMU is busy
- * with another session's address space.
+/* Used to set all the registers except frame renderer list address and fragment shader stack address
+ * It means the caller must set these two registers properly before calling this function
  */
-static inline mali_bool mali_group_other_reschedule_needed(struct mali_group *group)
+static void mali_group_start_pp_job(struct mali_group *group, struct mali_pp_job *job, u32 sub_job)
 {
+	struct mali_session_data *session;
+
 	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE == group->state);
 
-#if defined(USING_MALI200)
-	if (group->pagedir_activation_failed)
-	{
-		group->pagedir_activation_failed = MALI_FALSE;
-		return MALI_TRUE;
-	}
-	else
-#endif
-	{
-		return MALI_FALSE;
+	session = mali_pp_job_get_session(job);
+
+	if (NULL != group->l2_cache_core[0]) {
+		mali_l2_cache_invalidate_conditional(group->l2_cache_core[0], mali_pp_job_get_cache_order(job));
 	}
-}
 
-static enum mali_group_activate_pd_status mali_group_activate_page_directory(struct mali_group *group, struct mali_session_data *session)
-{
-	enum mali_group_activate_pd_status retval;
-	MALI_ASSERT_GROUP_LOCKED(group);
+	if (NULL != group->l2_cache_core[1]) {
+		mali_l2_cache_invalidate_conditional(group->l2_cache_core[1], mali_pp_job_get_cache_order(job));
+	}
 
-	MALI_DEBUG_PRINT(5, ("Mali group: Activating page directory 0x%08X from session 0x%08X on group 0x%08X\n", mali_session_get_page_directory(session), session, group));
-	MALI_DEBUG_ASSERT(0 <= group->page_dir_ref_count);
+	mali_group_activate_page_directory(group, session);
 
-	if (0 != group->page_dir_ref_count)
-	{
-		if (group->session != session)
-		{
-			MALI_DEBUG_PRINT(4, ("Mali group: Activating session FAILED: 0x%08x on group 0x%08X. Existing session: 0x%08x\n", session, group, group->session));
-			return MALI_GROUP_ACTIVATE_PD_STATUS_FAILED;
-		}
-		else
-		{
-			MALI_DEBUG_PRINT(4, ("Mali group: Activating session already activated: 0x%08x on group 0x%08X. New Ref: %d\n", session, group, 1+group->page_dir_ref_count));
-			retval = MALI_GROUP_ACTIVATE_PD_STATUS_OK_KEPT_PD;
+	if (mali_group_is_virtual(group)) {
+		MALI_DEBUG_ASSERT(mali_pp_job_is_virtual_group_job(job));
 
+		/* Try to use DMA unit to start job, fallback to writing directly to the core */
+		MALI_DEBUG_ASSERT(mali_dma_cmd_buf_is_valid(&job->dma_cmd_buf));
+		if (_MALI_OSK_ERR_OK != mali_dma_start(mali_dma_get_global_dma_core(), &job->dma_cmd_buf)) {
+			mali_pp_job_start(group->pp_core, job, sub_job);
 		}
+	} else {
+		mali_pp_job_start(group->pp_core, job, sub_job);
 	}
-	else
-	{
-		/* There might be another session here, but it is ok to overwrite it since group->page_dir_ref_count==0 */
-		if (group->session != session)
-		{
-			mali_bool activate_success;
-			MALI_DEBUG_PRINT(5, ("Mali group: Activate session: %08x previous: %08x on group 0x%08X. Ref: %d\n", session, group->session, group, 1+group->page_dir_ref_count));
 
-			activate_success = mali_mmu_activate_page_directory(group->mmu, mali_session_get_page_directory(session));
-			MALI_DEBUG_ASSERT(activate_success);
-			if ( MALI_FALSE== activate_success ) return MALI_FALSE;
-			group->session = session;
-			retval = MALI_GROUP_ACTIVATE_PD_STATUS_OK_SWITCHED_PD;
+	/* if the group is virtual, loop through physical groups which belong to this group
+	 * and call profiling events for its cores as virtual */
+	if (MALI_TRUE == mali_group_is_virtual(group)) {
+		struct mali_group *child;
+		struct mali_group *temp;
+
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(child->pp_core)) |
+						      MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH,
+						      mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job), 0, 0, 0);
+
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(child->pp_core)) |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_HW_VIRTUAL,
+						      mali_pp_job_get_pid(job), mali_pp_job_get_tid(job), 0, 0, 0);
+
+#if defined(CONFIG_MALI400_PROFILING)
+			trace_mali_core_active(mali_pp_job_get_pid(job), 1 /* active */, 0 /* PP */, mali_pp_core_get_id(child->pp_core),
+					       mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job));
+#endif
 		}
-		else
-		{
-			MALI_DEBUG_PRINT(4, ("Mali group: Activate existing session 0x%08X on group 0x%08X. Ref: %d\n", session->page_directory, group, 1+group->page_dir_ref_count));
-			retval = MALI_GROUP_ACTIVATE_PD_STATUS_OK_KEPT_PD;
+#if defined(CONFIG_MALI400_PROFILING)
+		if (0 != group->l2_cache_core_ref_count[0]) {
+			if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+			    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0]))) {
+				mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[0]));
+			}
+		}
+		if (0 != group->l2_cache_core_ref_count[1]) {
+			if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[1])) &&
+			    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[1]))) {
+				mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[1]));
+			}
+		}
+#endif /* #if defined(CONFIG_MALI400_PROFILING) */
+	} else { /* group is physical - call profiling events for physical cores */
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE |
+					      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(group->pp_core)) |
+					      MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH,
+					      mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job), 0, 0, 0);
+
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+					      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(group->pp_core)) |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_HW_PHYSICAL,
+					      mali_pp_job_get_pid(job), mali_pp_job_get_tid(job), 0, 0, 0);
+
+#if defined(CONFIG_MALI400_PROFILING)
+		trace_mali_core_active(mali_pp_job_get_pid(job), 1 /* active */, 0 /* PP */, mali_pp_core_get_id(group->pp_core),
+				       mali_pp_job_get_frame_builder_id(job), mali_pp_job_get_flush_id(job));
+#endif
+
+#if defined(CONFIG_MALI400_PROFILING)
+		if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+		    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0]))) {
+			mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[0]));
 		}
+#endif /* #if defined(CONFIG_MALI400_PROFILING) */
 	}
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+	trace_gpu_sched_switch(mali_pp_get_hw_core_desc(group->pp_core), sched_clock(), mali_pp_job_get_tid(job), 0, mali_pp_job_get_id(job));
+#endif
+	group->pp_running_job = job;
+	group->pp_running_sub_job = sub_job;
+	group->state = MALI_GROUP_STATE_WORKING;
 
-	group->page_dir_ref_count++;
-	return retval;
+	/* Setup the timeout timer value and save the job id for the job running on the pp core */
+	_mali_osk_timer_mod(group->timeout_timer, _mali_osk_time_mstoticks(mali_max_job_runtime));
 }
 
-static void mali_group_deactivate_page_directory(struct mali_group *group, struct mali_session_data *session)
+void mali_group_start_job_on_virtual(struct mali_group *group, struct mali_pp_job *job,
+				     u32 first_subjob, u32 last_subjob)
 {
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT(mali_pp_job_is_virtual_group_job(job));
+
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(group));
 	MALI_ASSERT_GROUP_LOCKED(group);
 
-	MALI_DEBUG_ASSERT(0 < group->page_dir_ref_count);
-	MALI_DEBUG_ASSERT(session == group->session);
+	MALI_DEBUG_ASSERT(first_subjob <= last_subjob);
 
-	group->page_dir_ref_count--;
+	/* Prepare the group for running this job */
+	mali_group_job_prepare_virtual(group, job, first_subjob, last_subjob);
 
-	/* As an optimization, the MMU still points to the group->session even if (0 == group->page_dir_ref_count),
-	   and we do not call mali_mmu_activate_empty_page_directory(group->mmu); */
-	MALI_DEBUG_ASSERT(0 <= group->page_dir_ref_count);
+	/* Start job. General setting for all the PP cores */
+	mali_group_start_pp_job(group, job, first_subjob);
 }
 
-void mali_group_remove_session_if_unused(struct mali_group *group, struct mali_session_data *session)
+void mali_group_start_job_on_group(struct mali_group *group, struct mali_pp_job *job, u32 subjob)
 {
-	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(!mali_group_is_virtual(group));
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE == group->state || MALI_GROUP_STATE_IN_VIRTUAL == group->state);
+
+	/*
+	 * There are two frame registers which are different for each sub job:
+	 * 1. The Renderer List Address Register (MALI200_REG_ADDR_FRAME)
+	 * 2. The FS Stack Address Register (MALI200_REG_ADDR_STACK)
+	 */
+	mali_pp_write_addr_renderer_list(group->pp_core, job, subjob);
+
+	/* Write specific stack address for each child group */
+	mali_pp_write_addr_stack(group->pp_core, job, subjob);
+
+	/* For start a job in a group which is just joining the virtual group
+	 * just start the job directly, all the accouting information and state
+	 * updates have been covered by virtual group state
+	 */
+	if (MALI_GROUP_STATE_IN_VIRTUAL == group->state) {
+		mali_pp_job_start(group->pp_core, job, subjob);
+		return;
+	}
 
-	if (0 == group->page_dir_ref_count)
-	{
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->gp_state);
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->pp_state);
+	/* Start job. General setting for all the PP cores */
+	mali_group_start_pp_job(group, job, subjob);
+}
 
-		if (group->session == session)
-		{
-			MALI_DEBUG_ASSERT(MALI_TRUE == group->power_is_on);
-			MALI_DEBUG_PRINT(3, ("Mali group: Deactivating unused session 0x%08X on group %08X\n", session, group));
-			mali_mmu_activate_empty_page_directory(group->mmu);
-			group->session = NULL;
+
+
+struct mali_gp_job *mali_group_resume_gp_with_new_heap(struct mali_group *group, u32 job_id, u32 start_addr, u32 end_addr)
+{
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	if (group->state != MALI_GROUP_STATE_OOM ||
+	    mali_gp_job_get_id(group->gp_running_job) != job_id) {
+		return NULL; /* Illegal request or job has already been aborted */
+	}
+
+	if (NULL != group->l2_cache_core[0]) {
+		mali_l2_cache_invalidate(group->l2_cache_core[0]);
+	}
+
+	mali_mmu_zap_tlb_without_stall(group->mmu);
+
+	mali_gp_resume_with_new_heap(group->gp_core, start_addr, end_addr);
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_RESUME | MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0), 0, 0, 0, 0, 0);
+
+#if defined(CONFIG_MALI400_PROFILING)
+	trace_mali_core_active(mali_gp_job_get_pid(group->gp_running_job), 1 /* active */, 1 /* GP */,  0 /* core */,
+			       mali_gp_job_get_frame_builder_id(group->gp_running_job), mali_gp_job_get_flush_id(group->gp_running_job));
+#endif
+
+	group->state = MALI_GROUP_STATE_WORKING;
+
+	return group->gp_running_job;
+}
+
+static void mali_group_reset_mmu(struct mali_group *group)
+{
+	struct mali_group *child;
+	struct mali_group *temp;
+	_mali_osk_errcode_t err;
+
+	if (!mali_group_is_virtual(group)) {
+		/* This is a physical group or an idle virtual group -- simply wait for
+		 * the reset to complete. */
+		err = mali_mmu_reset(group->mmu);
+		MALI_DEBUG_ASSERT(_MALI_OSK_ERR_OK == err);
+	} else { /* virtual group */
+		err = mali_mmu_reset(group->mmu);
+		if (_MALI_OSK_ERR_OK == err) {
+			return;
+		}
+
+		/* Loop through all members of this virtual group and wait
+		 * until they are done resetting.
+		 */
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			err = mali_mmu_reset(child->mmu);
+			MALI_DEBUG_ASSERT(_MALI_OSK_ERR_OK == err);
 		}
 	}
 }
 
-void mali_group_power_on(void)
+static void mali_group_reset_pp(struct mali_group *group)
 {
-	int i;
-	for (i = 0; i < mali_global_num_groups; i++)
-	{
-		struct mali_group *group = mali_global_groups[i];
-		mali_group_lock(group);
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->gp_state);
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->pp_state);
-		MALI_DEBUG_ASSERT_POINTER(group->cluster);
-		group->power_is_on = MALI_TRUE;
-		mali_cluster_power_is_enabled_set(group->cluster, MALI_TRUE);
+	struct mali_group *child;
+	struct mali_group *temp;
+
+	mali_pp_reset_async(group->pp_core);
+
+	if (!mali_group_is_virtual(group) || NULL == group->pp_running_job) {
+		/* This is a physical group or an idle virtual group -- simply wait for
+		 * the reset to complete. */
+		mali_pp_reset_wait(group->pp_core);
+	} else { /* virtual group */
+		/* Loop through all members of this virtual group and wait until they
+		 * are done resetting.
+		 */
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+			mali_pp_reset_wait(child->pp_core);
+		}
+	}
+}
+
+/* Group must be locked when entering this function.  Will be unlocked before exiting. */
+static void mali_group_complete_pp_and_unlock(struct mali_group *group, mali_bool success, mali_bool in_upper_half)
+{
+	struct mali_pp_job *pp_job_to_return;
+	u32 pp_sub_job_to_return;
+
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_POINTER(group->pp_core);
+	MALI_DEBUG_ASSERT_POINTER(group->pp_running_job);
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	mali_group_post_process_job_pp(group);
+
+	if (success) {
+		/* Only do soft reset for successful jobs, a full recovery
+		 * reset will be done for failed jobs. */
+		mali_pp_reset_async(group->pp_core);
+	}
+
+	pp_job_to_return = group->pp_running_job;
+	pp_sub_job_to_return = group->pp_running_sub_job;
+	group->state = MALI_GROUP_STATE_IDLE;
+	group->pp_running_job = NULL;
+
+	if (!success) {
+		MALI_DEBUG_PRINT(2, ("Mali group: Executing recovery reset due to job failure\n"));
+		mali_group_recovery_reset(group);
+	} else if (_MALI_OSK_ERR_OK != mali_pp_reset_wait(group->pp_core)) {
+		MALI_PRINT_ERROR(("Mali group: Executing recovery reset due to reset failure\n"));
+		mali_group_recovery_reset(group);
+	}
+
+	/* Return job to user, schedule and unlock group. */
+	mali_pp_scheduler_job_done(group, pp_job_to_return, pp_sub_job_to_return, success, in_upper_half);
+}
+
+/* Group must be locked when entering this function.  Will be unlocked before exiting. */
+static void mali_group_complete_gp_and_unlock(struct mali_group *group, mali_bool success)
+{
+	struct mali_gp_job *gp_job_to_return;
+
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_POINTER(group->gp_core);
+	MALI_DEBUG_ASSERT_POINTER(group->gp_running_job);
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	mali_group_post_process_job_gp(group, MALI_FALSE);
+
+	if (success) {
+		/* Only do soft reset for successful jobs, a full recovery
+		 * reset will be done for failed jobs. */
+		mali_gp_reset_async(group->gp_core);
+	}
+
+	gp_job_to_return = group->gp_running_job;
+	group->state = MALI_GROUP_STATE_IDLE;
+	group->gp_running_job = NULL;
+
+	if (!success) {
+		MALI_DEBUG_PRINT(2, ("Mali group: Executing recovery reset due to job failure\n"));
+		mali_group_recovery_reset(group);
+	} else if (_MALI_OSK_ERR_OK != mali_gp_reset_wait(group->gp_core)) {
+		MALI_PRINT_ERROR(("Mali group: Executing recovery reset due to reset failure\n"));
+		mali_group_recovery_reset(group);
+	}
+
+	/* Return job to user, schedule and unlock group. */
+	mali_gp_scheduler_job_done(group, gp_job_to_return, success);
+}
+
+void mali_group_abort_gp_job(struct mali_group *group, u32 job_id)
+{
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	if (MALI_GROUP_STATE_IDLE == group->state ||
+	    mali_gp_job_get_id(group->gp_running_job) != job_id) {
+		return; /* No need to cancel or job has already been aborted or completed */
+	}
+
+	/* Function will unlock the group, so we need to lock it again */
+	mali_group_complete_gp_and_unlock(group, MALI_FALSE);
+	mali_group_lock(group);
+}
+
+static void mali_group_abort_pp_job(struct mali_group *group, u32 job_id)
+{
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	if (MALI_GROUP_STATE_IDLE == group->state ||
+	    mali_pp_job_get_id(group->pp_running_job) != job_id) {
+		return; /* No need to cancel or job has already been aborted or completed */
+	}
+
+	mali_group_complete_pp_and_unlock(group, MALI_FALSE, MALI_FALSE);
+	mali_group_lock(group);
+}
+
+void mali_group_abort_session(struct mali_group *group, struct mali_session_data *session)
+{
+	struct mali_gp_job *gp_job;
+	struct mali_pp_job *pp_job;
+	u32 gp_job_id = 0;
+	u32 pp_job_id = 0;
+	mali_bool abort_pp = MALI_FALSE;
+	mali_bool abort_gp = MALI_FALSE;
+
+	mali_group_lock(group);
+
+	if (mali_group_is_in_virtual(group)) {
+		/* Group is member of a virtual group, don't touch it! */
 		mali_group_unlock(group);
+		return;
+	}
+
+	gp_job = group->gp_running_job;
+	pp_job = group->pp_running_job;
+
+	if ((NULL != gp_job) && (mali_gp_job_get_session(gp_job) == session)) {
+		MALI_DEBUG_PRINT(4, ("Aborting GP job 0x%08x from session 0x%08x\n", gp_job, session));
+
+		gp_job_id = mali_gp_job_get_id(gp_job);
+		abort_gp = MALI_TRUE;
+	}
+
+	if ((NULL != pp_job) && (mali_pp_job_get_session(pp_job) == session)) {
+		MALI_DEBUG_PRINT(4, ("Mali group: Aborting PP job 0x%08x from session 0x%08x\n", pp_job, session));
+
+		pp_job_id = mali_pp_job_get_id(pp_job);
+		abort_pp = MALI_TRUE;
+	}
+
+	if (abort_gp) {
+		mali_group_abort_gp_job(group, gp_job_id);
+	}
+	if (abort_pp) {
+		mali_group_abort_pp_job(group, pp_job_id);
 	}
-	MALI_DEBUG_PRINT(3,("group: POWER ON\n"));
+
+	mali_group_remove_session_if_unused(group, session);
+
+	mali_group_unlock(group);
 }
 
-mali_bool mali_group_power_is_on(struct mali_group *group)
+struct mali_group *mali_group_get_glob_group(u32 index)
+{
+	if (mali_global_num_groups > index) {
+		return mali_global_groups[index];
+	}
+
+	return NULL;
+}
+
+u32 mali_group_get_glob_num_groups(void)
+{
+	return mali_global_num_groups;
+}
+
+static void mali_group_activate_page_directory(struct mali_group *group, struct mali_session_data *session)
+{
+	MALI_ASSERT_GROUP_LOCKED(group);
+
+	MALI_DEBUG_PRINT(5, ("Mali group: Activating page directory 0x%08X from session 0x%08X on group 0x%08X\n", mali_session_get_page_directory(session), session, group));
+
+	if (group->session != session) {
+		/* Different session than last time, so we need to do some work */
+		MALI_DEBUG_PRINT(5, ("Mali group: Activate session: %08x previous: %08x on group 0x%08X\n", session, group->session, group));
+		mali_mmu_activate_page_directory(group->mmu, mali_session_get_page_directory(session));
+		group->session = session;
+	} else {
+		/* Same session as last time, so no work required */
+		MALI_DEBUG_PRINT(4, ("Mali group: Activate existing session 0x%08X on group 0x%08X\n", session->page_directory, group));
+		mali_mmu_zap_tlb_without_stall(group->mmu);
+	}
+}
+
+static void mali_group_remove_session_if_unused(struct mali_group *group, struct mali_session_data *session)
 {
 	MALI_ASSERT_GROUP_LOCKED(group);
+
+	if (MALI_GROUP_STATE_IDLE == group->state) {
+		if (group->session == session) {
+			MALI_DEBUG_ASSERT(MALI_GROUP_STATE_WORKING != group->state);
+			MALI_DEBUG_ASSERT(MALI_TRUE == group->power_is_on);
+			MALI_DEBUG_PRINT(3, ("Mali group: Deactivating unused session 0x%08X on group %08X\n", session, group));
+			mali_mmu_activate_empty_page_directory(group->mmu);
+			group->session = NULL;
+		}
+	}
+}
+
+mali_bool mali_group_power_is_on(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_LOCK_HELD(group->lock);
 	return group->power_is_on;
 }
 
-void mali_group_power_off(void)
+void mali_group_power_on_group(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_LOCK_HELD(group->lock);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE       == group->state
+			  || MALI_GROUP_STATE_IN_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_JOINING_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_LEAVING_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_DISABLED   == group->state);
+
+	MALI_DEBUG_PRINT(3, ("Group %p powered on\n", group));
+
+	group->power_is_on = MALI_TRUE;
+}
+
+void mali_group_power_off_group(struct mali_group *group, mali_bool do_power_change)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_LOCK_HELD(group->lock);
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE       == group->state
+			  || MALI_GROUP_STATE_IN_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_JOINING_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_LEAVING_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_DISABLED   == group->state);
+
+	MALI_DEBUG_PRINT(3, ("Group %p powered off\n", group));
+
+	/* It is necessary to set group->session = NULL so that the powered off MMU is not written
+	 * to on map/unmap.  It is also necessary to set group->power_is_on = MALI_FALSE so that
+	 * pending bottom_halves does not access powered off cores. */
+
+	group->session = NULL;
+
+	if (do_power_change) {
+		group->power_is_on = MALI_FALSE;
+	}
+}
+
+void mali_group_power_on(void)
 {
 	int i;
-	/* It is necessary to set group->session = NULL; so that the powered off MMU is not written to on map /unmap */
-	/* It is necessary to set group->power_is_on=MALI_FALSE so that pending bottom_halves does not access powered off cores. */
-	for (i = 0; i < mali_global_num_groups; i++)
-	{
+	for (i = 0; i < mali_global_num_groups; i++) {
 		struct mali_group *group = mali_global_groups[i];
+
 		mali_group_lock(group);
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->gp_state);
-		MALI_DEBUG_ASSERT(MALI_GROUP_CORE_STATE_IDLE == group->pp_state);
-		MALI_DEBUG_ASSERT_POINTER(group->cluster);
-		group->session = NULL;
-		MALI_DEBUG_ASSERT(MALI_TRUE == group->power_is_on);
-		group->power_is_on = MALI_FALSE;
-		mali_cluster_power_is_enabled_set(group->cluster, MALI_FALSE);
+		if (MALI_GROUP_STATE_DISABLED == group->state) {
+			MALI_DEBUG_ASSERT(MALI_FALSE == group->power_is_on);
+		} else {
+			mali_group_power_on_group(group);
+		}
 		mali_group_unlock(group);
 	}
-	MALI_DEBUG_PRINT(3,("group: POWER OFF\n"));
+	MALI_DEBUG_PRINT(4, ("Mali Group: power on\n"));
 }
 
+void mali_group_power_off(mali_bool do_power_change)
+{
+	int i;
+
+	for (i = 0; i < mali_global_num_groups; i++) {
+		struct mali_group *group = mali_global_groups[i];
+
+		mali_group_lock(group);
+		if (MALI_GROUP_STATE_DISABLED == group->state) {
+			MALI_DEBUG_ASSERT(MALI_FALSE == group->power_is_on);
+		} else {
+			mali_group_power_off_group(group, do_power_change);
+		}
+		mali_group_unlock(group);
+	}
+	MALI_DEBUG_PRINT(4, ("Mali Group: power off\n"));
+}
 
 static void mali_group_recovery_reset(struct mali_group *group)
 {
+	_mali_osk_errcode_t err;
+
 	MALI_ASSERT_GROUP_LOCKED(group);
 
 	/* Stop cores, bus stop */
-	if (NULL != group->pp_core)
-	{
+	if (NULL != group->pp_core) {
 		mali_pp_stop_bus(group->pp_core);
-	}
-	if (NULL != group->gp_core)
-	{
+	} else {
 		mali_gp_stop_bus(group->gp_core);
 	}
 
-	/* Flush MMU */
+	/* Flush MMU and clear page fault (if any) */
 	mali_mmu_activate_fault_flush_page_directory(group->mmu);
 	mali_mmu_page_fault_done(group->mmu);
 
-	/* Wait for cores to stop bus */
-	if (NULL != group->pp_core)
-	{
-		mali_pp_stop_bus_wait(group->pp_core);
-	}
-	if (NULL != group->gp_core)
-	{
-		mali_gp_stop_bus_wait(group->gp_core);
-	}
+	/* Wait for cores to stop bus, then do a hard reset on them */
+	if (NULL != group->pp_core) {
+		if (mali_group_is_virtual(group)) {
+			struct mali_group *child, *temp;
 
-	/* Reset cores */
-	if (NULL != group->pp_core)
-	{
-		mali_pp_hard_reset(group->pp_core);
-	}
-	if (NULL != group->gp_core)
-	{
+			/* Disable the broadcast unit while we do reset directly on the member cores. */
+			mali_bcast_disable(group->bcast_core);
+
+			_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+				mali_pp_stop_bus_wait(child->pp_core);
+				mali_pp_hard_reset(child->pp_core);
+			}
+
+			mali_bcast_enable(group->bcast_core);
+		} else {
+			mali_pp_stop_bus_wait(group->pp_core);
+			mali_pp_hard_reset(group->pp_core);
+		}
+	} else {
+		mali_gp_stop_bus_wait(group->gp_core);
 		mali_gp_hard_reset(group->gp_core);
 	}
 
 	/* Reset MMU */
-	mali_mmu_reset(group->mmu);
+	err = mali_mmu_reset(group->mmu);
+	MALI_DEBUG_ASSERT(_MALI_OSK_ERR_OK == err);
+	MALI_IGNORE(err);
+
 	group->session = NULL;
 }
 
-/* Group lock need to be taken before calling mali_group_complete_jobs. Will release the lock here. */
-static void mali_group_complete_jobs(struct mali_group *group, mali_bool complete_gp, mali_bool complete_pp, bool success)
+#if MALI_STATE_TRACKING
+u32 mali_group_dump_state(struct mali_group *group, char *buf, u32 size)
 {
-	mali_bool need_group_reset = MALI_FALSE;
-	mali_bool gp_success = success;
-	mali_bool pp_success = success;
+	int n = 0;
+
+	n += _mali_osk_snprintf(buf + n, size - n, "Group: %p\n", group);
+	n += _mali_osk_snprintf(buf + n, size - n, "\tstate: %d\n", group->state);
+	if (group->gp_core) {
+		n += mali_gp_dump_state(group->gp_core, buf + n, size - n);
+		n += _mali_osk_snprintf(buf + n, size - n, "\tGP job: %p\n", group->gp_running_job);
+	}
+	if (group->pp_core) {
+		n += mali_pp_dump_state(group->pp_core, buf + n, size - n);
+		n += _mali_osk_snprintf(buf + n, size - n, "\tPP job: %p, subjob %d \n",
+					group->pp_running_job, group->pp_running_sub_job);
+	}
+
+	return n;
+}
+#endif
 
+/* Group must be locked when entering this function.  Will be unlocked before exiting. */
+static void mali_group_mmu_page_fault_and_unlock(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
 	MALI_ASSERT_GROUP_LOCKED(group);
 
-	if (complete_gp && !complete_pp)
-	{
-		MALI_DEBUG_ASSERT_POINTER(group->gp_core);
-		if (_MALI_OSK_ERR_OK == mali_gp_reset(group->gp_core))
-		{
-			struct mali_gp_job *gp_job_to_return = group->gp_running_job;
-			group->gp_state = MALI_GROUP_CORE_STATE_IDLE;
-			group->gp_running_job = NULL;
+	if (NULL != group->pp_core) {
+		struct mali_pp_job *pp_job_to_return;
+		u32 pp_sub_job_to_return;
 
-			MALI_DEBUG_ASSERT_POINTER(gp_job_to_return);
+		MALI_DEBUG_ASSERT_POINTER(group->pp_running_job);
 
-			mali_group_deactivate_page_directory(group, mali_gp_job_get_session(gp_job_to_return));
+		mali_group_post_process_job_pp(group);
 
-			if(mali_group_other_reschedule_needed(group))
-			{
-				mali_group_unlock(group);
-				mali_pp_scheduler_do_schedule();
-			}
-			else
-			{
-				mali_group_unlock(group);
-			}
+		pp_job_to_return = group->pp_running_job;
+		pp_sub_job_to_return = group->pp_running_sub_job;
+		group->state = MALI_GROUP_STATE_IDLE;
+		group->pp_running_job = NULL;
+
+		mali_group_recovery_reset(group); /* This will also clear the page fault itself */
+
+		/* Will unlock group. */
+		mali_pp_scheduler_job_done(group, pp_job_to_return, pp_sub_job_to_return, MALI_FALSE, MALI_FALSE);
+	} else {
+		struct mali_gp_job *gp_job_to_return;
+
+		MALI_DEBUG_ASSERT_POINTER(group->gp_running_job);
+
+		mali_group_post_process_job_gp(group, MALI_FALSE);
+
+		gp_job_to_return = group->gp_running_job;
+		group->state = MALI_GROUP_STATE_IDLE;
+		group->gp_running_job = NULL;
+
+		mali_group_recovery_reset(group); /* This will also clear the page fault itself */
 
-			mali_gp_scheduler_job_done(group, gp_job_to_return, gp_success);
-			mali_pm_core_event(MALI_CORE_EVENT_GP_STOP); /* It is ok to do this after schedule, since START/STOP is simply ++ and -- anyways */
+		/* Will unlock group. */
+		mali_gp_scheduler_job_done(group, gp_job_to_return, MALI_FALSE);
+	}
+}
+
+_mali_osk_errcode_t mali_group_upper_half_mmu(void *data)
+{
+	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
+	struct mali_group *group = (struct mali_group *)data;
+	struct mali_mmu_core *mmu = group->mmu;
+	u32 int_stat;
+
+	MALI_DEBUG_ASSERT_POINTER(mmu);
+
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	if (MALI_FALSE == mali_pm_domain_lock_state(group->pm_domain)) {
+		goto out;
+	}
+#endif
+
+	/* Check if it was our device which caused the interrupt (we could be sharing the IRQ line) */
+	int_stat = mali_mmu_get_int_status(mmu);
+	if (0 != int_stat) {
+		struct mali_group *parent = group->parent_group;
+
+		/* page fault or bus error, we thread them both in the same way */
+		mali_mmu_mask_all_interrupts(mmu);
+		if (NULL == parent) {
+			_mali_osk_wq_schedule_work(group->bottom_half_work_mmu);
+		} else {
+			_mali_osk_wq_schedule_work(parent->bottom_half_work_mmu);
+		}
+		err = _MALI_OSK_ERR_OK;
+		goto out;
+	}
+
+out:
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	mali_pm_domain_unlock_state(group->pm_domain);
+#endif
+
+	return err;
+}
+
+static void mali_group_bottom_half_mmu(void *data)
+{
+	struct mali_group *group = (struct mali_group *)data;
+	struct mali_mmu_core *mmu = group->mmu;
+	u32 rawstat;
+	MALI_DEBUG_CODE(u32 status);
+
+	MALI_DEBUG_ASSERT_POINTER(mmu);
+
+	mali_group_lock(group);
+
+	MALI_DEBUG_ASSERT(NULL == group->parent_group);
+
+	if (MALI_FALSE == mali_group_power_is_on(group)) {
+		MALI_PRINT_ERROR(("Interrupt bottom half of %s when core is OFF.", mmu->hw_core.description));
+		mali_group_unlock(group);
+		return;
+	}
+
+	rawstat = mali_mmu_get_rawstat(mmu);
+	MALI_DEBUG_CODE(status = mali_mmu_get_status(mmu));
+
+	MALI_DEBUG_PRINT(4, ("Mali MMU: Bottom half, interrupt 0x%08X, status 0x%08X\n", rawstat, status));
+
+	if (rawstat & (MALI_MMU_INTERRUPT_PAGE_FAULT | MALI_MMU_INTERRUPT_READ_BUS_ERROR)) {
+		/* An actual page fault has occurred. */
+#ifdef DEBUG
+		u32 fault_address = mali_mmu_get_page_fault_addr(mmu);
+		MALI_DEBUG_PRINT(2, ("Mali MMU: Page fault detected at 0x%x from bus id %d of type %s on %s\n",
+				     (void *)fault_address,
+				     (status >> 6) & 0x1F,
+				     (status & 32) ? "write" : "read",
+				     mmu->hw_core.description));
+#endif
+
+		mali_group_mmu_page_fault_and_unlock(group);
+		return;
+	}
+
+	mali_group_unlock(group);
+}
+
+_mali_osk_errcode_t mali_group_upper_half_gp(void *data)
+{
+	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
+	struct mali_group *group = (struct mali_group *)data;
+	struct mali_gp_core *core = group->gp_core;
+	u32 irq_readout;
+
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	if (MALI_FALSE == mali_pm_domain_lock_state(group->pm_domain)) {
+		goto out;
+	}
+#endif
+
+	irq_readout = mali_gp_get_int_stat(core);
+
+	if (MALIGP2_REG_VAL_IRQ_MASK_NONE != irq_readout) {
+		/* Mask out all IRQs from this core until IRQ is handled */
+		mali_gp_mask_all_interrupts(core);
+
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE | MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0) | MALI_PROFILING_EVENT_REASON_SINGLE_HW_INTERRUPT, irq_readout, 0, 0, 0, 0);
+
+		/* We do need to handle this in a bottom half */
+		_mali_osk_wq_schedule_work(group->bottom_half_work_gp);
+
+		err = _MALI_OSK_ERR_OK;
+		goto out;
+	}
+
+out:
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	mali_pm_domain_unlock_state(group->pm_domain);
+#endif
+
+	return err;
+}
+
+static void mali_group_bottom_half_gp(void *data)
+{
+	struct mali_group *group = (struct mali_group *)data;
+	u32 irq_readout;
+	u32 irq_errors;
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF, 0, _mali_osk_get_tid(), MALI_PROFILING_MAKE_EVENT_DATA_CORE_GP(0), 0, 0);
+
+	mali_group_lock(group);
 
+	if (MALI_FALSE == mali_group_power_is_on(group)) {
+		MALI_PRINT_ERROR(("Mali group: Interrupt bottom half of %s when core is OFF.", mali_gp_get_hw_core_desc(group->gp_core)));
+		mali_group_unlock(group);
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF, 0, _mali_osk_get_tid(), 0, 0, 0);
+		return;
+	}
+
+	irq_readout = mali_gp_read_rawstat(group->gp_core);
+
+	MALI_DEBUG_PRINT(4, ("Mali group: GP bottom half IRQ 0x%08X from core %s\n", irq_readout, mali_gp_get_hw_core_desc(group->gp_core)));
+
+	if (irq_readout & (MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST | MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST)) {
+		u32 core_status = mali_gp_read_core_status(group->gp_core);
+		if (0 == (core_status & MALIGP2_REG_VAL_STATUS_MASK_ACTIVE)) {
+			MALI_DEBUG_PRINT(4, ("Mali group: GP job completed, calling group handler\n"));
+			group->core_timed_out = MALI_FALSE;
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+						      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+						      0, _mali_osk_get_tid(), 0, 0, 0);
+
+			mali_group_complete_gp_and_unlock(group, MALI_TRUE);
 			return;
 		}
-		else
-		{
-			need_group_reset = MALI_TRUE;
-			MALI_DEBUG_PRINT(3, ("Mali group: Failed to reset GP, need to reset entire group\n"));
-			pp_success = MALI_FALSE; /* This might kill PP as well, so this should fail */
+	}
+
+	/*
+	 * Now lets look at the possible error cases (IRQ indicating error or timeout)
+	 * END_CMD_LST, HANG and PLBU_OOM interrupts are not considered error.
+	 */
+	irq_errors = irq_readout & ~(MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST | MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST | MALIGP2_REG_VAL_IRQ_HANG | MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM);
+	if (0 != irq_errors) {
+		MALI_PRINT_ERROR(("Mali group: Unknown interrupt 0x%08X from core %s, aborting job\n", irq_readout, mali_gp_get_hw_core_desc(group->gp_core)));
+		group->core_timed_out = MALI_FALSE;
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+					      0, _mali_osk_get_tid(), 0, 0, 0);
+
+		mali_group_complete_gp_and_unlock(group, MALI_FALSE);
+		return;
+	} else if (group->core_timed_out) { /* SW timeout */
+		group->core_timed_out = MALI_FALSE;
+		if (!_mali_osk_timer_pending(group->timeout_timer) && NULL != group->gp_running_job) {
+			MALI_PRINT(("Mali group: Job %d timed out\n", mali_gp_job_get_id(group->gp_running_job)));
+
+			mali_group_complete_gp_and_unlock(group, MALI_FALSE);
+			return;
 		}
+	} else if (irq_readout & MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM) {
+		/* GP wants more memory in order to continue. */
+		MALI_DEBUG_PRINT(3, ("Mali group: PLBU needs more heap memory\n"));
+
+		group->state = MALI_GROUP_STATE_OOM;
+		mali_group_unlock(group); /* Nothing to do on the HW side, so just release group lock right away */
+		mali_gp_scheduler_oom(group, group->gp_running_job);
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF, 0, _mali_osk_get_tid(), 0, 0, 0);
+		return;
+	}
+
+	/*
+	 * The only way to get here is if we only got one of two needed END_CMD_LST
+	 * interrupts. Enable all but not the complete interrupt that has been
+	 * received and continue to run.
+	 */
+	mali_gp_enable_interrupts(group->gp_core, irq_readout & (MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST | MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST));
+	mali_group_unlock(group);
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF, 0, _mali_osk_get_tid(), 0, 0, 0);
+}
+
+static void mali_group_post_process_job_gp(struct mali_group *group, mali_bool suspend)
+{
+	/* Stop the timeout timer. */
+	_mali_osk_timer_del_async(group->timeout_timer);
+
+	if (NULL == group->gp_running_job) {
+		/* Nothing to do */
+		return;
 	}
-	if (complete_pp && !complete_gp)
-	{
-		MALI_DEBUG_ASSERT_POINTER(group->pp_core);
-		if (_MALI_OSK_ERR_OK == mali_pp_reset(group->pp_core))
-		{
-			struct mali_pp_job *pp_job_to_return = group->pp_running_job;
-			u32 pp_sub_job_to_return = group->pp_running_sub_job;
-			group->pp_state = MALI_GROUP_CORE_STATE_IDLE;
-			group->pp_running_job = NULL;
 
-			MALI_DEBUG_ASSERT_POINTER(pp_job_to_return);
+	mali_gp_update_performance_counters(group->gp_core, group->gp_running_job, suspend);
+
+#if defined(CONFIG_MALI400_PROFILING)
+	if (suspend) {
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SUSPEND | MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0),
+					      mali_gp_job_get_perf_counter_value0(group->gp_running_job),
+					      mali_gp_job_get_perf_counter_value1(group->gp_running_job),
+					      mali_gp_job_get_perf_counter_src0(group->gp_running_job) | (mali_gp_job_get_perf_counter_src1(group->gp_running_job) << 8),
+					      0, 0);
+	} else {
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP | MALI_PROFILING_MAKE_EVENT_CHANNEL_GP(0),
+					      mali_gp_job_get_perf_counter_value0(group->gp_running_job),
+					      mali_gp_job_get_perf_counter_value1(group->gp_running_job),
+					      mali_gp_job_get_perf_counter_src0(group->gp_running_job) | (mali_gp_job_get_perf_counter_src1(group->gp_running_job) << 8),
+					      0, 0);
+
+		if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+		    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0])))
+			mali_group_report_l2_cache_counters_per_core(group, 0);
+	}
+#endif
 
-			mali_group_deactivate_page_directory(group, mali_pp_job_get_session(pp_job_to_return));
+#if defined(CONFIG_MALI400_PROFILING)
+	trace_mali_core_active(mali_gp_job_get_pid(group->gp_running_job), 0 /* active */, 1 /* GP */,  0 /* core */,
+			       mali_gp_job_get_frame_builder_id(group->gp_running_job), mali_gp_job_get_flush_id(group->gp_running_job));
+#endif
 
-			if(mali_group_other_reschedule_needed(group))
-			{
+	mali_gp_job_set_current_heap_addr(group->gp_running_job,
+					  mali_gp_read_plbu_alloc_start_addr(group->gp_core));
+}
+
+_mali_osk_errcode_t mali_group_upper_half_pp(void *data)
+{
+	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
+	struct mali_group *group = (struct mali_group *)data;
+	struct mali_pp_core *core = group->pp_core;
+	u32 irq_readout;
+
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	if (MALI_FALSE == mali_pm_domain_lock_state(group->pm_domain)) {
+		goto out;
+	}
+#endif
+
+	/*
+	 * For Mali-450 there is one particular case we need to watch out for:
+	 *
+	 * Criteria 1) this function call can be due to a shared interrupt,
+	 * and not necessary because this core signaled an interrupt.
+	 * Criteria 2) this core is a part of a virtual group, and thus it should
+	 * not do any post processing.
+	 * Criteria 3) this core has actually indicated that is has completed by
+	 * having set raw_stat/int_stat registers to != 0
+	 *
+	 * If all this criteria is meet, then we could incorrectly start post
+	 * processing on the wrong group object (this should only happen on the
+	 * parent group)
+	 */
+#if !defined(MALI_UPPER_HALF_SCHEDULING)
+	if (mali_group_is_in_virtual(group)) {
+		/*
+		 * This check is done without the group lock held, which could lead to
+		 * a potential race. This is however ok, since we will safely re-check
+		 * this with the group lock held at a later stage. This is just an
+		 * early out which will strongly benefit shared IRQ systems.
+		 */
+		err = _MALI_OSK_ERR_OK;
+		goto out;
+	}
+#endif
+
+	irq_readout = mali_pp_get_int_stat(core);
+	if (MALI200_REG_VAL_IRQ_MASK_NONE != irq_readout) {
+		/* Mask out all IRQs from this core until IRQ is handled */
+		mali_pp_mask_all_interrupts(core);
+
+#if defined(CONFIG_MALI400_PROFILING)
+		/* Currently no support for this interrupt event for the virtual PP core */
+		if (!mali_group_is_virtual(group)) {
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(core->core_id) |
+						      MALI_PROFILING_EVENT_REASON_SINGLE_HW_INTERRUPT,
+						      irq_readout, 0, 0, 0, 0);
+		}
+#endif
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+		/* Check if job is complete without errors */
+		if (MALI200_REG_VAL_IRQ_END_OF_FRAME == irq_readout) {
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+						      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF,
+						      0, 0, MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
+
+			MALI_DEBUG_PRINT(3, ("Mali PP: Job completed, calling group handler from upper half\n"));
+
+			mali_group_lock(group);
+
+			/* Check if job is complete without errors, again, after taking the group lock */
+			irq_readout = mali_pp_read_rawstat(core);
+			if (MALI200_REG_VAL_IRQ_END_OF_FRAME != irq_readout) {
+				mali_pp_enable_interrupts(core);
 				mali_group_unlock(group);
-				mali_gp_scheduler_do_schedule();
+				_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+							      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+							      MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF,
+							      0, 0, MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
+				err = _MALI_OSK_ERR_OK;
+				goto out;
+			}
+
+			if (mali_group_is_virtual(group)) {
+				u32 status_readout = mali_pp_read_status(group->pp_core);
+				if (status_readout & MALI200_REG_VAL_STATUS_RENDERING_ACTIVE) {
+					MALI_DEBUG_PRINT(6, ("Mali PP: Not all cores in broadcast completed\n"));
+					mali_pp_enable_interrupts(core);
+					mali_group_unlock(group);
+					_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+								      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+								      MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF,
+								      0, 0, MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
+					err = _MALI_OSK_ERR_OK;
+					goto out;
+				}
 			}
-			else
-			{
+
+			if (mali_group_is_in_virtual(group)) {
+				/* We're member of a virtual group, so interrupt should be handled by the virtual group */
+				mali_pp_enable_interrupts(core);
 				mali_group_unlock(group);
+				_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+							      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+							      MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF,
+							      0, 0, MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
+				err =  _MALI_OSK_ERR_FAULT;
+				goto out;
 			}
 
-			mali_pp_scheduler_job_done(group, pp_job_to_return, pp_sub_job_to_return, pp_success);
-			mali_pm_core_event(MALI_CORE_EVENT_PP_STOP); /* It is ok to do this after schedule, since START/STOP is simply ++ and -- anyways */
+			group->core_timed_out = MALI_FALSE;
 
-			return;
-		}
-		else
-		{
-			need_group_reset = MALI_TRUE;
-			MALI_DEBUG_PRINT(3, ("Mali group: Failed to reset PP, need to reset entire group\n"));
-			gp_success = MALI_FALSE; /* This might kill GP as well, so this should fail */
+			mali_group_complete_pp_and_unlock(group, MALI_TRUE, MALI_TRUE);
+
+			/* No need to enable interrupts again, since the core will be reset while completing the job */
+
+			MALI_DEBUG_PRINT(6, ("Mali PP: Upper half job done\n"));
+
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+						      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF,
+						      0, 0, MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
+
+			err = _MALI_OSK_ERR_OK;
+			goto out;
 		}
-	}
-	else if (complete_gp && complete_pp)
-	{
-		need_group_reset = MALI_TRUE;
+#endif
+
+		/* We do need to handle this in a bottom half */
+		_mali_osk_wq_schedule_work(group->bottom_half_work_pp);
+		err = _MALI_OSK_ERR_OK;
+		goto out;
 	}
 
-	if (MALI_TRUE == need_group_reset)
-	{
-		struct mali_gp_job *gp_job_to_return = group->gp_running_job;
-		struct mali_pp_job *pp_job_to_return = group->pp_running_job;
-		u32 pp_sub_job_to_return = group->pp_running_sub_job;
-		mali_bool schedule_other = MALI_FALSE;
+out:
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	mali_pm_domain_unlock_state(group->pm_domain);
+#endif
 
-		MALI_DEBUG_PRINT(3, ("Mali group: Resetting entire group\n"));
+	return err;
+}
 
-		group->gp_state = MALI_GROUP_CORE_STATE_IDLE;
-		group->gp_running_job = NULL;
-		if (NULL != gp_job_to_return)
-		{
-			mali_group_deactivate_page_directory(group, mali_gp_job_get_session(gp_job_to_return));
-		}
+static void mali_group_bottom_half_pp(void *data)
+{
+	struct mali_group *group = (struct mali_group *)data;
+	struct mali_pp_core *core = group->pp_core;
+	u32 irq_readout;
+	u32 irq_errors;
 
-		group->pp_state = MALI_GROUP_CORE_STATE_IDLE;
-		group->pp_running_job = NULL;
-		if (NULL != pp_job_to_return)
-		{
-			mali_group_deactivate_page_directory(group, mali_pp_job_get_session(pp_job_to_return));
-		}
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START |
+				      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+				      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+				      0, _mali_osk_get_tid(), MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(core->core_id), 0, 0);
 
-		/* The reset has to be done after mali_group_deactivate_page_directory() */
-		mali_group_recovery_reset(group);
+	mali_group_lock(group);
 
-		if (mali_group_other_reschedule_needed(group) && (NULL == gp_job_to_return || NULL == pp_job_to_return))
-		{
-			schedule_other = MALI_TRUE;
-		}
+	if (mali_group_is_in_virtual(group)) {
+		/* We're member of a virtual group, so interrupt should be handled by the virtual group */
+		mali_pp_enable_interrupts(core);
+		mali_group_unlock(group);
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+					      0, _mali_osk_get_tid(), 0, 0, 0);
+		return;
+	}
 
+	if (MALI_FALSE == mali_group_power_is_on(group)) {
+		MALI_PRINT_ERROR(("Interrupt bottom half of %s when core is OFF.", mali_pp_get_hw_core_desc(core)));
 		mali_group_unlock(group);
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+					      0, _mali_osk_get_tid(), 0, 0, 0);
+		return;
+	}
 
-		if (NULL != gp_job_to_return)
-		{
-			mali_gp_scheduler_job_done(group, gp_job_to_return, gp_success);
-			mali_pm_core_event(MALI_CORE_EVENT_GP_STOP); /* It is ok to do this after schedule, since START/STOP is simply ++ and -- anyways */
-		}
-		else if (schedule_other)
-		{
-			mali_pp_scheduler_do_schedule();
+	irq_readout = mali_pp_read_rawstat(group->pp_core);
+
+	MALI_DEBUG_PRINT(4, ("Mali PP: Bottom half IRQ 0x%08X from core %s\n", irq_readout, mali_pp_get_hw_core_desc(group->pp_core)));
+
+	/* Check if job is complete without errors */
+	if (MALI200_REG_VAL_IRQ_END_OF_FRAME == irq_readout) {
+		if (mali_group_is_virtual(group)) {
+			u32 status_readout = mali_pp_read_status(group->pp_core);
+
+			if (status_readout & MALI200_REG_VAL_STATUS_RENDERING_ACTIVE && !group->core_timed_out) {
+				MALI_DEBUG_PRINT(6, ("Mali PP: Not all cores in broadcast completed\n"));
+				mali_pp_enable_interrupts(core);
+				mali_group_unlock(group);
+
+				_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+							      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+							      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+							      0, _mali_osk_get_tid(), 0, 0, 0);
+				return;
+			}
 		}
 
-		if (NULL != pp_job_to_return)
-		{
-			mali_pp_scheduler_job_done(group, pp_job_to_return, pp_sub_job_to_return, pp_success);
-			mali_pm_core_event(MALI_CORE_EVENT_PP_STOP); /* It is ok to do this after schedule, since START/STOP is simply ++ and -- anyways */
+		if (!group->core_timed_out) {
+			MALI_DEBUG_PRINT(3, ("Mali PP: Job completed, calling group handler\n"));
+			group->core_timed_out = MALI_FALSE;
+
+			mali_group_complete_pp_and_unlock(group, MALI_TRUE, MALI_FALSE);
+
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+						      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+						      0, _mali_osk_get_tid(), 0, 0, 0);
+			return;
 		}
-		else if (schedule_other)
-		{
-			mali_gp_scheduler_do_schedule();
+	}
+
+	/*
+	 * Now lets look at the possible error cases (IRQ indicating error or timeout)
+	 * END_OF_FRAME and HANG interrupts are not considered error.
+	 */
+	irq_errors = irq_readout & ~(MALI200_REG_VAL_IRQ_END_OF_FRAME | MALI200_REG_VAL_IRQ_HANG);
+	if (0 != irq_errors) {
+		MALI_PRINT_ERROR(("Mali PP: Unexpected interrupt 0x%08X from core %s, aborting job\n",
+				  irq_readout, mali_pp_get_hw_core_desc(group->pp_core)));
+		group->core_timed_out = MALI_FALSE;
+
+		mali_group_complete_pp_and_unlock(group, MALI_FALSE, MALI_FALSE);
+
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+					      0, _mali_osk_get_tid(), 0, 0, 0);
+		return;
+	} else if (group->core_timed_out) { /* SW timeout */
+		group->core_timed_out = MALI_FALSE;
+		if (!_mali_osk_timer_pending(group->timeout_timer) && NULL != group->pp_running_job) {
+			MALI_PRINT(("Mali PP: Job %d timed out on core %s\n",
+				    mali_pp_job_get_id(group->pp_running_job), mali_pp_get_hw_core_desc(core)));
+
+			mali_group_complete_pp_and_unlock(group, MALI_FALSE, MALI_FALSE);
+		} else {
+			mali_group_unlock(group);
 		}
 
+		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+					      0, _mali_osk_get_tid(), 0, 0, 0);
 		return;
 	}
 
+	/*
+	 * We should never get here, re-enable interrupts and continue
+	 */
+	if (0 == irq_readout) {
+		MALI_DEBUG_PRINT(3, ("Mali group: No interrupt found on core %s\n",
+				     mali_pp_get_hw_core_desc(group->pp_core)));
+	} else {
+		MALI_PRINT_ERROR(("Mali group: Unhandled PP interrupt 0x%08X on %s\n", irq_readout,
+				  mali_pp_get_hw_core_desc(group->pp_core)));
+	}
+	mali_pp_enable_interrupts(core);
 	mali_group_unlock(group);
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+				      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+				      MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF,
+				      0, _mali_osk_get_tid(), 0, 0, 0);
 }
 
-#if MALI_STATE_TRACKING
-u32 mali_group_dump_state(struct mali_group *group, char *buf, u32 size)
+static void mali_group_post_process_job_pp(struct mali_group *group)
 {
-	int n = 0;
+	MALI_ASSERT_GROUP_LOCKED(group);
 
-	n += _mali_osk_snprintf(buf + n, size - n, "Group: %p\n", group);
-	if (group->gp_core)
-	{
-		n += mali_gp_dump_state(group->gp_core, buf + n, size - n);
-		n += _mali_osk_snprintf(buf + n, size - n, "\tGP state: %d\n", group->gp_state);
-		n += _mali_osk_snprintf(buf + n, size - n, "\tGP job: %p\n", group->gp_running_job);
+	/* Stop the timeout timer. */
+	_mali_osk_timer_del_async(group->timeout_timer);
+
+	if (NULL != group->pp_running_job) {
+		if (MALI_TRUE == mali_group_is_virtual(group)) {
+			struct mali_group *child;
+			struct mali_group *temp;
+
+			/* update performance counters from each physical pp core within this virtual group */
+			_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+				mali_pp_update_performance_counters(group->pp_core, child->pp_core, group->pp_running_job, mali_pp_core_get_id(child->pp_core));
+			}
+
+#if defined(CONFIG_MALI400_PROFILING)
+			/* send profiling data per physical core */
+			_MALI_OSK_LIST_FOREACHENTRY(child, temp, &group->group_list, struct mali_group, group_list) {
+				_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+							      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(child->pp_core)) |
+							      MALI_PROFILING_EVENT_REASON_START_STOP_HW_VIRTUAL,
+							      mali_pp_job_get_perf_counter_value0(group->pp_running_job, mali_pp_core_get_id(child->pp_core)),
+							      mali_pp_job_get_perf_counter_value1(group->pp_running_job, mali_pp_core_get_id(child->pp_core)),
+							      mali_pp_job_get_perf_counter_src0(group->pp_running_job, group->pp_running_sub_job) | (mali_pp_job_get_perf_counter_src1(group->pp_running_job, group->pp_running_sub_job) << 8),
+							      0, 0);
+
+				trace_mali_core_active(mali_pp_job_get_pid(group->pp_running_job),
+						       0 /* active */, 0 /* PP */, mali_pp_core_get_id(child->pp_core),
+						       mali_pp_job_get_frame_builder_id(group->pp_running_job),
+						       mali_pp_job_get_flush_id(group->pp_running_job));
+			}
+			if (0 != group->l2_cache_core_ref_count[0]) {
+				if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+				    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0]))) {
+					mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[0]));
+				}
+			}
+			if (0 != group->l2_cache_core_ref_count[1]) {
+				if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[1])) &&
+				    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[1]))) {
+					mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[1]));
+				}
+			}
+
+#endif
+		} else {
+			/* update performance counters for a physical group's pp core */
+			mali_pp_update_performance_counters(group->pp_core, group->pp_core, group->pp_running_job, group->pp_running_sub_job);
+
+#if defined(CONFIG_MALI400_PROFILING)
+			_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP |
+						      MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(mali_pp_core_get_id(group->pp_core)) |
+						      MALI_PROFILING_EVENT_REASON_START_STOP_HW_PHYSICAL,
+						      mali_pp_job_get_perf_counter_value0(group->pp_running_job, group->pp_running_sub_job),
+						      mali_pp_job_get_perf_counter_value1(group->pp_running_job, group->pp_running_sub_job),
+						      mali_pp_job_get_perf_counter_src0(group->pp_running_job, group->pp_running_sub_job) | (mali_pp_job_get_perf_counter_src1(group->pp_running_job, group->pp_running_sub_job) << 8),
+						      0, 0);
+
+			trace_mali_core_active(mali_pp_job_get_pid(group->pp_running_job), 0 /* active */, 0 /* PP */, mali_pp_core_get_id(group->pp_core),
+					       mali_pp_job_get_frame_builder_id(group->pp_running_job), mali_pp_job_get_flush_id(group->pp_running_job));
+
+			if ((MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src0(group->l2_cache_core[0])) &&
+			    (MALI_HW_CORE_NO_COUNTER != mali_l2_cache_core_get_counter_src1(group->l2_cache_core[0]))) {
+				mali_group_report_l2_cache_counters_per_core(group, mali_l2_cache_get_id(group->l2_cache_core[0]));
+			}
+#endif
+		}
 	}
-	if (group->pp_core)
-	{
-		n += mali_pp_dump_state(group->pp_core, buf + n, size - n);
-		n += _mali_osk_snprintf(buf + n, size - n, "\tPP state: %d\n", group->pp_state);
-		n += _mali_osk_snprintf(buf + n, size - n, "\tPP job: %p, subjob %d \n",
-		                        group->pp_running_job, group->pp_running_sub_job);
+}
+
+static void mali_group_timeout(void *data)
+{
+	struct mali_group *group = (struct mali_group *)data;
+
+	group->core_timed_out = MALI_TRUE;
+
+	if (NULL != group->gp_core) {
+		MALI_DEBUG_PRINT(2, ("Mali group: TIMEOUT on %s\n", mali_gp_get_hw_core_desc(group->gp_core)));
+		_mali_osk_wq_schedule_work(group->bottom_half_work_gp);
+	} else {
+		MALI_DEBUG_PRINT(2, ("Mali group: TIMEOUT on %s\n", mali_pp_get_hw_core_desc(group->pp_core)));
+		_mali_osk_wq_schedule_work(group->bottom_half_work_pp);
 	}
+}
 
-	return n;
+void mali_group_zap_session(struct mali_group *group, struct mali_session_data *session)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT_POINTER(session);
+
+	/* Early out - safe even if mutex is not held */
+	if (group->session != session) return;
+
+	mali_group_lock(group);
+
+	mali_group_remove_session_if_unused(group, session);
+
+	if (group->session == session) {
+		/* The Zap also does the stall and disable_stall */
+		mali_bool zap_success = mali_mmu_zap_tlb(group->mmu);
+		if (MALI_TRUE != zap_success) {
+			MALI_DEBUG_PRINT(2, ("Mali memory unmap failed. Doing pagefault handling.\n"));
+
+			mali_group_mmu_page_fault_and_unlock(group);
+			return;
+		}
+	}
+
+	mali_group_unlock(group);
+}
+
+#if defined(CONFIG_MALI400_PROFILING)
+static void mali_group_report_l2_cache_counters_per_core(struct mali_group *group, u32 core_num)
+{
+	u32 source0 = 0;
+	u32 value0 = 0;
+	u32 source1 = 0;
+	u32 value1 = 0;
+	u32 profiling_channel = 0;
+
+	switch (core_num) {
+	case 0:
+		profiling_channel = MALI_PROFILING_EVENT_TYPE_SINGLE |
+				    MALI_PROFILING_EVENT_CHANNEL_GPU |
+				    MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L20_COUNTERS;
+		break;
+	case 1:
+		profiling_channel = MALI_PROFILING_EVENT_TYPE_SINGLE |
+				    MALI_PROFILING_EVENT_CHANNEL_GPU |
+				    MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L21_COUNTERS;
+		break;
+	case 2:
+		profiling_channel = MALI_PROFILING_EVENT_TYPE_SINGLE |
+				    MALI_PROFILING_EVENT_CHANNEL_GPU |
+				    MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L22_COUNTERS;
+		break;
+	default:
+		profiling_channel = MALI_PROFILING_EVENT_TYPE_SINGLE |
+				    MALI_PROFILING_EVENT_CHANNEL_GPU |
+				    MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L20_COUNTERS;
+		break;
+	}
+
+	if (0 == core_num) {
+		mali_l2_cache_core_get_counter_values(group->l2_cache_core[0], &source0, &value0, &source1, &value1);
+	}
+	if (1 == core_num) {
+		if (1 == mali_l2_cache_get_id(group->l2_cache_core[0])) {
+			mali_l2_cache_core_get_counter_values(group->l2_cache_core[0], &source0, &value0, &source1, &value1);
+		} else if (1 == mali_l2_cache_get_id(group->l2_cache_core[1])) {
+			mali_l2_cache_core_get_counter_values(group->l2_cache_core[1], &source0, &value0, &source1, &value1);
+		}
+	}
+	if (2 == core_num) {
+		if (2 == mali_l2_cache_get_id(group->l2_cache_core[0])) {
+			mali_l2_cache_core_get_counter_values(group->l2_cache_core[0], &source0, &value0, &source1, &value1);
+		} else if (2 == mali_l2_cache_get_id(group->l2_cache_core[1])) {
+			mali_l2_cache_core_get_counter_values(group->l2_cache_core[1], &source0, &value0, &source1, &value1);
+		}
+	}
+
+	_mali_osk_profiling_add_event(profiling_channel, source1 << 8 | source0, value0, value1, 0, 0);
+}
+#endif /* #if defined(CONFIG_MALI400_PROFILING) */
+
+mali_bool mali_group_is_enabled(struct mali_group *group)
+{
+	mali_bool enabled = MALI_TRUE;
+
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	mali_group_lock(group);
+	if (MALI_GROUP_STATE_DISABLED == group->state) {
+		enabled = MALI_FALSE;
+	}
+	mali_group_unlock(group);
+
+	return enabled;
+}
+
+void mali_group_enable(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(NULL != mali_group_get_pp_core(group)
+			  || NULL != mali_group_get_gp_core(group));
+
+	if (NULL != mali_group_get_pp_core(group)) {
+		mali_pp_scheduler_enable_group(group);
+	} else {
+		mali_gp_scheduler_enable_group(group);
+	}
+}
+
+void mali_group_disable(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+	MALI_DEBUG_ASSERT(NULL != mali_group_get_pp_core(group)
+			  || NULL != mali_group_get_gp_core(group));
+
+	if (NULL != mali_group_get_pp_core(group)) {
+		mali_pp_scheduler_disable_group(group);
+	} else {
+		mali_gp_scheduler_disable_group(group);
+	}
+}
+
+static struct mali_pm_domain *mali_group_get_l2_domain(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT(NULL == group->l2_cache_core[1]);
+
+	/* l2_cache_core[0] stores the related l2 domain */
+	return group->l2_cache_core[0]->pm_domain;
+}
+
+void mali_group_get_pm_domain_ref(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	/* Get group used l2 domain ref */
+	mali_pm_domain_ref_get(mali_group_get_l2_domain(group));
+	/* Get group used core domain ref */
+	mali_pm_domain_ref_get(group->pm_domain);
+}
+
+void mali_group_put_pm_domain_ref(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	/* Put group used core domain ref */
+	mali_pm_domain_ref_put(group->pm_domain);
+	/* Put group used l2 domain ref */
+	mali_pm_domain_ref_put(mali_group_get_l2_domain(group));
 }
-#endif
diff --git a/drivers/gpu/mali/mali/common/mali_group.h b/drivers/gpu/mali/mali/common/mali_group.h
old mode 100644
new mode 100755
index 6d594ee..c7301f2
--- a/drivers/gpu/mali/mali/common/mali_group.h
+++ b/drivers/gpu/mali/mali/common/mali_group.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,38 +13,84 @@
 
 #include "linux/jiffies.h"
 #include "mali_osk.h"
-#include "mali_cluster.h"
+#include "mali_l2_cache.h"
 #include "mali_mmu.h"
 #include "mali_gp.h"
 #include "mali_pp.h"
 #include "mali_session.h"
 
-/* max runtime [ms] for a core job - used by timeout timers  */
-#define MAX_RUNTIME 5000
+/**
+ * @brief Default max runtime [ms] for a core job - used by timeout timers
+ */
+#define MALI_MAX_JOB_RUNTIME_DEFAULT 4000
+
 /** @brief A mali group object represents a MMU and a PP and/or a GP core.
  *
  */
-#define MALI_MAX_NUMBER_OF_GROUPS 9
-
-struct mali_group;
+#define MALI_MAX_NUMBER_OF_GROUPS 10
 
-enum mali_group_event_t
-{
-	GROUP_EVENT_PP_JOB_COMPLETED,  /**< PP job completed successfully */
-	GROUP_EVENT_PP_JOB_FAILED,     /**< PP job completed with failure */
-	GROUP_EVENT_PP_JOB_TIMED_OUT,  /**< PP job reached max runtime */
-	GROUP_EVENT_GP_JOB_COMPLETED,  /**< GP job completed successfully */
-	GROUP_EVENT_GP_JOB_FAILED,     /**< GP job completed with failure */
-	GROUP_EVENT_GP_JOB_TIMED_OUT,  /**< GP job reached max runtime */
-	GROUP_EVENT_GP_OOM,            /**< GP job ran out of heap memory */
-	GROUP_EVENT_MMU_PAGE_FAULT,    /**< MMU page fault */
+enum mali_group_core_state {
+	MALI_GROUP_STATE_IDLE,
+	MALI_GROUP_STATE_WORKING,
+	MALI_GROUP_STATE_OOM,
+	MALI_GROUP_STATE_IN_VIRTUAL,
+	MALI_GROUP_STATE_JOINING_VIRTUAL,
+	MALI_GROUP_STATE_LEAVING_VIRTUAL,
+	MALI_GROUP_STATE_DISABLED,
 };
 
-enum mali_group_core_state
-{
-	MALI_GROUP_CORE_STATE_IDLE,
-	MALI_GROUP_CORE_STATE_WORKING,
-	MALI_GROUP_CORE_STATE_OOM
+/* Forward declaration from mali_pm_domain.h */
+struct mali_pm_domain;
+
+/**
+ * The structure represents a render group
+ * A render group is defined by all the cores that share the same Mali MMU
+ */
+
+struct mali_group {
+	struct mali_mmu_core        *mmu;
+	struct mali_session_data    *session;
+
+	mali_bool                   power_is_on;
+	enum mali_group_core_state  state;
+
+	struct mali_gp_core         *gp_core;
+	struct mali_gp_job          *gp_running_job;
+
+	struct mali_pp_core         *pp_core;
+	struct mali_pp_job          *pp_running_job;
+	u32                         pp_running_sub_job;
+
+	struct mali_l2_cache_core   *l2_cache_core[2];
+	u32                         l2_cache_core_ref_count[2];
+
+	struct mali_dlbu_core       *dlbu_core;
+	struct mali_bcast_unit      *bcast_core;
+
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_t        *lock;
+#else
+	_mali_osk_spinlock_t            *lock;
+#endif
+
+	_mali_osk_list_t            pp_scheduler_list;
+
+	/* List used for virtual groups. For a virtual group, the list represents the
+	 * head element. */
+	_mali_osk_list_t            group_list;
+
+	struct mali_group           *pm_domain_list;
+	struct mali_pm_domain       *pm_domain;
+
+	/* Parent virtual group (if any) */
+	struct mali_group           *parent_group;
+
+	_mali_osk_wq_work_t         *bottom_half_work_mmu;
+	_mali_osk_wq_work_t         *bottom_half_work_gp;
+	_mali_osk_wq_work_t         *bottom_half_work_pp;
+
+	_mali_osk_timer_t           *timeout_timer;
+	mali_bool                   core_timed_out;
 };
 
 /** @brief Create a new Mali group object
@@ -53,11 +99,53 @@ enum mali_group_core_state
  * @param mmu Pointer to the MMU that defines this group
  * @return A pointer to a new group object
  */
-struct mali_group *mali_group_create(struct mali_cluster *cluster, struct mali_mmu_core *mmu);
-void mali_group_add_gp_core(struct mali_group *group, struct mali_gp_core* gp_core);
-void mali_group_add_pp_core(struct mali_group *group, struct mali_pp_core* pp_core);
+struct mali_group *mali_group_create(struct mali_l2_cache_core *core,
+				     struct mali_dlbu_core *dlbu,
+				     struct mali_bcast_unit *bcast);
+
+_mali_osk_errcode_t mali_group_add_mmu_core(struct mali_group *group, struct mali_mmu_core *mmu_core);
+void mali_group_remove_mmu_core(struct mali_group *group);
+
+_mali_osk_errcode_t mali_group_add_gp_core(struct mali_group *group, struct mali_gp_core *gp_core);
+void mali_group_remove_gp_core(struct mali_group *group);
+
+_mali_osk_errcode_t mali_group_add_pp_core(struct mali_group *group, struct mali_pp_core *pp_core);
+void mali_group_remove_pp_core(struct mali_group *group);
+
+void mali_group_set_pm_domain(struct mali_group *group, struct mali_pm_domain *domain);
+
 void mali_group_delete(struct mali_group *group);
 
+/** @brief Virtual groups */
+void mali_group_add_group(struct mali_group *parent, struct mali_group *child, mali_bool update_hw);
+void mali_group_remove_group(struct mali_group *parent, struct mali_group *child);
+struct mali_group *mali_group_acquire_group(struct mali_group *parent);
+
+MALI_STATIC_INLINE mali_bool mali_group_is_virtual(struct mali_group *group)
+{
+#if defined(CONFIG_MALI450)
+	return (NULL != group->dlbu_core);
+#else
+	return MALI_FALSE;
+#endif
+}
+
+/** @brief Check if a group is considered as part of a virtual group
+ *
+ * @note A group is considered to be "part of" a virtual group also during the transition
+ *       in to / out of the virtual group.
+ */
+MALI_STATIC_INLINE mali_bool mali_group_is_in_virtual(struct mali_group *group)
+{
+#if defined(CONFIG_MALI450)
+	return (MALI_GROUP_STATE_IN_VIRTUAL == group->state ||
+		MALI_GROUP_STATE_JOINING_VIRTUAL == group->state ||
+		MALI_GROUP_STATE_LEAVING_VIRTUAL == group->state);
+#else
+	return MALI_FALSE;
+#endif
+}
+
 /** @brief Reset group
  *
  * This function will reset the entire group, including all the cores present in the group.
@@ -66,13 +154,19 @@ void mali_group_delete(struct mali_group *group);
  */
 void mali_group_reset(struct mali_group *group);
 
+/** @brief Zap MMU TLB on all groups
+ *
+ * Zap TLB on group if \a session is active.
+ */
+void mali_group_zap_session(struct mali_group *group, struct mali_session_data *session);
+
 /** @brief Get pointer to GP core object
  */
-struct mali_gp_core* mali_group_get_gp_core(struct mali_group *group);
+struct mali_gp_core *mali_group_get_gp_core(struct mali_group *group);
 
 /** @brief Get pointer to PP core object
  */
-struct mali_pp_core* mali_group_get_pp_core(struct mali_group *group);
+struct mali_pp_core *mali_group_get_pp_core(struct mali_group *group);
 
 /** @brief Lock group object
  *
@@ -97,14 +191,26 @@ void mali_group_assert_locked(struct mali_group *group);
 
 /** @brief Start GP job
  */
-_mali_osk_errcode_t mali_group_start_gp_job(struct mali_group *group, struct mali_gp_job *job);
-/** @brief Start fragment of PP job
+void mali_group_start_gp_job(struct mali_group *group, struct mali_gp_job *job);
+
+/** @brief Start virtual group Job on a virtual group
+*/
+void mali_group_start_job_on_virtual(struct mali_group *group, struct mali_pp_job *job, u32 first_subjob, u32 last_subjob);
+
+
+/** @brief Start a subjob from a particular on a specific PP group
+*/
+void mali_group_start_job_on_group(struct mali_group *group, struct mali_pp_job *job, u32 subjob);
+
+
+/** @brief remove all the unused groups in tmp_unused group  list, so that the group is in consistent status.
  */
-_mali_osk_errcode_t mali_group_start_pp_job(struct mali_group *group, struct mali_pp_job *job, u32 sub_job);
+void mali_group_non_dlbu_job_done_virtual(struct mali_group *group);
+
 
-/** @brief Resume GP job that suspended waiting for more heap memory
+/** @brief Resume GP job that suspended waiting for more heap memory
  */
-void mali_group_resume_gp_with_new_heap(struct mali_group *group, u32 job_id, u32 start_addr, u32 end_addr);
+struct mali_gp_job *mali_group_resume_gp_with_new_heap(struct mali_group *group, u32 job_id, u32 start_addr, u32 end_addr);
 /** @brief Abort GP job
  *
  * Used to abort suspended OOM jobs when user space failed to allocte more memory.
@@ -116,31 +222,101 @@ void mali_group_abort_gp_job(struct mali_group *group, u32 job_id);
  */
 void mali_group_abort_session(struct mali_group *group, struct mali_session_data *session);
 
-enum mali_group_core_state mali_group_gp_state(struct mali_group *group);
-enum mali_group_core_state mali_group_pp_state(struct mali_group *group);
+mali_bool mali_group_power_is_on(struct mali_group *group);
+void mali_group_power_on_group(struct mali_group *group);
+void mali_group_power_off_group(struct mali_group *group, mali_bool power_status);
+void mali_group_power_on(void);
 
-/** @brief The common group bottom half interrupt handler
+/** @brief Prepare group for power off
  *
- * This is only called from the GP and PP bottom halves.
+ * Update the group's state and prepare for the group to be powered off.
  *
- * The action taken is dictated by the \a event.
+ * If do_power_change is MALI_FALSE group session will be set to NULL so that
+ * no more activity will happen to this group, but the power state flag will be
+ * left unchanged.
  *
- * @param event The event code
+ * @do_power_change MALI_TRUE if power status is to be updated
  */
-void mali_group_bottom_half(struct mali_group *group, enum mali_group_event_t event);
-
-struct mali_mmu_core *mali_group_get_mmu(struct mali_group *group);
-struct mali_session_data *mali_group_get_session(struct mali_group *group);
-
-void mali_group_remove_session_if_unused(struct mali_group *group, struct mali_session_data *session_data);
-
-void mali_group_power_on(void);
-void mali_group_power_off(void);
-mali_bool mali_group_power_is_on(struct mali_group *group);
+void mali_group_power_off(mali_bool do_power_change);
 
 struct mali_group *mali_group_get_glob_group(u32 index);
 u32 mali_group_get_glob_num_groups(void);
 
 u32 mali_group_dump_state(struct mali_group *group, char *buf, u32 size);
 
+/* MMU-related functions */
+_mali_osk_errcode_t mali_group_upper_half_mmu(void *data);
+
+/* GP-related functions */
+_mali_osk_errcode_t mali_group_upper_half_gp(void *data);
+
+/* PP-related functions */
+_mali_osk_errcode_t mali_group_upper_half_pp(void *data);
+
+/** @brief Check if group is enabled
+ *
+ * @param group group to check
+ * @return MALI_TRUE if enabled, MALI_FALSE if not
+ */
+mali_bool mali_group_is_enabled(struct mali_group *group);
+
+/** @brief Enable group
+ *
+ * An enabled job is put on the idle scheduler list and can be used to handle jobs.  Does nothing if
+ * group is already enabled.
+ *
+ * @param group group to enable
+ */
+void mali_group_enable(struct mali_group *group);
+
+/** @brief Disable group
+ *
+ * A disabled group will no longer be used by the scheduler.  If part of a virtual group, the group
+ * will be removed before being disabled.  Cores part of a disabled group is safe to power down.
+ *
+ * @param group group to disable
+ */
+void mali_group_disable(struct mali_group *group);
+
+MALI_STATIC_INLINE mali_bool mali_group_virtual_disable_if_empty(struct mali_group *group)
+{
+	mali_bool empty = MALI_FALSE;
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(group));
+
+	if (_mali_osk_list_empty(&group->group_list)) {
+		group->state = MALI_GROUP_STATE_DISABLED;
+		group->session = NULL;
+
+		empty = MALI_TRUE;
+	}
+
+	return empty;
+}
+
+MALI_STATIC_INLINE mali_bool mali_group_virtual_enable_if_empty(struct mali_group *group)
+{
+	mali_bool empty = MALI_FALSE;
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT(mali_group_is_virtual(group));
+
+	if (_mali_osk_list_empty(&group->group_list)) {
+		MALI_DEBUG_ASSERT(MALI_GROUP_STATE_DISABLED == group->state);
+
+		group->state = MALI_GROUP_STATE_IDLE;
+
+		empty = MALI_TRUE;
+	}
+
+	return empty;
+}
+
+
+/* Get group used l2 domain and core domain ref */
+void mali_group_get_pm_domain_ref(struct mali_group *group);
+/* Put group used l2 domain and core domain ref */
+void mali_group_put_pm_domain_ref(struct mali_group *group);
+
 #endif /* __MALI_GROUP_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_hw_core.c b/drivers/gpu/mali/mali/common/mali_hw_core.c
old mode 100644
new mode 100755
index efbe28a..e5004ab
--- a/drivers/gpu/mali/mali/common/mali_hw_core.c
+++ b/drivers/gpu/mali/mali/common/mali_hw_core.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,27 +11,26 @@
 #include "mali_hw_core.h"
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
+#include "mali_osk_mali.h"
 
 _mali_osk_errcode_t mali_hw_core_create(struct mali_hw_core *core, const _mali_osk_resource_t *resource, u32 reg_size)
 {
 	core->phys_addr = resource->base;
+	core->phys_offset = resource->base - _mali_osk_resource_base_address();
 	core->description = resource->description;
 	core->size = reg_size;
-	if (_MALI_OSK_ERR_OK == _mali_osk_mem_reqregion(core->phys_addr, core->size, core->description))
-	{
+
+	MALI_DEBUG_ASSERT(core->phys_offset < core->phys_addr);
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_mem_reqregion(core->phys_addr, core->size, core->description)) {
 		core->mapped_registers = _mali_osk_mem_mapioregion(core->phys_addr, core->size, core->description);
-		if (NULL != core->mapped_registers)
-		{
+		if (NULL != core->mapped_registers) {
 			return _MALI_OSK_ERR_OK;
-		}
-		else
-		{
+		} else {
 			MALI_PRINT_ERROR(("Failed to map memory region for core %s at phys_addr 0x%08X\n", core->description, core->phys_addr));
 		}
 		_mali_osk_mem_unreqregion(core->phys_addr, core->size);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Failed to request memory region for core %s at phys_addr 0x%08X\n", core->description, core->phys_addr));
 	}
 
diff --git a/drivers/gpu/mali/mali/common/mali_hw_core.h b/drivers/gpu/mali/mali/common/mali_hw_core.h
old mode 100644
new mode 100755
index ab8efa3..341d303
--- a/drivers/gpu/mali/mali/common/mali_hw_core.h
+++ b/drivers/gpu/mali/mali/common/mali_hw_core.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,16 +18,16 @@
  * The common parts for all Mali HW cores (GP, PP, MMU, L2 and PMU)
  * This struct is embedded inside all core specific structs.
  */
-struct mali_hw_core
-{
+struct mali_hw_core {
 	u32 phys_addr;                    /**< Physical address of the registers */
+	u32 phys_offset;                  /**< Offset from start of Mali to registers */
 	u32 size;                         /**< Size of registers */
 	mali_io_address mapped_registers; /**< Virtual mapping of the registers */
-	const char* description;          /**< Name of unit (as specified in device configuration) */
+	const char *description;          /**< Name of unit (as specified in device configuration) */
 };
 
-#define MALI_HW_CORE_NO_COUNTER     ((u32)-1)
-#define MALI_HW_CORE_INVALID_VALUE  ((u32)-1)
+#define MALI_REG_POLL_COUNT_FAST 1000
+#define MALI_REG_POLL_COUNT_SLOW 1000000
 
 _mali_osk_errcode_t mali_hw_core_create(struct mali_hw_core *core, const _mali_osk_resource_t *resource, u32 reg_size);
 void mali_hw_core_delete(struct mali_hw_core *core);
@@ -37,21 +37,34 @@ MALI_STATIC_INLINE u32 mali_hw_core_register_read(struct mali_hw_core *core, u32
 	u32 read_val;
 	read_val = _mali_osk_mem_ioread32(core->mapped_registers, relative_address);
 	MALI_DEBUG_PRINT(6, ("register_read for core %s, relative addr=0x%04X, val=0x%08X\n",
-	                     core->description, relative_address, read_val));
+			     core->description, relative_address, read_val));
 	return read_val;
 }
 
 MALI_STATIC_INLINE void mali_hw_core_register_write_relaxed(struct mali_hw_core *core, u32 relative_address, u32 new_val)
 {
 	MALI_DEBUG_PRINT(6, ("register_write_relaxed for core %s, relative addr=0x%04X, val=0x%08X\n",
-	                      core->description, relative_address, new_val));
+			     core->description, relative_address, new_val));
 	_mali_osk_mem_iowrite32_relaxed(core->mapped_registers, relative_address, new_val);
 }
 
+/* Conditionally write a register.
+ * The register will only be written if the new value is different from the old_value.
+ * If the new value is different, the old value will also be updated */
+MALI_STATIC_INLINE void mali_hw_core_register_write_relaxed_conditional(struct mali_hw_core *core, u32 relative_address, u32 new_val, const u32 old_val)
+{
+	MALI_DEBUG_PRINT(6, ("register_write_relaxed for core %s, relative addr=0x%04X, val=0x%08X\n",
+			     core->description, relative_address, new_val));
+	if (old_val != new_val) {
+		_mali_osk_mem_iowrite32_relaxed(core->mapped_registers, relative_address, new_val);
+	}
+}
+
+
 MALI_STATIC_INLINE void mali_hw_core_register_write(struct mali_hw_core *core, u32 relative_address, u32 new_val)
 {
 	MALI_DEBUG_PRINT(6, ("register_write for core %s, relative addr=0x%04X, val=0x%08X\n",
-	                      core->description, relative_address, new_val));
+			     core->description, relative_address, new_val));
 	_mali_osk_mem_iowrite32(core->mapped_registers, relative_address, new_val);
 }
 
@@ -59,12 +72,28 @@ MALI_STATIC_INLINE void mali_hw_core_register_write_array_relaxed(struct mali_hw
 {
 	u32 i;
 	MALI_DEBUG_PRINT(6, ("register_write_array: for core %s, relative addr=0x%04X, nr of regs=%u\n",
-	                     core->description,relative_address, nr_of_regs));
+			     core->description, relative_address, nr_of_regs));
+
+	/* Do not use burst writes against the registers */
+	for (i = 0; i < nr_of_regs; i++) {
+		mali_hw_core_register_write_relaxed(core, relative_address + i * 4, write_array[i]);
+	}
+}
+
+/* Conditionally write a set of registers.
+ * The register will only be written if the new value is different from the old_value.
+ * If the new value is different, the old value will also be updated */
+MALI_STATIC_INLINE void mali_hw_core_register_write_array_relaxed_conditional(struct mali_hw_core *core, u32 relative_address, u32 *write_array, u32 nr_of_regs, const u32 *old_array)
+{
+	u32 i;
+	MALI_DEBUG_PRINT(6, ("register_write_array: for core %s, relative addr=0x%04X, nr of regs=%u\n",
+			     core->description, relative_address, nr_of_regs));
 
 	/* Do not use burst writes against the registers */
-	for (i = 0; i< nr_of_regs; i++)
-	{
-		mali_hw_core_register_write_relaxed(core, relative_address + i*4, write_array[i]);
+	for (i = 0; i < nr_of_regs; i++) {
+		if (old_array[i] != write_array[i]) {
+			mali_hw_core_register_write_relaxed(core, relative_address + i * 4, write_array[i]);
+		}
 	}
 }
 
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_common.h b/drivers/gpu/mali/mali/common/mali_kernel_common.h
old mode 100644
new mode 100755
index c9cb328..f6e14f7
--- a/drivers/gpu/mali/mali/common/mali_kernel_common.h
+++ b/drivers/gpu/mali/mali/common/mali_kernel_common.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,11 +11,13 @@
 #ifndef __MALI_KERNEL_COMMON_H__
 #define __MALI_KERNEL_COMMON_H__
 
+#include "mali_osk.h"
+
 /* Make sure debug is defined when it should be */
 #ifndef DEBUG
-	#if defined(_DEBUG)
-		#define DEBUG
-	#endif
+#if defined(_DEBUG)
+#define DEBUG
+#endif
 #endif
 
 /* The file include several useful macros for error checking, debugging and printing.
@@ -36,15 +38,15 @@
  * [5:6] Is messages with low priority, used during extensive debugging.
  */
 
- /**
- *  Fundamental error macro. Reports an error code. This is abstracted to allow us to
- *  easily switch to a different error reporting method if we want, and also to allow
- *  us to search for error returns easily.
- *
- *  Note no closing semicolon - this is supplied in typical usage:
- *
- *  MALI_ERROR(MALI_ERROR_OUT_OF_MEMORY);
- */
+/**
+*  Fundamental error macro. Reports an error code. This is abstracted to allow us to
+*  easily switch to a different error reporting method if we want, and also to allow
+*  us to search for error returns easily.
+*
+*  Note no closing semicolon - this is supplied in typical usage:
+*
+*  MALI_ERROR(MALI_ERROR_OUT_OF_MEMORY);
+*/
 #define MALI_ERROR(error_code) return (error_code)
 
 /**
@@ -56,30 +58,32 @@
 #define MALI_SUCCESS MALI_ERROR(_MALI_OSK_ERR_OK)
 
 /**
- *	Basic error macro. This checks whether the given condition is true, and if not returns
- *	from this function with the supplied error code. This is a macro so that we can override it
- *	for stress testing.
+ *  Basic error macro. This checks whether the given condition is true, and if not returns
+ *  from this function with the supplied error code. This is a macro so that we can override it
+ *  for stress testing.
  *
- *	Note that this uses the do-while-0 wrapping to ensure that we don't get problems with dangling
- *	else clauses. Note also no closing semicolon - this is supplied in typical usage:
+ *  Note that this uses the do-while-0 wrapping to ensure that we don't get problems with dangling
+ *  else clauses. Note also no closing semicolon - this is supplied in typical usage:
  *
- *	MALI_CHECK((p!=NULL), ERROR_NO_OBJECT);
+ *  MALI_CHECK((p!=NULL), ERROR_NO_OBJECT);
  */
 #define MALI_CHECK(condition, error_code) do { if(!(condition)) MALI_ERROR(error_code); } while(0)
 
 /**
- *	Error propagation macro. If the expression given is anything other than _MALI_OSK_NO_ERROR,
- *	then the value is returned from the enclosing function as an error code. This effectively
- *	acts as a guard clause, and propagates error values up the call stack. This uses a
- *	temporary value to ensure that the error expression is not evaluated twice.
- *  If the counter for forcing a failure has been set using _mali_force_error, this error will be
- *  returned without evaluating the expression in MALI_CHECK_NO_ERROR
+ *  Error propagation macro. If the expression given is anything other than
+ *  _MALI_OSK_NO_ERROR, then the value is returned from the enclosing function
+ *  as an error code. This effectively acts as a guard clause, and propagates
+ *  error values up the call stack. This uses a temporary value to ensure that
+ *  the error expression is not evaluated twice.
+ *  If the counter for forcing a failure has been set using _mali_force_error,
+ *  this error will be returned without evaluating the expression in
+ *  MALI_CHECK_NO_ERROR
  */
 #define MALI_CHECK_NO_ERROR(expression) \
-    do { _mali_osk_errcode_t _check_no_error_result=(expression); \
-         if(_check_no_error_result != _MALI_OSK_ERR_OK) \
-         MALI_ERROR(_check_no_error_result); \
-    } while(0)
+	do { _mali_osk_errcode_t _check_no_error_result=(expression); \
+		if(_check_no_error_result != _MALI_OSK_ERR_OK) \
+			MALI_ERROR(_check_no_error_result); \
+	} while(0)
 
 /**
  *  Pointer check macro. Checks non-null pointer.
@@ -87,13 +91,13 @@
 #define MALI_CHECK_NON_NULL(pointer, error_code) MALI_CHECK( ((pointer)!=NULL), (error_code) )
 
 /**
- *	Error macro with goto. This checks whether the given condition is true, and if not jumps
- *	to the specified label using a goto. The label must therefore be local to the function in
- *	which this macro appears. This is most usually used to execute some clean-up code before
- *	exiting with a call to ERROR.
+ *  Error macro with goto. This checks whether the given condition is true, and if not jumps
+ *  to the specified label using a goto. The label must therefore be local to the function in
+ *  which this macro appears. This is most usually used to execute some clean-up code before
+ *  exiting with a call to ERROR.
  *
- *	Like the other macros, this is a macro to allow us to override the condition if we wish,
- *	e.g. to force an error during stress testing.
+ *  Like the other macros, this is a macro to allow us to override the condition if we wish,
+ *  e.g. to force an error during stress testing.
  */
 #define MALI_CHECK_GOTO(condition, label) do { if(!(condition)) goto label; } while(0)
 
@@ -103,18 +107,22 @@
  */
 #define MALI_IGNORE(x) x=x
 
+#if defined(CONFIG_MALI_QUIET)
+#define MALI_PRINTF(args)
+#else
 #define MALI_PRINTF(args) _mali_osk_dbgmsg args;
+#endif
 
 #define MALI_PRINT_ERROR(args) do{ \
-	MALI_PRINTF(("Mali: ERR: %s\n" ,__FILE__)); \
-	MALI_PRINTF(("           %s()%4d\n           ", __FUNCTION__, __LINE__)) ; \
-	MALI_PRINTF(args); \
-	MALI_PRINTF(("\n")); \
+		MALI_PRINTF(("Mali: ERR: %s\n" ,__FILE__)); \
+		MALI_PRINTF(("           %s()%4d\n           ", __FUNCTION__, __LINE__)) ; \
+		MALI_PRINTF(args); \
+		MALI_PRINTF(("\n")); \
 	} while(0)
 
 #define MALI_PRINT(args) do{ \
-	MALI_PRINTF(("Mali: ")); \
-	MALI_PRINTF(args); \
+		MALI_PRINTF(("Mali: ")); \
+		MALI_PRINTF(args); \
 	} while (0)
 
 #ifdef DEBUG
@@ -124,19 +132,19 @@ extern int mali_debug_level;
 
 #define MALI_DEBUG_CODE(code) code
 #define MALI_DEBUG_PRINT(level, args)  do { \
-	if((level) <=  mali_debug_level)\
-        {MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); } \
+		if((level) <=  mali_debug_level)\
+		{MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); } \
 	} while (0)
 
 #define MALI_DEBUG_PRINT_ERROR(args) MALI_PRINT_ERROR(args)
 
 #define MALI_DEBUG_PRINT_IF(level,condition,args)  \
 	if((condition)&&((level) <=  mali_debug_level))\
-        {MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); }
+	{MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); }
 
 #define MALI_DEBUG_PRINT_ELSE(level, args)\
 	else if((level) <=  mali_debug_level)\
-    { MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); }
+	{ MALI_PRINTF(("Mali<" #level ">: ")); MALI_PRINTF(args); }
 
 /**
  * @note these variants of DEBUG ASSERTS will cause a debugger breakpoint
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_core.c b/drivers/gpu/mali/mali/common/mali_kernel_core.c
old mode 100644
new mode 100755
index 70e78fa..770cf66
--- a/drivers/gpu/mali/mali/common/mali_kernel_core.c
+++ b/drivers/gpu/mali/mali/common/mali_kernel_core.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -19,615 +19,939 @@
 #include "mali_mmu.h"
 #include "mali_mmu_page_directory.h"
 #include "mali_dlbu.h"
+#include "mali_broadcast.h"
 #include "mali_gp.h"
 #include "mali_pp.h"
 #include "mali_gp_scheduler.h"
 #include "mali_pp_scheduler.h"
-#include "mali_cluster.h"
+#include "mali_pp_job.h"
 #include "mali_group.h"
 #include "mali_pm.h"
 #include "mali_pmu.h"
 #include "mali_scheduler.h"
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
 #include "mali_kernel_utilization.h"
-#endif
 #include "mali_l2_cache.h"
-#if MALI_TIMELINE_PROFILING_ENABLED
+#include "mali_dma.h"
+#include "mali_timeline.h"
+#include "mali_soft_job.h"
+#include "mali_pm_domain.h"
+#if defined(CONFIG_MALI400_PROFILING)
 #include "mali_osk_profiling.h"
 #endif
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+#include "mali_profiling_internal.h"
+#endif
 
-/** Pointer to table of resource definitions available to the Mali driver.
- *  _mali_osk_resources_init() sets up the pointer to this table.
- */
-static _mali_osk_resource_t *arch_configuration = NULL;
+
+/* Mali GPU memory. Real values come from module parameter or from device specific data */
+unsigned int mali_dedicated_mem_start = 0;
+unsigned int mali_dedicated_mem_size = 0;
+unsigned int mali_shared_mem_size = 0;
+
+/* Frame buffer memory to be accessible by Mali GPU */
+int mali_fb_start = 0;
+int mali_fb_size = 0;
+
+/* Mali max job runtime */
+extern int mali_max_job_runtime;
 
 /** Start profiling from module load? */
 int mali_boot_profiling = 0;
 
-/** Number of resources initialized by _mali_osk_resources_init() */
-static u32 num_resources;
+/** Limits for the number of PP cores behind each L2 cache. */
+int mali_max_pp_cores_group_1 = 0xFF;
+int mali_max_pp_cores_group_2 = 0xFF;
+
+int mali_inited_pp_cores_group_1 = 0;
+int mali_inited_pp_cores_group_2 = 0;
 
 static _mali_product_id_t global_product_id = _MALI_PRODUCT_ID_UNKNOWN;
 static u32 global_gpu_base_address = 0;
 static u32 global_gpu_major_version = 0;
 static u32 global_gpu_minor_version = 0;
 
-static _mali_osk_errcode_t build_system_info(void);
-static void cleanup_system_info(_mali_system_info *cleanup);
-
-/* system info variables */
-static _mali_osk_lock_t *system_info_lock = NULL;
-static _mali_system_info *system_info = NULL;
-static u32 system_info_size = 0;
-static u32 first_pp_offset = 0;
-
-#define WATCHDOG_MSECS_DEFAULT 4000 /* 4 s */
+mali_bool mali_gpu_class_is_mali450 = MALI_FALSE;
 
-/* timer related */
-int mali_max_job_runtime = WATCHDOG_MSECS_DEFAULT;
-
-static _mali_osk_resource_t *mali_find_resource(_mali_osk_resource_type_t type, u32 offset)
+static _mali_osk_errcode_t mali_set_global_gpu_base_address(void)
 {
-	int i;
-	u32 addr = global_gpu_base_address + offset;
-
-	for (i = 0; i < num_resources; i++)
-	{
-		if (type == arch_configuration[i].type && arch_configuration[i].base == addr)
-		{
-			return &(arch_configuration[i]);
-		}
+	global_gpu_base_address = _mali_osk_resource_base_address();
+	if (0 == global_gpu_base_address) {
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
 	}
 
-	return NULL;
+	return _MALI_OSK_ERR_OK;
 }
 
-static u32 mali_count_resources(_mali_osk_resource_type_t type)
+static u32 mali_get_bcast_id(_mali_osk_resource_t *resource_pp)
 {
-	int i;
-	u32 retval = 0;
-
-	for (i = 0; i < num_resources; i++)
-	{
-		if (type == arch_configuration[i].type)
-		{
-			retval++;
-		}
+	switch (resource_pp->base - global_gpu_base_address) {
+	case 0x08000:
+	case 0x20000: /* fall-through for aliased mapping */
+		return 0x01;
+	case 0x0A000:
+	case 0x22000: /* fall-through for aliased mapping */
+		return 0x02;
+	case 0x0C000:
+	case 0x24000: /* fall-through for aliased mapping */
+		return 0x04;
+	case 0x0E000:
+	case 0x26000: /* fall-through for aliased mapping */
+		return 0x08;
+	case 0x28000:
+		return 0x10;
+	case 0x2A000:
+		return 0x20;
+	case 0x2C000:
+		return 0x40;
+	case 0x2E000:
+		return 0x80;
+	default:
+		return 0;
 	}
-
-	return retval;
 }
 
-
-static _mali_osk_errcode_t mali_parse_gpu_base_and_first_pp_offset_address(void)
+static _mali_osk_errcode_t mali_parse_product_info(void)
 {
-	int i;
-	_mali_osk_resource_t *first_gp_resource = NULL;
-	_mali_osk_resource_t *first_pp_resource = NULL;
-
-	for (i = 0; i < num_resources; i++)
-	{
-		if (MALI_GP == arch_configuration[i].type)
-		{
-			if (NULL == first_gp_resource || first_gp_resource->base > arch_configuration[i].base)
-			{
-				first_gp_resource = &(arch_configuration[i]);
-			}
-		}
-		if (MALI_PP == arch_configuration[i].type)
-		{
-			if (NULL == first_pp_resource || first_pp_resource->base > arch_configuration[i].base)
-			{
-				first_pp_resource = &(arch_configuration[i]);
-			}
-		}
-	}
+	/*
+	 * Mali-200 has the PP core first, while Mali-300, Mali-400 and Mali-450 have the GP core first.
+	 * Look at the version register for the first PP core in order to determine the GPU HW revision.
+	 */
 
-	if (NULL == first_gp_resource || NULL == first_pp_resource)
-	{
-		MALI_PRINT_ERROR(("No GP+PP core specified in config file\n"));
-		return _MALI_OSK_ERR_FAULT;
-	}
+	u32 first_pp_offset;
+	_mali_osk_resource_t first_pp_resource;
 
-	if (first_gp_resource->base < first_pp_resource->base)
-	{
-		/* GP is first, so we are dealing with Mali-300, Mali-400 or Mali-450 */
-		global_gpu_base_address = first_gp_resource->base;
+	/* Find out where the first PP core is located */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x8000, NULL)) {
+		/* Mali-300/400/450 */
 		first_pp_offset = 0x8000;
+	} else {
+		/* Mali-200 */
+		first_pp_offset = 0x0000;
 	}
-	else
-	{
-		/* PP is first, so we are dealing with Mali-200 */
-		global_gpu_base_address = first_pp_resource->base;
-		first_pp_offset = 0x0;
-	}
-	MALI_SUCCESS;
-}
-
-static _mali_osk_errcode_t mali_parse_product_info(void)
-{
-	_mali_osk_resource_t *first_pp_resource = NULL;
 
-	/* Find the first PP core */
-	first_pp_resource = mali_find_resource(MALI_PP, first_pp_offset);
-	if (NULL != first_pp_resource)
-	{
+	/* Find the first PP core resource (again) */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + first_pp_offset, &first_pp_resource)) {
 		/* Create a dummy PP object for this core so that we can read the version register */
-		struct mali_group *group = mali_group_create(NULL, NULL);
-		if (NULL != group)
-		{
-			/*struct mali_pp_core *pp_core = mali_pp_create(first_pp_resource, group, 0);*/
-			struct mali_pp_core *pp_core = mali_pp_create(first_pp_resource, group);
-			if (NULL != pp_core)
-			{
+		struct mali_group *group = mali_group_create(NULL, NULL, NULL);
+		if (NULL != group) {
+			struct mali_pp_core *pp_core = mali_pp_create(&first_pp_resource, group, MALI_FALSE, mali_get_bcast_id(&first_pp_resource));
+			if (NULL != pp_core) {
 				u32 pp_version = mali_pp_core_get_version(pp_core);
-				mali_pp_delete(pp_core);
 				mali_group_delete(group);
 
 				global_gpu_major_version = (pp_version >> 8) & 0xFF;
 				global_gpu_minor_version = pp_version & 0xFF;
 
-				switch (pp_version >> 16)
-				{
-					case MALI200_PP_PRODUCT_ID:
-						global_product_id = _MALI_PRODUCT_ID_MALI200;
-						MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-200 r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
-						break;
-					case MALI300_PP_PRODUCT_ID:
-						global_product_id = _MALI_PRODUCT_ID_MALI300;
-						MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-300 r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
-						break;
-					case MALI400_PP_PRODUCT_ID:
-						global_product_id = _MALI_PRODUCT_ID_MALI400;
-						MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-400 MP r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
-						break;
-					case MALI450_PP_PRODUCT_ID:
-						global_product_id = _MALI_PRODUCT_ID_MALI450;
-						MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-450 MP r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
-						break;
-					default:
-						MALI_DEBUG_PRINT(2, ("Found unknown Mali GPU GPU (r%up%u)\n", global_gpu_major_version, global_gpu_minor_version));
-						return _MALI_OSK_ERR_FAULT;
+				switch (pp_version >> 16) {
+				case MALI200_PP_PRODUCT_ID:
+					global_product_id = _MALI_PRODUCT_ID_MALI200;
+					MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-200 r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
+					MALI_PRINT_ERROR(("Mali-200 is not supported by this driver.\n"));
+					_mali_osk_abort();
+					break;
+				case MALI300_PP_PRODUCT_ID:
+					global_product_id = _MALI_PRODUCT_ID_MALI300;
+					MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-300 r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
+					break;
+				case MALI400_PP_PRODUCT_ID:
+					global_product_id = _MALI_PRODUCT_ID_MALI400;
+					MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-400 MP r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
+					break;
+				case MALI450_PP_PRODUCT_ID:
+					global_product_id = _MALI_PRODUCT_ID_MALI450;
+					MALI_DEBUG_PRINT(2, ("Found Mali GPU Mali-450 MP r%up%u\n", global_gpu_major_version, global_gpu_minor_version));
+					break;
+				default:
+					MALI_DEBUG_PRINT(2, ("Found unknown Mali GPU (r%up%u)\n", global_gpu_major_version, global_gpu_minor_version));
+					return _MALI_OSK_ERR_FAULT;
 				}
 
 				return _MALI_OSK_ERR_OK;
-			}
-			else
-			{
+			} else {
 				MALI_PRINT_ERROR(("Failed to create initial PP object\n"));
 			}
-		}
-		else
-		{
+		} else {
 			MALI_PRINT_ERROR(("Failed to create initial group object\n"));
 		}
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("First PP core not specified in config file\n"));
 	}
 
 	return _MALI_OSK_ERR_FAULT;
 }
 
-static void mali_delete_clusters(void)
+
+static void mali_resource_count(u32 *pp_count, u32 *l2_count)
 {
-	u32 i;
-	u32 number_of_clusters = mali_cluster_get_glob_num_clusters();
+	*pp_count = 0;
+	*l2_count = 0;
 
-	for (i = 0; i < number_of_clusters; i++)
-	{
-		mali_cluster_delete(mali_cluster_get_global_cluster(i));
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x08000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0A000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0C000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0E000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x28000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2A000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2C000, NULL)) {
+		++(*pp_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2E000, NULL)) {
+		++(*pp_count);
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x1000, NULL)) {
+		++(*l2_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x10000, NULL)) {
+		++(*l2_count);
+	}
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x11000, NULL)) {
+		++(*l2_count);
 	}
 }
 
-static _mali_osk_errcode_t mali_create_cluster(_mali_osk_resource_t *resource)
+static void mali_delete_groups(void)
 {
-	if (NULL != resource)
-	{
-		struct mali_l2_cache_core *l2_cache;
+	struct mali_group *group;
 
-		if (mali_l2_cache_core_get_glob_num_l2_cores() >= mali_l2_cache_core_get_max_num_l2_cores())
-		{
-			MALI_PRINT_ERROR(("Found too many L2 cache core objects, max %u is supported\n", mali_l2_cache_core_get_max_num_l2_cores()));
-			return _MALI_OSK_ERR_FAULT;
-		}
+	group = mali_group_get_glob_group(0);
+	while (NULL != group) {
+		mali_group_delete(group);
+		group = mali_group_get_glob_group(0);
+	}
 
-		MALI_DEBUG_PRINT(3, ("Found L2 cache %s, starting new cluster\n", resource->description));
+	MALI_DEBUG_ASSERT(0 == mali_group_get_glob_num_groups());
+}
 
-		/*l2_cache = mali_l2_cache_create(resource, global_num_l2_cache_cores);*/
-		l2_cache = mali_l2_cache_create(resource);
-		if (NULL == l2_cache)
-		{
-			MALI_PRINT_ERROR(("Failed to create L2 cache object\n"));
-			return _MALI_OSK_ERR_FAULT;
-		}
+static void mali_delete_l2_cache_cores(void)
+{
+	struct mali_l2_cache_core *l2;
 
-		if (NULL == mali_cluster_create(l2_cache))
-		{
-			MALI_PRINT_ERROR(("Failed to create cluster object\n"));
-			mali_l2_cache_delete(l2_cache);
-			return _MALI_OSK_ERR_FAULT;
-		}
+	l2 = mali_l2_cache_core_get_glob_l2_core(0);
+	while (NULL != l2) {
+		mali_l2_cache_delete(l2);
+		l2 = mali_l2_cache_core_get_glob_l2_core(0);
 	}
-	else
-	{
-		mali_cluster_create(NULL);
-		if (NULL == mali_cluster_get_global_cluster(0))
-		{
-			MALI_PRINT_ERROR(("Failed to create cluster object\n"));
-			return _MALI_OSK_ERR_FAULT;
+
+	MALI_DEBUG_ASSERT(0 == mali_l2_cache_core_get_glob_num_l2_cores());
+}
+
+static struct mali_l2_cache_core *mali_create_l2_cache_core(_mali_osk_resource_t *resource)
+{
+	struct mali_l2_cache_core *l2_cache = NULL;
+
+	if (NULL != resource) {
+
+		MALI_DEBUG_PRINT(3, ("Found L2 cache %s\n", resource->description));
+
+		l2_cache = mali_l2_cache_create(resource);
+		if (NULL == l2_cache) {
+			MALI_PRINT_ERROR(("Failed to create L2 cache object\n"));
+			return NULL;
 		}
 	}
+	MALI_DEBUG_PRINT(3, ("Created L2 cache core object\n"));
 
-	MALI_DEBUG_PRINT(3, ("Created cluster object\n"));
-	return _MALI_OSK_ERR_OK;
+	return l2_cache;
 }
 
-static _mali_osk_errcode_t mali_parse_config_cluster(void)
+static _mali_osk_errcode_t mali_parse_config_l2_cache(void)
 {
-	if (_MALI_PRODUCT_ID_MALI200 == global_product_id)
-	{
-		/* Create dummy cluster without L2 cache */
-		return mali_create_cluster(NULL);
-	}
-	else if (_MALI_PRODUCT_ID_MALI300 == global_product_id || _MALI_PRODUCT_ID_MALI400 == global_product_id)
-	{
-		_mali_osk_resource_t *l2_resource = mali_find_resource(MALI_L2, 0x1000);
-		if (NULL == l2_resource)
-		{
+	struct mali_l2_cache_core *l2_cache = NULL;
+
+	if (mali_is_mali400()) {
+		_mali_osk_resource_t l2_resource;
+		if (_MALI_OSK_ERR_OK != _mali_osk_resource_find(global_gpu_base_address + 0x1000, &l2_resource)) {
 			MALI_DEBUG_PRINT(3, ("Did not find required Mali L2 cache in config file\n"));
 			return _MALI_OSK_ERR_FAULT;
 		}
 
-		return mali_create_cluster(l2_resource);
-	}
-	else if (_MALI_PRODUCT_ID_MALI450 == global_product_id)
-	{
+		l2_cache = mali_create_l2_cache_core(&l2_resource);
+		if (NULL == l2_cache) {
+			return _MALI_OSK_ERR_FAULT;
+		}
+		mali_pm_domain_add_l2(mali_pmu_get_domain_mask(MALI_L20_DOMAIN_INDEX), l2_cache);
+	} else if (mali_is_mali450()) {
 		/*
 		 * L2 for GP    at 0x10000
 		 * L2 for PP0-3 at 0x01000
 		 * L2 for PP4-7 at 0x11000 (optional)
 		 */
 
-		_mali_osk_resource_t *l2_gp_resource;
-		_mali_osk_resource_t *l2_pp_grp0_resource;
-		_mali_osk_resource_t *l2_pp_grp1_resource;
+		_mali_osk_resource_t l2_gp_resource;
+		_mali_osk_resource_t l2_pp_grp0_resource;
+		_mali_osk_resource_t l2_pp_grp1_resource;
 
 		/* Make cluster for GP's L2 */
-		l2_gp_resource = mali_find_resource(MALI_L2, 0x10000);
-		if (NULL != l2_gp_resource)
-		{
-			_mali_osk_errcode_t ret;
-			MALI_DEBUG_PRINT(3, ("Creating Mali-450 cluster for GP\n"));
-			ret = mali_create_cluster(l2_gp_resource);
-			if (_MALI_OSK_ERR_OK != ret)
-			{
-				return ret;
+		if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x10000, &l2_gp_resource)) {
+			MALI_DEBUG_PRINT(3, ("Creating Mali-450 L2 cache core for GP\n"));
+			l2_cache = mali_create_l2_cache_core(&l2_gp_resource);
+			if (NULL == l2_cache) {
+				return _MALI_OSK_ERR_FAULT;
 			}
-		}
-		else
-		{
+			mali_pm_domain_add_l2(mali_pmu_get_domain_mask(MALI_L20_DOMAIN_INDEX), l2_cache);
+		} else {
 			MALI_DEBUG_PRINT(3, ("Did not find required Mali L2 cache for GP in config file\n"));
 			return _MALI_OSK_ERR_FAULT;
 		}
 
-		/* Make cluster for first PP core group */
-		l2_pp_grp0_resource = mali_find_resource(MALI_L2, 0x1000);
-		if (NULL != l2_pp_grp0_resource)
-		{
-			_mali_osk_errcode_t ret;
-			MALI_DEBUG_PRINT(3, ("Creating Mali-450 cluster for PP group 0\n"));
-			ret = mali_create_cluster(l2_pp_grp0_resource);
-			if (_MALI_OSK_ERR_OK != ret)
-			{
-				return ret;
+		/* Find corresponding l2 domain */
+		if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x1000, &l2_pp_grp0_resource)) {
+			MALI_DEBUG_PRINT(3, ("Creating Mali-450 L2 cache core for PP group 0\n"));
+			l2_cache = mali_create_l2_cache_core(&l2_pp_grp0_resource);
+			if (NULL == l2_cache) {
+				return _MALI_OSK_ERR_FAULT;
 			}
-		}
-		else
-		{
+			mali_pm_domain_add_l2(mali_pmu_get_domain_mask(MALI_L21_DOMAIN_INDEX), l2_cache);
+		} else {
 			MALI_DEBUG_PRINT(3, ("Did not find required Mali L2 cache for PP group 0 in config file\n"));
 			return _MALI_OSK_ERR_FAULT;
 		}
 
 		/* Second PP core group is optional, don't fail if we don't find it */
-		l2_pp_grp1_resource = mali_find_resource(MALI_L2, 0x11000);
-		if (NULL != l2_pp_grp1_resource)
-		{
-			_mali_osk_errcode_t ret;
-			MALI_DEBUG_PRINT(3, ("Creating Mali-450 cluster for PP group 0\n"));
-			ret = mali_create_cluster(l2_pp_grp1_resource);
-			if (_MALI_OSK_ERR_OK != ret)
-			{
-				return ret;
+		if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x11000, &l2_pp_grp1_resource)) {
+			MALI_DEBUG_PRINT(3, ("Creating Mali-450 L2 cache core for PP group 1\n"));
+			l2_cache = mali_create_l2_cache_core(&l2_pp_grp1_resource);
+			if (NULL == l2_cache) {
+				return _MALI_OSK_ERR_FAULT;
 			}
+			mali_pm_domain_add_l2(mali_pmu_get_domain_mask(MALI_L22_DOMAIN_INDEX), l2_cache);
 		}
 	}
 
 	return _MALI_OSK_ERR_OK;
 }
 
-static _mali_osk_errcode_t mali_create_group(struct mali_cluster *cluster,
-                                             _mali_osk_resource_t *resource_mmu,
-                                             _mali_osk_resource_t *resource_gp,
-                                             _mali_osk_resource_t *resource_pp)
+static struct mali_group *mali_create_group(struct mali_l2_cache_core *cache,
+		_mali_osk_resource_t *resource_mmu,
+		_mali_osk_resource_t *resource_gp,
+		_mali_osk_resource_t *resource_pp)
 {
 	struct mali_mmu_core *mmu;
 	struct mali_group *group;
-	struct mali_pp_core *pp;
 
 	MALI_DEBUG_PRINT(3, ("Starting new group for MMU %s\n", resource_mmu->description));
 
-	/* Create the MMU object */
-	mmu = mali_mmu_create(resource_mmu);
-	if (NULL == mmu)
-	{
+	/* Create the group object */
+	group = mali_group_create(cache, NULL, NULL);
+	if (NULL == group) {
+		MALI_PRINT_ERROR(("Failed to create group object for MMU %s\n", resource_mmu->description));
+		return NULL;
+	}
+
+	/* Create the MMU object inside group */
+	mmu = mali_mmu_create(resource_mmu, group, MALI_FALSE);
+	if (NULL == mmu) {
 		MALI_PRINT_ERROR(("Failed to create MMU object\n"));
+		mali_group_delete(group);
+		return NULL;
+	}
+
+	if (NULL != resource_gp) {
+		/* Create the GP core object inside this group */
+		struct mali_gp_core *gp_core = mali_gp_create(resource_gp, group);
+		if (NULL == gp_core) {
+			/* No need to clean up now, as we will clean up everything linked in from the cluster when we fail this function */
+			MALI_PRINT_ERROR(("Failed to create GP object\n"));
+			mali_group_delete(group);
+			return NULL;
+		}
+	}
+
+	if (NULL != resource_pp) {
+		struct mali_pp_core *pp_core;
+
+		/* Create the PP core object inside this group */
+		pp_core = mali_pp_create(resource_pp, group, MALI_FALSE, mali_get_bcast_id(resource_pp));
+		if (NULL == pp_core) {
+			/* No need to clean up now, as we will clean up everything linked in from the cluster when we fail this function */
+			MALI_PRINT_ERROR(("Failed to create PP object\n"));
+			mali_group_delete(group);
+			return NULL;
+		}
+	}
+
+	/* Reset group */
+	mali_group_lock(group);
+	mali_group_reset(group);
+	mali_group_unlock(group);
+
+	return group;
+}
+
+static _mali_osk_errcode_t mali_create_virtual_group(_mali_osk_resource_t *resource_mmu_pp_bcast,
+		_mali_osk_resource_t *resource_pp_bcast,
+		_mali_osk_resource_t *resource_dlbu,
+		_mali_osk_resource_t *resource_bcast)
+{
+	struct mali_mmu_core *mmu_pp_bcast_core;
+	struct mali_pp_core *pp_bcast_core;
+	struct mali_dlbu_core *dlbu_core;
+	struct mali_bcast_unit *bcast_core;
+	struct mali_group *group;
+
+	MALI_DEBUG_PRINT(2, ("Starting new virtual group for MMU PP broadcast core %s\n", resource_mmu_pp_bcast->description));
+
+	/* Create the DLBU core object */
+	dlbu_core = mali_dlbu_create(resource_dlbu);
+	if (NULL == dlbu_core) {
+		MALI_PRINT_ERROR(("Failed to create DLBU object \n"));
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	/* Create the Broadcast unit core */
+	bcast_core = mali_bcast_unit_create(resource_bcast);
+	if (NULL == bcast_core) {
+		MALI_PRINT_ERROR(("Failed to create Broadcast unit object!\n"));
+		mali_dlbu_delete(dlbu_core);
 		return _MALI_OSK_ERR_FAULT;
 	}
 
 	/* Create the group object */
-	group = mali_group_create(cluster, mmu);
-	if (NULL == group)
+#if defined(DEBUG)
+	/* Get a physical PP group to temporarily add to broadcast unit.  IRQ
+	 * verification needs a physical group in the broadcast unit to test
+	 * the broadcast unit interrupt line. */
 	{
-		MALI_PRINT_ERROR(("Failed to create group object for MMU %s\n", resource_mmu->description));
-		mali_mmu_delete(mmu);
+		struct mali_group *phys_group = NULL;
+		int i;
+		for (i = 0; i < mali_group_get_glob_num_groups(); i++) {
+			phys_group = mali_group_get_glob_group(i);
+			if (NULL != mali_group_get_pp_core(phys_group)) break;
+		}
+		MALI_DEBUG_ASSERT(NULL != mali_group_get_pp_core(phys_group));
+
+		/* Add the group temporarily to the broadcast, and update the
+		 * broadcast HW. Since the HW is not updated when removing the
+		 * group the IRQ check will work when the virtual PP is created
+		 * later.
+		 *
+		 * When the virtual group gets populated, the actually used
+		 * groups will be added to the broadcast unit and the HW will
+		 * be updated.
+		 */
+		mali_bcast_add_group(bcast_core, phys_group);
+		mali_bcast_reset(bcast_core);
+		mali_bcast_remove_group(bcast_core, phys_group);
+	}
+#endif /* DEBUG */
+	group = mali_group_create(NULL, dlbu_core, bcast_core);
+	if (NULL == group) {
+		MALI_PRINT_ERROR(("Failed to create group object for MMU PP broadcast core %s\n", resource_mmu_pp_bcast->description));
+		mali_bcast_unit_delete(bcast_core);
+		mali_dlbu_delete(dlbu_core);
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	/* Set pointer back to group in mmu.*/
-	mali_mmu_set_group(mmu, group);
+	/* Create the MMU object inside group */
+	mmu_pp_bcast_core = mali_mmu_create(resource_mmu_pp_bcast, group, MALI_TRUE);
+	if (NULL == mmu_pp_bcast_core) {
+		MALI_PRINT_ERROR(("Failed to create MMU PP broadcast object\n"));
+		mali_group_delete(group);
+		return _MALI_OSK_ERR_FAULT;
+	}
 
-	/* Add this group to current cluster */
-	mali_cluster_add_group(cluster, group);
+	/* Create the PP core object inside this group */
+	pp_bcast_core = mali_pp_create(resource_pp_bcast, group, MALI_TRUE, 0);
+	if (NULL == pp_bcast_core) {
+		/* No need to clean up now, as we will clean up everything linked in from the cluster when we fail this function */
+		MALI_PRINT_ERROR(("Failed to create PP object\n"));
+		mali_group_delete(group);
+		return _MALI_OSK_ERR_FAULT;
+	}
 
-	if (NULL != resource_gp)
-	{
-		/* Create the GP core object inside this group */
-		/* global_gp_core = mali_gp_create(resource_gp, group); */
-		if (NULL == mali_gp_create(resource_gp, group))
-		{
-			/* No need to clean up now, as we will clean up everything linked in from the cluster when we fail this function */
-			MALI_PRINT_ERROR(("Failed to create GP object\n"));
+	return _MALI_OSK_ERR_OK;
+}
+
+static _mali_osk_errcode_t mali_parse_config_groups(void)
+{
+	struct mali_group *group;
+	int cluster_id_gp = 0;
+	int cluster_id_pp_grp0 = 0;
+	int cluster_id_pp_grp1 = 0;
+	int i;
+
+	_mali_osk_resource_t resource_gp;
+	_mali_osk_resource_t resource_gp_mmu;
+	_mali_osk_resource_t resource_pp[8];
+	_mali_osk_resource_t resource_pp_mmu[8];
+	_mali_osk_resource_t resource_pp_mmu_bcast;
+	_mali_osk_resource_t resource_pp_bcast;
+	_mali_osk_resource_t resource_dlbu;
+	_mali_osk_resource_t resource_bcast;
+	_mali_osk_errcode_t resource_gp_found;
+	_mali_osk_errcode_t resource_gp_mmu_found;
+	_mali_osk_errcode_t resource_pp_found[8];
+	_mali_osk_errcode_t resource_pp_mmu_found[8];
+	_mali_osk_errcode_t resource_pp_mmu_bcast_found;
+	_mali_osk_errcode_t resource_pp_bcast_found;
+	_mali_osk_errcode_t resource_dlbu_found;
+	_mali_osk_errcode_t resource_bcast_found;
+
+	if (!(mali_is_mali400() || mali_is_mali450())) {
+		/* No known HW core */
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	if (MALI_MAX_JOB_RUNTIME_DEFAULT == mali_max_job_runtime) {
+		/* Group settings are not overridden by module parameters, so use device settings */
+		_mali_osk_device_data data = { 0, };
+
+		if (_MALI_OSK_ERR_OK == _mali_osk_device_data_get(&data)) {
+			/* Use device specific settings (if defined) */
+			if (0 != data.max_job_runtime) {
+				mali_max_job_runtime = data.max_job_runtime;
+			}
+		}
+	}
+
+	if (mali_is_mali450()) {
+		/* Mali-450 have separate L2s for GP, and PP core group(s) */
+		cluster_id_pp_grp0 = 1;
+		cluster_id_pp_grp1 = 2;
+	}
+
+	resource_gp_found = _mali_osk_resource_find(global_gpu_base_address + 0x00000, &resource_gp);
+	resource_gp_mmu_found = _mali_osk_resource_find(global_gpu_base_address + 0x03000, &resource_gp_mmu);
+	resource_pp_found[0] = _mali_osk_resource_find(global_gpu_base_address + 0x08000, &(resource_pp[0]));
+	resource_pp_found[1] = _mali_osk_resource_find(global_gpu_base_address + 0x0A000, &(resource_pp[1]));
+	resource_pp_found[2] = _mali_osk_resource_find(global_gpu_base_address + 0x0C000, &(resource_pp[2]));
+	resource_pp_found[3] = _mali_osk_resource_find(global_gpu_base_address + 0x0E000, &(resource_pp[3]));
+	resource_pp_found[4] = _mali_osk_resource_find(global_gpu_base_address + 0x28000, &(resource_pp[4]));
+	resource_pp_found[5] = _mali_osk_resource_find(global_gpu_base_address + 0x2A000, &(resource_pp[5]));
+	resource_pp_found[6] = _mali_osk_resource_find(global_gpu_base_address + 0x2C000, &(resource_pp[6]));
+	resource_pp_found[7] = _mali_osk_resource_find(global_gpu_base_address + 0x2E000, &(resource_pp[7]));
+	resource_pp_mmu_found[0] = _mali_osk_resource_find(global_gpu_base_address + 0x04000, &(resource_pp_mmu[0]));
+	resource_pp_mmu_found[1] = _mali_osk_resource_find(global_gpu_base_address + 0x05000, &(resource_pp_mmu[1]));
+	resource_pp_mmu_found[2] = _mali_osk_resource_find(global_gpu_base_address + 0x06000, &(resource_pp_mmu[2]));
+	resource_pp_mmu_found[3] = _mali_osk_resource_find(global_gpu_base_address + 0x07000, &(resource_pp_mmu[3]));
+	resource_pp_mmu_found[4] = _mali_osk_resource_find(global_gpu_base_address + 0x1C000, &(resource_pp_mmu[4]));
+	resource_pp_mmu_found[5] = _mali_osk_resource_find(global_gpu_base_address + 0x1D000, &(resource_pp_mmu[5]));
+	resource_pp_mmu_found[6] = _mali_osk_resource_find(global_gpu_base_address + 0x1E000, &(resource_pp_mmu[6]));
+	resource_pp_mmu_found[7] = _mali_osk_resource_find(global_gpu_base_address + 0x1F000, &(resource_pp_mmu[7]));
+
+
+	if (mali_is_mali450()) {
+		resource_bcast_found = _mali_osk_resource_find(global_gpu_base_address + 0x13000, &resource_bcast);
+		resource_dlbu_found = _mali_osk_resource_find(global_gpu_base_address + 0x14000, &resource_dlbu);
+		resource_pp_mmu_bcast_found = _mali_osk_resource_find(global_gpu_base_address + 0x15000, &resource_pp_mmu_bcast);
+		resource_pp_bcast_found = _mali_osk_resource_find(global_gpu_base_address + 0x16000, &resource_pp_bcast);
+
+		if (_MALI_OSK_ERR_OK != resource_bcast_found ||
+		    _MALI_OSK_ERR_OK != resource_dlbu_found ||
+		    _MALI_OSK_ERR_OK != resource_pp_mmu_bcast_found ||
+		    _MALI_OSK_ERR_OK != resource_pp_bcast_found) {
+			/* Missing mandatory core(s) for Mali-450 */
+			MALI_DEBUG_PRINT(2, ("Missing mandatory resources, Mali-450 needs DLBU, Broadcast unit, virtual PP core and virtual MMU\n"));
 			return _MALI_OSK_ERR_FAULT;
 		}
+	}
+
+	if (_MALI_OSK_ERR_OK != resource_gp_found ||
+	    _MALI_OSK_ERR_OK != resource_gp_mmu_found ||
+	    _MALI_OSK_ERR_OK != resource_pp_found[0] ||
+	    _MALI_OSK_ERR_OK != resource_pp_mmu_found[0]) {
+		/* Missing mandatory core(s) */
+		MALI_DEBUG_PRINT(2, ("Missing mandatory resource, need at least one GP and one PP, both with a separate MMU\n"));
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	MALI_DEBUG_ASSERT(1 <= mali_l2_cache_core_get_glob_num_l2_cores());
+	group = mali_create_group(mali_l2_cache_core_get_glob_l2_core(cluster_id_gp), &resource_gp_mmu, &resource_gp, NULL);
+	if (NULL == group) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	/* Add GP in group, for PMU ref count */
+	mali_pm_domain_add_group(mali_pmu_get_domain_mask(MALI_GP_DOMAIN_INDEX), group);
+
+	/* Create group for first (and mandatory) PP core */
+	MALI_DEBUG_ASSERT(mali_l2_cache_core_get_glob_num_l2_cores() >= (cluster_id_pp_grp0 + 1)); /* >= 1 on Mali-300 and Mali-400, >= 2 on Mali-450 */
+	group = mali_create_group(mali_l2_cache_core_get_glob_l2_core(cluster_id_pp_grp0), &resource_pp_mmu[0], NULL, &resource_pp[0]);
+	if (NULL == group) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	/* Find corresponding pp domain */
+	mali_pm_domain_add_group(mali_pmu_get_domain_mask(MALI_PP0_DOMAIN_INDEX), group);
+
+	mali_inited_pp_cores_group_1++;
+
+	/* Create groups for rest of the cores in the first PP core group */
+	for (i = 1; i < 4; i++) { /* First half of the PP cores belong to first core group */
+		if (mali_inited_pp_cores_group_1 < mali_max_pp_cores_group_1) {
+			if (_MALI_OSK_ERR_OK == resource_pp_found[i] && _MALI_OSK_ERR_OK == resource_pp_mmu_found[i]) {
+				group = mali_create_group(mali_l2_cache_core_get_glob_l2_core(cluster_id_pp_grp0), &resource_pp_mmu[i], NULL, &resource_pp[i]);
+				if (NULL == group) {
+					return _MALI_OSK_ERR_FAULT;
+				}
+
+				mali_pm_domain_add_group(mali_pmu_get_domain_mask(i + MALI_PP0_DOMAIN_INDEX), group);
+
+				mali_inited_pp_cores_group_1++;
+			}
+		}
+	}
+
+	/* Create groups for cores in the second PP core group */
+	for (i = 4; i < 8; i++) { /* Second half of the PP cores belong to second core group */
+		if (mali_inited_pp_cores_group_2 < mali_max_pp_cores_group_2) {
+			if (_MALI_OSK_ERR_OK == resource_pp_found[i] && _MALI_OSK_ERR_OK == resource_pp_mmu_found[i]) {
+				MALI_DEBUG_ASSERT(mali_l2_cache_core_get_glob_num_l2_cores() >= 2); /* Only Mali-450 have a second core group */
+				group = mali_create_group(mali_l2_cache_core_get_glob_l2_core(cluster_id_pp_grp1), &resource_pp_mmu[i], NULL, &resource_pp[i]);
+				if (NULL == group) {
+					return _MALI_OSK_ERR_FAULT;
+				}
+				mali_pm_domain_add_group(mali_pmu_get_domain_mask(i + MALI_PP0_DOMAIN_INDEX), group);
+				mali_inited_pp_cores_group_2++;
+			}
+		}
+	}
+
+	if (mali_is_mali450()) {
+		_mali_osk_errcode_t err = mali_create_virtual_group(&resource_pp_mmu_bcast, &resource_pp_bcast, &resource_dlbu, &resource_bcast);
+		if (_MALI_OSK_ERR_OK != err) {
+			return err;
+		}
+	}
+
+	mali_max_pp_cores_group_1 = mali_inited_pp_cores_group_1;
+	mali_max_pp_cores_group_2 = mali_inited_pp_cores_group_2;
+	MALI_DEBUG_PRINT(2, ("%d+%d PP cores initialized\n", mali_inited_pp_cores_group_1, mali_inited_pp_cores_group_2));
+
+	return _MALI_OSK_ERR_OK;
+}
+
+static _mali_osk_errcode_t mali_check_shared_interrupts(void)
+{
+#if !defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	if (MALI_TRUE == _mali_osk_shared_interrupts()) {
+		MALI_PRINT_ERROR(("Shared interrupts detected, but driver support is not enabled\n"));
+		return _MALI_OSK_ERR_FAULT;
+	}
+#endif /* !defined(CONFIG_MALI_SHARED_INTERRUPTS) */
+
+	/* It is OK to compile support for shared interrupts even if Mali is not using it. */
+	return _MALI_OSK_ERR_OK;
+}
+
+static _mali_osk_errcode_t mali_create_pm_domains(void)
+{
+	int i;
+
+	for (i = 0; i < MALI_MAX_NUMBER_OF_DOMAINS; i++) {
+		if (0x0 == mali_pmu_get_domain_mask(i)) continue;
+
+		if (NULL == mali_pm_domain_create(mali_pmu_get_domain_mask(i))) {
+			return _MALI_OSK_ERR_NOMEM;
+		}
+	}
+
+	return _MALI_OSK_ERR_OK;
+}
+
+static void mali_use_default_pm_domain_config(void)
+{
+	u32 pp_count_gr1 = 0;
+	u32 pp_count_gr2 = 0;
+	u32 l2_count = 0;
+
+	MALI_DEBUG_ASSERT(0 != global_gpu_base_address);
+
+	/* GP core */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x00000, NULL)) {
+		mali_pmu_set_domain_mask(MALI_GP_DOMAIN_INDEX, 0x01);
+	}
+
+	/* PP0 - PP3 core */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x08000, NULL)) {
+		++pp_count_gr1;
+
+		if (mali_is_mali400()) {
+			mali_pmu_set_domain_mask(MALI_PP0_DOMAIN_INDEX, 0x01 << 2);
+		} else if (mali_is_mali450()) {
+			mali_pmu_set_domain_mask(MALI_PP0_DOMAIN_INDEX, 0x01 << 1);
+		}
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0A000, NULL)) {
+		++pp_count_gr1;
+
+		if (mali_is_mali400()) {
+			mali_pmu_set_domain_mask(MALI_PP1_DOMAIN_INDEX, 0x01 << 3);
+		} else if (mali_is_mali450()) {
+			mali_pmu_set_domain_mask(MALI_PP1_DOMAIN_INDEX, 0x01 << 2);
+		}
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0C000, NULL)) {
+		++pp_count_gr1;
+
+		if (mali_is_mali400()) {
+			mali_pmu_set_domain_mask(MALI_PP2_DOMAIN_INDEX, 0x01 << 4);
+		} else if (mali_is_mali450()) {
+			mali_pmu_set_domain_mask(MALI_PP2_DOMAIN_INDEX, 0x01 << 2);
+		}
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x0E000, NULL)) {
+		++pp_count_gr1;
+
+		if (mali_is_mali400()) {
+			mali_pmu_set_domain_mask(MALI_PP3_DOMAIN_INDEX, 0x01 << 5);
+		} else if (mali_is_mali450()) {
+			mali_pmu_set_domain_mask(MALI_PP3_DOMAIN_INDEX, 0x01 << 2);
+		}
+	}
+
+	/* PP4 - PP7 */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x28000, NULL)) {
+		++pp_count_gr2;
+
+		mali_pmu_set_domain_mask(MALI_PP4_DOMAIN_INDEX, 0x01 << 3);
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2A000, NULL)) {
+		++pp_count_gr2;
+
+		mali_pmu_set_domain_mask(MALI_PP5_DOMAIN_INDEX, 0x01 << 3);
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2C000, NULL)) {
+		++pp_count_gr2;
+
+		mali_pmu_set_domain_mask(MALI_PP6_DOMAIN_INDEX, 0x01 << 3);
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x2E000, NULL)) {
+		++pp_count_gr2;
+
+		mali_pmu_set_domain_mask(MALI_PP7_DOMAIN_INDEX, 0x01 << 3);
+	}
+
+	/* L2gp/L2PP0/L2PP4 */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x10000, NULL)) {
+		++l2_count;
+
+		if (mali_is_mali400()) {
+			mali_pmu_set_domain_mask(MALI_L20_DOMAIN_INDEX, 0x01 << 1);
+		} else if (mali_is_mali450()) {
+			mali_pmu_set_domain_mask(MALI_L20_DOMAIN_INDEX, 0x01 << 0);
+		}
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x1000, NULL)) {
+		++l2_count;
+
+		mali_pmu_set_domain_mask(MALI_L21_DOMAIN_INDEX, 0x01 << 1);
+	}
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x11000, NULL)) {
+		++l2_count;
+
+		mali_pmu_set_domain_mask(MALI_L22_DOMAIN_INDEX, 0x01 << 3);
+	}
+
+	MALI_DEBUG_PRINT(2, ("Using default PMU domain config: (%d) gr1_pp_cores, (%d) gr2_pp_cores, (%d) l2_count. \n", pp_count_gr1, pp_count_gr2, l2_count));
+}
+
+static void mali_set_pmu_global_domain_config(void)
+{
+	_mali_osk_device_data data = { 0, };
+	int i = 0;
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_device_data_get(&data)) {
+		/* Check whether has customized pmu domain configure */
+		for (i = 0; i < MALI_MAX_NUMBER_OF_DOMAINS; i++) {
+			if (0 != data.pmu_domain_config[i]) break;
+		}
+
+		if (MALI_MAX_NUMBER_OF_DOMAINS == i) {
+			mali_use_default_pm_domain_config();
+		} else {
+			/* Copy the customer config to global config */
+			mali_pmu_copy_domain_mask(data.pmu_domain_config, sizeof(data.pmu_domain_config));
+		}
+	}
+}
+
+static _mali_osk_errcode_t mali_parse_config_pmu(void)
+{
+	_mali_osk_resource_t resource_pmu;
 
-		/* Add GP object to this group */
-		MALI_DEBUG_PRINT(3, ("Adding GP %s to group\n", resource_gp->description));
-		mali_group_add_gp_core(group, mali_gp_get_global_gp_core());
-	}
+	MALI_DEBUG_ASSERT(0 != global_gpu_base_address);
 
-	if (NULL != resource_pp)
-	{
-		/* Create the PP core object inside this group */
-		pp = mali_pp_create(resource_pp, group);
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x02000, &resource_pmu)) {
+		struct mali_pmu_core *pmu;
 
-		if (NULL == pp)
-		{
-			/* No need to clean up now, as we will clean up everything linked in from the cluster when we fail this function */
-			MALI_PRINT_ERROR(("Failed to create PP object\n"));
+		mali_set_pmu_global_domain_config();
+
+		pmu = mali_pmu_create(&resource_pmu);
+		if (NULL == pmu) {
+			MALI_PRINT_ERROR(("Failed to create PMU\n"));
 			return _MALI_OSK_ERR_FAULT;
 		}
-
-		/* Add PP object to this group */
-		MALI_DEBUG_PRINT(3, ("Adding PP %s to group\n", resource_pp->description));
-		mali_group_add_pp_core(group, pp);
 	}
 
+	/* It's ok if the PMU doesn't exist */
 	return _MALI_OSK_ERR_OK;
 }
 
-static _mali_osk_errcode_t mali_parse_config_groups(void)
+static _mali_osk_errcode_t mali_parse_config_dma(void)
 {
-	if (_MALI_PRODUCT_ID_MALI200 == global_product_id)
-	{
-		_mali_osk_resource_t *resource_gp;
-		_mali_osk_resource_t *resource_pp;
-		_mali_osk_resource_t *resource_mmu;
-
-		MALI_DEBUG_ASSERT(1 == mali_cluster_get_glob_num_clusters());
-
-		resource_gp  = mali_find_resource(MALI_GP, 0x02000);
-		resource_pp  = mali_find_resource(MALI_PP, 0x00000);
-		resource_mmu = mali_find_resource(MMU, 0x03000);
+	_mali_osk_resource_t resource_dma;
 
-		if (NULL == resource_mmu || NULL == resource_gp || NULL == resource_pp)
-		{
-			/* Missing mandatory core(s) */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x12000, &resource_dma)) {
+		if (NULL == mali_dma_create(&resource_dma)) {
 			return _MALI_OSK_ERR_FAULT;
 		}
-
-		/*return mali_create_group(global_clusters[0], resource_mmu, resource_gp, resource_pp);*/
-		return mali_create_group(mali_cluster_get_global_cluster(0), resource_mmu, resource_gp, resource_pp);
+		return _MALI_OSK_ERR_OK;
+	} else {
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
 	}
-	else if (_MALI_PRODUCT_ID_MALI300 == global_product_id ||
-	         _MALI_PRODUCT_ID_MALI400 == global_product_id ||
-	         _MALI_PRODUCT_ID_MALI450 == global_product_id)
-	{
-		_mali_osk_errcode_t err;
-		int cluster_id_gp = 0;
-		int cluster_id_pp_grp0 = 0;
-		int cluster_id_pp_grp1 = 0;
-		int i;
-		_mali_osk_resource_t *resource_gp;
-		_mali_osk_resource_t *resource_gp_mmu;
-		_mali_osk_resource_t *resource_pp[mali_pp_get_max_num_pp_cores()];
-		_mali_osk_resource_t *resource_pp_mmu[mali_pp_get_max_num_pp_cores()];
-		u32 max_num_pp_cores = mali_pp_get_max_num_pp_cores();
+}
 
-		if (_MALI_PRODUCT_ID_MALI450 == global_product_id)
-		{
-			/* Mali-450 has separate L2s for GP, and PP core group(s) */
-			cluster_id_pp_grp0 = 1;
-			cluster_id_pp_grp1 = 2;
+static _mali_osk_errcode_t mali_parse_config_memory(void)
+{
+	_mali_osk_errcode_t ret;
+
+	if (0 == mali_dedicated_mem_start && 0 == mali_dedicated_mem_size && 0 == mali_shared_mem_size) {
+		/* Memory settings are not overridden by module parameters, so use device settings */
+		_mali_osk_device_data data = { 0, };
+
+		if (_MALI_OSK_ERR_OK == _mali_osk_device_data_get(&data)) {
+			/* Use device specific settings (if defined) */
+			mali_dedicated_mem_start = data.dedicated_mem_start;
+			mali_dedicated_mem_size = data.dedicated_mem_size;
+			mali_shared_mem_size = data.shared_mem_size;
 		}
 
-		resource_gp = mali_find_resource(MALI_GP, 0x00000);
-		resource_gp_mmu = mali_find_resource(MMU, 0x03000);
-		resource_pp[0] = mali_find_resource(MALI_PP, 0x08000);
-		resource_pp[1] = mali_find_resource(MALI_PP, 0x0A000);
-		resource_pp[2] = mali_find_resource(MALI_PP, 0x0C000);
-		resource_pp[3] = mali_find_resource(MALI_PP, 0x0E000);
-		resource_pp[4] = mali_find_resource(MALI_PP, 0x28000);
-		resource_pp[5] = mali_find_resource(MALI_PP, 0x2A000);
-		resource_pp[6] = mali_find_resource(MALI_PP, 0x2C000);
-		resource_pp[7] = mali_find_resource(MALI_PP, 0x2E000);
-		resource_pp_mmu[0] = mali_find_resource(MMU, 0x04000);
-		resource_pp_mmu[1] = mali_find_resource(MMU, 0x05000);
-		resource_pp_mmu[2] = mali_find_resource(MMU, 0x06000);
-		resource_pp_mmu[3] = mali_find_resource(MMU, 0x07000);
-		resource_pp_mmu[4] = mali_find_resource(MMU, 0x1C000);
-		resource_pp_mmu[5] = mali_find_resource(MMU, 0x1D000);
-		resource_pp_mmu[6] = mali_find_resource(MMU, 0x1E000);
-		resource_pp_mmu[7] = mali_find_resource(MMU, 0x1F000);
-
-		if (NULL == resource_gp || NULL == resource_gp_mmu || NULL == resource_pp[0] || NULL == resource_pp_mmu[0])
-		{
-			/* Missing mandatory core(s) */
-			MALI_DEBUG_PRINT(2, ("Missing mandatory resource, need at least one GP and one PP, both with a separate MMU (0x%08X, 0x%08X, 0x%08X, 0x%08X)\n",
-			                     resource_gp, resource_gp_mmu, resource_pp[0], resource_pp_mmu[0]));
-			return _MALI_OSK_ERR_FAULT;
+		if (0 == mali_dedicated_mem_start && 0 == mali_dedicated_mem_size && 0 == mali_shared_mem_size) {
+			/* No GPU memory specified */
+			return _MALI_OSK_ERR_INVALID_ARGS;
 		}
 
-		MALI_DEBUG_ASSERT(1 <= mali_cluster_get_glob_num_clusters());
-		err = mali_create_group(mali_cluster_get_global_cluster(cluster_id_gp), resource_gp_mmu, resource_gp, NULL);
-		if (err != _MALI_OSK_ERR_OK)
-		{
-			return err;
+		MALI_DEBUG_PRINT(2, ("Using device defined memory settings (dedicated: 0x%08X@0x%08X, shared: 0x%08X)\n",
+				     mali_dedicated_mem_size, mali_dedicated_mem_start, mali_shared_mem_size));
+	} else {
+		MALI_DEBUG_PRINT(2, ("Using module defined memory settings (dedicated: 0x%08X@0x%08X, shared: 0x%08X)\n",
+				     mali_dedicated_mem_size, mali_dedicated_mem_start, mali_shared_mem_size));
+	}
+
+	if (0 < mali_dedicated_mem_size && 0 != mali_dedicated_mem_start) {
+		/* Dedicated memory */
+		ret = mali_memory_core_resource_dedicated_memory(mali_dedicated_mem_start, mali_dedicated_mem_size);
+		if (_MALI_OSK_ERR_OK != ret) {
+			MALI_PRINT_ERROR(("Failed to register dedicated memory\n"));
+			mali_memory_terminate();
+			return ret;
 		}
+	}
 
-		/* Create group for first (and mandatory) PP core */
-		MALI_DEBUG_ASSERT(mali_cluster_get_glob_num_clusters() >= (cluster_id_pp_grp0 + 1)); /* >= 1 on Mali-300 and Mali-400, >= 2 on Mali-450 */
-		err = mali_create_group(mali_cluster_get_global_cluster(cluster_id_pp_grp0), resource_pp_mmu[0], NULL, resource_pp[0]);
-		if (err != _MALI_OSK_ERR_OK)
-		{
-			return err;
+	if (0 < mali_shared_mem_size) {
+		/* Shared OS memory */
+		ret = mali_memory_core_resource_os_memory(mali_shared_mem_size);
+		if (_MALI_OSK_ERR_OK != ret) {
+			MALI_PRINT_ERROR(("Failed to register shared OS memory\n"));
+			mali_memory_terminate();
+			return ret;
 		}
+	}
 
-		/* Create groups for rest of the cores in the first PP core group */
-		for (i = 1; i < 4; i++) /* First half of the PP cores belong to first core group */
-		{
-			if (NULL != resource_pp[i])
-			{
-				err = mali_create_group(mali_cluster_get_global_cluster(cluster_id_pp_grp0), resource_pp_mmu[i], NULL, resource_pp[i]);
-				if (err != _MALI_OSK_ERR_OK)
-				{
-					return err;
-				}
-			}
+	if (0 == mali_fb_start && 0 == mali_fb_size) {
+		/* Frame buffer settings are not overridden by module parameters, so use device settings */
+		_mali_osk_device_data data = { 0, };
+
+		if (_MALI_OSK_ERR_OK == _mali_osk_device_data_get(&data)) {
+			/* Use device specific settings (if defined) */
+			mali_fb_start = data.fb_start;
+			mali_fb_size = data.fb_size;
 		}
 
-		/* Create groups for cores in the second PP core group */
-		for (i = 4; i < max_num_pp_cores; i++) /* Second half of the PP cores belong to second core group */
-		{
-			if (NULL != resource_pp[i])
-			{
-				MALI_DEBUG_ASSERT(mali_cluster_get_glob_num_clusters() >= 2); /* Only Mali-450 have more than 4 PPs, and these cores belong to second core group */
-				err = mali_create_group(mali_cluster_get_global_cluster(cluster_id_pp_grp1), resource_pp_mmu[i], NULL, resource_pp[i]);
-				if (err != _MALI_OSK_ERR_OK)
-				{
-					return err;
-				}
-			}
+		MALI_DEBUG_PRINT(2, ("Using device defined frame buffer settings (0x%08X@0x%08X)\n",
+				     mali_fb_size, mali_fb_start));
+	} else {
+		MALI_DEBUG_PRINT(2, ("Using module defined frame buffer settings (0x%08X@0x%08X)\n",
+				     mali_fb_size, mali_fb_start));
+	}
+
+	if (0 != mali_fb_size) {
+		/* Register frame buffer */
+		ret = mali_mem_validation_add_range(mali_fb_start, mali_fb_size);
+		if (_MALI_OSK_ERR_OK != ret) {
+			MALI_PRINT_ERROR(("Failed to register frame buffer memory region\n"));
+			mali_memory_terminate();
+			return ret;
 		}
 	}
 
 	return _MALI_OSK_ERR_OK;
 }
 
-static _mali_osk_errcode_t mali_parse_config_pmu(void)
+static void mali_detect_gpu_class(void)
 {
-	_mali_osk_errcode_t err = _MALI_OSK_ERR_OK;
-	_mali_osk_resource_t *resource_pmu;
-	u32 number_of_pp_cores;
-	u32 number_of_l2_caches;
-
-	resource_pmu = mali_find_resource(PMU, 0x02000);
-	number_of_pp_cores = mali_count_resources(MALI_PP);
-	number_of_l2_caches = mali_count_resources(MALI_L2);
+	u32 number_of_pp_cores = 0;
+	u32 number_of_l2_caches = 0;
 
-	if (NULL != resource_pmu)
-	{
-		if (NULL == mali_pmu_create(resource_pmu, number_of_pp_cores, number_of_l2_caches))
-		{
-			err = _MALI_OSK_ERR_FAULT;
-		}
+	mali_resource_count(&number_of_pp_cores, &number_of_l2_caches);
+	if (number_of_l2_caches > 1) {
+		mali_gpu_class_is_mali450 = MALI_TRUE;
 	}
-	return err;
 }
 
-static _mali_osk_errcode_t mali_parse_config_memory(void)
+static _mali_osk_errcode_t mali_init_hw_reset(void)
 {
-	int i;
-	_mali_osk_errcode_t ret;
+#if defined(CONFIG_MALI450)
+	_mali_osk_resource_t resource_bcast;
 
-	for(i = 0; i < num_resources; i++)
-	{
-		switch(arch_configuration[i].type)
-		{
-			case OS_MEMORY:
-				ret = mali_memory_core_resource_os_memory(&arch_configuration[i]);
-				if (_MALI_OSK_ERR_OK != ret)
-				{
-					MALI_PRINT_ERROR(("Failed to register OS_MEMORY\n"));
-					mali_memory_terminate();
-					return ret;
-				}
-				break;
-			case MEMORY:
-				ret = mali_memory_core_resource_dedicated_memory(&arch_configuration[i]);
-				if (_MALI_OSK_ERR_OK != ret)
-				{
-					MALI_PRINT_ERROR(("Failed to register MEMORY\n"));
-					mali_memory_terminate();
-					return ret;
-				}
-				break;
-			case MEM_VALIDATION:
-				ret = mali_mem_validation_add_range(&arch_configuration[i]);
-				if (_MALI_OSK_ERR_OK != ret)
-				{
-					MALI_PRINT_ERROR(("Failed to register MEM_VALIDATION\n"));
-					mali_memory_terminate();
-					return ret;
-				}
-				break;
-			default:
-				break;
+	/* Ensure broadcast unit is in a good state before we start creating
+	 * groups and cores.
+	 */
+	if (_MALI_OSK_ERR_OK == _mali_osk_resource_find(global_gpu_base_address + 0x13000, &resource_bcast)) {
+		struct mali_bcast_unit *bcast_core;
+
+		bcast_core = mali_bcast_unit_create(&resource_bcast);
+		if (NULL == bcast_core) {
+			MALI_PRINT_ERROR(("Failed to create Broadcast unit object!\n"));
+			return _MALI_OSK_ERR_FAULT;
 		}
+		mali_bcast_unit_delete(bcast_core);
 	}
+#endif /* CONFIG_MALI450 */
+
 	return _MALI_OSK_ERR_OK;
 }
 
 _mali_osk_errcode_t mali_initialize_subsystems(void)
 {
 	_mali_osk_errcode_t err;
-	mali_bool is_pmu_enabled;
+	struct mali_pmu_core *pmu;
 
-	MALI_CHECK_NON_NULL(system_info_lock = _mali_osk_lock_init( (_mali_osk_lock_flags_t)(_MALI_OSK_LOCKFLAG_SPINLOCK
-	                                           | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE), 0, 0 ), _MALI_OSK_ERR_FAULT);
+	mali_pp_job_initialize();
 
 	err = mali_session_initialize();
 	if (_MALI_OSK_ERR_OK != err) goto session_init_failed;
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 	err = _mali_osk_profiling_init(mali_boot_profiling ? MALI_TRUE : MALI_FALSE);
-	if (_MALI_OSK_ERR_OK != err)
-	{
-		/* No biggie if we wheren't able to initialize the profiling */
+	if (_MALI_OSK_ERR_OK != err) {
+		/* No biggie if we weren't able to initialize the profiling */
 		MALI_PRINT_ERROR(("Failed to initialize profiling, feature will be unavailable\n"));
 	}
 #endif
 
-	/* Build dummy system info. Will be removed in the future. */
-	err = build_system_info();
-	if (_MALI_OSK_ERR_OK != err) goto build_system_info_failed;
-
-	/* Get data from config.h */
-	err = _mali_osk_resources_init(&arch_configuration, &num_resources);
-	if (_MALI_OSK_ERR_OK != err) goto osk_resources_init_failed;
-
-	/* Initialize driver subsystems */
 	err = mali_memory_initialize();
 	if (_MALI_OSK_ERR_OK != err) goto memory_init_failed;
 
@@ -635,22 +959,49 @@ _mali_osk_errcode_t mali_initialize_subsystems(void)
 	err = mali_parse_config_memory();
 	if (_MALI_OSK_ERR_OK != err) goto parse_memory_config_failed;
 
-	/* Parsing the GPU base address and first pp offset */
-	err = mali_parse_gpu_base_and_first_pp_offset_address();
-	if (_MALI_OSK_ERR_OK != err) goto parse_gpu_base_address_failed;
+	err = mali_set_global_gpu_base_address();
+	if (_MALI_OSK_ERR_OK != err) goto set_global_gpu_base_address_failed;
 
-	/* Initialize the MALI PMU */
-	err = mali_parse_config_pmu();
-	if (_MALI_OSK_ERR_OK != err) goto parse_pmu_config_failed;
+	/* Detect gpu class according to l2 cache number */
+	mali_detect_gpu_class();
+
+	err = mali_check_shared_interrupts();
+	if (_MALI_OSK_ERR_OK != err) goto check_shared_interrupts_failed;
 
-	is_pmu_enabled = mali_pmu_get_global_pmu_core() != NULL ? MALI_TRUE : MALI_FALSE;
+	err = mali_pp_scheduler_initialize();
+	if (_MALI_OSK_ERR_OK != err) goto pp_scheduler_init_failed;
 
 	/* Initialize the power management module */
 	err = mali_pm_initialize();
 	if (_MALI_OSK_ERR_OK != err) goto pm_init_failed;
 
+	/* Initialize the MALI PMU */
+	err = mali_parse_config_pmu();
+	if (_MALI_OSK_ERR_OK != err) goto parse_pmu_config_failed;
+
 	/* Make sure the power stays on for the rest of this function */
-	mali_pm_always_on(MALI_TRUE);
+	err = _mali_osk_pm_dev_ref_add();
+	if (_MALI_OSK_ERR_OK != err) goto pm_always_on_failed;
+
+	/*
+	 * If run-time PM is used, then the mali_pm module has now already been
+	 * notified that the power now is on (through the resume callback functions).
+	 * However, if run-time PM is not used, then there will probably not be any
+	 * calls to the resume callback functions, so we need to explicitly tell it
+	 * that the power is on.
+	 */
+	mali_pm_set_power_is_on();
+
+	/* Reset PMU HW and ensure all Mali power domains are on */
+	pmu = mali_pmu_get_global_pmu_core();
+	if (NULL != pmu) {
+		err = mali_pmu_reset(pmu);
+		if (_MALI_OSK_ERR_OK != err) goto pmu_reset_failed;
+	}
+
+	/* Ensure HW is in a good state before starting to access cores. */
+	err = mali_init_hw_reset();
+	if (_MALI_OSK_ERR_OK != err) goto init_hw_reset_failed;
 
 	/* Detect which Mali GPU we are dealing with */
 	err = mali_parse_product_info();
@@ -658,19 +1009,26 @@ _mali_osk_errcode_t mali_initialize_subsystems(void)
 
 	/* The global_product_id is now populated with the correct Mali GPU */
 
+	/* Create PM domains only if PMU exists */
+	if (NULL != pmu) {
+		err = mali_create_pm_domains();
+		if (_MALI_OSK_ERR_OK != err) goto pm_domain_failed;
+	}
+
 	/* Initialize MMU module */
 	err = mali_mmu_initialize();
 	if (_MALI_OSK_ERR_OK != err) goto mmu_init_failed;
 
-	/* Initialize the DLBU module for Mali-450 */
-	if (_MALI_PRODUCT_ID_MALI450 == global_product_id)
-	{
+	if (mali_is_mali450()) {
 		err = mali_dlbu_initialize();
 		if (_MALI_OSK_ERR_OK != err) goto dlbu_init_failed;
+
+		err = mali_parse_config_dma();
+		if (_MALI_OSK_ERR_OK != err) goto dma_parsing_failed;
 	}
 
 	/* Start configuring the actual Mali hardware. */
-	err = mali_parse_config_cluster();
+	err = mali_parse_config_l2_cache();
 	if (_MALI_OSK_ERR_OK != err) goto config_parsing_failed;
 	err = mali_parse_config_groups();
 	if (_MALI_OSK_ERR_OK != err) goto config_parsing_failed;
@@ -680,114 +1038,115 @@ _mali_osk_errcode_t mali_initialize_subsystems(void)
 	if (_MALI_OSK_ERR_OK != err) goto scheduler_init_failed;
 	err = mali_gp_scheduler_initialize();
 	if (_MALI_OSK_ERR_OK != err) goto gp_scheduler_init_failed;
-	err = mali_pp_scheduler_initialize();
-	if (_MALI_OSK_ERR_OK != err) goto pp_scheduler_init_failed;
 
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
+	/* PP scheduler population can't fail */
+	mali_pp_scheduler_populate();
+
 	/* Initialize the GPU utilization tracking */
 	err = mali_utilization_init();
 	if (_MALI_OSK_ERR_OK != err) goto utilization_init_failed;
-#endif
 
-	/* We no longer need to stay */
-	mali_pm_always_on(MALI_FALSE);
+	/* Allowing the system to be turned off */
+	_mali_osk_pm_dev_ref_dec();
+
 	MALI_SUCCESS; /* all ok */
 
 	/* Error handling */
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
+
 utilization_init_failed:
-	mali_pp_scheduler_terminate();
-#endif
-pp_scheduler_init_failed:
+	mali_pp_scheduler_depopulate();
 	mali_gp_scheduler_terminate();
 gp_scheduler_init_failed:
 	mali_scheduler_terminate();
 scheduler_init_failed:
 config_parsing_failed:
-	mali_delete_clusters(); /* Delete clusters even if config parsing failed. */
-	if (_MALI_PRODUCT_ID_MALI450 == global_product_id)
+	mali_delete_groups(); /* Delete any groups not (yet) owned by a scheduler */
+	mali_delete_l2_cache_cores(); /* Delete L2 cache cores even if config parsing failed. */
 	{
-		mali_dlbu_terminate();
+		struct mali_dma_core *dma = mali_dma_get_global_dma_core();
+		if (NULL != dma) mali_dma_delete(dma);
 	}
+dma_parsing_failed:
+	mali_dlbu_terminate();
 dlbu_init_failed:
 	mali_mmu_terminate();
 mmu_init_failed:
+	mali_pm_domain_terminate();
+pm_domain_failed:
 	/* Nothing to roll back */
 product_info_parsing_failed:
-	mali_pm_terminate();
-pm_init_failed:
-	if (is_pmu_enabled)
-	{
-		mali_pmu_delete(mali_pmu_get_global_pmu_core());
+	/* Nothing to roll back */
+init_hw_reset_failed:
+	/* Nothing to roll back */
+pmu_reset_failed:
+	/* Allowing the system to be turned off */
+	_mali_osk_pm_dev_ref_dec();
+pm_always_on_failed:
+	pmu = mali_pmu_get_global_pmu_core();
+	if (NULL != pmu) {
+		mali_pmu_delete(pmu);
 	}
 parse_pmu_config_failed:
-parse_gpu_base_address_failed:
+	mali_pm_terminate();
+pm_init_failed:
+	mali_pp_scheduler_terminate();
+pp_scheduler_init_failed:
+check_shared_interrupts_failed:
+	global_gpu_base_address = 0;
+set_global_gpu_base_address_failed:
+	/* undoing mali_parse_config_memory() is done by mali_memory_terminate() */
 parse_memory_config_failed:
 	mali_memory_terminate();
 memory_init_failed:
-	_mali_osk_resources_term(&arch_configuration, num_resources);
-osk_resources_init_failed:
-	cleanup_system_info(system_info);
-build_system_info_failed:
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 	_mali_osk_profiling_term();
 #endif
 	mali_session_terminate();
 session_init_failed:
+	mali_pp_job_terminate();
 	return err;
 }
 
 void mali_terminate_subsystems(void)
 {
-	struct mali_pmu_core *pmu;
+	struct mali_pmu_core *pmu = mali_pmu_get_global_pmu_core();
+	struct mali_dma_core *dma = mali_dma_get_global_dma_core();
 
 	MALI_DEBUG_PRINT(2, ("terminate_subsystems() called\n"));
 
 	/* shut down subsystems in reverse order from startup */
 
-	mali_pm_always_on(MALI_TRUE); /* Mali will be powered off once PM subsystem terminates */
+	/* We need the GPU to be powered up for the terminate sequence */
+	_mali_osk_pm_dev_ref_add();
 
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
 	mali_utilization_term();
-#endif
-
-	mali_pp_scheduler_terminate();
+	mali_pp_scheduler_depopulate();
 	mali_gp_scheduler_terminate();
 	mali_scheduler_terminate();
-
-	mali_delete_clusters(); /* Delete clusters even if config parsing failed. */
-
-	if (_MALI_PRODUCT_ID_MALI450 == global_product_id)
-	{
+	mali_delete_l2_cache_cores();
+	if (mali_is_mali450()) {
 		mali_dlbu_terminate();
 	}
-
 	mali_mmu_terminate();
-
-	pmu = mali_pmu_get_global_pmu_core();
-	if (NULL != pmu)
-	{
+	if (NULL != pmu) {
 		mali_pmu_delete(pmu);
 	}
-
+	if (NULL != dma) {
+		mali_dma_delete(dma);
+	}
 	mali_pm_terminate();
-
 	mali_memory_terminate();
-
-	_mali_osk_resources_term(&arch_configuration, num_resources);
-
-	cleanup_system_info(system_info);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 	_mali_osk_profiling_term();
 #endif
 
+	/* Allowing the system to be turned off */
+	_mali_osk_pm_dev_ref_dec();
+
+	mali_pp_scheduler_terminate();
 	mali_session_terminate();
 
-	if (NULL != system_info_lock)
-	{
-		_mali_osk_lock_term( system_info_lock );
-	}
+	mali_pp_job_terminate();
 }
 
 _mali_product_id_t mali_kernel_core_get_product_id(void)
@@ -795,119 +1154,25 @@ _mali_product_id_t mali_kernel_core_get_product_id(void)
 	return global_product_id;
 }
 
-void mali_kernel_core_wakeup(void)
-{
-	u32 i;
-	u32 glob_num_clusters = mali_cluster_get_glob_num_clusters();
-	struct mali_cluster *cluster;
-
-	for (i = 0; i < glob_num_clusters; i++)
-	{
-		cluster = mali_cluster_get_global_cluster(i);
-		mali_cluster_reset(cluster);
-	}
-}
-
-static void cleanup_system_info(_mali_system_info *cleanup)
+u32 mali_kernel_core_get_gpu_major_version(void)
 {
-	_mali_core_info * current_core;
-	_mali_mem_info * current_mem;
-
-	/* delete all the core info structs */
-	while (NULL != cleanup->core_info)
-	{
-		current_core = cleanup->core_info;
-		cleanup->core_info = cleanup->core_info->next;
-		_mali_osk_free(current_core);
-	}
-
-	/* delete all the mem info struct */
-	while (NULL != cleanup->mem_info)
-	{
-		current_mem = cleanup->mem_info;
-		cleanup->mem_info = cleanup->mem_info->next;
-		_mali_osk_free(current_mem);
-	}
-
-	/* delete the system info struct itself */
-	_mali_osk_free(cleanup);
+	return global_gpu_major_version;
 }
 
-/* Build a dummy system info struct. User space still need this. */
-static _mali_osk_errcode_t build_system_info(void)
+u32 mali_kernel_core_get_gpu_minor_version(void)
 {
-	_mali_system_info * new_info;
-	_mali_core_info * current_core;
-	_mali_mem_info * current_mem;
-	u32 new_size = 0;
-
-	/* create a new system info struct */
-	MALI_CHECK_NON_NULL(new_info = (_mali_system_info *)_mali_osk_malloc(sizeof(_mali_system_info)), _MALI_OSK_ERR_NOMEM);
-
-	_mali_osk_memset(new_info, 0, sizeof(_mali_system_info));
-
-	/* fill in the info */
-	new_info->has_mmu = 1;
-	new_info->drivermode = _MALI_DRIVER_MODE_NORMAL;
-
-	new_info->core_info = NULL; /* Not used by user space */
-
-	new_info->mem_info = _mali_osk_calloc(1, sizeof(_mali_mem_info));
-	if(NULL == new_info->mem_info)
-	{
-		_mali_osk_free(new_info);
-		return _MALI_OSK_ERR_NOMEM;
-	}
-
-	new_info->mem_info->size = 1024 * 1024 * 1024; /* 1GiB */
-	new_info->mem_info->flags = _MALI_CPU_WRITEABLE | _MALI_CPU_READABLE | _MALI_PP_READABLE | _MALI_PP_WRITEABLE |_MALI_GP_READABLE | _MALI_GP_WRITEABLE | _MALI_MMU_READABLE | _MALI_MMU_WRITEABLE;
-	new_info->mem_info->maximum_order_supported = 30;
-	new_info->mem_info->identifier = 0;
-	new_info->mem_info->next = NULL;
-
-	/* building succeeded, calculate the size */
-
-	/* size needed of the system info struct itself */
-	new_size = sizeof(_mali_system_info);
-
-	/* size needed for the cores */
-	for (current_core = new_info->core_info; NULL != current_core; current_core = current_core->next)
-	{
-		new_size += sizeof(_mali_core_info);
-	}
-
-	/* size needed for the memory banks */
-	for (current_mem = new_info->mem_info; NULL != current_mem; current_mem = current_mem->next)
-	{
-		new_size += sizeof(_mali_mem_info);
-	}
-
-	/* lock system info access so a user wont't get a corrupted version */
-	_mali_osk_lock_wait( system_info_lock, _MALI_OSK_LOCKMODE_RW );
-
-	/* set new info */
-	system_info = new_info;
-	system_info_size = new_size;
-
-	/* we're safe */
-	_mali_osk_lock_signal( system_info_lock, _MALI_OSK_LOCKMODE_RW );
-
-	/* ok result */
-	return _MALI_OSK_ERR_OK;
+	return global_gpu_minor_version;
 }
 
-_mali_osk_errcode_t _mali_ukk_get_api_version( _mali_uk_get_api_version_s *args )
+_mali_osk_errcode_t _mali_ukk_get_api_version(_mali_uk_get_api_version_s *args)
 {
 	MALI_DEBUG_ASSERT_POINTER(args);
 	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
 
 	/* check compatability */
-	if ( args->version == _MALI_UK_API_VERSION )
-	{
+	if (args->version == _MALI_UK_API_VERSION) {
 		args->compatible = 1;
-	}
-	else
-	{
+	} else {
 		args->compatible = 0;
 	}
 
@@ -917,103 +1182,7 @@ _mali_osk_errcode_t _mali_ukk_get_api_version( _mali_uk_get_api_version_s *args
 	MALI_SUCCESS;
 }
 
-_mali_osk_errcode_t _mali_ukk_get_system_info_size(_mali_uk_get_system_info_size_s *args)
-{
-	MALI_DEBUG_ASSERT_POINTER(args);
-	args->size = system_info_size;
-	MALI_SUCCESS;
-}
-
-_mali_osk_errcode_t _mali_ukk_get_system_info( _mali_uk_get_system_info_s *args )
-{
-	_mali_core_info * current_core;
-	_mali_mem_info * current_mem;
-	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
-	void * current_write_pos, ** current_patch_pos;
-	u32 adjust_ptr_base;
-
-	/* check input */
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-	MALI_CHECK_NON_NULL(args->system_info, _MALI_OSK_ERR_INVALID_ARGS);
-
-	/* lock the system info */
-	_mali_osk_lock_wait( system_info_lock, _MALI_OSK_LOCKMODE_RW );
-
-	/* first check size */
-	if (args->size < system_info_size) goto exit_when_locked;
-
-	/* we build a copy of system_info in the user space buffer specified by the user and
-	 * patch up the pointers. The ukk_private members of _mali_uk_get_system_info_s may
-	 * indicate a different base address for patching the pointers (normally the
-	 * address of the provided system_info buffer would be used). This is helpful when
-	 * the system_info buffer needs to get copied to user space and the pointers need
-	 * to be in user space.
-	 */
-	if (0 == args->ukk_private)
-	{
-		adjust_ptr_base = (u32)args->system_info;
-	}
-	else
-	{
-		adjust_ptr_base = args->ukk_private;
-	}
-
-	/* copy each struct into the buffer, and update its pointers */
-	current_write_pos = (void *)args->system_info;
-
-	/* first, the master struct */
-	_mali_osk_memcpy(current_write_pos, system_info, sizeof(_mali_system_info));
-
-	/* advance write pointer */
-	current_write_pos = (void *)((u32)current_write_pos + sizeof(_mali_system_info));
-
-	/* first we write the core info structs, patch starts at master's core_info pointer */
-	current_patch_pos = (void **)((u32)args->system_info + offsetof(_mali_system_info, core_info));
-
-	for (current_core = system_info->core_info; NULL != current_core; current_core = current_core->next)
-	{
-
-		/* patch the pointer pointing to this core */
-		*current_patch_pos = (void*)(adjust_ptr_base + ((u32)current_write_pos - (u32)args->system_info));
-
-		/* copy the core info */
-		_mali_osk_memcpy(current_write_pos, current_core, sizeof(_mali_core_info));
-
-		/* update patch pos */
-		current_patch_pos = (void **)((u32)current_write_pos + offsetof(_mali_core_info, next));
-
-		/* advance write pos in memory */
-		current_write_pos = (void *)((u32)current_write_pos + sizeof(_mali_core_info));
-	}
-	/* patching of last patch pos is not needed, since we wrote NULL there in the first place */
-
-	/* then we write the mem info structs, patch starts at master's mem_info pointer */
-	current_patch_pos = (void **)((u32)args->system_info + offsetof(_mali_system_info, mem_info));
-
-	for (current_mem = system_info->mem_info; NULL != current_mem; current_mem = current_mem->next)
-	{
-		/* patch the pointer pointing to this core */
-		*current_patch_pos = (void*)(adjust_ptr_base + ((u32)current_write_pos - (u32)args->system_info));
-
-		/* copy the core info */
-		_mali_osk_memcpy(current_write_pos, current_mem, sizeof(_mali_mem_info));
-
-		/* update patch pos */
-		current_patch_pos = (void **)((u32)current_write_pos + offsetof(_mali_mem_info, next));
-
-		/* advance write pos in memory */
-		current_write_pos = (void *)((u32)current_write_pos + sizeof(_mali_mem_info));
-	}
-	/* patching of last patch pos is not needed, since we wrote NULL there in the first place */
-
-	err = _MALI_OSK_ERR_OK;
-exit_when_locked:
-	_mali_osk_lock_signal( system_info_lock, _MALI_OSK_LOCKMODE_RW );
-	MALI_ERROR(err);
-}
-
-_mali_osk_errcode_t _mali_ukk_wait_for_notification( _mali_uk_wait_for_notification_s *args )
+_mali_osk_errcode_t _mali_ukk_wait_for_notification(_mali_uk_wait_for_notification_s *args)
 {
 	_mali_osk_errcode_t err;
 	_mali_osk_notification_t *notification;
@@ -1026,8 +1195,7 @@ _mali_osk_errcode_t _mali_ukk_wait_for_notification( _mali_uk_wait_for_notificat
 	queue = ((struct mali_session_data *)args->ctx)->ioctl_queue;
 
 	/* if the queue does not exist we're currently shutting down */
-	if (NULL == queue)
-	{
+	if (NULL == queue) {
 		MALI_DEBUG_PRINT(1, ("No notification queue registered with the session. Asking userspace to stop querying\n"));
 		args->type = _MALI_NOTIFICATION_CORE_SHUTDOWN_IN_PROGRESS;
 		MALI_SUCCESS;
@@ -1035,8 +1203,7 @@ _mali_osk_errcode_t _mali_ukk_wait_for_notification( _mali_uk_wait_for_notificat
 
 	/* receive a notification, might sleep */
 	err = _mali_osk_notification_queue_receive(queue, &notification);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		MALI_ERROR(err); /* errcode returned, pass on to caller */
 	}
 
@@ -1045,14 +1212,14 @@ _mali_osk_errcode_t _mali_ukk_wait_for_notification( _mali_uk_wait_for_notificat
 	_mali_osk_memcpy(&args->data, notification->result_buffer, notification->result_buffer_size);
 
 	/* finished with the notification */
-	_mali_osk_notification_delete( notification );
+	_mali_osk_notification_delete(notification);
 
 	MALI_SUCCESS; /* all ok */
 }
 
-_mali_osk_errcode_t _mali_ukk_post_notification( _mali_uk_post_notification_s *args )
+_mali_osk_errcode_t _mali_ukk_post_notification(_mali_uk_post_notification_s *args)
 {
-	_mali_osk_notification_t * notification;
+	_mali_osk_notification_t *notification;
 	_mali_osk_notification_queue_t *queue;
 
 	/* check input */
@@ -1062,16 +1229,14 @@ _mali_osk_errcode_t _mali_ukk_post_notification( _mali_uk_post_notification_s *a
 	queue = ((struct mali_session_data *)args->ctx)->ioctl_queue;
 
 	/* if the queue does not exist we're currently shutting down */
-	if (NULL == queue)
-	{
+	if (NULL == queue) {
 		MALI_DEBUG_PRINT(1, ("No notification queue registered with the session. Asking userspace to stop querying\n"));
 		MALI_SUCCESS;
 	}
 
 	notification = _mali_osk_notification_create(args->type, 0);
-	if ( NULL == notification)
-	{
-		MALI_PRINT_ERROR( ("Failed to create notification object\n"));
+	if (NULL == notification) {
+		MALI_PRINT_ERROR(("Failed to create notification object\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
@@ -1080,59 +1245,117 @@ _mali_osk_errcode_t _mali_ukk_post_notification( _mali_uk_post_notification_s *a
 	MALI_SUCCESS; /* all ok */
 }
 
+_mali_osk_errcode_t _mali_ukk_request_high_priority(_mali_uk_request_high_priority_s *args)
+{
+	struct mali_session_data *session;
+
+	MALI_DEBUG_ASSERT_POINTER(args);
+	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
+
+	session = (struct mali_session_data *) args->ctx;
+
+	if (!session->use_high_priority_job_queue) {
+		session->use_high_priority_job_queue = MALI_TRUE;
+		MALI_DEBUG_PRINT(2, ("Session 0x%08X with pid %d was granted higher priority.\n", session, _mali_osk_get_pid()));
+	}
+
+	MALI_SUCCESS;
+}
+
 _mali_osk_errcode_t _mali_ukk_open(void **context)
 {
-	struct mali_session_data *session_data;
+	u32 i;
+	struct mali_session_data *session;
 
 	/* allocated struct to track this session */
-	session_data = (struct mali_session_data *)_mali_osk_calloc(1, sizeof(struct mali_session_data));
-	MALI_CHECK_NON_NULL(session_data, _MALI_OSK_ERR_NOMEM);
+	session = (struct mali_session_data *)_mali_osk_calloc(1, sizeof(struct mali_session_data));
+	MALI_CHECK_NON_NULL(session, _MALI_OSK_ERR_NOMEM);
 
-	MALI_DEBUG_PRINT(2, ("Session starting\n"));
+	MALI_DEBUG_PRINT(3, ("Session starting\n"));
 
 	/* create a response queue for this session */
-	session_data->ioctl_queue = _mali_osk_notification_queue_init();
-	if (NULL == session_data->ioctl_queue)
-	{
-		_mali_osk_free(session_data);
+	session->ioctl_queue = _mali_osk_notification_queue_init();
+	if (NULL == session->ioctl_queue) {
+		_mali_osk_free(session);
 		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 	}
 
-	session_data->page_directory = mali_mmu_pagedir_alloc();
-	if (NULL == session_data->page_directory)
-	{
-		_mali_osk_notification_queue_term(session_data->ioctl_queue);
-		_mali_osk_free(session_data);
+	session->page_directory = mali_mmu_pagedir_alloc();
+	if (NULL == session->page_directory) {
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
 		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 	}
 
-	if (_MALI_OSK_ERR_OK != mali_mmu_pagedir_map(session_data->page_directory, MALI_DLB_VIRT_ADDR, _MALI_OSK_MALI_PAGE_SIZE))
-	{
-		MALI_PRINT_ERROR(("Failed to map DLB page into session\n"));
-		_mali_osk_notification_queue_term(session_data->ioctl_queue);
-		_mali_osk_free(session_data);
+	if (_MALI_OSK_ERR_OK != mali_mmu_pagedir_map(session->page_directory, MALI_DLBU_VIRT_ADDR, _MALI_OSK_MALI_PAGE_SIZE)) {
+		MALI_PRINT_ERROR(("Failed to map DLBU page into session\n"));
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
 		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 	}
 
-	if (0 != mali_dlbu_phys_addr)
-	{
-		mali_mmu_pagedir_update(session_data->page_directory, MALI_DLB_VIRT_ADDR, mali_dlbu_phys_addr, _MALI_OSK_MALI_PAGE_SIZE);
+	if (0 != mali_dlbu_phys_addr) {
+		mali_mmu_pagedir_update(session->page_directory, MALI_DLBU_VIRT_ADDR, mali_dlbu_phys_addr,
+					_MALI_OSK_MALI_PAGE_SIZE, MALI_MMU_FLAGS_DEFAULT);
 	}
 
-	if (_MALI_OSK_ERR_OK != mali_memory_session_begin(session_data))
-	{
-		mali_mmu_pagedir_free(session_data->page_directory);
-		_mali_osk_notification_queue_term(session_data->ioctl_queue);
-		_mali_osk_free(session_data);
+	if (_MALI_OSK_ERR_OK != mali_memory_session_begin(session)) {
+		mali_mmu_pagedir_free(session->page_directory);
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
+		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
+	}
+
+	/* Create soft system. */
+	session->soft_job_system = mali_soft_job_system_create(session);
+	if (NULL == session->soft_job_system) {
+		mali_memory_session_end(session);
+		mali_mmu_pagedir_free(session->page_directory);
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
+		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
+	}
+
+	/* Create timeline system. */
+	session->timeline_system = mali_timeline_system_create(session);
+	if (NULL == session->timeline_system) {
+		mali_soft_job_system_destroy(session->soft_job_system);
+		mali_memory_session_end(session);
+		mali_mmu_pagedir_free(session->page_directory);
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
 		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 	}
 
-	*context = (void*)session_data;
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	if (_MALI_OSK_ERR_OK != _mali_osk_atomic_init(&session->number_of_window_jobs, 0)) {
+		MALI_DEBUG_PRINT_ERROR(("Initialization of atomic number_of_window_jobs failed.\n"));
+		mali_timeline_system_destroy(session->timeline_system);
+		mali_soft_job_system_destroy(session->soft_job_system);
+		mali_memory_session_end(session);
+		mali_mmu_pagedir_free(session->page_directory);
+		_mali_osk_notification_queue_term(session->ioctl_queue);
+		_mali_osk_free(session);
+		return _MALI_OSK_ERR_FAULT;
+	}
+#endif
+
+	session->use_high_priority_job_queue = MALI_FALSE;
+
+	/* Initialize list of PP jobs on this session. */
+	_MALI_OSK_INIT_LIST_HEAD(&session->pp_job_list);
+
+	/* Initialize the pp_job_fb_lookup_list array used to quickly lookup jobs from a given frame builder */
+	for (i = 0; i < MALI_PP_JOB_FB_LOOKUP_LIST_SIZE; ++i) {
+		_MALI_OSK_INIT_LIST_HEAD(&session->pp_job_fb_lookup_list[i]);
+	}
+
+	*context = (void *)session;
 
 	/* Add session to the list of all sessions. */
-	mali_session_add(session_data);
+	mali_session_add(session);
 
-	MALI_DEBUG_PRINT(3, ("Session started\n"));
+	MALI_DEBUG_PRINT(2, ("Session started\n"));
 	MALI_SUCCESS;
 }
 
@@ -1144,22 +1367,69 @@ _mali_osk_errcode_t _mali_ukk_close(void **context)
 
 	MALI_DEBUG_PRINT(3, ("Session ending\n"));
 
+	MALI_DEBUG_ASSERT_POINTER(session->soft_job_system);
+	MALI_DEBUG_ASSERT_POINTER(session->timeline_system);
+
 	/* Remove session from list of all sessions. */
 	mali_session_remove(session);
 
-	/* Abort queued and running jobs */
+	/* This flag is used to prevent queueing of jobs due to activation. */
+	session->is_aborting = MALI_TRUE;
+
+	/* Stop the soft job timer. */
+	mali_timeline_system_stop_timer(session->timeline_system);
+
+	/* Abort queued and running GP and PP jobs. */
 	mali_gp_scheduler_abort_session(session);
 	mali_pp_scheduler_abort_session(session);
 
+	/* Abort the soft job system. */
+	mali_soft_job_system_abort(session->soft_job_system);
+
+	/* Force execution of all pending bottom half processing for GP and PP. */
+	_mali_osk_wq_flush();
+
+	/* The session PP list should now be empty. */
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&session->pp_job_list));
+
+	/* At this point the GP and PP scheduler no longer has any jobs queued or running from this
+	 * session, and all soft jobs in the soft job system has been destroyed. */
+
+	/* Any trackers left in the timeline system are directly or indirectly waiting on external
+	 * sync fences.  Cancel all sync fence waiters to trigger activation of all remaining
+	 * trackers.  This call will sleep until all timelines are empty. */
+	mali_timeline_system_abort(session->timeline_system);
+
 	/* Flush pending work.
 	 * Needed to make sure all bottom half processing related to this
 	 * session has been completed, before we free internal data structures.
 	 */
-	_mali_osk_flush_workqueue(NULL);
+	_mali_osk_wq_flush();
+
+	/* Destroy timeline system. */
+	mali_timeline_system_destroy(session->timeline_system);
+	session->timeline_system = NULL;
+
+	/* Destroy soft system. */
+	mali_soft_job_system_destroy(session->soft_job_system);
+	session->soft_job_system = NULL;
+
+	MALI_DEBUG_CODE({
+		/* Check that the pp_job_fb_lookup_list array is empty. */
+		u32 i;
+		for (i = 0; i < MALI_PP_JOB_FB_LOOKUP_LIST_SIZE; ++i)
+		{
+			MALI_DEBUG_ASSERT(_mali_osk_list_empty(&session->pp_job_fb_lookup_list[i]));
+		}
+	});
 
 	/* Free remaining memory allocated to this session */
 	mali_memory_session_end(session);
 
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	_mali_osk_atomic_term(&session->number_of_window_jobs);
+#endif
+
 	/* Free session data structures */
 	mali_mmu_pagedir_free(session->page_directory);
 	_mali_osk_notification_queue_term(session->ioctl_queue);
@@ -1173,7 +1443,7 @@ _mali_osk_errcode_t _mali_ukk_close(void **context)
 }
 
 #if MALI_STATE_TRACKING
-u32 _mali_kernel_core_dump_state(char* buf, u32 size)
+u32 _mali_kernel_core_dump_state(char *buf, u32 size)
 {
 	int n = 0; /* Number of bytes written to buf */
 
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_core.h b/drivers/gpu/mali/mali/common/mali_kernel_core.h
old mode 100644
new mode 100755
index 70ca272..88dc80e
--- a/drivers/gpu/mali/mali/common/mali_kernel_core.h
+++ b/drivers/gpu/mali/mali/common/mali_kernel_core.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,10 +13,7 @@
 
 #include "mali_osk.h"
 
-extern int mali_max_job_runtime;
-
-typedef enum
-{
+typedef enum {
 	_MALI_PRODUCT_ID_UNKNOWN,
 	_MALI_PRODUCT_ID_MALI200,
 	_MALI_PRODUCT_ID_MALI300,
@@ -24,14 +21,36 @@ typedef enum
 	_MALI_PRODUCT_ID_MALI450,
 } _mali_product_id_t;
 
+extern mali_bool mali_gpu_class_is_mali450;
+
 _mali_osk_errcode_t mali_initialize_subsystems(void);
 
 void mali_terminate_subsystems(void);
 
-void mali_kernel_core_wakeup(void);
-
 _mali_product_id_t mali_kernel_core_get_product_id(void);
 
-u32 _mali_kernel_core_dump_state(char* buf, u32 size);
+u32 mali_kernel_core_get_gpu_major_version(void);
+
+u32 mali_kernel_core_get_gpu_minor_version(void);
+
+u32 _mali_kernel_core_dump_state(char *buf, u32 size);
+
+MALI_STATIC_INLINE mali_bool mali_is_mali450(void)
+{
+#if defined(CONFIG_MALI450)
+	return mali_gpu_class_is_mali450;
+#else
+	return MALI_FALSE;
+#endif
+}
+
+MALI_STATIC_INLINE mali_bool mali_is_mali400(void)
+{
+#if !defined(CONFIG_MALI450)
+	return MALI_TRUE;
+#else
+	return !mali_gpu_class_is_mali450;
+#endif
+}
 
 #endif /* __MALI_KERNEL_CORE_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.c b/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.c
old mode 100644
new mode 100755
index e8fb316..893994e
--- a/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.c
+++ b/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,71 +20,67 @@
  * @param count Number of mappings in the table
  * @return Pointer to a new table, NULL on error
  */
-static mali_descriptor_table * descriptor_table_alloc(int count);
+static mali_descriptor_table *descriptor_table_alloc(int count);
 
 /**
  * Free a descriptor table
  * @param table The table to free
  */
-static void descriptor_table_free(mali_descriptor_table * table);
+static void descriptor_table_free(mali_descriptor_table *table);
 
-mali_descriptor_mapping * mali_descriptor_mapping_create(int init_entries, int max_entries)
+mali_descriptor_mapping *mali_descriptor_mapping_create(int init_entries, int max_entries)
 {
-	mali_descriptor_mapping * map = _mali_osk_calloc(1, sizeof(mali_descriptor_mapping));
+	mali_descriptor_mapping *map = _mali_osk_calloc(1, sizeof(mali_descriptor_mapping));
 
 	init_entries = MALI_PAD_INT(init_entries);
 	max_entries = MALI_PAD_INT(max_entries);
 
-	if (NULL != map)
-	{
+	if (NULL != map) {
 		map->table = descriptor_table_alloc(init_entries);
-		if (NULL != map->table)
-		{
-            map->lock = _mali_osk_lock_init( (_mali_osk_lock_flags_t)(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_READERWRITER | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE), 0, _MALI_OSK_LOCK_ORDER_DESCRIPTOR_MAP);
-            if (NULL != map->lock)
-            {
-			    _mali_osk_set_nonatomic_bit(0, map->table->usage); /* reserve bit 0 to prevent NULL/zero logic to kick in */
-			    map->max_nr_mappings_allowed = max_entries;
-			    map->current_nr_mappings = init_entries;
-			    return map;
-            }
-        	descriptor_table_free(map->table);
+		if (NULL != map->table) {
+			map->lock = _mali_osk_mutex_rw_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_DESCRIPTOR_MAP);
+			if (NULL != map->lock) {
+				_mali_osk_set_nonatomic_bit(0, map->table->usage); /* reserve bit 0 to prevent NULL/zero logic to kick in */
+				map->max_nr_mappings_allowed = max_entries;
+				map->current_nr_mappings = init_entries;
+				return map;
+			}
+			descriptor_table_free(map->table);
 		}
 		_mali_osk_free(map);
 	}
 	return NULL;
 }
 
-void mali_descriptor_mapping_destroy(mali_descriptor_mapping * map)
+void mali_descriptor_mapping_destroy(mali_descriptor_mapping *map)
 {
 	descriptor_table_free(map->table);
-    _mali_osk_lock_term(map->lock);
+	_mali_osk_mutex_rw_term(map->lock);
 	_mali_osk_free(map);
 }
 
-_mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_mapping * map, void * target, int *odescriptor)
+_mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_mapping *map, void *target, int *odescriptor)
 {
 	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
 	int new_descriptor;
 
-    MALI_DEBUG_ASSERT_POINTER(map);
-    MALI_DEBUG_ASSERT_POINTER(odescriptor);
+	MALI_DEBUG_ASSERT_POINTER(map);
+	MALI_DEBUG_ASSERT_POINTER(odescriptor);
 
-    _mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
 	new_descriptor = _mali_osk_find_first_zero_bit(map->table->usage, map->current_nr_mappings);
-	if (new_descriptor == map->current_nr_mappings)
-	{
+	if (new_descriptor == map->current_nr_mappings) {
 		/* no free descriptor, try to expand the table */
-		mali_descriptor_table * new_table, * old_table;
+		mali_descriptor_table *new_table, * old_table;
 		if (map->current_nr_mappings >= map->max_nr_mappings_allowed) goto unlock_and_exit;
 
-        map->current_nr_mappings += BITS_PER_LONG;
+		map->current_nr_mappings += BITS_PER_LONG;
 		new_table = descriptor_table_alloc(map->current_nr_mappings);
 		if (NULL == new_table) goto unlock_and_exit;
 
-        old_table = map->table;
+		old_table = map->table;
 		_mali_osk_memcpy(new_table->usage, old_table->usage, (sizeof(unsigned long)*map->current_nr_mappings) / BITS_PER_LONG);
-		_mali_osk_memcpy(new_table->mappings, old_table->mappings, map->current_nr_mappings * sizeof(void*));
+		_mali_osk_memcpy(new_table->mappings, old_table->mappings, map->current_nr_mappings * sizeof(void *));
 		map->table = new_table;
 		descriptor_table_free(old_table);
 	}
@@ -93,92 +89,85 @@ _mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_map
 	_mali_osk_set_nonatomic_bit(new_descriptor, map->table->usage);
 	map->table->mappings[new_descriptor] = target;
 	*odescriptor = new_descriptor;
-    err = _MALI_OSK_ERR_OK;
+	err = _MALI_OSK_ERR_OK;
 
 unlock_and_exit:
-    _mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
-    MALI_ERROR(err);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
+	MALI_ERROR(err);
 }
 
-void mali_descriptor_mapping_call_for_each(mali_descriptor_mapping * map, void (*callback)(int, void*))
+void mali_descriptor_mapping_call_for_each(mali_descriptor_mapping *map, void (*callback)(int, void *))
 {
 	int i;
 
 	MALI_DEBUG_ASSERT_POINTER(map);
 	MALI_DEBUG_ASSERT_POINTER(callback);
 
-    _mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
 	/* id 0 is skipped as it's an reserved ID not mapping to anything */
-	for (i = 1; i < map->current_nr_mappings; ++i)
-	{
-		if (_mali_osk_test_bit(i, map->table->usage))
-		{
+	for (i = 1; i < map->current_nr_mappings; ++i) {
+		if (_mali_osk_test_bit(i, map->table->usage)) {
 			callback(i, map->table->mappings[i]);
 		}
 	}
-    _mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
 }
 
-_mali_osk_errcode_t mali_descriptor_mapping_get(mali_descriptor_mapping * map, int descriptor, void** target)
+_mali_osk_errcode_t mali_descriptor_mapping_get(mali_descriptor_mapping *map, int descriptor, void **target)
 {
 	_mali_osk_errcode_t result = _MALI_OSK_ERR_FAULT;
 	MALI_DEBUG_ASSERT_POINTER(map);
-    _mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
-	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
+	if ((descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		*target = map->table->mappings[descriptor];
 		result = _MALI_OSK_ERR_OK;
-	}
-	else *target = NULL;
-    _mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
+	} else *target = NULL;
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
 	MALI_ERROR(result);
 }
 
-_mali_osk_errcode_t mali_descriptor_mapping_set(mali_descriptor_mapping * map, int descriptor, void * target)
+_mali_osk_errcode_t mali_descriptor_mapping_set(mali_descriptor_mapping *map, int descriptor, void *target)
 {
 	_mali_osk_errcode_t result = _MALI_OSK_ERR_FAULT;
-    _mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
-	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
+	if ((descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		map->table->mappings[descriptor] = target;
 		result = _MALI_OSK_ERR_OK;
 	}
-    _mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
 	MALI_ERROR(result);
 }
 
-void *mali_descriptor_mapping_free(mali_descriptor_mapping * map, int descriptor)
+void *mali_descriptor_mapping_free(mali_descriptor_mapping *map, int descriptor)
 {
 	void *old_value = NULL;
 
-    _mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
-	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
+	if ((descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		old_value = map->table->mappings[descriptor];
 		map->table->mappings[descriptor] = NULL;
 		_mali_osk_clear_nonatomic_bit(descriptor, map->table->usage);
 	}
-    _mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
 
 	return old_value;
 }
 
-static mali_descriptor_table * descriptor_table_alloc(int count)
+static mali_descriptor_table *descriptor_table_alloc(int count)
 {
-	mali_descriptor_table * table;
+	mali_descriptor_table *table;
 
-	table = _mali_osk_calloc(1, sizeof(mali_descriptor_table) + ((sizeof(unsigned long) * count)/BITS_PER_LONG) + (sizeof(void*) * count));
+	table = _mali_osk_calloc(1, sizeof(mali_descriptor_table) + ((sizeof(unsigned long) * count) / BITS_PER_LONG) + (sizeof(void *) * count));
 
-	if (NULL != table)
-	{
-		table->usage = (u32*)((u8*)table + sizeof(mali_descriptor_table));
-		table->mappings = (void**)((u8*)table + sizeof(mali_descriptor_table) + ((sizeof(unsigned long) * count)/BITS_PER_LONG));
+	if (NULL != table) {
+		table->usage = (u32 *)((u8 *)table + sizeof(mali_descriptor_table));
+		table->mappings = (void **)((u8 *)table + sizeof(mali_descriptor_table) + ((sizeof(unsigned long) * count) / BITS_PER_LONG));
 	}
 
 	return table;
 }
 
-static void descriptor_table_free(mali_descriptor_table * table)
+static void descriptor_table_free(mali_descriptor_table *table)
 {
 	_mali_osk_free(table);
 }
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.h b/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.h
old mode 100644
new mode 100755
index 7b8ce08..de2b8f5
--- a/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.h
+++ b/drivers/gpu/mali/mali/common/mali_kernel_descriptor_mapping.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,22 +20,20 @@
 /**
  * The actual descriptor mapping table, never directly accessed by clients
  */
-typedef struct mali_descriptor_table
-{
-	u32 * usage; /**< Pointer to bitpattern indicating if a descriptor is valid/used or not */
-	void** mappings; /**< Array of the pointers the descriptors map to */
+typedef struct mali_descriptor_table {
+	u32 *usage;  /**< Pointer to bitpattern indicating if a descriptor is valid/used or not */
+	void **mappings; /**< Array of the pointers the descriptors map to */
 } mali_descriptor_table;
 
 /**
  * The descriptor mapping object
  * Provides a separate namespace where we can map an integer to a pointer
  */
-typedef struct mali_descriptor_mapping
-{
-    _mali_osk_lock_t *lock; /**< Lock protecting access to the mapping object */
+typedef struct mali_descriptor_mapping {
+	_mali_osk_mutex_rw_t *lock; /**< Lock protecting access to the mapping object */
 	int max_nr_mappings_allowed; /**< Max number of mappings to support in this namespace */
 	int current_nr_mappings; /**< Current number of possible mappings */
-	mali_descriptor_table * table; /**< Pointer to the current mapping table */
+	mali_descriptor_table *table;  /**< Pointer to the current mapping table */
 } mali_descriptor_mapping;
 
 /**
@@ -45,13 +43,13 @@ typedef struct mali_descriptor_mapping
  * @param max_entries Number of entries to max support
  * @return Pointer to a descriptor mapping object, NULL on failure
  */
-mali_descriptor_mapping * mali_descriptor_mapping_create(int init_entries, int max_entries);
+mali_descriptor_mapping *mali_descriptor_mapping_create(int init_entries, int max_entries);
 
 /**
  * Destroy a descriptor mapping object
  * @param map The map to free
  */
-void mali_descriptor_mapping_destroy(mali_descriptor_mapping * map);
+void mali_descriptor_mapping_destroy(mali_descriptor_mapping *map);
 
 /**
  * Allocate a new mapping entry (descriptor ID)
@@ -60,7 +58,7 @@ void mali_descriptor_mapping_destroy(mali_descriptor_mapping * map);
  * @param target The value to map to
  * @return The descriptor allocated, a negative value on error
  */
-_mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_mapping * map, void * target, int *descriptor);
+_mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_mapping *map, void *target, int *descriptor);
 
 /**
  * Get the value mapped to by a descriptor ID
@@ -69,7 +67,7 @@ _mali_osk_errcode_t mali_descriptor_mapping_allocate_mapping(mali_descriptor_map
  * @param target Pointer to a pointer which will receive the stored value
  * @return 0 on successful lookup, negative on error
  */
-_mali_osk_errcode_t mali_descriptor_mapping_get(mali_descriptor_mapping * map, int descriptor, void** target);
+_mali_osk_errcode_t mali_descriptor_mapping_get(mali_descriptor_mapping *map, int descriptor, void **target);
 
 /**
  * Set the value mapped to by a descriptor ID
@@ -78,7 +76,7 @@ _mali_osk_errcode_t mali_descriptor_mapping_get(mali_descriptor_mapping * map, i
  * @param target Pointer to replace the current value with
  * @return 0 on successful lookup, negative on error
  */
-_mali_osk_errcode_t mali_descriptor_mapping_set(mali_descriptor_mapping * map, int descriptor, void * target);
+_mali_osk_errcode_t mali_descriptor_mapping_set(mali_descriptor_mapping *map, int descriptor, void *target);
 
 /**
  * Call the specified callback function for each descriptor in map.
@@ -86,7 +84,7 @@ _mali_osk_errcode_t mali_descriptor_mapping_set(mali_descriptor_mapping * map, i
  * @param map The map to do callbacks for
  * @param callback A callback function which will be calle for each entry in map
  */
-void mali_descriptor_mapping_call_for_each(mali_descriptor_mapping * map, void (*callback)(int, void*));
+void mali_descriptor_mapping_call_for_each(mali_descriptor_mapping *map, void (*callback)(int, void *));
 
 /**
  * Free the descriptor ID
@@ -96,6 +94,6 @@ void mali_descriptor_mapping_call_for_each(mali_descriptor_mapping * map, void (
  *
  * @return old value of descriptor mapping
  */
-void *mali_descriptor_mapping_free(mali_descriptor_mapping * map, int descriptor);
+void *mali_descriptor_mapping_free(mali_descriptor_mapping *map, int descriptor);
 
 #endif /* __MALI_KERNEL_DESCRIPTOR_MAPPING_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_mem_os.c b/drivers/gpu/mali/mali/common/mali_kernel_mem_os.c
deleted file mode 100644
index e63c7c2..0000000
--- a/drivers/gpu/mali/mali/common/mali_kernel_mem_os.c
+++ /dev/null
@@ -1,346 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include "mali_kernel_common.h"
-#include "mali_kernel_core.h"
-#include "mali_kernel_memory_engine.h"
-#include "mali_osk.h"
-
-typedef struct os_allocation
-{
-	u32 num_pages;
-	u32 offset_start;
-	mali_allocation_engine * engine;
-	mali_memory_allocation * descriptor;
-} os_allocation;
-
-typedef struct os_allocator
-{
-	_mali_osk_lock_t *mutex;
-
-	/**
-	 * Maximum number of pages to allocate from the OS
-	 */
-	u32 num_pages_max;
-
-	/**
-	 * Number of pages allocated from the OS
-	 */
-	u32 num_pages_allocated;
-
-	/** CPU Usage adjustment (add to mali physical address to get cpu physical address) */
-	u32 cpu_usage_adjust;
-} os_allocator;
-
-static mali_physical_memory_allocation_result os_allocator_allocate(void* ctx, mali_allocation_engine * engine,  mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info);
-static mali_physical_memory_allocation_result os_allocator_allocate_page_table_block(void * ctx, mali_page_table_block * block);
-static void os_allocator_release(void * ctx, void * handle);
-static void os_allocator_page_table_block_release( mali_page_table_block *page_table_block );
-static void os_allocator_destroy(mali_physical_memory_allocator * allocator);
-static u32 os_allocator_stat(mali_physical_memory_allocator * allocator);
-
-mali_physical_memory_allocator * mali_os_allocator_create(u32 max_allocation, u32 cpu_usage_adjust, const char *name)
-{
-	mali_physical_memory_allocator * allocator;
-	os_allocator * info;
-
-	max_allocation = (max_allocation + _MALI_OSK_CPU_PAGE_SIZE-1) & ~(_MALI_OSK_CPU_PAGE_SIZE-1);
-
-	MALI_DEBUG_PRINT(2, ("Mali OS memory allocator created with max allocation size of 0x%X bytes, cpu_usage_adjust 0x%08X\n", max_allocation, cpu_usage_adjust));
-
-	allocator = _mali_osk_malloc(sizeof(mali_physical_memory_allocator));
-	if (NULL != allocator)
-	{
-		info = _mali_osk_malloc(sizeof(os_allocator));
-		if (NULL != info)
-		{
-			info->num_pages_max = max_allocation / _MALI_OSK_CPU_PAGE_SIZE;
-			info->num_pages_allocated = 0;
-			info->cpu_usage_adjust = cpu_usage_adjust;
-
-			info->mutex = _mali_osk_lock_init( _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE | _MALI_OSK_LOCKFLAG_ORDERED, 0, _MALI_OSK_LOCK_ORDER_MEM_INFO);
-            if (NULL != info->mutex)
-            {
-			    allocator->allocate = os_allocator_allocate;
-			    allocator->allocate_page_table_block = os_allocator_allocate_page_table_block;
-			    allocator->destroy = os_allocator_destroy;
-				allocator->stat = os_allocator_stat;
-			    allocator->ctx = info;
-				allocator->name = name;
-
-			    return allocator;
-            }
-            _mali_osk_free(info);
-		}
-		_mali_osk_free(allocator);
-	}
-
-	return NULL;
-}
-
-static u32 os_allocator_stat(mali_physical_memory_allocator * allocator)
-{
-	os_allocator * info;
-	info = (os_allocator*)allocator->ctx;
-	return info->num_pages_allocated * _MALI_OSK_MALI_PAGE_SIZE;
-}
-
-static void os_allocator_destroy(mali_physical_memory_allocator * allocator)
-{
-	os_allocator * info;
-	MALI_DEBUG_ASSERT_POINTER(allocator);
-	MALI_DEBUG_ASSERT_POINTER(allocator->ctx);
-	info = (os_allocator*)allocator->ctx;
-	_mali_osk_lock_term(info->mutex);
-	_mali_osk_free(info);
-	_mali_osk_free(allocator);
-}
-
-static mali_physical_memory_allocation_result os_allocator_allocate(void* ctx, mali_allocation_engine * engine,  mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info)
-{
-	mali_physical_memory_allocation_result result = MALI_MEM_ALLOC_NONE;
-	u32 left;
-	os_allocator * info;
-	os_allocation * allocation;
-	int pages_allocated = 0;
-	_mali_osk_errcode_t err = _MALI_OSK_ERR_OK;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(offset);
-	MALI_DEBUG_ASSERT_POINTER(alloc_info);
-
-	info = (os_allocator*)ctx;
-	left = descriptor->size - *offset;
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW)) return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	/** @note this code may not work on Linux, or may require a more complex Linux implementation */
-	allocation = _mali_osk_malloc(sizeof(os_allocation));
-	if (NULL != allocation)
-	{
-		u32 os_mem_max_usage = info->num_pages_max * _MALI_OSK_CPU_PAGE_SIZE;
-		allocation->offset_start = *offset;
-		allocation->num_pages = ((left + _MALI_OSK_CPU_PAGE_SIZE - 1) & ~(_MALI_OSK_CPU_PAGE_SIZE - 1)) >> _MALI_OSK_CPU_PAGE_ORDER;
-		MALI_DEBUG_PRINT(6, ("Allocating page array of size %d bytes\n", allocation->num_pages * sizeof(struct page*)));
-
-		while (left > 0 && ((info->num_pages_allocated + pages_allocated) < info->num_pages_max) && _mali_osk_mem_check_allocated(os_mem_max_usage))
-		{
-			err = mali_allocation_engine_map_physical(engine, descriptor, *offset, MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC, info->cpu_usage_adjust, _MALI_OSK_CPU_PAGE_SIZE);
-			if ( _MALI_OSK_ERR_OK != err)
-			{
-				if (  _MALI_OSK_ERR_NOMEM == err)
-				{
-					/* 'Partial' allocation (or, out-of-memory on first page) */
-					break;
-				}
-
-				MALI_DEBUG_PRINT(1, ("Mapping of physical memory failed\n"));
-
-				/* Fatal error, cleanup any previous pages allocated. */
-				if ( pages_allocated > 0 )
-				{
-					mali_allocation_engine_unmap_physical( engine, descriptor, allocation->offset_start, _MALI_OSK_CPU_PAGE_SIZE*pages_allocated, _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR );
-					/* (*offset) doesn't need to be restored; it will not be used by the caller on failure */
-				}
-
-				pages_allocated = 0;
-
-				result = MALI_MEM_ALLOC_INTERNAL_FAILURE;
-				break;
-			}
-
-			/* Loop iteration */
-			if (left < _MALI_OSK_CPU_PAGE_SIZE) left = 0;
-			else left -= _MALI_OSK_CPU_PAGE_SIZE;
-
-			pages_allocated++;
-
-			*offset += _MALI_OSK_CPU_PAGE_SIZE;
-		}
-
-		if (left) MALI_PRINT(("Out of memory. Mali memory allocated: %d kB  Configured maximum OS memory usage: %d kB\n",
-				 (info->num_pages_allocated * _MALI_OSK_CPU_PAGE_SIZE)/1024, (info->num_pages_max* _MALI_OSK_CPU_PAGE_SIZE)/1024));
-
-		/* Loop termination; decide on result */
-		if (pages_allocated)
-		{
-			MALI_DEBUG_PRINT(6, ("Allocated %d pages\n", pages_allocated));
-			if (left) result = MALI_MEM_ALLOC_PARTIAL;
-			else result = MALI_MEM_ALLOC_FINISHED;
-
-            /* Some OS do not perform a full cache flush (including all outer caches) for uncached mapped memory.
-             * They zero the memory through a cached mapping, then flush the inner caches but not the outer caches.
-             * This is required for MALI to have the correct view of the memory.
-             */
-            _mali_osk_cache_ensure_uncached_range_flushed( (void *)descriptor, allocation->offset_start, pages_allocated *_MALI_OSK_CPU_PAGE_SIZE );
-			allocation->num_pages = pages_allocated;
-			allocation->engine = engine;         /* Necessary to make the engine's unmap call */
-			allocation->descriptor = descriptor; /* Necessary to make the engine's unmap call */
-			info->num_pages_allocated += pages_allocated;
-
-			MALI_DEBUG_PRINT(6, ("%d out of %d pages now allocated\n", info->num_pages_allocated, info->num_pages_max));
-
-			alloc_info->ctx = info;
-			alloc_info->handle = allocation;
-			alloc_info->release = os_allocator_release;
-		}
-		else
-		{
-			MALI_DEBUG_PRINT(6, ("Releasing pages array due to no pages allocated\n"));
-			_mali_osk_free( allocation );
-		}
-	}
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	return result;
-}
-
-static void os_allocator_release(void * ctx, void * handle)
-{
-	os_allocator * info;
-	os_allocation * allocation;
-	mali_allocation_engine * engine;
-	mali_memory_allocation * descriptor;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(handle);
-
-	info = (os_allocator*)ctx;
-	allocation = (os_allocation*)handle;
-	engine = allocation->engine;
-	descriptor = allocation->descriptor;
-
-	MALI_DEBUG_ASSERT_POINTER( engine );
-	MALI_DEBUG_ASSERT_POINTER( descriptor );
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW))
-	{
-		MALI_DEBUG_PRINT(1, ("allocator release: Failed to get mutex\n"));
-		return;
-	}
-
-	MALI_DEBUG_PRINT(6, ("Releasing %d os pages\n", allocation->num_pages));
-
-	MALI_DEBUG_ASSERT( allocation->num_pages <= info->num_pages_allocated);
-	info->num_pages_allocated -= allocation->num_pages;
-
-	mali_allocation_engine_unmap_physical( engine, descriptor, allocation->offset_start, _MALI_OSK_CPU_PAGE_SIZE*allocation->num_pages, _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR );
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	_mali_osk_free(allocation);
-}
-
-static mali_physical_memory_allocation_result os_allocator_allocate_page_table_block(void * ctx, mali_page_table_block * block)
-{
-	int allocation_order = 6; /* _MALI_OSK_CPU_PAGE_SIZE << 6 */
-	void *virt = NULL;
-	u32 size = _MALI_OSK_CPU_PAGE_SIZE << allocation_order;
-	os_allocator * info;
-
-	u32 cpu_phys_base;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	info = (os_allocator*)ctx;
-
-	/* Ensure we don't allocate more than we're supposed to from the ctx */
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW)) return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	/* if the number of pages to be requested lead to exceeding the memory
-	 * limit in info->num_pages_max, reduce the size that is to be requested. */
-	while ( (info->num_pages_allocated + (1 << allocation_order) > info->num_pages_max)
-	        && _mali_osk_mem_check_allocated(info->num_pages_max * _MALI_OSK_CPU_PAGE_SIZE) )
-	{
-		if ( allocation_order > 0 ) {
-			--allocation_order;
-		} else {
-			/* return OOM */
-			_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-			return MALI_MEM_ALLOC_NONE;
-		}
-	}
-
-	/* try to allocate 2^(allocation_order) pages, if that fails, try
-	 * allocation_order-1 to allocation_order 0 (inclusive) */
-	while ( allocation_order >= 0 )
-	{
-		size = _MALI_OSK_CPU_PAGE_SIZE << allocation_order;
-		virt = _mali_osk_mem_allocioregion( &cpu_phys_base, size );
-
-		if (NULL != virt) break;
-
-		--allocation_order;
-	}
-
-	if ( NULL == virt )
-	{
-		MALI_DEBUG_PRINT(1, ("Failed to allocate consistent memory. Is CONSISTENT_DMA_SIZE set too low?\n"));
-		/* return OOM */
-		_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-		return MALI_MEM_ALLOC_NONE;
-	}
-
-	MALI_DEBUG_PRINT(5, ("os_allocator_allocate_page_table_block: Allocation of order %i succeeded\n",
-				allocation_order));
-
-	/* we now know the size of the allocation since we know for what
-	 * allocation_order the allocation succeeded */
-	size = _MALI_OSK_CPU_PAGE_SIZE << allocation_order;
-
-
-	block->release = os_allocator_page_table_block_release;
-	block->ctx = ctx;
-	block->handle = (void*)allocation_order;
-	block->size = size;
-	block->phys_base = cpu_phys_base - info->cpu_usage_adjust;
-	block->mapping = virt;
-
-	info->num_pages_allocated += (1 << allocation_order);
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-
-	return MALI_MEM_ALLOC_FINISHED;
-}
-
-static void os_allocator_page_table_block_release( mali_page_table_block *page_table_block )
-{
-	os_allocator * info;
-	u32 allocation_order;
-	u32 pages_allocated;
-
-	MALI_DEBUG_ASSERT_POINTER( page_table_block );
-
-	info = (os_allocator*)page_table_block->ctx;
-
-	MALI_DEBUG_ASSERT_POINTER( info );
-
-	allocation_order = (u32)page_table_block->handle;
-
-	pages_allocated = 1 << allocation_order;
-
-	MALI_DEBUG_ASSERT( pages_allocated * _MALI_OSK_CPU_PAGE_SIZE == page_table_block->size );
-
-	if (_MALI_OSK_ERR_OK != _mali_osk_lock_wait(info->mutex, _MALI_OSK_LOCKMODE_RW))
-	{
-		MALI_DEBUG_PRINT(1, ("allocator release: Failed to get mutex\n"));
-		return;
-	}
-
-	MALI_DEBUG_ASSERT( pages_allocated <= info->num_pages_allocated);
-	info->num_pages_allocated -= pages_allocated;
-
-	/* Adjust phys_base from mali physical address to CPU physical address */
-	_mali_osk_mem_freeioregion( page_table_block->phys_base + info->cpu_usage_adjust, page_table_block->size, page_table_block->mapping );
-
-	_mali_osk_lock_signal(info->mutex, _MALI_OSK_LOCKMODE_RW);
-}
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_mem_os.h b/drivers/gpu/mali/mali/common/mali_kernel_mem_os.h
deleted file mode 100644
index 0af9728..0000000
--- a/drivers/gpu/mali/mali/common/mali_kernel_mem_os.h
+++ /dev/null
@@ -1,36 +0,0 @@
-/*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_KERNEL_MEM_OS_H__
-#define __MALI_KERNEL_MEM_OS_H__
-
-/**
- * @brief Creates an object that manages allocating OS memory
- *
- * Creates an object that provides an interface to allocate OS memory and
- * have it mapped into the Mali virtual memory space.
- *
- * The object exposes pointers to
- * - allocate OS memory
- * - allocate Mali page tables in OS memory
- * - destroy the object
- *
- * Allocations from OS memory are of type mali_physical_memory_allocation
- * which provides a function to release the allocation.
- *
- * @param max_allocation max. number of bytes that can be allocated from OS memory
- * @param cpu_usage_adjust value to add to mali physical addresses to obtain CPU physical addresses
- * @param name description of the allocator
- * @return pointer to mali_physical_memory_allocator object. NULL on failure.
- **/
-mali_physical_memory_allocator * mali_os_allocator_create(u32 max_allocation, u32 cpu_usage_adjust, const char *name);
-
-#endif /* __MALI_KERNEL_MEM_OS_H__ */
-
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.c b/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.c
deleted file mode 100644
index 47e8324..0000000
--- a/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.c
+++ /dev/null
@@ -1,394 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include <asm/memory.h>  /* For PHYS_OFFSET */
-
-#include "mali_kernel_common.h"
-#include "mali_kernel_core.h"
-#include "mali_kernel_memory_engine.h"
-#include "mali_osk.h"
-#include "mali_osk_list.h"
-
-typedef struct memory_engine
-{
-	mali_kernel_mem_address_manager * mali_address;
-	mali_kernel_mem_address_manager * process_address;
-} memory_engine;
-
-mali_allocation_engine mali_allocation_engine_create(mali_kernel_mem_address_manager * mali_address_manager, mali_kernel_mem_address_manager * process_address_manager)
-{
-	memory_engine * engine;
-
-	/* Mali Address Manager need not support unmap_physical */
-	MALI_DEBUG_ASSERT_POINTER(mali_address_manager);
-	MALI_DEBUG_ASSERT_POINTER(mali_address_manager->allocate);
-	MALI_DEBUG_ASSERT_POINTER(mali_address_manager->release);
-	MALI_DEBUG_ASSERT_POINTER(mali_address_manager->map_physical);
-
-	/* Process Address Manager must support unmap_physical for OS allocation
-	 * error path handling */
-	MALI_DEBUG_ASSERT_POINTER(process_address_manager);
-	MALI_DEBUG_ASSERT_POINTER(process_address_manager->allocate);
-	MALI_DEBUG_ASSERT_POINTER(process_address_manager->release);
-	MALI_DEBUG_ASSERT_POINTER(process_address_manager->map_physical);
-	MALI_DEBUG_ASSERT_POINTER(process_address_manager->unmap_physical);
-
-
-	engine = (memory_engine*)_mali_osk_malloc(sizeof(memory_engine));
-	if (NULL == engine) return NULL;
-
-	engine->mali_address = mali_address_manager;
-	engine->process_address = process_address_manager;
-
-	return (mali_allocation_engine)engine;
-}
-
-void mali_allocation_engine_destroy(mali_allocation_engine engine)
-{
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	_mali_osk_free(engine);
-}
-
-_mali_osk_errcode_t mali_allocation_engine_allocate_memory(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor, mali_physical_memory_allocator * physical_allocators, _mali_osk_list_t *tracking_list )
-{
-	memory_engine * engine = (memory_engine*)mem_engine;
-
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(physical_allocators);
-	/* ASSERT that the list member has been initialized, even if it won't be
-	 * used for tracking. We need it to be initialized to see if we need to
-	 * delete it from a list in the release function. */
-	MALI_DEBUG_ASSERT( NULL != descriptor->list.next && NULL != descriptor->list.prev );
-
-	if (_MALI_OSK_ERR_OK == engine->mali_address->allocate(descriptor))
-	{
-		_mali_osk_errcode_t res = _MALI_OSK_ERR_OK;
-		if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-		{
-			res = engine->process_address->allocate(descriptor);
-		}
-		if ( _MALI_OSK_ERR_OK == res )
-		{
-			/* address space setup OK, commit physical memory to the allocation */
-			mali_physical_memory_allocator * active_allocator = physical_allocators;
-			struct mali_physical_memory_allocation * active_allocation_tracker = &descriptor->physical_allocation;
-			u32 offset = 0;
-
-			while ( NULL != active_allocator )
-			{
-				switch (active_allocator->allocate(active_allocator->ctx, mem_engine, descriptor, &offset, active_allocation_tracker))
-				{
-					case MALI_MEM_ALLOC_FINISHED:
-						if ( NULL != tracking_list )
-						{
-							/* Insert into the memory session list */
-							/* ASSERT that it is not already part of a list */
-							MALI_DEBUG_ASSERT( _mali_osk_list_empty( &descriptor->list ) );
-							_mali_osk_list_add( &descriptor->list, tracking_list );
-						}
-
-						MALI_SUCCESS; /* all done */
-					case MALI_MEM_ALLOC_NONE:
-						/* reuse current active_allocation_tracker */
-						MALI_DEBUG_PRINT( 4, ("Memory Engine Allocate: No allocation on %s, resorting to %s\n",
-											  ( active_allocator->name ) ? active_allocator->name : "UNNAMED",
-											  ( active_allocator->next ) ? (( active_allocator->next->name )? active_allocator->next->name : "UNNAMED") : "NONE") );
-						active_allocator = active_allocator->next;
-						break;
-					case MALI_MEM_ALLOC_PARTIAL:
-						if (NULL != active_allocator->next)
-						{
-							/* need a new allocation tracker */
-							active_allocation_tracker->next = _mali_osk_calloc(1, sizeof(mali_physical_memory_allocation));
-							if (NULL != active_allocation_tracker->next)
-							{
-								active_allocation_tracker = active_allocation_tracker->next;
-								MALI_DEBUG_PRINT( 2, ("Memory Engine Allocate: Partial allocation on %s, resorting to %s\n",
-													  ( active_allocator->name ) ? active_allocator->name : "UNNAMED",
-													  ( active_allocator->next ) ? (( active_allocator->next->name )? active_allocator->next->name : "UNNAMED") : "NONE") );
-								active_allocator = active_allocator->next;
-								break;
-							}
-						}
-					   /* FALL THROUGH */
-					case MALI_MEM_ALLOC_INTERNAL_FAILURE:
-					   active_allocator = NULL; /* end the while loop */
-					   break;
-				}
-			}
-
-			MALI_PRINT(("Memory allocate failed, could not allocate size %d kB.\n", descriptor->size/1024));
-
-			/* allocation failure, start cleanup */
-			/* loop over any potential partial allocations */
-			active_allocation_tracker = &descriptor->physical_allocation;
-			while (NULL != active_allocation_tracker)
-			{
-				/* handle blank trackers which will show up during failure */
-				if (NULL != active_allocation_tracker->release)
-				{
-					active_allocation_tracker->release(active_allocation_tracker->ctx, active_allocation_tracker->handle);
-				}
-				active_allocation_tracker = active_allocation_tracker->next;
-			}
-
-			/* free the allocation tracker objects themselves, skipping the tracker stored inside the descriptor itself */
-			for ( active_allocation_tracker = descriptor->physical_allocation.next; active_allocation_tracker != NULL; )
-			{
-				void * buf = active_allocation_tracker;
-				active_allocation_tracker = active_allocation_tracker->next;
-				_mali_osk_free(buf);
-			}
-
-			/* release the address spaces */
-
-			if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-			{
-				engine->process_address->release(descriptor);
-			}
-		}
-		engine->mali_address->release(descriptor);
-	}
-
-	MALI_ERROR(_MALI_OSK_ERR_FAULT);
-}
-
-void mali_allocation_engine_release_memory(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor)
-{
-	mali_allocation_engine_release_pt1_mali_pagetables_unmap(mem_engine, descriptor);
-	mali_allocation_engine_release_pt2_physical_memory_free(mem_engine, descriptor);
-}
-
-void mali_allocation_engine_release_pt1_mali_pagetables_unmap(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor)
-{
-	memory_engine * engine = (memory_engine*)mem_engine;
-
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	/* Calling: mali_address_manager_release()  */
-	/* This function is allowed to be called several times, and it only does the release on the first call. */
-	engine->mali_address->release(descriptor);
-}
-
-void mali_allocation_engine_release_pt2_physical_memory_free(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor)
-{
-	memory_engine * engine = (memory_engine*)mem_engine;
-	mali_physical_memory_allocation * active_allocation_tracker;
-
-	/* Remove this from a tracking list in session_data->memory_head */
-	if ( ! _mali_osk_list_empty( &descriptor->list ) )
-	{
-		_mali_osk_list_del( &descriptor->list );
-		/* Clear the list for debug mode, catch use-after-free */
-		MALI_DEBUG_CODE( descriptor->list.next = descriptor->list.prev = NULL; )
-	}
-
-	active_allocation_tracker = &descriptor->physical_allocation;
-	while (NULL != active_allocation_tracker)
-	{
-		MALI_DEBUG_ASSERT_POINTER(active_allocation_tracker->release);
-		active_allocation_tracker->release(active_allocation_tracker->ctx, active_allocation_tracker->handle);
-		active_allocation_tracker = active_allocation_tracker->next;
-	}
-
-	/* free the allocation tracker objects themselves, skipping the tracker stored inside the descriptor itself */
-	for ( active_allocation_tracker = descriptor->physical_allocation.next; active_allocation_tracker != NULL; )
-	{
-		void * buf = active_allocation_tracker;
-		active_allocation_tracker = active_allocation_tracker->next;
-		_mali_osk_free(buf);
-	}
-
-	if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-	{
-		engine->process_address->release(descriptor);
-	}
-}
-
-_mali_osk_errcode_t mali_allocation_engine_map_physical(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor, u32 offset, u32 phys, u32 cpu_usage_adjust, u32 size)
-{
-	_mali_osk_errcode_t err;
-	memory_engine * engine = (memory_engine*)mem_engine;
-	_mali_osk_mem_mapregion_flags_t unmap_flags = (_mali_osk_mem_mapregion_flags_t)0;
-
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	/*
-	 * Hack: Override the 'cpu_usage_adjust' function argument, because we
-	 *       know that it should be equal to PHYS_OFFSET. Also if 'phys'
-	 *       is not MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC
-	 *       (OS allocated memory), then convert it to the bus address
-	 *       right here (this should handle both UMP buffers and external
-	 *       memory).
-	 *
-	 * Note: Apparently mali driver uses a bit different terminology, which
-	 *       may be a source of confusion:
-	 *           linux       : "physical address"     and "bus address"
-	 *           mali driver : "cpu physical address" and "physical address"
-	 */
-	cpu_usage_adjust = PHYS_OFFSET;
-	if (MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC != phys)
-		phys -= cpu_usage_adjust;
-
-	MALI_DEBUG_PRINT(7, ("Mapping phys 0x%08X length 0x%08X at offset 0x%08X\n", phys, size, offset));
-
-	MALI_DEBUG_ASSERT_POINTER(engine->mali_address);
-	MALI_DEBUG_ASSERT_POINTER(engine->mali_address->map_physical);
-
-	/* Handle process address manager first, because we may need them to
-	 * allocate the physical page */
-	if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-	{
-		/* Handle OS-allocated specially, since an adjustment may be required */
-		if ( MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC == phys )
-		{
-			MALI_DEBUG_ASSERT( _MALI_OSK_CPU_PAGE_SIZE == size );
-
-			/* Set flags to use on error path */
-			unmap_flags |= _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR;
-
-			err = engine->process_address->map_physical(descriptor, offset, &phys, size);
-			/* Adjust for cpu physical address to mali physical address */
-			phys -= cpu_usage_adjust;
-		}
-		else
-		{
-			u32 cpu_phys;
-			/* Adjust mali physical address to cpu physical address */
-			cpu_phys = phys + cpu_usage_adjust;
-			err = engine->process_address->map_physical(descriptor, offset, &cpu_phys, size);
-		}
-
-		if ( _MALI_OSK_ERR_OK != err )
-		{
-			MALI_ERROR( err );
-		}
-	}
-
-	MALI_DEBUG_PRINT(7, ("Mapping phys 0x%08X length 0x%08X at offset 0x%08X to CPUVA 0x%08X\n", phys, size, offset, (u32)(descriptor->mapping) + offset));
-
-	/* Mali address manager must use the physical address - no point in asking
-	 * it to allocate another one for us */
-	MALI_DEBUG_ASSERT( MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC != phys );
-
-	err = engine->mali_address->map_physical(descriptor, offset, &phys, size);
-
-	if ( _MALI_OSK_ERR_OK != err )
-	{
-		if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-		{
-			MALI_DEBUG_PRINT( 2, ("Process address manager succeeded, but Mali Address manager failed for phys=0x%08X size=0x%08X, offset=0x%08X. Will unmap.\n", phys, size, offset));
-			engine->process_address->unmap_physical(descriptor, offset, size, unmap_flags);
-		}
-
-		MALI_ERROR( err );
-	}
-
-	MALI_SUCCESS;
-}
-
-void mali_allocation_engine_unmap_physical(mali_allocation_engine mem_engine, mali_memory_allocation * descriptor, u32 offset, u32 size, _mali_osk_mem_mapregion_flags_t unmap_flags )
-{
-	memory_engine * engine = (memory_engine*)mem_engine;
-
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	MALI_DEBUG_PRINT(7, ("UnMapping length 0x%08X at offset 0x%08X\n", size, offset));
-
-	MALI_DEBUG_ASSERT_POINTER(engine->mali_address);
-	MALI_DEBUG_ASSERT_POINTER(engine->process_address);
-
-	if ( descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE )
-	{
-		/* Mandetory for process_address manager to have an unmap function*/
-		engine->process_address->unmap_physical( descriptor, offset, size, unmap_flags );
-	}
-
-	/* Optional for mali_address manager to have an unmap function*/
-	if ( NULL != engine->mali_address->unmap_physical )
-	{
-		engine->mali_address->unmap_physical( descriptor, offset, size, unmap_flags );
-	}
-}
-
-
-_mali_osk_errcode_t mali_allocation_engine_allocate_page_tables(mali_allocation_engine engine, mali_page_table_block * descriptor, mali_physical_memory_allocator * physical_provider)
-{
-	mali_physical_memory_allocator * active_allocator = physical_provider;
-
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(physical_provider);
-
-	while ( NULL != active_allocator )
-	{
-		switch (active_allocator->allocate_page_table_block(active_allocator->ctx, descriptor))
-		{
-			case MALI_MEM_ALLOC_FINISHED:
-				MALI_SUCCESS; /* all done */
-			case MALI_MEM_ALLOC_NONE:
-				/* try next */
-				MALI_DEBUG_PRINT( 2, ("Memory Engine Allocate PageTables: No allocation on %s, resorting to %s\n",
-									  ( active_allocator->name ) ? active_allocator->name : "UNNAMED",
-									  ( active_allocator->next ) ? (( active_allocator->next->name )? active_allocator->next->name : "UNNAMED") : "NONE") );
-				active_allocator = active_allocator->next;
-				break;
-			case MALI_MEM_ALLOC_PARTIAL:
-				MALI_DEBUG_PRINT(1, ("Invalid return value from allocate_page_table_block call: MALI_MEM_ALLOC_PARTIAL\n"));
-				/* FALL THROUGH */
-			case MALI_MEM_ALLOC_INTERNAL_FAILURE:
-				MALI_DEBUG_PRINT(1, ("Aborting due to allocation failure\n"));
-				active_allocator = NULL; /* end the while loop */
-				break;
-		}
-	}
-
-	MALI_ERROR(_MALI_OSK_ERR_FAULT);
-}
-
-
-void mali_allocation_engine_report_allocators( mali_physical_memory_allocator * physical_provider )
-{
-	mali_physical_memory_allocator * active_allocator = physical_provider;
-	MALI_DEBUG_ASSERT_POINTER(physical_provider);
-
-	MALI_DEBUG_PRINT( 1, ("Mali memory allocators will be used in this order of preference (lowest numbered first) :\n"));
-	while ( NULL != active_allocator )
-	{
-		if ( NULL != active_allocator->name )
-		{
-			MALI_DEBUG_PRINT( 1, ("\t%d: %s\n", active_allocator->alloc_order, active_allocator->name) );
-		}
-		else
-		{
-			MALI_DEBUG_PRINT( 1, ("\t%d: (UNNAMED ALLOCATOR)\n", active_allocator->alloc_order) );
-		}
-		active_allocator = active_allocator->next;
-	}
-
-}
-
-u32 mali_allocation_engine_memory_usage(mali_physical_memory_allocator *allocator)
-{
-	u32 sum = 0;
-	while(NULL != allocator)
-	{
-		/* Only count allocators that have set up a stat function. */
-		if(allocator->stat)
-			sum += allocator->stat(allocator);
-
-		allocator = allocator->next;
-	}
-
-	return sum;
-}
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.h b/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.h
deleted file mode 100644
index ae95b1d..0000000
--- a/drivers/gpu/mali/mali/common/mali_kernel_memory_engine.h
+++ /dev/null
@@ -1,151 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_KERNEL_MEMORY_ENGINE_H__
-#define  __MALI_KERNEL_MEMORY_ENGINE_H__
-
-typedef void * mali_allocation_engine;
-
-typedef enum { MALI_MEM_ALLOC_FINISHED, MALI_MEM_ALLOC_PARTIAL, MALI_MEM_ALLOC_NONE, MALI_MEM_ALLOC_INTERNAL_FAILURE } mali_physical_memory_allocation_result;
-
-typedef struct mali_physical_memory_allocation
-{
-	void (*release)(void * ctx, void * handle); /**< Function to call on to release the physical memory */
-	void * ctx;
-	void * handle;
-	struct mali_physical_memory_allocation * next;
-} mali_physical_memory_allocation;
-
-struct mali_page_table_block;
-
-typedef struct mali_page_table_block
-{
-	void (*release)(struct mali_page_table_block *page_table_block);
-	void * ctx;
-	void * handle;
-	u32 size; /**< In bytes, should be a multiple of MALI_MMU_PAGE_SIZE to avoid internal fragementation */
-	u32 phys_base; /**< Mali physical address */
-	mali_io_address mapping;
-} mali_page_table_block;
-
-
-/** @addtogroup _mali_osk_low_level_memory
- * @{ */
-
-typedef enum
-{
-	MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE = 0x1,
-	MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE     = 0x2,
-} mali_memory_allocation_flag;
-
-/**
- * Supplying this 'magic' physical address requests that the OS allocate the
- * physical address at page commit time, rather than committing a specific page
- */
-#define MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC ((u32)(-1))
-
-typedef struct mali_memory_allocation
-{
-	/* Information about the allocation */
-	void * mapping; /**< CPU virtual address where the memory is mapped at */
-	u32 mali_address; /**< The Mali seen address of the memory allocation */
-	u32 size; /**< Size of the allocation */
-	u32 permission; /**< Permission settings */
-	mali_memory_allocation_flag flags;
-
-	_mali_osk_lock_t * lock;
-
-	/* Manager specific information pointers */
-	void * mali_addr_mapping_info; /**< Mali address allocation specific info */
-	void * process_addr_mapping_info; /**< Mapping manager specific info */
-
-	mali_physical_memory_allocation physical_allocation;
-
-	_mali_osk_list_t list; /**< List for linking together memory allocations into the session's memory head */
-} mali_memory_allocation;
-/** @} */ /* end group _mali_osk_low_level_memory */
-
-
-typedef struct mali_physical_memory_allocator
-{
-	mali_physical_memory_allocation_result (*allocate)(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info);
-	mali_physical_memory_allocation_result (*allocate_page_table_block)(void * ctx, mali_page_table_block * block); /* MALI_MEM_ALLOC_PARTIAL not allowed */
-	void (*destroy)(struct mali_physical_memory_allocator * allocator);
-	u32 (*stat)(struct mali_physical_memory_allocator * allocator);
-	void * ctx;
-	const char * name; /**< Descriptive name for use in mali_allocation_engine_report_allocators, or NULL */
-	u32 alloc_order; /**< Order in which the allocations should happen */
-	struct mali_physical_memory_allocator * next;
-} mali_physical_memory_allocator;
-
-typedef struct mali_kernel_mem_address_manager
-{
-	_mali_osk_errcode_t (*allocate)(mali_memory_allocation *); /**< Function to call to reserve an address */
-	void (*release)(mali_memory_allocation *); /**< Function to call to free the address allocated */
-
-	 /**
-	  * Function called for each physical sub allocation.
-	  * Called for each physical block allocated by the physical memory manager.
-	  * @param[in] descriptor The memory descriptor in question
-	  * @param[in] off Offset from the start of range
-	  * @param[in,out] phys_addr A pointer to the physical address of the start of the
-	  * physical block. When *phys_addr == MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC
-	  * is used, this requests the function to allocate the physical page
-	  * itself, and return it through the pointer provided.
-	  * @param[in] size Length in bytes of the physical block
-	  * @return _MALI_OSK_ERR_OK on success.
-	  * A value of type _mali_osk_errcode_t other than _MALI_OSK_ERR_OK indicates failure.
-	  * Specifically, _MALI_OSK_ERR_UNSUPPORTED indicates that the function
-	  * does not support allocating physical pages itself.
-	  */
-	 _mali_osk_errcode_t (*map_physical)(mali_memory_allocation * descriptor, u32 offset, u32 *phys_addr, u32 size);
-
-	 /**
-	  * Function called to remove a physical sub allocation.
-	  * Called on error paths where one of the address managers fails.
-	  *
-	  * @note this is optional. For address managers where this is not
-	  * implemented, the value of this member is NULL. The memory engine
-	  * currently does not require the mali address manager to be able to
-	  * unmap individual pages, but the process address manager must have this
-	  * capability.
-	  *
-	  * @param[in] descriptor The memory descriptor in question
-	  * @param[in] off Offset from the start of range
-	  * @param[in] size Length in bytes of the physical block
-	  * @param[in] flags flags to use on a per-page basis. For OS-allocated
-	  * physical pages, this must include _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR.
-	  * @return _MALI_OSK_ERR_OK on success.
-	  * A value of type _mali_osk_errcode_t other than _MALI_OSK_ERR_OK indicates failure.
-	  */
-	void (*unmap_physical)(mali_memory_allocation * descriptor, u32 offset, u32 size, _mali_osk_mem_mapregion_flags_t flags);
-
-} mali_kernel_mem_address_manager;
-
-mali_allocation_engine mali_allocation_engine_create(mali_kernel_mem_address_manager * mali_address_manager, mali_kernel_mem_address_manager * process_address_manager);
-
-void mali_allocation_engine_destroy(mali_allocation_engine engine);
-
-int mali_allocation_engine_allocate_memory(mali_allocation_engine engine, mali_memory_allocation * descriptor, mali_physical_memory_allocator * physical_provider, _mali_osk_list_t *tracking_list );
-void mali_allocation_engine_release_memory(mali_allocation_engine engine, mali_memory_allocation * descriptor);
-
-void mali_allocation_engine_release_pt1_mali_pagetables_unmap(mali_allocation_engine engine, mali_memory_allocation * descriptor);
-void mali_allocation_engine_release_pt2_physical_memory_free(mali_allocation_engine engine, mali_memory_allocation * descriptor);
-
-int mali_allocation_engine_map_physical(mali_allocation_engine engine, mali_memory_allocation * descriptor, u32 offset, u32 phys, u32 cpu_usage_adjust, u32 size);
-void mali_allocation_engine_unmap_physical(mali_allocation_engine engine, mali_memory_allocation * descriptor, u32 offset, u32 size, _mali_osk_mem_mapregion_flags_t unmap_flags);
-
-int mali_allocation_engine_allocate_page_tables(mali_allocation_engine, mali_page_table_block * descriptor, mali_physical_memory_allocator * physical_provider);
-
-void mali_allocation_engine_report_allocators(mali_physical_memory_allocator * physical_provider);
-
-u32 mali_allocation_engine_memory_usage(mali_physical_memory_allocator *allocator);
-
-#endif /* __MALI_KERNEL_MEMORY_ENGINE_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_utilization.c b/drivers/gpu/mali/mali/common/mali_kernel_utilization.c
old mode 100644
new mode 100755
index dbbfbd3..19a9aae
--- a/drivers/gpu/mali/mali/common/mali_kernel_utilization.c
+++ b/drivers/gpu/mali/mali/common/mali_kernel_utilization.c
@@ -1,65 +1,149 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
 #include "mali_kernel_utilization.h"
 #include "mali_osk.h"
-#include "mali_platform.h"
+#include "mali_osk_mali.h"
+#include "mali_kernel_common.h"
+#include "mali_session.h"
+#include "mali_scheduler.h"
+
+/* Thresholds for GP bound detection. */
+#define MALI_GP_BOUND_GP_UTILIZATION_THRESHOLD 240
+#define MALI_GP_BOUND_PP_UTILIZATION_THRESHOLD 250
 
 /* Define how often to calculate and report GPU utilization, in milliseconds */
-#define MALI_GPU_UTILIZATION_TIMEOUT 1000
+static _mali_osk_spinlock_irq_t *time_data_lock;
 
-static _mali_osk_lock_t *time_data_lock;
+static u32 num_running_gp_cores;
+static u32 num_running_pp_cores;
 
-static _mali_osk_atomic_t num_running_cores;
+static u64 work_start_time_gpu = 0;
+static u64 work_start_time_gp = 0;
+static u64 work_start_time_pp = 0;
+static u64 accumulated_work_time_gpu = 0;
+static u64 accumulated_work_time_gp = 0;
+static u64 accumulated_work_time_pp = 0;
 
 static u64 period_start_time = 0;
-static u64 work_start_time = 0;
-static u64 accumulated_work_time = 0;
-
 static _mali_osk_timer_t *utilization_timer = NULL;
 static mali_bool timer_running = MALI_FALSE;
 
+static u32 last_utilization_gpu = 0 ;
+static u32 last_utilization_gp = 0 ;
+static u32 last_utilization_pp = 0 ;
+
+static u32 mali_utilization_timeout = 1000;
+void (*mali_utilization_callback)(struct mali_gpu_utilization_data *data) = NULL;
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+extern void mali_power_performance_policy_callback(struct mali_gpu_utilization_data *data);
+#define NUMBER_OF_NANOSECONDS_PER_SECOND  1000000000ULL
 
-static void calculate_gpu_utilization(void* arg)
+static u32 calculate_window_render_fps(u64 time_period)
+{
+	u32 max_window_number;
+	u64 tmp;
+	u64 max = time_period;
+	u32 leading_zeroes;
+	u32 shift_val;
+	u32 time_period_shift;
+	u32 max_window_number_shift;
+	u32 ret_val;
+
+	max_window_number = mali_session_max_window_num();
+	/* To avoid float division, extend the dividend to ns unit */
+	tmp = (u64)max_window_number * NUMBER_OF_NANOSECONDS_PER_SECOND;
+	if (tmp > time_period) {
+		max = tmp;
+	}
+
+	/*
+	 * We may have 64-bit values, a dividend or a divisor or both
+	 * To avoid dependencies to a 64-bit divider, we shift down the two values
+	 * equally first.
+	 */
+	leading_zeroes = _mali_osk_clz((u32)(max >> 32));
+	shift_val = 32 - leading_zeroes;
+
+	time_period_shift = (u32)(time_period >> shift_val);
+	max_window_number_shift = (u32)(tmp >> shift_val);
+
+	ret_val = max_window_number_shift / time_period_shift;
+
+	return ret_val;
+}
+#endif  /* defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY) */
+
+static void calculate_gpu_utilization(void *arg)
 {
 	u64 time_now;
 	u64 time_period;
 	u32 leading_zeroes;
 	u32 shift_val;
-	u32 work_normalized;
+	u32 work_normalized_gpu;
+	u32 work_normalized_gp;
+	u32 work_normalized_pp;
 	u32 period_normalized;
-	u32 utilization;
+	u32 utilization_gpu;
+	u32 utilization_gp;
+	u32 utilization_pp;
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	u32 window_render_fps;
+#endif
 
-	_mali_osk_lock_wait(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_spinlock_irq_lock(time_data_lock);
 
-	if (accumulated_work_time == 0 && work_start_time == 0)
-	{
-		/* Don't reschedule timer, this will be started if new work arrives */
+	if (accumulated_work_time_gpu == 0 && work_start_time_gpu == 0) {
+		/*
+		 * No work done for this period
+		 * - No need to reschedule timer
+		 * - Report zero usage
+		 */
 		timer_running = MALI_FALSE;
 
-		_mali_osk_lock_signal(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+		last_utilization_gpu = 0;
+		last_utilization_gp = 0;
+		last_utilization_pp = 0;
+
+		_mali_osk_spinlock_irq_unlock(time_data_lock);
+
+		if (NULL != mali_utilization_callback) {
+			struct mali_gpu_utilization_data data = { 0, };
+			mali_utilization_callback(&data);
+		}
 
-		/* No work done for this period, report zero usage */
-		mali_gpu_utilization_handler(0);
+		mali_scheduler_hint_disable(MALI_SCHEDULER_HINT_GP_BOUND);
 
 		return;
 	}
 
 	time_now = _mali_osk_time_get_ns();
+
 	time_period = time_now - period_start_time;
 
 	/* If we are currently busy, update working period up to now */
-	if (work_start_time != 0)
-	{
-		accumulated_work_time += (time_now - work_start_time);
-		work_start_time = time_now;
+	if (work_start_time_gpu != 0) {
+		accumulated_work_time_gpu += (time_now - work_start_time_gpu);
+		work_start_time_gpu = time_now;
+
+		/* GP and/or PP will also be busy if the GPU is busy at this point */
+
+		if (work_start_time_gp != 0) {
+			accumulated_work_time_gp += (time_now - work_start_time_gp);
+			work_start_time_gp = time_now;
+		}
+
+		if (work_start_time_pp != 0) {
+			accumulated_work_time_pp += (time_now - work_start_time_pp);
+			work_start_time_pp = time_now;
+		}
 	}
 
 	/*
@@ -72,7 +156,9 @@ static void calculate_gpu_utilization(void* arg)
 	/* Shift the 64-bit values down so they fit inside a 32-bit integer */
 	leading_zeroes = _mali_osk_clz((u32)(time_period >> 32));
 	shift_val = 32 - leading_zeroes;
-	work_normalized = (u32)(accumulated_work_time >> shift_val);
+	work_normalized_gpu = (u32)(accumulated_work_time_gpu >> shift_val);
+	work_normalized_gp = (u32)(accumulated_work_time_gp >> shift_val);
+	work_normalized_pp = (u32)(accumulated_work_time_pp >> shift_val);
 	period_normalized = (u32)(time_period >> shift_val);
 
 	/*
@@ -81,49 +167,100 @@ static void calculate_gpu_utilization(void* arg)
 	 * (we could do a combination, but we just use one for simplicity,
 	 * but the end result should be good enough anyway)
 	 */
-	if (period_normalized > 0x00FFFFFF)
-	{
+	if (period_normalized > 0x00FFFFFF) {
 		/* The divisor is so big that it is safe to shift it down */
 		period_normalized >>= 8;
-	}
-	else
-	{
+	} else {
 		/*
 		 * The divisor is so small that we can shift up the dividend, without loosing any data.
 		 * (dividend is always smaller than the divisor)
 		 */
-		work_normalized <<= 8;
+		work_normalized_gpu <<= 8;
+		work_normalized_gp <<= 8;
+		work_normalized_pp <<= 8;
 	}
 
-	utilization = work_normalized / period_normalized;
+	utilization_gpu = work_normalized_gpu / period_normalized;
+	utilization_gp = work_normalized_gp / period_normalized;
+	utilization_pp = work_normalized_pp / period_normalized;
+
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	window_render_fps = calculate_window_render_fps(time_period);
+#endif
 
-	accumulated_work_time = 0;
-	period_start_time = time_now; /* starting a new period */
+	last_utilization_gpu = utilization_gpu;
+	last_utilization_gp = utilization_gp;
+	last_utilization_pp = utilization_pp;
 
-	_mali_osk_lock_signal(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+	if ((MALI_GP_BOUND_GP_UTILIZATION_THRESHOLD < last_utilization_gp) &&
+	    (MALI_GP_BOUND_PP_UTILIZATION_THRESHOLD > last_utilization_pp)) {
+		mali_scheduler_hint_enable(MALI_SCHEDULER_HINT_GP_BOUND);
+	} else {
+		mali_scheduler_hint_disable(MALI_SCHEDULER_HINT_GP_BOUND);
+	}
 
-	_mali_osk_timer_add(utilization_timer, _mali_osk_time_mstoticks(MALI_GPU_UTILIZATION_TIMEOUT));
+	/* starting a new period */
+	accumulated_work_time_gpu = 0;
+	accumulated_work_time_gp = 0;
+	accumulated_work_time_pp = 0;
+	period_start_time = time_now;
 
+	_mali_osk_spinlock_irq_unlock(time_data_lock);
 
-	mali_gpu_utilization_handler(utilization);
+	_mali_osk_timer_add(utilization_timer, _mali_osk_time_mstoticks(mali_utilization_timeout));
+
+	if (NULL != mali_utilization_callback) {
+		struct mali_gpu_utilization_data data = {
+			utilization_gpu, utilization_gp, utilization_pp,
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+			window_render_fps, window_render_fps
+#endif
+		};
+		mali_utilization_callback(&data);
+	}
 }
 
 _mali_osk_errcode_t mali_utilization_init(void)
 {
-	time_data_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ |
-	                     _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_UTILIZATION);
+#if USING_GPU_UTILIZATION
+	_mali_osk_device_data data;
 
-	if (NULL == time_data_lock)
-	{
+	if (_MALI_OSK_ERR_OK == _mali_osk_device_data_get(&data)) {
+		/* Use device specific settings (if defined) */
+		if (0 != data.utilization_interval) {
+			mali_utilization_timeout = data.utilization_interval;
+		}
+		if (NULL != data.utilization_callback) {
+			mali_utilization_callback = data.utilization_callback;
+			MALI_DEBUG_PRINT(2, ("Mali GPU Utilization: Platform has it's own policy \n"));
+			MALI_DEBUG_PRINT(2, ("Mali GPU Utilization: Utilization handler installed with interval %u\n", mali_utilization_timeout));
+		}
+	}
+#endif
+
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	if (mali_utilization_callback == NULL) {
+		MALI_DEBUG_PRINT(2, ("Mali GPU Utilization: MALI Power Performance Policy Algorithm \n"));
+		mali_utilization_callback = mali_power_performance_policy_callback;
+	}
+#endif
+
+	if (NULL == mali_utilization_callback) {
+		MALI_DEBUG_PRINT(2, ("Mali GPU Utilization: No utilization handler installed\n"));
+	}
+
+	time_data_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_UTILIZATION);
+
+	if (NULL == time_data_lock) {
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	_mali_osk_atomic_init(&num_running_cores, 0);
+	num_running_gp_cores = 0;
+	num_running_pp_cores = 0;
 
 	utilization_timer = _mali_osk_timer_init();
-	if (NULL == utilization_timer)
-	{
-		_mali_osk_lock_term(time_data_lock);
+	if (NULL == utilization_timer) {
+		_mali_osk_spinlock_irq_term(time_data_lock);
 		return _MALI_OSK_ERR_FAULT;
 	}
 	_mali_osk_timer_setcallback(utilization_timer, calculate_gpu_utilization, NULL);
@@ -133,86 +270,171 @@ _mali_osk_errcode_t mali_utilization_init(void)
 
 void mali_utilization_suspend(void)
 {
-	if (NULL != utilization_timer)
-	{
-		_mali_osk_timer_del(utilization_timer);
+	_mali_osk_spinlock_irq_lock(time_data_lock);
+
+	if (timer_running == MALI_TRUE) {
 		timer_running = MALI_FALSE;
+		_mali_osk_spinlock_irq_unlock(time_data_lock);
+		_mali_osk_timer_del(utilization_timer);
+		return;
 	}
+
+	_mali_osk_spinlock_irq_unlock(time_data_lock);
 }
 
 void mali_utilization_term(void)
 {
-	if (NULL != utilization_timer)
-	{
+	if (NULL != utilization_timer) {
 		_mali_osk_timer_del(utilization_timer);
 		timer_running = MALI_FALSE;
 		_mali_osk_timer_term(utilization_timer);
 		utilization_timer = NULL;
 	}
 
-	_mali_osk_atomic_term(&num_running_cores);
-
-	_mali_osk_lock_term(time_data_lock);
+	_mali_osk_spinlock_irq_term(time_data_lock);
 }
 
-void mali_utilization_core_start(u64 time_now)
+void mali_utilization_gp_start(void)
 {
-	if (_mali_osk_atomic_inc_return(&num_running_cores) == 1)
-	{
-		/*
-		 * We went from zero cores working, to one core working,
-		 * we now consider the entire GPU for being busy
-		 */
+	_mali_osk_spinlock_irq_lock(time_data_lock);
 
-		_mali_osk_lock_wait(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+	++num_running_gp_cores;
+	if (1 == num_running_gp_cores) {
+		u64 time_now = _mali_osk_time_get_ns();
 
-		if (time_now < period_start_time)
-		{
+		/* First GP core started, consider GP busy from now and onwards */
+		work_start_time_gp = time_now;
+
+		if (0 == num_running_pp_cores) {
 			/*
-			 * This might happen if the calculate_gpu_utilization() was able
-			 * to run between the sampling of time_now and us grabbing the lock above
+			 * There are no PP cores running, so this is also the point
+			 * at which we consider the GPU to be busy as well.
 			 */
-			time_now = period_start_time;
+			work_start_time_gpu = time_now;
 		}
 
-		work_start_time = time_now;
-		if (timer_running != MALI_TRUE)
-		{
+		/* Start a new period (and timer) if needed */
+		if (timer_running != MALI_TRUE) {
 			timer_running = MALI_TRUE;
-			period_start_time = work_start_time; /* starting a new period */
+			period_start_time = time_now;
+
+			/* Clear session->number_of_window_jobs */
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+			mali_session_max_window_num();
+#endif
+			_mali_osk_spinlock_irq_unlock(time_data_lock);
+
+			_mali_osk_timer_add(utilization_timer, _mali_osk_time_mstoticks(mali_utilization_timeout));
+		} else {
+			_mali_osk_spinlock_irq_unlock(time_data_lock);
+		}
+	} else {
+		/* Nothing to do */
+		_mali_osk_spinlock_irq_unlock(time_data_lock);
+	}
+}
+
+void mali_utilization_pp_start(void)
+{
+	_mali_osk_spinlock_irq_lock(time_data_lock);
 
-			_mali_osk_lock_signal(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+	++num_running_pp_cores;
+	if (1 == num_running_pp_cores) {
+		u64 time_now = _mali_osk_time_get_ns();
 
-			_mali_osk_timer_add(utilization_timer, _mali_osk_time_mstoticks(MALI_GPU_UTILIZATION_TIMEOUT));
+		/* First PP core started, consider PP busy from now and onwards */
+		work_start_time_pp = time_now;
+
+		if (0 == num_running_gp_cores) {
+			/*
+			 * There are no GP cores running, so this is also the point
+			 * at which we consider the GPU to be busy as well.
+			 */
+			work_start_time_gpu = time_now;
 		}
-		else
-		{
-			_mali_osk_lock_signal(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+
+		/* Start a new period (and timer) if needed */
+		if (timer_running != MALI_TRUE) {
+			timer_running = MALI_TRUE;
+			period_start_time = time_now;
+
+			/* Clear session->number_of_window_jobs */
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+			mali_session_max_window_num();
+#endif
+			_mali_osk_spinlock_irq_unlock(time_data_lock);
+
+			_mali_osk_timer_add(utilization_timer, _mali_osk_time_mstoticks(mali_utilization_timeout));
+		} else {
+			_mali_osk_spinlock_irq_unlock(time_data_lock);
 		}
+	} else {
+		/* Nothing to do */
+		_mali_osk_spinlock_irq_unlock(time_data_lock);
 	}
 }
 
-void mali_utilization_core_end(u64 time_now)
+void mali_utilization_gp_end(void)
 {
-	if (_mali_osk_atomic_dec_return(&num_running_cores) == 0)
-	{
-		/*
-		 * No more cores are working, so accumulate the time we was busy.
-		 */
-		_mali_osk_lock_wait(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_spinlock_irq_lock(time_data_lock);
+
+	--num_running_gp_cores;
+	if (0 == num_running_gp_cores) {
+		u64 time_now = _mali_osk_time_get_ns();
+
+		/* Last GP core ended, consider GP idle from now and onwards */
+		accumulated_work_time_gp += (time_now - work_start_time_gp);
+		work_start_time_gp = 0;
 
-		if (time_now < work_start_time)
-		{
+		if (0 == num_running_pp_cores) {
 			/*
-			 * This might happen if the calculate_gpu_utilization() was able
-			 * to run between the sampling of time_now and us grabbing the lock above
+			 * There are no PP cores running, so this is also the point
+			 * at which we consider the GPU to be idle as well.
 			 */
-			time_now = work_start_time;
+			accumulated_work_time_gpu += (time_now - work_start_time_gpu);
+			work_start_time_gpu = 0;
 		}
+	}
 
-		accumulated_work_time += (time_now - work_start_time);
-		work_start_time = 0;
+	_mali_osk_spinlock_irq_unlock(time_data_lock);
+}
 
-		_mali_osk_lock_signal(time_data_lock, _MALI_OSK_LOCKMODE_RW);
+void mali_utilization_pp_end(void)
+{
+	_mali_osk_spinlock_irq_lock(time_data_lock);
+
+	--num_running_pp_cores;
+	if (0 == num_running_pp_cores) {
+		u64 time_now = _mali_osk_time_get_ns();
+
+		/* Last PP core ended, consider PP idle from now and onwards */
+		accumulated_work_time_pp += (time_now - work_start_time_pp);
+		work_start_time_pp = 0;
+
+		if (0 == num_running_gp_cores) {
+			/*
+			 * There are no GP cores running, so this is also the point
+			 * at which we consider the GPU to be idle as well.
+			 */
+			accumulated_work_time_gpu += (time_now - work_start_time_gpu);
+			work_start_time_gpu = 0;
+		}
 	}
+
+	_mali_osk_spinlock_irq_unlock(time_data_lock);
+}
+
+u32 _mali_ukk_utilization_gp_pp(void)
+{
+	return last_utilization_gpu;
+}
+
+u32 _mali_ukk_utilization_gp(void)
+{
+	return last_utilization_gp;
+}
+
+u32 _mali_ukk_utilization_pp(void)
+{
+	return last_utilization_pp;
 }
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_utilization.h b/drivers/gpu/mali/mali/common/mali_kernel_utilization.h
old mode 100644
new mode 100755
index 1f60517..7d588eb
--- a/drivers/gpu/mali/mali/common/mali_kernel_utilization.h
+++ b/drivers/gpu/mali/mali/common/mali_kernel_utilization.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
  * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
@@ -11,8 +11,11 @@
 #ifndef __MALI_KERNEL_UTILIZATION_H__
 #define __MALI_KERNEL_UTILIZATION_H__
 
+#include <linux/mali/mali_utgard.h>
 #include "mali_osk.h"
 
+extern void (*mali_utilization_callback)(struct mali_gpu_utilization_data *data);
+
 /**
  * Initialize/start the Mali GPU utilization metrics reporting.
  *
@@ -26,19 +29,37 @@ _mali_osk_errcode_t mali_utilization_init(void);
 void mali_utilization_term(void);
 
 /**
- * Should be called when a job is about to execute a job
+ * Check if Mali utilization is enabled
  */
-void mali_utilization_core_start(u64 time_now);
+MALI_STATIC_INLINE mali_bool mali_utilization_enabled(void)
+{
+	return (NULL != mali_utilization_callback);
+}
 
 /**
- * Should be called to stop the utilization timer during system suspend
+ * Should be called when a job is about to execute a GP job
  */
-void mali_utilization_suspend(void);
+void mali_utilization_gp_start(void);
+
+/**
+ * Should be called when a job has completed executing a GP job
+ */
+void mali_utilization_gp_end(void);
+
+/**
+ * Should be called when a job is about to execute a PP job
+ */
+void mali_utilization_pp_start(void);
 
 /**
- * Should be called when a job has completed executing a job
+ * Should be called when a job has completed executing a PP job
  */
-void mali_utilization_core_end(u64 time_now);
+void mali_utilization_pp_end(void);
+
+/**
+ * Should be called to stop the utilization timer during system suspend
+ */
+void mali_utilization_suspend(void);
 
 
 #endif /* __MALI_KERNEL_UTILIZATION_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_kernel_vsync.c b/drivers/gpu/mali/mali/common/mali_kernel_vsync.c
old mode 100644
new mode 100755
index 2aab2fc..d067937
--- a/drivers/gpu/mali/mali/common/mali_kernel_vsync.c
+++ b/drivers/gpu/mali/mali/common/mali_kernel_vsync.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,7 +12,7 @@
 #include "mali_osk.h"
 #include "mali_ukk.h"
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 #include "mali_osk_profiling.h"
 #endif
 
@@ -21,30 +21,29 @@ _mali_osk_errcode_t _mali_ukk_vsync_event_report(_mali_uk_vsync_event_report_s *
 	_mali_uk_vsync_event event = (_mali_uk_vsync_event)args->event;
 	MALI_IGNORE(event); /* event is not used for release code, and that is OK */
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 	/*
 	 * Manually generate user space events in kernel space.
 	 * This saves user space from calling kernel space twice in this case.
 	 * We just need to remember to add pid and tid manually.
 	 */
-	if ( event==_MALI_UK_VSYNC_EVENT_BEGIN_WAIT)
-	{
+	if (event == _MALI_UK_VSYNC_EVENT_BEGIN_WAIT) {
 		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SUSPEND |
-		                              MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
-		                              MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC,
-		                              _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC,
+					      _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
 	}
 
-	if (event==_MALI_UK_VSYNC_EVENT_END_WAIT)
-	{
+	if (event == _MALI_UK_VSYNC_EVENT_END_WAIT) {
 
 		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_RESUME |
-		                              MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
-		                              MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC,
-		                              _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
+					      MALI_PROFILING_EVENT_CHANNEL_SOFTWARE |
+					      MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC,
+					      _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
 	}
 #endif
 
 	MALI_DEBUG_PRINT(4, ("Received VSYNC event: %d\n", event));
 	MALI_SUCCESS;
 }
+
diff --git a/drivers/gpu/mali/mali/common/mali_l2_cache.c b/drivers/gpu/mali/mali/common/mali_l2_cache.c
old mode 100644
new mode 100755
index e2719e2..3893f27
--- a/drivers/gpu/mali/mali/common/mali_l2_cache.c
+++ b/drivers/gpu/mali/mali/common/mali_l2_cache.c
@@ -1,32 +1,31 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 #include "mali_kernel_common.h"
 #include "mali_osk.h"
-
 #include "mali_l2_cache.h"
 #include "mali_hw_core.h"
-#include "mali_pm.h"
+#include "mali_scheduler.h"
+#include "mali_pm_domain.h"
 
 /**
  * Size of the Mali L2 cache registers in bytes
  */
 #define MALI400_L2_CACHE_REGISTERS_SIZE 0x30
 
-#define MALI_MAX_NUMBER_OF_L2_CACHE_CORES  3
-
 /**
  * Mali L2 cache register numbers
  * Used in the register read/write routines.
  * See the hardware documentation for more information about each register
  */
 typedef enum mali_l2_cache_register {
+	MALI400_L2_CACHE_REGISTER_SIZE         = 0x0004,
 	MALI400_L2_CACHE_REGISTER_STATUS       = 0x0008,
 	/*unused                               = 0x000C */
 	MALI400_L2_CACHE_REGISTER_COMMAND      = 0x0010, /**< Misc cache commands, e.g. clear */
@@ -43,8 +42,7 @@ typedef enum mali_l2_cache_register {
  * Mali L2 cache commands
  * These are the commands that can be sent to the Mali L2 cache unit
  */
-typedef enum mali_l2_cache_command
-{
+typedef enum mali_l2_cache_command {
 	MALI400_L2_CACHE_COMMAND_CLEAR_ALL = 0x01, /**< Clear the entire cache */
 	/* Read HW TRM carefully before adding/using other commands than the clear above */
 } mali_l2_cache_command;
@@ -53,8 +51,7 @@ typedef enum mali_l2_cache_command
  * Mali L2 cache commands
  * These are the commands that can be sent to the Mali L2 cache unit
  */
-typedef enum mali_l2_cache_enable
-{
+typedef enum mali_l2_cache_enable {
 	MALI400_L2_CACHE_ENABLE_DEFAULT = 0x0, /**< Default state of enable register */
 	MALI400_L2_CACHE_ENABLE_ACCESS = 0x01, /**< Permit cacheable accesses */
 	MALI400_L2_CACHE_ENABLE_READ_ALLOCATE = 0x02, /**< Permit cache read allocate */
@@ -63,89 +60,115 @@ typedef enum mali_l2_cache_enable
 /**
  * Mali L2 cache status bits
  */
-typedef enum mali_l2_cache_status
-{
+typedef enum mali_l2_cache_status {
 	MALI400_L2_CACHE_STATUS_COMMAND_BUSY = 0x01, /**< Command handler of L2 cache is busy */
 	MALI400_L2_CACHE_STATUS_DATA_BUSY    = 0x02, /**< L2 cache is busy handling data requests */
 } mali_l2_cache_status;
 
-/**
- * Definition of the L2 cache core struct
- * Used to track a L2 cache unit in the system.
- * Contains information about the mapping of the registers
- */
-struct mali_l2_cache_core
-{
-	struct mali_hw_core  hw_core;      /**< Common for all HW cores */
-	u32                  core_id;      /**< Unique core ID */
-	_mali_osk_lock_t    *command_lock; /**< Serialize all L2 cache commands */
-	_mali_osk_lock_t    *counter_lock; /**< Synchronize L2 cache counter access */
-	u32                  counter_src0; /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
-	u32                  counter_src1; /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
-};
-
 #define MALI400_L2_MAX_READS_DEFAULT 0x1C
 
-static struct mali_l2_cache_core *mali_global_l2_cache_cores[MALI_MAX_NUMBER_OF_L2_CACHE_CORES];
+static struct mali_l2_cache_core *mali_global_l2_cache_cores[MALI_MAX_NUMBER_OF_L2_CACHE_CORES] = { NULL, };
 static u32 mali_global_num_l2_cache_cores = 0;
 
 int mali_l2_max_reads = MALI400_L2_MAX_READS_DEFAULT;
 
+
 /* Local helper functions */
 static _mali_osk_errcode_t mali_l2_cache_send_command(struct mali_l2_cache_core *cache, u32 reg, u32 val);
 
 
+static void mali_l2_cache_counter_lock(struct mali_l2_cache_core *cache)
+{
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_lock(cache->counter_lock);
+#else
+	_mali_osk_spinlock_lock(cache->counter_lock);
+#endif
+}
+
+static void mali_l2_cache_counter_unlock(struct mali_l2_cache_core *cache)
+{
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_unlock(cache->counter_lock);
+#else
+	_mali_osk_spinlock_unlock(cache->counter_lock);
+#endif
+}
+
+static void mali_l2_cache_command_lock(struct mali_l2_cache_core *cache)
+{
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_lock(cache->command_lock);
+#else
+	_mali_osk_spinlock_lock(cache->command_lock);
+#endif
+}
+
+static void mali_l2_cache_command_unlock(struct mali_l2_cache_core *cache)
+{
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_unlock(cache->command_lock);
+#else
+	_mali_osk_spinlock_unlock(cache->command_lock);
+#endif
+}
+
 struct mali_l2_cache_core *mali_l2_cache_create(_mali_osk_resource_t *resource)
 {
 	struct mali_l2_cache_core *cache = NULL;
 
-	MALI_DEBUG_PRINT(2, ("Mali L2 cache: Creating Mali L2 cache: %s\n", resource->description));
+	MALI_DEBUG_PRINT(4, ("Mali L2 cache: Creating Mali L2 cache: %s\n", resource->description));
 
-	if (mali_global_num_l2_cache_cores >= MALI_MAX_NUMBER_OF_L2_CACHE_CORES)
-	{
+	if (mali_global_num_l2_cache_cores >= MALI_MAX_NUMBER_OF_L2_CACHE_CORES) {
 		MALI_PRINT_ERROR(("Mali L2 cache: Too many L2 cache core objects created\n"));
 		return NULL;
 	}
 
 	cache = _mali_osk_malloc(sizeof(struct mali_l2_cache_core));
-	if (NULL != cache)
-	{
+	if (NULL != cache) {
 		cache->core_id =  mali_global_num_l2_cache_cores;
 		cache->counter_src0 = MALI_HW_CORE_NO_COUNTER;
 		cache->counter_src1 = MALI_HW_CORE_NO_COUNTER;
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&cache->hw_core, resource, MALI400_L2_CACHE_REGISTERS_SIZE))
-		{
-			cache->command_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_SPINLOCK | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE,
-			                                          0, _MALI_OSK_LOCK_ORDER_L2_COMMAND);
-			if (NULL != cache->command_lock)
-			{
-				cache->counter_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_SPINLOCK | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE,
-				                                          0, _MALI_OSK_LOCK_ORDER_L2_COUNTER);
-				if (NULL != cache->counter_lock)
-				{
-					if (_MALI_OSK_ERR_OK == mali_l2_cache_reset(cache))
-					{
-						mali_global_l2_cache_cores[mali_global_num_l2_cache_cores] = cache;
-						mali_global_num_l2_cache_cores++;
-
-						return cache;
-					}
-					else
-					{
-						MALI_PRINT_ERROR(("Mali L2 cache: Failed to reset L2 cache core %s\n", cache->hw_core.description));
-					}
-
-					_mali_osk_lock_term(cache->counter_lock);
-				}
-				else
-				{
+		cache->pm_domain = NULL;
+		cache->mali_l2_status = MALI_L2_NORMAL;
+		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&cache->hw_core, resource, MALI400_L2_CACHE_REGISTERS_SIZE)) {
+			MALI_DEBUG_CODE(u32 cache_size = mali_hw_core_register_read(&cache->hw_core, MALI400_L2_CACHE_REGISTER_SIZE));
+			MALI_DEBUG_PRINT(2, ("Mali L2 cache: Created %s: % 3uK, %u-way, % 2ubyte cache line, % 3ubit external bus\n",
+					     resource->description,
+					     1 << (((cache_size >> 16) & 0xff) - 10),
+					     1 << ((cache_size >> 8) & 0xff),
+					     1 << (cache_size & 0xff),
+					     1 << ((cache_size >> 24) & 0xff)));
+
+#ifdef MALI_UPPER_HALF_SCHEDULING
+			cache->command_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_L2_COMMAND);
+#else
+			cache->command_lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_L2_COMMAND);
+#endif
+			if (NULL != cache->command_lock) {
+#ifdef MALI_UPPER_HALF_SCHEDULING
+				cache->counter_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_L2_COMMAND);
+#else
+				cache->counter_lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_L2_COMMAND);
+#endif
+				if (NULL != cache->counter_lock) {
+					mali_l2_cache_reset(cache);
+
+					cache->last_invalidated_id = 0;
+
+					mali_global_l2_cache_cores[mali_global_num_l2_cache_cores] = cache;
+					mali_global_num_l2_cache_cores++;
+
+					return cache;
+				} else {
 					MALI_PRINT_ERROR(("Mali L2 cache: Failed to create counter lock for L2 cache core %s\n", cache->hw_core.description));
 				}
-
-				_mali_osk_lock_term(cache->command_lock);
-			}
-			else
-			{
+#ifdef MALI_UPPER_HALF_SCHEDULING
+				_mali_osk_spinlock_irq_term(cache->command_lock);
+#else
+				_mali_osk_spinlock_term(cache->command_lock);
+#endif
+			} else {
 				MALI_PRINT_ERROR(("Mali L2 cache: Failed to create command lock for L2 cache core %s\n", cache->hw_core.description));
 			}
 
@@ -153,9 +176,7 @@ struct mali_l2_cache_core *mali_l2_cache_create(_mali_osk_resource_t *resource)
 		}
 
 		_mali_osk_free(cache);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Mali L2 cache: Failed to allocate memory for L2 cache core\n"));
 	}
 
@@ -170,16 +191,29 @@ void mali_l2_cache_delete(struct mali_l2_cache_core *cache)
 	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_MAX_READS, (u32)MALI400_L2_MAX_READS_DEFAULT);
 	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_ENABLE, (u32)MALI400_L2_CACHE_ENABLE_DEFAULT);
 
-	_mali_osk_lock_term(cache->counter_lock);
-	_mali_osk_lock_term(cache->command_lock);
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_term(cache->counter_lock);
+	_mali_osk_spinlock_irq_term(cache->command_lock);
+#else
+	_mali_osk_spinlock_term(cache->command_lock);
+	_mali_osk_spinlock_term(cache->counter_lock);
+#endif
+
 	mali_hw_core_delete(&cache->hw_core);
 
-	for (i = 0; i < mali_global_num_l2_cache_cores; i++)
-	{
-		if (mali_global_l2_cache_cores[i] == cache)
-		{
+	for (i = 0; i < mali_global_num_l2_cache_cores; i++) {
+		if (mali_global_l2_cache_cores[i] == cache) {
 			mali_global_l2_cache_cores[i] = NULL;
 			mali_global_num_l2_cache_cores--;
+
+			if (i != mali_global_num_l2_cache_cores) {
+				/* We removed a l2 cache from the middle of the array -- move the last
+				 * l2 cache to the current position to close the gap */
+				mali_global_l2_cache_cores[i] = mali_global_l2_cache_cores[mali_global_num_l2_cache_cores];
+				mali_global_l2_cache_cores[mali_global_num_l2_cache_cores] = NULL;
+			}
+
+			break;
 		}
 	}
 
@@ -191,48 +225,60 @@ u32 mali_l2_cache_get_id(struct mali_l2_cache_core *cache)
 	return cache->core_id;
 }
 
-mali_bool mali_l2_cache_core_set_counter_src0(struct mali_l2_cache_core *cache, u32 counter)
+static void mali_l2_cache_core_set_counter_internal(struct mali_l2_cache_core *cache, u32 source_id, u32 counter)
 {
 	u32 value = 0; /* disabled src */
+	u32 reg_offset = 0;
+	mali_bool core_is_on;
 
 	MALI_DEBUG_ASSERT_POINTER(cache);
-	MALI_DEBUG_ASSERT(counter < (1 << 7)); /* the possible values are 0-127 */
 
-	_mali_osk_lock_wait(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
+	core_is_on = mali_l2_cache_lock_power_state(cache);
 
-	cache->counter_src0 = counter;
-
-	if (counter != MALI_HW_CORE_NO_COUNTER)
-	{
-		value = counter;
-	}
+	mali_l2_cache_counter_lock(cache);
 
-	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_SRC0, value);
+	switch (source_id) {
+	case 0:
+		cache->counter_src0 = counter;
+		reg_offset = MALI400_L2_CACHE_REGISTER_PERFCNT_SRC0;
+		break;
 
-	_mali_osk_lock_signal(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
-	return MALI_TRUE;
-}
+	case 1:
+		cache->counter_src1 = counter;
+		reg_offset = MALI400_L2_CACHE_REGISTER_PERFCNT_SRC1;
+		break;
 
-mali_bool mali_l2_cache_core_set_counter_src1(struct mali_l2_cache_core *cache, u32 counter)
-{
-	u32 value = 0; /* disabled src */
-
-	MALI_DEBUG_ASSERT_POINTER(cache);
-	MALI_DEBUG_ASSERT(counter < (1 << 7)); /* the possible values are 0-127 */
-
-	_mali_osk_lock_wait(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
+	default:
+		MALI_DEBUG_ASSERT(0);
+		break;
+	}
 
-	cache->counter_src1 = counter;
+	if (MALI_L2_PAUSE == cache->mali_l2_status) {
+		mali_l2_cache_counter_unlock(cache);
+		mali_l2_cache_unlock_power_state(cache);
+		return;
+	}
 
-	if (counter != MALI_HW_CORE_NO_COUNTER)
-	{
+	if (MALI_HW_CORE_NO_COUNTER != counter) {
 		value = counter;
 	}
 
-	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_SRC1, value);
+	if (MALI_TRUE == core_is_on) {
+		mali_hw_core_register_write(&cache->hw_core, reg_offset, value);
+	}
 
-	_mali_osk_lock_signal(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
-	return MALI_TRUE;
+	mali_l2_cache_counter_unlock(cache);
+	mali_l2_cache_unlock_power_state(cache);
+}
+
+void mali_l2_cache_core_set_counter_src0(struct mali_l2_cache_core *cache, u32 counter)
+{
+	mali_l2_cache_core_set_counter_internal(cache, 0, counter);
+}
+
+void mali_l2_cache_core_set_counter_src1(struct mali_l2_cache_core *cache, u32 counter)
+{
+	mali_l2_cache_core_set_counter_internal(cache, 1, counter);
 }
 
 u32 mali_l2_cache_core_get_counter_src0(struct mali_l2_cache_core *cache)
@@ -254,28 +300,77 @@ void mali_l2_cache_core_get_counter_values(struct mali_l2_cache_core *cache, u32
 
 	/* Caller must hold the PM lock and know that we are powered on */
 
-	_mali_osk_lock_wait(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
+	mali_l2_cache_counter_lock(cache);
+
+	if (MALI_L2_PAUSE == cache->mali_l2_status) {
+		mali_l2_cache_counter_unlock(cache);
+
+		return;
+	}
 
 	*src0 = cache->counter_src0;
 	*src1 = cache->counter_src1;
 
-	if (cache->counter_src0 != MALI_HW_CORE_NO_COUNTER)
-	{
+	if (cache->counter_src0 != MALI_HW_CORE_NO_COUNTER) {
 		*value0 = mali_hw_core_register_read(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_VAL0);
 	}
 
-	if (cache->counter_src0 != MALI_HW_CORE_NO_COUNTER)
-	{
+	if (cache->counter_src1 != MALI_HW_CORE_NO_COUNTER) {
 		*value1 = mali_hw_core_register_read(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_VAL1);
 	}
 
-	_mali_osk_lock_signal(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
+	mali_l2_cache_counter_unlock(cache);
 }
 
+static void mali_l2_cache_reset_counters_all(void)
+{
+	int i;
+	u32 value;
+	struct mali_l2_cache_core *cache;
+	u32 num_cores = mali_l2_cache_core_get_glob_num_l2_cores();
+
+	for (i = 0; i < num_cores; i++) {
+		cache = mali_l2_cache_core_get_glob_l2_core(i);
+		if (!cache)
+			continue;
+
+		if (mali_l2_cache_lock_power_state(cache)) {
+			mali_l2_cache_counter_lock(cache);
+
+			if (MALI_L2_PAUSE == cache->mali_l2_status) {
+				mali_l2_cache_counter_unlock(cache);
+				mali_l2_cache_unlock_power_state(cache);
+				return;
+			}
+
+			/* Reset performance counters */
+			if (MALI_HW_CORE_NO_COUNTER == cache->counter_src0) {
+				value = 0;
+			} else {
+				value = cache->counter_src0;
+			}
+			mali_hw_core_register_write(&cache->hw_core,
+						    MALI400_L2_CACHE_REGISTER_PERFCNT_SRC0, value);
+
+			if (MALI_HW_CORE_NO_COUNTER == cache->counter_src1) {
+				value = 0;
+			} else {
+				value = cache->counter_src1;
+			}
+			mali_hw_core_register_write(&cache->hw_core,
+						    MALI400_L2_CACHE_REGISTER_PERFCNT_SRC1, value);
+
+			mali_l2_cache_counter_unlock(cache);
+		}
+
+		mali_l2_cache_unlock_power_state(cache);
+	}
+}
+
+
 struct mali_l2_cache_core *mali_l2_cache_core_get_glob_l2_core(u32 index)
 {
-	if (MALI_MAX_NUMBER_OF_L2_CACHE_CORES > index)
-	{
+	if (mali_global_num_l2_cache_cores > index) {
 		return mali_global_l2_cache_cores[index];
 	}
 
@@ -287,75 +382,121 @@ u32 mali_l2_cache_core_get_glob_num_l2_cores(void)
 	return mali_global_num_l2_cache_cores;
 }
 
-u32 mali_l2_cache_core_get_max_num_l2_cores(void)
-{
-	return MALI_MAX_NUMBER_OF_L2_CACHE_CORES;
-}
-
-_mali_osk_errcode_t mali_l2_cache_reset(struct mali_l2_cache_core *cache)
+void mali_l2_cache_reset(struct mali_l2_cache_core *cache)
 {
 	/* Invalidate cache (just to keep it in a known state at startup) */
-	mali_l2_cache_invalidate_all(cache);
+	mali_l2_cache_send_command(cache, MALI400_L2_CACHE_REGISTER_COMMAND, MALI400_L2_CACHE_COMMAND_CLEAR_ALL);
+
+	mali_l2_cache_counter_lock(cache);
+
+	if (MALI_L2_PAUSE == cache->mali_l2_status) {
+		mali_l2_cache_counter_unlock(cache);
+
+		return;
+	}
 
 	/* Enable cache */
 	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_ENABLE, (u32)MALI400_L2_CACHE_ENABLE_ACCESS | (u32)MALI400_L2_CACHE_ENABLE_READ_ALLOCATE);
 	mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_MAX_READS, (u32)mali_l2_max_reads);
 
 	/* Restart any performance counters (if enabled) */
-	_mali_osk_lock_wait(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (cache->counter_src0 != MALI_HW_CORE_NO_COUNTER)
-	{
+	if (cache->counter_src0 != MALI_HW_CORE_NO_COUNTER) {
 		mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_SRC0, cache->counter_src0);
 	}
 
-	if (cache->counter_src1 != MALI_HW_CORE_NO_COUNTER)
-	{
+	if (cache->counter_src1 != MALI_HW_CORE_NO_COUNTER) {
 		mali_hw_core_register_write(&cache->hw_core, MALI400_L2_CACHE_REGISTER_PERFCNT_SRC1, cache->counter_src1);
 	}
 
-	_mali_osk_lock_signal(cache->counter_lock, _MALI_OSK_LOCKMODE_RW);
+	mali_l2_cache_counter_unlock(cache);
+}
 
-	return _MALI_OSK_ERR_OK;
+void mali_l2_cache_reset_all(void)
+{
+	int i;
+	u32 num_cores = mali_l2_cache_core_get_glob_num_l2_cores();
+
+	for (i = 0; i < num_cores; i++) {
+		mali_l2_cache_reset(mali_l2_cache_core_get_glob_l2_core(i));
+	}
 }
 
-_mali_osk_errcode_t mali_l2_cache_invalidate_all(struct mali_l2_cache_core *cache)
+void mali_l2_cache_invalidate(struct mali_l2_cache_core *cache)
 {
-	return mali_l2_cache_send_command(cache, MALI400_L2_CACHE_REGISTER_COMMAND, MALI400_L2_CACHE_COMMAND_CLEAR_ALL);
+	MALI_DEBUG_ASSERT_POINTER(cache);
+
+	if (NULL != cache) {
+		cache->last_invalidated_id = mali_scheduler_get_new_cache_order();
+		mali_l2_cache_send_command(cache, MALI400_L2_CACHE_REGISTER_COMMAND, MALI400_L2_CACHE_COMMAND_CLEAR_ALL);
+	}
 }
 
-_mali_osk_errcode_t mali_l2_cache_invalidate_pages(struct mali_l2_cache_core *cache, u32 *pages, u32 num_pages)
+mali_bool mali_l2_cache_invalidate_conditional(struct mali_l2_cache_core *cache, u32 id)
+{
+	MALI_DEBUG_ASSERT_POINTER(cache);
+
+	if (NULL != cache) {
+		/* If the last cache invalidation was done by a job with a higher id we
+		 * don't have to flush. Since user space will store jobs w/ their
+		 * corresponding memory in sequence (first job #0, then job #1, ...),
+		 * we don't have to flush for job n-1 if job n has already invalidated
+		 * the cache since we know for sure that job n-1's memory was already
+		 * written when job n was started. */
+		if (((s32)id) <= ((s32)cache->last_invalidated_id)) {
+			return MALI_FALSE;
+		} else {
+			cache->last_invalidated_id = mali_scheduler_get_new_cache_order();
+		}
+
+		mali_l2_cache_send_command(cache, MALI400_L2_CACHE_REGISTER_COMMAND, MALI400_L2_CACHE_COMMAND_CLEAR_ALL);
+	}
+	return MALI_TRUE;
+}
+
+void mali_l2_cache_invalidate_all(void)
 {
 	u32 i;
-	_mali_osk_errcode_t ret1, ret = _MALI_OSK_ERR_OK;
-
-	for (i = 0; i < num_pages; i++)
-	{
-		ret1 = mali_l2_cache_send_command(cache, MALI400_L2_CACHE_REGISTER_CLEAR_PAGE, pages[i]);
-		if (_MALI_OSK_ERR_OK != ret1)
-		{
-			ret = ret1;
+	for (i = 0; i < mali_global_num_l2_cache_cores; i++) {
+		/*additional check*/
+		if (MALI_TRUE == mali_l2_cache_lock_power_state(mali_global_l2_cache_cores[i])) {
+			_mali_osk_errcode_t ret;
+			mali_global_l2_cache_cores[i]->last_invalidated_id = mali_scheduler_get_new_cache_order();
+			ret = mali_l2_cache_send_command(mali_global_l2_cache_cores[i], MALI400_L2_CACHE_REGISTER_COMMAND, MALI400_L2_CACHE_COMMAND_CLEAR_ALL);
+			if (_MALI_OSK_ERR_OK != ret) {
+				MALI_PRINT_ERROR(("Failed to invalidate cache\n"));
+			}
 		}
+		mali_l2_cache_unlock_power_state(mali_global_l2_cache_cores[i]);
 	}
+}
 
-	return ret;
+void mali_l2_cache_invalidate_all_pages(u32 *pages, u32 num_pages)
+{
+	u32 i;
+	for (i = 0; i < mali_global_num_l2_cache_cores; i++) {
+		/*additional check*/
+		if (MALI_TRUE == mali_l2_cache_lock_power_state(mali_global_l2_cache_cores[i])) {
+			u32 j;
+			for (j = 0; j < num_pages; j++) {
+				_mali_osk_errcode_t ret;
+				ret = mali_l2_cache_send_command(mali_global_l2_cache_cores[i], MALI400_L2_CACHE_REGISTER_CLEAR_PAGE, pages[j]);
+				if (_MALI_OSK_ERR_OK != ret) {
+					MALI_PRINT_ERROR(("Failed to invalidate page cache\n"));
+				}
+			}
+		}
+		mali_l2_cache_unlock_power_state(mali_global_l2_cache_cores[i]);
+	}
 }
 
 mali_bool mali_l2_cache_lock_power_state(struct mali_l2_cache_core *cache)
 {
-	/*
-	 * Take PM lock and check power state.
-	 * Returns MALI_TRUE if module is powered on.
-	 * Power state will not change until mali_l2_cache_unlock_power_state() is called.
-	 */
-	mali_pm_lock();
-	return mali_pm_is_powered_on();
+	return mali_pm_domain_lock_state(cache->pm_domain);
 }
 
 void mali_l2_cache_unlock_power_state(struct mali_l2_cache_core *cache)
 {
-	/* Release PM lock */
-	mali_pm_unlock();
+	return mali_pm_domain_unlock_state(cache->pm_domain);
 }
 
 /* -------- local helper functions below -------- */
@@ -370,29 +511,74 @@ static _mali_osk_errcode_t mali_l2_cache_send_command(struct mali_l2_cache_core
 	 * Grab lock in order to send commands to the L2 cache in a serialized fashion.
 	 * The L2 cache will ignore commands if it is busy.
 	 */
-	_mali_osk_lock_wait(cache->command_lock, _MALI_OSK_LOCKMODE_RW);
+	mali_l2_cache_command_lock(cache);
+
+	if (MALI_L2_PAUSE == cache->mali_l2_status) {
+		mali_l2_cache_command_unlock(cache);
+		MALI_DEBUG_PRINT(1, ("Mali L2 cache: aborting wait for L2 come back\n"));
+
+		MALI_ERROR(_MALI_OSK_ERR_BUSY);
+	}
 
 	/* First, wait for L2 cache command handler to go idle */
 
-	for (i = 0; i < loop_count; i++)
-	{
-		if (!(mali_hw_core_register_read(&cache->hw_core, MALI400_L2_CACHE_REGISTER_STATUS) & (u32)MALI400_L2_CACHE_STATUS_COMMAND_BUSY))
-		{
+	for (i = 0; i < loop_count; i++) {
+		if (!(mali_hw_core_register_read(&cache->hw_core, MALI400_L2_CACHE_REGISTER_STATUS) & (u32)MALI400_L2_CACHE_STATUS_COMMAND_BUSY)) {
 			break;
 		}
 	}
 
-	if (i == loop_count)
-	{
-		_mali_osk_lock_signal(cache->command_lock, _MALI_OSK_LOCKMODE_RW);
-		MALI_DEBUG_PRINT(1, ( "Mali L2 cache: aborting wait for command interface to go idle\n"));
-		MALI_ERROR( _MALI_OSK_ERR_FAULT );
+	if (i == loop_count) {
+		mali_l2_cache_command_unlock(cache);
+		MALI_DEBUG_PRINT(1, ("Mali L2 cache: aborting wait for command interface to go idle\n"));
+		MALI_ERROR(_MALI_OSK_ERR_FAULT);
 	}
 
 	/* then issue the command */
 	mali_hw_core_register_write(&cache->hw_core, reg, val);
 
-	_mali_osk_lock_signal(cache->command_lock, _MALI_OSK_LOCKMODE_RW);
+	mali_l2_cache_command_unlock(cache);
 
 	MALI_SUCCESS;
 }
+
+void mali_l2_cache_pause_all(mali_bool pause)
+{
+	int i;
+	struct mali_l2_cache_core *cache;
+	u32 num_cores = mali_l2_cache_core_get_glob_num_l2_cores();
+	mali_l2_power_status status = MALI_L2_NORMAL;
+
+	if (pause) {
+		status = MALI_L2_PAUSE;
+	}
+
+	for (i = 0; i < num_cores; i++) {
+		cache = mali_l2_cache_core_get_glob_l2_core(i);
+		if (NULL != cache) {
+			cache->mali_l2_status = status;
+
+			/* Take and release the counter and command locks to
+			 * ensure there are no active threads that didn't get
+			 * the status flag update.
+			 *
+			 * The locks will also ensure the necessary memory
+			 * barriers are done on SMP systems.
+			 */
+			mali_l2_cache_counter_lock(cache);
+			mali_l2_cache_counter_unlock(cache);
+
+			mali_l2_cache_command_lock(cache);
+			mali_l2_cache_command_unlock(cache);
+		}
+	}
+
+	/* Resume from pause: do the cache invalidation here to prevent any
+	 * loss of cache operation during the pause period to make sure the SW
+	 * status is consistent with L2 cache status.
+	 */
+	if (!pause) {
+		mali_l2_cache_invalidate_all();
+		mali_l2_cache_reset_counters_all();
+	}
+}
diff --git a/drivers/gpu/mali/mali/common/mali_l2_cache.h b/drivers/gpu/mali/mali/common/mali_l2_cache.h
old mode 100644
new mode 100755
index 4779020..4882e31
--- a/drivers/gpu/mali/mali/common/mali_l2_cache.h
+++ b/drivers/gpu/mali/mali/common/mali_l2_cache.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,30 +12,76 @@
 #define __MALI_KERNEL_L2_CACHE_H__
 
 #include "mali_osk.h"
+#include "mali_hw_core.h"
 
-struct mali_l2_cache_core;
+#define MALI_MAX_NUMBER_OF_L2_CACHE_CORES  3
+/* Maximum 1 GP and 4 PP for an L2 cache core (Mali-400 Quad-core) */
+#define MALI_MAX_NUMBER_OF_GROUPS_PER_L2_CACHE 5
+
+struct mali_group;
+struct mali_pm_domain;
+
+/* Flags describing state of the L2 */
+typedef enum mali_l2_power_status {
+	MALI_L2_NORMAL, /**< L2 is in normal state and operational */
+	MALI_L2_PAUSE,  /**< L2 may not be accessed and may be powered off */
+} mali_l2_power_status;
+
+/**
+ * Definition of the L2 cache core struct
+ * Used to track a L2 cache unit in the system.
+ * Contains information about the mapping of the registers
+ */
+struct mali_l2_cache_core {
+	struct mali_hw_core  hw_core;      /**< Common for all HW cores */
+	u32                  core_id;      /**< Unique core ID */
+#ifdef MALI_UPPER_HALF_SCHEDULING
+	_mali_osk_spinlock_irq_t    *command_lock; /**< Serialize all L2 cache commands */
+	_mali_osk_spinlock_irq_t    *counter_lock; /**< Synchronize L2 cache counter access */
+#else
+	_mali_osk_spinlock_t        *command_lock;
+	_mali_osk_spinlock_t        *counter_lock;
+#endif
+	u32                  counter_src0; /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
+	u32                  counter_src1; /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
+	u32                  last_invalidated_id;
+	struct mali_pm_domain *pm_domain;
+	mali_l2_power_status   mali_l2_status; /**< Indicate whether the L2 is paused or not */
+};
 
 _mali_osk_errcode_t mali_l2_cache_initialize(void);
 void mali_l2_cache_terminate(void);
-
-struct mali_l2_cache_core *mali_l2_cache_create(_mali_osk_resource_t * resource);
+/**
+ * L2 pause is just a status that the L2 can't be accessed temporarily.
+*/
+void mali_l2_cache_pause_all(mali_bool pause);
+struct mali_l2_cache_core *mali_l2_cache_create(_mali_osk_resource_t *resource);
 void mali_l2_cache_delete(struct mali_l2_cache_core *cache);
 
+MALI_STATIC_INLINE void mali_l2_cache_set_pm_domain(struct mali_l2_cache_core *cache, struct mali_pm_domain *domain)
+{
+	cache->pm_domain = domain;
+}
+
 u32 mali_l2_cache_get_id(struct mali_l2_cache_core *cache);
 
-mali_bool mali_l2_cache_core_set_counter_src0(struct mali_l2_cache_core *cache, u32 counter);
-mali_bool mali_l2_cache_core_set_counter_src1(struct mali_l2_cache_core *cache, u32 counter);
+void mali_l2_cache_core_set_counter_src0(struct mali_l2_cache_core *cache, u32 counter);
+void mali_l2_cache_core_set_counter_src1(struct mali_l2_cache_core *cache, u32 counter);
 u32 mali_l2_cache_core_get_counter_src0(struct mali_l2_cache_core *cache);
 u32 mali_l2_cache_core_get_counter_src1(struct mali_l2_cache_core *cache);
 void mali_l2_cache_core_get_counter_values(struct mali_l2_cache_core *cache, u32 *src0, u32 *value0, u32 *src1, u32 *value1);
 struct mali_l2_cache_core *mali_l2_cache_core_get_glob_l2_core(u32 index);
 u32 mali_l2_cache_core_get_glob_num_l2_cores(void);
-u32 mali_l2_cache_core_get_max_num_l2_cores(void);
 
-_mali_osk_errcode_t mali_l2_cache_reset(struct mali_l2_cache_core *cache);
+void mali_l2_cache_reset(struct mali_l2_cache_core *cache);
+void mali_l2_cache_reset_all(void);
+
+struct mali_group *mali_l2_cache_get_group(struct mali_l2_cache_core *cache, u32 index);
 
-_mali_osk_errcode_t mali_l2_cache_invalidate_all(struct mali_l2_cache_core *cache);
-_mali_osk_errcode_t mali_l2_cache_invalidate_pages(struct mali_l2_cache_core *cache, u32 *pages, u32 num_pages);
+void mali_l2_cache_invalidate(struct mali_l2_cache_core *cache);
+mali_bool mali_l2_cache_invalidate_conditional(struct mali_l2_cache_core *cache, u32 id);
+void mali_l2_cache_invalidate_all(void);
+void mali_l2_cache_invalidate_all_pages(u32 *pages, u32 num_pages);
 
 mali_bool mali_l2_cache_lock_power_state(struct mali_l2_cache_core *cache);
 void mali_l2_cache_unlock_power_state(struct mali_l2_cache_core *cache);
diff --git a/drivers/gpu/mali/mali/common/mali_mem_validation.c b/drivers/gpu/mali/mali/common/mali_mem_validation.c
old mode 100644
new mode 100755
index 2f57459..b2c3c17
--- a/drivers/gpu/mali/mali/common/mali_mem_validation.c
+++ b/drivers/gpu/mali/mali/common/mali_mem_validation.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,51 +14,45 @@
 
 #define MALI_INVALID_MEM_ADDR 0xFFFFFFFF
 
-typedef struct
-{
+typedef struct {
 	u32 phys_base;        /**< Mali physical base of the memory, page aligned */
 	u32 size;             /**< size in bytes of the memory, multiple of page size */
 } _mali_mem_validation_t;
 
 static _mali_mem_validation_t mali_mem_validator = { MALI_INVALID_MEM_ADDR, MALI_INVALID_MEM_ADDR };
 
-_mali_osk_errcode_t mali_mem_validation_add_range(const _mali_osk_resource_t *resource)
+_mali_osk_errcode_t mali_mem_validation_add_range(u32 start, u32 size)
 {
 	/* Check that no other MEM_VALIDATION resources exist */
-	if (MALI_INVALID_MEM_ADDR != mali_mem_validator.phys_base)
-	{
-		MALI_PRINT_ERROR(("Failed to add MEM_VALIDATION resource %s; another range is already specified\n", resource->description));
+	if (MALI_INVALID_MEM_ADDR != mali_mem_validator.phys_base) {
+		MALI_PRINT_ERROR(("Failed to add frame buffer memory; another range is already specified\n"));
 		return _MALI_OSK_ERR_FAULT;
 	}
 
 	/* Check restrictions on page alignment */
-	if ((0 != (resource->base & (~_MALI_OSK_CPU_PAGE_MASK))) ||
-	    (0 != (resource->size & (~_MALI_OSK_CPU_PAGE_MASK))))
-	{
-		MALI_PRINT_ERROR(("Failed to add MEM_VALIDATION resource %s; incorrect alignment\n", resource->description));
+	if ((0 != (start & (~_MALI_OSK_CPU_PAGE_MASK))) ||
+	    (0 != (size & (~_MALI_OSK_CPU_PAGE_MASK)))) {
+		MALI_PRINT_ERROR(("Failed to add frame buffer memory; incorrect alignment\n"));
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	mali_mem_validator.phys_base = resource->base;
-	mali_mem_validator.size = resource->size;
-	MALI_DEBUG_PRINT(2, ("Memory Validator '%s' installed for Mali physical address base=0x%08X, size=0x%08X\n",
-	                 resource->description, mali_mem_validator.phys_base, mali_mem_validator.size));
+	mali_mem_validator.phys_base = start;
+	mali_mem_validator.size = size;
+	MALI_DEBUG_PRINT(2, ("Memory Validator installed for Mali physical address base=0x%08X, size=0x%08X\n",
+			     mali_mem_validator.phys_base, mali_mem_validator.size));
 
 	return _MALI_OSK_ERR_OK;
 }
 
 _mali_osk_errcode_t mali_mem_validation_check(u32 phys_addr, u32 size)
 {
-	if (phys_addr < (phys_addr + size)) /* Don't allow overflow (or zero size) */
-	{
-		if ((0 == ( phys_addr & (~_MALI_OSK_CPU_PAGE_MASK))) &&
-			(0 == ( size & (~_MALI_OSK_CPU_PAGE_MASK))))
-		{
+	if (phys_addr < (phys_addr + size)) { /* Don't allow overflow (or zero size) */
+		if ((0 == (phys_addr & (~_MALI_OSK_CPU_PAGE_MASK))) &&
+		    (0 == (size & (~_MALI_OSK_CPU_PAGE_MASK)))) {
 			if ((phys_addr          >= mali_mem_validator.phys_base) &&
-				((phys_addr + (size - 1)) >= mali_mem_validator.phys_base) &&
-				(phys_addr          <= (mali_mem_validator.phys_base + (mali_mem_validator.size - 1))) &&
-				((phys_addr + (size - 1)) <= (mali_mem_validator.phys_base + (mali_mem_validator.size - 1))) )
-			{
+			    ((phys_addr + (size - 1)) >= mali_mem_validator.phys_base) &&
+			    (phys_addr          <= (mali_mem_validator.phys_base + (mali_mem_validator.size - 1))) &&
+			    ((phys_addr + (size - 1)) <= (mali_mem_validator.phys_base + (mali_mem_validator.size - 1)))) {
 				MALI_DEBUG_PRINT(3, ("Accepted range 0x%08X + size 0x%08X (= 0x%08X)\n", phys_addr, size, (phys_addr + size - 1)));
 				return _MALI_OSK_ERR_OK;
 			}
diff --git a/drivers/gpu/mali/mali/common/mali_mem_validation.h b/drivers/gpu/mali/mali/common/mali_mem_validation.h
old mode 100644
new mode 100755
index 3d4f15a..f0a76d1
--- a/drivers/gpu/mali/mali/common/mali_mem_validation.h
+++ b/drivers/gpu/mali/mali/common/mali_mem_validation.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,7 +13,7 @@
 
 #include "mali_osk.h"
 
-_mali_osk_errcode_t mali_mem_validation_add_range(const _mali_osk_resource_t * resource);
+_mali_osk_errcode_t mali_mem_validation_add_range(u32 start, u32 size);
 _mali_osk_errcode_t mali_mem_validation_check(u32 phys_addr, u32 size);
 
 #endif /* __MALI_MEM_VALIDATION_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_memory.c b/drivers/gpu/mali/mali/common/mali_memory.c
deleted file mode 100644
index 776dd1e..0000000
--- a/drivers/gpu/mali/mali/common/mali_memory.c
+++ /dev/null
@@ -1,1321 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include "mali_kernel_common.h"
-#include "mali_kernel_descriptor_mapping.h"
-#include "mali_mem_validation.h"
-#include "mali_memory.h"
-#include "mali_mmu_page_directory.h"
-#include "mali_kernel_memory_engine.h"
-#include "mali_block_allocator.h"
-#include "mali_kernel_mem_os.h"
-#include "mali_session.h"
-#include "mali_l2_cache.h"
-#include "mali_cluster.h"
-#include "mali_group.h"
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-#include "ump_kernel_interface.h"
-#endif
-
-/* kernel side OS functions and user-kernel interface */
-#include "mali_osk.h"
-#include "mali_osk_mali.h"
-#include "mali_ukk.h"
-#include "mali_osk_list.h"
-#include "mali_osk_bitops.h"
-
-/**
- * Per-session memory descriptor mapping table sizes
- */
-#define MALI_MEM_DESCRIPTORS_INIT 64
-#define MALI_MEM_DESCRIPTORS_MAX 65536
-
-typedef struct dedicated_memory_info
-{
-	u32 base;
-	u32 size;
-	struct dedicated_memory_info * next;
-} dedicated_memory_info;
-
-/* types used for external_memory and ump_memory physical memory allocators, which are using the mali_allocation_engine */
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-typedef struct ump_mem_allocation
-{
-	mali_allocation_engine * engine;
-	mali_memory_allocation * descriptor;
-	u32 initial_offset;
-	u32 size_allocated;
-	ump_dd_handle ump_mem;
-} ump_mem_allocation ;
-#endif
-
-typedef struct external_mem_allocation
-{
-	mali_allocation_engine * engine;
-	mali_memory_allocation * descriptor;
-	u32 initial_offset;
-	u32 size;
-} external_mem_allocation;
-
-/**
- * @brief Internal function for unmapping memory
- *
- * Worker function for unmapping memory from a user-process. We assume that the
- * session/descriptor's lock was obtained before entry. For example, the
- * wrapper _mali_ukk_mem_munmap() will lock the descriptor, then call this
- * function to do the actual unmapping. mali_memory_core_session_end() could
- * also call this directly (depending on compilation options), having locked
- * the descriptor.
- *
- * This function will fail if it is unable to put the MMU in stall mode (which
- * might be the case if a page fault is also being processed).
- *
- * @param args see _mali_uk_mem_munmap_s in "mali_utgard_uk_types.h"
- * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
- */
-static _mali_osk_errcode_t _mali_ukk_mem_munmap_internal( _mali_uk_mem_munmap_s *args );
-
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-static void ump_memory_release(void * ctx, void * handle);
-static mali_physical_memory_allocation_result ump_memory_commit(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info);
-#endif /* MALI_USE_UNIFIED_MEMORY_PROVIDER != 0*/
-
-
-static void external_memory_release(void * ctx, void * handle);
-static mali_physical_memory_allocation_result external_memory_commit(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info);
-
-
-/* nop functions */
-
-/* mali address manager needs to allocate page tables on allocate, write to page table(s) on map, write to page table(s) and release page tables on release */
-static _mali_osk_errcode_t  mali_address_manager_allocate(mali_memory_allocation * descriptor); /* validates the range, allocates memory for the page tables if needed */
-static _mali_osk_errcode_t  mali_address_manager_map(mali_memory_allocation * descriptor, u32 offset, u32 *phys_addr, u32 size);
-static void mali_address_manager_release(mali_memory_allocation * descriptor);
-
-/* MMU variables */
-
-typedef struct mali_mmu_page_table_allocation
-{
-	_mali_osk_list_t list;
-	u32 * usage_map;
-	u32 usage_count;
-	u32 num_pages;
-	mali_page_table_block pages;
-} mali_mmu_page_table_allocation;
-
-typedef struct mali_mmu_page_table_allocations
-{
-	_mali_osk_lock_t *lock;
-	_mali_osk_list_t partial;
-	_mali_osk_list_t full;
-	/* we never hold on to a empty allocation */
-} mali_mmu_page_table_allocations;
-
-static mali_kernel_mem_address_manager mali_address_manager =
-{
-	mali_address_manager_allocate, /* allocate */
-	mali_address_manager_release,  /* release */
-	mali_address_manager_map,      /* map_physical */
-	NULL                           /* unmap_physical not present*/
-};
-
-/* the mmu page table cache */
-static struct mali_mmu_page_table_allocations page_table_cache;
-
-
-static mali_kernel_mem_address_manager process_address_manager =
-{
-	_mali_osk_mem_mapregion_init,  /* allocate */
-	_mali_osk_mem_mapregion_term,  /* release */
-	_mali_osk_mem_mapregion_map,   /* map_physical */
-	_mali_osk_mem_mapregion_unmap  /* unmap_physical */
-};
-
-static _mali_osk_errcode_t mali_mmu_page_table_cache_create(void);
-static void mali_mmu_page_table_cache_destroy(void);
-
-static mali_allocation_engine memory_engine = NULL;
-static mali_physical_memory_allocator * physical_memory_allocators = NULL;
-
-static dedicated_memory_info * mem_region_registrations = NULL;
-
-/* called during module init */
-_mali_osk_errcode_t mali_memory_initialize(void)
-{
-	_mali_osk_errcode_t err;
-
-	MALI_DEBUG_PRINT(2, ("Memory system initializing\n"));
-
-	err = mali_mmu_page_table_cache_create();
-	if(_MALI_OSK_ERR_OK != err)
-	{
-		MALI_ERROR(err);
-	}
-
-	memory_engine = mali_allocation_engine_create(&mali_address_manager, &process_address_manager);
-	MALI_CHECK_NON_NULL( memory_engine, _MALI_OSK_ERR_FAULT);
-
-	MALI_SUCCESS;
-}
-
-/* called if/when our module is unloaded */
-void mali_memory_terminate(void)
-{
-	MALI_DEBUG_PRINT(2, ("Memory system terminating\n"));
-
-	mali_mmu_page_table_cache_destroy();
-
-	while ( NULL != mem_region_registrations)
-	{
-		dedicated_memory_info * m;
-		m = mem_region_registrations;
-		mem_region_registrations = m->next;
-		_mali_osk_mem_unreqregion(m->base, m->size);
-		_mali_osk_free(m);
-	}
-
-	while ( NULL != physical_memory_allocators)
-	{
-		mali_physical_memory_allocator * m;
-		m = physical_memory_allocators;
-		physical_memory_allocators = m->next;
-		m->destroy(m);
-	}
-
-	if (NULL != memory_engine)
-	{
-		mali_allocation_engine_destroy(memory_engine);
-		memory_engine = NULL;
-	}
-}
-
-_mali_osk_errcode_t mali_memory_session_begin(struct mali_session_data * session_data)
-{
-	MALI_DEBUG_PRINT(5, ("Memory session begin\n"));
-
-	/* create descriptor mapping table */
-	session_data->descriptor_mapping = mali_descriptor_mapping_create(MALI_MEM_DESCRIPTORS_INIT, MALI_MEM_DESCRIPTORS_MAX);
-
-	if (NULL == session_data->descriptor_mapping)
-	{
-		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-	}
-
-	session_data->memory_lock = _mali_osk_lock_init( _MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_ONELOCK
-	                                | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_MEM_SESSION);
-	if (NULL == session_data->memory_lock)
-	{
-		mali_descriptor_mapping_destroy(session_data->descriptor_mapping);
-		_mali_osk_free(session_data);
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	/* Init the session's memory allocation list */
-	_MALI_OSK_INIT_LIST_HEAD( &session_data->memory_head );
-
-	MALI_DEBUG_PRINT(5, ("MMU session begin: success\n"));
-	MALI_SUCCESS;
-}
-
-static void descriptor_table_cleanup_callback(int descriptor_id, void* map_target)
-{
-	mali_memory_allocation * descriptor;
-
-	descriptor = (mali_memory_allocation*)map_target;
-
-	MALI_DEBUG_PRINT(3, ("Cleanup of descriptor %d mapping to 0x%x in descriptor table\n", descriptor_id, map_target));
-	MALI_DEBUG_ASSERT(descriptor);
-
-	mali_allocation_engine_release_memory(memory_engine, descriptor);
-	_mali_osk_free(descriptor);
-}
-
-void mali_memory_session_end(struct mali_session_data *session_data)
-{
-	MALI_DEBUG_PRINT(3, ("MMU session end\n"));
-
-	if (NULL == session_data)
-	{
-		MALI_DEBUG_PRINT(1, ("No session data found during session end\n"));
-		return;
-	}
-
-#ifndef MALI_UKK_HAS_IMPLICIT_MMAP_CLEANUP
-#if _MALI_OSK_SPECIFIC_INDIRECT_MMAP
-#error Indirect MMAP specified, but UKK does not have implicit MMAP cleanup. Current implementation does not handle this.
-#else
-	{
-		_mali_osk_errcode_t err;
-		err = _MALI_OSK_ERR_BUSY;
-		while (err == _MALI_OSK_ERR_BUSY)
-		{
-			/* Lock the session so we can modify the memory list */
-			_mali_osk_lock_wait( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-			err = _MALI_OSK_ERR_OK;
-
-			/* Free all memory engine allocations */
-			if (0 == _mali_osk_list_empty(&session_data->memory_head))
-			{
-				mali_memory_allocation *descriptor;
-				mali_memory_allocation *temp;
-				_mali_uk_mem_munmap_s unmap_args;
-
-				MALI_DEBUG_PRINT(1, ("Memory found on session usage list during session termination\n"));
-
-				unmap_args.ctx = session_data;
-
-				/* use the 'safe' list iterator, since freeing removes the active block from the list we're iterating */
-				_MALI_OSK_LIST_FOREACHENTRY(descriptor, temp, &session_data->memory_head, mali_memory_allocation, list)
-				{
-					MALI_DEBUG_PRINT(4, ("Freeing block with mali address 0x%x size %d mapped in user space at 0x%x\n",
-								descriptor->mali_address, descriptor->size, descriptor->size, descriptor->mapping)
-							);
-					/* ASSERT that the descriptor's lock references the correct thing */
-					MALI_DEBUG_ASSERT(  descriptor->lock == session_data->memory_lock );
-					/* Therefore, we have already locked the descriptor */
-
-					unmap_args.size = descriptor->size;
-					unmap_args.mapping = descriptor->mapping;
-					unmap_args.cookie = (u32)descriptor;
-
-					/*
-					 * This removes the descriptor from the list, and frees the descriptor
-					 *
-					 * Does not handle the _MALI_OSK_SPECIFIC_INDIRECT_MMAP case, since
-					 * the only OS we are aware of that requires indirect MMAP also has
-					 * implicit mmap cleanup.
-					 */
-					err = _mali_ukk_mem_munmap_internal( &unmap_args );
-
-					if (err == _MALI_OSK_ERR_BUSY)
-					{
-						_mali_osk_lock_signal( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-						/*
-						 * Reason for this;
-						 * We where unable to stall the MMU, probably because we are in page fault handling.
-						 * Sleep for a while with the session lock released, then try again.
-						 * Abnormal termination of programs with running Mali jobs is a normal reason for this.
-						 */
-						_mali_osk_time_ubusydelay(10);
-						break; /* Will jump back into: "while (err == _MALI_OSK_ERR_BUSY)" */
-					}
-				}
-			}
-		}
-		/* Assert that we really did free everything */
-		MALI_DEBUG_ASSERT( _mali_osk_list_empty(&session_data->memory_head) );
-	}
-#endif /* _MALI_OSK_SPECIFIC_INDIRECT_MMAP */
-#else
-	/* Lock the session so we can modify the memory list */
-	_mali_osk_lock_wait( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-#endif /* MALI_UKK_HAS_IMPLICIT_MMAP_CLEANUP */
-
-	if (NULL != session_data->descriptor_mapping)
-	{
-		mali_descriptor_mapping_call_for_each(session_data->descriptor_mapping, descriptor_table_cleanup_callback);
-		mali_descriptor_mapping_destroy(session_data->descriptor_mapping);
-		session_data->descriptor_mapping = NULL;
-	}
-
-	_mali_osk_lock_signal( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-
-	/**
-	 * @note Could the VMA close handler mean that we use the session data after it was freed?
-	 * In which case, would need to refcount the session data, and free on VMA close
-	 */
-
-	/* Free the lock */
-	_mali_osk_lock_term( session_data->memory_lock );
-
-	return;
-}
-
-_mali_osk_errcode_t mali_memory_core_resource_os_memory(_mali_osk_resource_t * resource)
-{
-	mali_physical_memory_allocator * allocator;
-	mali_physical_memory_allocator ** next_allocator_list;
-
-	u32 alloc_order = resource->alloc_order;
-
-	allocator = mali_os_allocator_create(resource->size, resource->cpu_usage_adjust, resource->description);
-	if (NULL == allocator)
-	{
-		MALI_DEBUG_PRINT(1, ("Failed to create OS memory allocator\n"));
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	allocator->alloc_order = alloc_order;
-
-	/* link in the allocator: insertion into ordered list
-	 * resources of the same alloc_order will be Last-in-first */
-	next_allocator_list = &physical_memory_allocators;
-
-	while (NULL != *next_allocator_list &&
-			(*next_allocator_list)->alloc_order < alloc_order )
-	{
-		next_allocator_list = &((*next_allocator_list)->next);
-	}
-
-	allocator->next = (*next_allocator_list);
-	(*next_allocator_list) = allocator;
-
-	MALI_SUCCESS;
-}
-
-_mali_osk_errcode_t mali_memory_core_resource_dedicated_memory(_mali_osk_resource_t * resource)
-{
-	mali_physical_memory_allocator * allocator;
-	mali_physical_memory_allocator ** next_allocator_list;
-	dedicated_memory_info * cleanup_data;
-
-	u32 alloc_order = resource->alloc_order;
-
-	/* do the low level linux operation first */
-
-	/* Request ownership of the memory */
-	if (_MALI_OSK_ERR_OK != _mali_osk_mem_reqregion(resource->base, resource->size, resource->description))
-	{
-		MALI_DEBUG_PRINT(1, ("Failed to request memory region %s (0x%08X - 0x%08X)\n", resource->description, resource->base, resource->base + resource->size - 1));
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	/* create generic block allocator object to handle it */
-	allocator = mali_block_allocator_create(resource->base, resource->cpu_usage_adjust, resource->size, resource->description );
-
-	if (NULL == allocator)
-	{
-		MALI_DEBUG_PRINT(1, ("Memory bank registration failed\n"));
-		_mali_osk_mem_unreqregion(resource->base, resource->size);
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	/* save low level cleanup info */
-	allocator->alloc_order = alloc_order;
-
-	cleanup_data = _mali_osk_malloc(sizeof(dedicated_memory_info));
-
-	if (NULL == cleanup_data)
-	{
-		_mali_osk_mem_unreqregion(resource->base, resource->size);
-		allocator->destroy(allocator);
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	cleanup_data->base = resource->base;
-	cleanup_data->size = resource->size;
-
-	cleanup_data->next = mem_region_registrations;
-	mem_region_registrations = cleanup_data;
-
-	/* link in the allocator: insertion into ordered list
-	 * resources of the same alloc_order will be Last-in-first */
-	next_allocator_list = &physical_memory_allocators;
-
-	while ( NULL != *next_allocator_list &&
-			(*next_allocator_list)->alloc_order < alloc_order )
-	{
-		next_allocator_list = &((*next_allocator_list)->next);
-	}
-
-	allocator->next = (*next_allocator_list);
-	(*next_allocator_list) = allocator;
-
-	MALI_SUCCESS;
-}
-
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-static mali_physical_memory_allocation_result ump_memory_commit(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info)
-{
-	ump_dd_handle ump_mem;
-	u32 nr_blocks;
-	u32 i;
-	ump_dd_physical_block * ump_blocks;
-	ump_mem_allocation *ret_allocation;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(alloc_info);
-
-	ret_allocation = _mali_osk_malloc( sizeof( ump_mem_allocation ) );
-	if ( NULL==ret_allocation ) return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-
-	ump_mem = (ump_dd_handle)ctx;
-
-	MALI_DEBUG_PRINT(4, ("In ump_memory_commit\n"));
-
-	nr_blocks = ump_dd_phys_block_count_get(ump_mem);
-
-	MALI_DEBUG_PRINT(4, ("Have %d blocks\n", nr_blocks));
-
-	if (nr_blocks == 0)
-	{
-		MALI_DEBUG_PRINT(1, ("No block count\n"));
-		_mali_osk_free( ret_allocation );
-		return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-	}
-
-	ump_blocks = _mali_osk_malloc(sizeof(*ump_blocks)*nr_blocks );
-	if ( NULL==ump_blocks )
-	{
-		_mali_osk_free( ret_allocation );
-		return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-	}
-
-	if (UMP_DD_INVALID == ump_dd_phys_blocks_get(ump_mem, ump_blocks, nr_blocks))
-	{
-		_mali_osk_free(ump_blocks);
-		_mali_osk_free( ret_allocation );
-		return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-	}
-
-	/* Store away the initial offset for unmapping purposes */
-	ret_allocation->initial_offset = *offset;
-
-	for(i=0; i<nr_blocks; ++i)
-	{
-		MALI_DEBUG_PRINT(4, ("Mapping in 0x%08x size %d\n", ump_blocks[i].addr , ump_blocks[i].size));
-		if (_MALI_OSK_ERR_OK != mali_allocation_engine_map_physical(engine, descriptor, *offset, ump_blocks[i].addr , 0, ump_blocks[i].size ))
-		{
-			u32 size_allocated = *offset - ret_allocation->initial_offset;
-			MALI_DEBUG_PRINT(1, ("Mapping of external memory failed\n"));
-
-			/* unmap all previous blocks (if any) */
-			mali_allocation_engine_unmap_physical(engine, descriptor, ret_allocation->initial_offset, size_allocated, (_mali_osk_mem_mapregion_flags_t)0 );
-
-			_mali_osk_free(ump_blocks);
-			_mali_osk_free(ret_allocation);
-			return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-		}
-		*offset += ump_blocks[i].size;
-	}
-
-	if (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE)
-	{
-		/* Map in an extra virtual guard page at the end of the VMA */
-		MALI_DEBUG_PRINT(4, ("Mapping in extra guard page\n"));
-		if (_MALI_OSK_ERR_OK != mali_allocation_engine_map_physical(engine, descriptor, *offset, ump_blocks[0].addr , 0, _MALI_OSK_MALI_PAGE_SIZE ))
-		{
-			u32 size_allocated = *offset - ret_allocation->initial_offset;
-			MALI_DEBUG_PRINT(1, ("Mapping of external memory (guard page) failed\n"));
-
-			/* unmap all previous blocks (if any) */
-			mali_allocation_engine_unmap_physical(engine, descriptor, ret_allocation->initial_offset, size_allocated, (_mali_osk_mem_mapregion_flags_t)0 );
-
-			_mali_osk_free(ump_blocks);
-			_mali_osk_free(ret_allocation);
-			return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-		}
-		*offset += _MALI_OSK_MALI_PAGE_SIZE;
-	}
-
-	_mali_osk_free( ump_blocks );
-
-	ret_allocation->engine = engine;
-	ret_allocation->descriptor = descriptor;
-	ret_allocation->ump_mem = ump_mem;
-	ret_allocation->size_allocated = *offset - ret_allocation->initial_offset;
-
-	alloc_info->ctx = NULL;
-	alloc_info->handle = ret_allocation;
-	alloc_info->next = NULL;
-	alloc_info->release = ump_memory_release;
-
-	return MALI_MEM_ALLOC_FINISHED;
-}
-
-static void ump_memory_release(void * ctx, void * handle)
-{
-	ump_dd_handle ump_mem;
-	ump_mem_allocation *allocation;
-
-	allocation = (ump_mem_allocation *)handle;
-
-	MALI_DEBUG_ASSERT_POINTER( allocation );
-
-	ump_mem = allocation->ump_mem;
-
-	MALI_DEBUG_ASSERT(UMP_DD_HANDLE_INVALID!=ump_mem);
-
-	/* At present, this is a no-op. But, it allows the mali_address_manager to
-	 * do unmapping of a subrange in future. */
-	mali_allocation_engine_unmap_physical( allocation->engine,
-										   allocation->descriptor,
-										   allocation->initial_offset,
-										   allocation->size_allocated,
-										   (_mali_osk_mem_mapregion_flags_t)0
-										   );
-	_mali_osk_free( allocation );
-
-
-	ump_dd_reference_release(ump_mem) ;
-	return;
-}
-
-_mali_osk_errcode_t _mali_ukk_attach_ump_mem( _mali_uk_attach_ump_mem_s *args )
-{
-	ump_dd_handle ump_mem;
-	mali_physical_memory_allocator external_memory_allocator;
-	struct mali_session_data *session_data;
-	mali_memory_allocation * descriptor;
-	int md;
-
-  	MALI_DEBUG_ASSERT_POINTER(args);
-  	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-
-	session_data = (struct mali_session_data *)args->ctx;
-	MALI_CHECK_NON_NULL(session_data, _MALI_OSK_ERR_INVALID_ARGS);
-
-	/* check arguments */
-	/* NULL might be a valid Mali address */
-	if ( ! args->size) MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS);
-
-	/* size must be a multiple of the system page size */
-	if ( args->size % _MALI_OSK_MALI_PAGE_SIZE ) MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS);
-
-	MALI_DEBUG_PRINT(3,
-	                 ("Requested to map ump memory with secure id %d into virtual memory 0x%08X, size 0x%08X\n",
-	                  args->secure_id, args->mali_address, args->size));
-
-	ump_mem = ump_dd_handle_create_from_secure_id( (int)args->secure_id ) ;
-
-	if ( UMP_DD_HANDLE_INVALID==ump_mem ) MALI_ERROR(_MALI_OSK_ERR_FAULT);
-
-	descriptor = _mali_osk_calloc(1, sizeof(mali_memory_allocation));
-	if (NULL == descriptor)
-	{
-		ump_dd_reference_release(ump_mem);
-		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-	}
-
-	descriptor->size = args->size;
-	descriptor->mapping = NULL;
-	descriptor->mali_address = args->mali_address;
-	descriptor->mali_addr_mapping_info = (void*)session_data;
-	descriptor->process_addr_mapping_info = NULL; /* do not map to process address space */
-	descriptor->lock = session_data->memory_lock;
-	if (args->flags & _MALI_MAP_EXTERNAL_MAP_GUARD_PAGE)
-	{
-		descriptor->flags = MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE;
-	}
-	_mali_osk_list_init( &descriptor->list );
-
-	if (_MALI_OSK_ERR_OK != mali_descriptor_mapping_allocate_mapping(session_data->descriptor_mapping, descriptor, &md))
-	{
-		ump_dd_reference_release(ump_mem);
-		_mali_osk_free(descriptor);
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	external_memory_allocator.allocate = ump_memory_commit;
-	external_memory_allocator.allocate_page_table_block = NULL;
-	external_memory_allocator.ctx = ump_mem;
-	external_memory_allocator.name = "UMP Memory";
-	external_memory_allocator.next = NULL;
-
-	_mali_osk_lock_wait(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (_MALI_OSK_ERR_OK != mali_allocation_engine_allocate_memory(memory_engine, descriptor, &external_memory_allocator, NULL))
-	{
-		_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-		mali_descriptor_mapping_free(session_data->descriptor_mapping, md);
-		ump_dd_reference_release(ump_mem);
-		_mali_osk_free(descriptor);
-		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-	}
-
-	_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-	args->cookie = md;
-
-	MALI_DEBUG_PRINT(5,("Returning from UMP attach\n"));
-
-	/* All OK */
-	MALI_SUCCESS;
-}
-
-
-_mali_osk_errcode_t _mali_ukk_release_ump_mem( _mali_uk_release_ump_mem_s *args )
-{
-	mali_memory_allocation * descriptor;
-	struct mali_session_data *session_data;
-
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-
-	session_data = (struct mali_session_data *)args->ctx;
-	MALI_CHECK_NON_NULL(session_data, _MALI_OSK_ERR_INVALID_ARGS);
-
-	if (_MALI_OSK_ERR_OK != mali_descriptor_mapping_get(session_data->descriptor_mapping, args->cookie, (void**)&descriptor))
-	{
-		MALI_DEBUG_PRINT(1, ("Invalid memory descriptor %d used to release ump memory\n", args->cookie));
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	descriptor = mali_descriptor_mapping_free(session_data->descriptor_mapping, args->cookie);
-
-	if (NULL != descriptor)
-	{
-		_mali_osk_lock_wait( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-
-		mali_allocation_engine_release_memory(memory_engine, descriptor);
-
-		_mali_osk_lock_signal( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-
-		_mali_osk_free(descriptor);
-	}
-
-	MALI_SUCCESS;
-
-}
-#endif /* MALI_USE_UNIFIED_MEMORY_PROVIDER != 0 */
-
-
-static mali_physical_memory_allocation_result external_memory_commit(void* ctx, mali_allocation_engine * engine, mali_memory_allocation * descriptor, u32* offset, mali_physical_memory_allocation * alloc_info)
-{
-	u32 * data;
-	external_mem_allocation * ret_allocation;
-
-	MALI_DEBUG_ASSERT_POINTER(ctx);
-	MALI_DEBUG_ASSERT_POINTER(engine);
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(alloc_info);
-
-	ret_allocation = _mali_osk_malloc( sizeof(external_mem_allocation) );
-
-	if ( NULL == ret_allocation )
-	{
-		return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-	}
-
-	data = (u32*)ctx;
-
-	ret_allocation->engine = engine;
-	ret_allocation->descriptor = descriptor;
-	ret_allocation->initial_offset = *offset;
-
-	alloc_info->ctx = NULL;
-	alloc_info->handle = ret_allocation;
-	alloc_info->next = NULL;
-	alloc_info->release = external_memory_release;
-
-	MALI_DEBUG_PRINT(5, ("External map: mapping phys 0x%08X at mali virtual address 0x%08X staring at offset 0x%08X length 0x%08X\n", data[0], descriptor->mali_address, *offset, data[1]));
-
-	if (_MALI_OSK_ERR_OK != mali_allocation_engine_map_physical(engine, descriptor, *offset, data[0], 0, data[1]))
-	{
-		MALI_DEBUG_PRINT(1, ("Mapping of external memory failed\n"));
-		_mali_osk_free(ret_allocation);
-		return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-	}
-	*offset += data[1];
-
-	if (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE)
-	{
-		/* Map in an extra virtual guard page at the end of the VMA */
-		MALI_DEBUG_PRINT(4, ("Mapping in extra guard page\n"));
-		if (_MALI_OSK_ERR_OK != mali_allocation_engine_map_physical(engine, descriptor, *offset, data[0], 0, _MALI_OSK_MALI_PAGE_SIZE))
-		{
-			u32 size_allocated = *offset - ret_allocation->initial_offset;
-			MALI_DEBUG_PRINT(1, ("Mapping of external memory (guard page) failed\n"));
-
-			/* unmap what we previously mapped */
-			mali_allocation_engine_unmap_physical(engine, descriptor, ret_allocation->initial_offset, size_allocated, (_mali_osk_mem_mapregion_flags_t)0 );
-			_mali_osk_free(ret_allocation);
-			return MALI_MEM_ALLOC_INTERNAL_FAILURE;
-		}
-		*offset += _MALI_OSK_MALI_PAGE_SIZE;
-	}
-
-	ret_allocation->size = *offset - ret_allocation->initial_offset;
-
-	return MALI_MEM_ALLOC_FINISHED;
-}
-
-static void external_memory_release(void * ctx, void * handle)
-{
-	external_mem_allocation * allocation;
-
-	allocation = (external_mem_allocation *) handle;
-	MALI_DEBUG_ASSERT_POINTER( allocation );
-
-	/* At present, this is a no-op. But, it allows the mali_address_manager to
-	 * do unmapping of a subrange in future. */
-
-	mali_allocation_engine_unmap_physical( allocation->engine,
-										   allocation->descriptor,
-										   allocation->initial_offset,
-										   allocation->size,
-										   (_mali_osk_mem_mapregion_flags_t)0
-										   );
-
-	_mali_osk_free( allocation );
-
-	return;
-}
-
-_mali_osk_errcode_t _mali_ukk_map_external_mem( _mali_uk_map_external_mem_s *args )
-{
-	mali_physical_memory_allocator external_memory_allocator;
-	struct mali_session_data *session_data;
-	u32 info[2];
-	mali_memory_allocation * descriptor;
-	int md;
-
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-
-	session_data = (struct mali_session_data *)args->ctx;
-	MALI_CHECK_NON_NULL(session_data, _MALI_OSK_ERR_INVALID_ARGS);
-
-	external_memory_allocator.allocate = external_memory_commit;
-	external_memory_allocator.allocate_page_table_block = NULL;
-	external_memory_allocator.ctx = &info[0];
-	external_memory_allocator.name = "External Memory";
-	external_memory_allocator.next = NULL;
-
-	/* check arguments */
-	/* NULL might be a valid Mali address */
-	if ( ! args->size) MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS);
-
-	/* size must be a multiple of the system page size */
-	if ( args->size % _MALI_OSK_MALI_PAGE_SIZE ) MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS);
-
-	MALI_DEBUG_PRINT(3,
-	        ("Requested to map physical memory 0x%x-0x%x into virtual memory 0x%x\n",
-	        (void*)args->phys_addr,
-	        (void*)(args->phys_addr + args->size -1),
-	        (void*)args->mali_address)
-	);
-
-	/* Validate the mali physical range */
-	if (_MALI_OSK_ERR_OK != mali_mem_validation_check(args->phys_addr, args->size))
-	{
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	info[0] = args->phys_addr;
-	info[1] = args->size;
-
-	descriptor = _mali_osk_calloc(1, sizeof(mali_memory_allocation));
-	if (NULL == descriptor) MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-
-	descriptor->size = args->size;
-	descriptor->mapping = NULL;
-	descriptor->mali_address = args->mali_address;
-	descriptor->mali_addr_mapping_info = (void*)session_data;
-	descriptor->process_addr_mapping_info = NULL; /* do not map to process address space */
-	descriptor->lock = session_data->memory_lock;
-	if (args->flags & _MALI_MAP_EXTERNAL_MAP_GUARD_PAGE)
-	{
-		descriptor->flags = MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE;
-	}
-	_mali_osk_list_init( &descriptor->list );
-
-	_mali_osk_lock_wait(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (_MALI_OSK_ERR_OK != mali_allocation_engine_allocate_memory(memory_engine, descriptor, &external_memory_allocator, NULL))
-	{
-		_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-		_mali_osk_free(descriptor);
-		MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-	}
-
-	_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (_MALI_OSK_ERR_OK != mali_descriptor_mapping_allocate_mapping(session_data->descriptor_mapping, descriptor, &md))
-	{
-		mali_allocation_engine_release_memory(memory_engine, descriptor);
-		_mali_osk_free(descriptor);
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	args->cookie = md;
-
-	MALI_DEBUG_PRINT(5,("Returning from range_map_external_memory\n"));
-
-	/* All OK */
-	MALI_SUCCESS;
-}
-
-
-_mali_osk_errcode_t _mali_ukk_unmap_external_mem( _mali_uk_unmap_external_mem_s *args )
-{
-	mali_memory_allocation * descriptor;
-	void* old_value;
-	struct mali_session_data *session_data;
-
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-
-	session_data = (struct mali_session_data *)args->ctx;
-	MALI_CHECK_NON_NULL(session_data, _MALI_OSK_ERR_INVALID_ARGS);
-
-	if (_MALI_OSK_ERR_OK != mali_descriptor_mapping_get(session_data->descriptor_mapping, args->cookie, (void**)&descriptor))
-	{
-		MALI_DEBUG_PRINT(1, ("Invalid memory descriptor %d used to unmap external memory\n", args->cookie));
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-
-	old_value = mali_descriptor_mapping_free(session_data->descriptor_mapping, args->cookie);
-
-	if (NULL != old_value)
-	{
-		_mali_osk_lock_wait( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-
-		mali_allocation_engine_release_memory(memory_engine, descriptor);
-
-		_mali_osk_lock_signal( session_data->memory_lock, _MALI_OSK_LOCKMODE_RW );
-
-		_mali_osk_free(descriptor);
-	}
-
-	MALI_SUCCESS;
-}
-
-_mali_osk_errcode_t _mali_ukk_init_mem( _mali_uk_init_mem_s *args )
-{
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-
-	args->memory_size = 2 * 1024 * 1024 * 1024UL; /* 2GB address space */
-	args->mali_address_base = 1 * 1024 * 1024 * 1024UL; /* staring at 1GB, causing this layout: (0-1GB unused)(1GB-3G usage by Mali)(3G-4G unused) */
-	MALI_SUCCESS;
-}
-
-_mali_osk_errcode_t _mali_ukk_term_mem( _mali_uk_term_mem_s *args )
-{
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
-	MALI_SUCCESS;
-}
-
-static _mali_osk_errcode_t mali_address_manager_allocate(mali_memory_allocation * descriptor)
-{
-	struct mali_session_data *session_data;
-	u32 actual_size;
-
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	session_data = (struct mali_session_data *)descriptor->mali_addr_mapping_info;
-
-	actual_size = descriptor->size;
-
-	if (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_GUARD_PAGE)
-	{
-		actual_size += _MALI_OSK_MALI_PAGE_SIZE;
-	}
-
-	return mali_mmu_pagedir_map(session_data->page_directory, descriptor->mali_address, actual_size);
-}
-
-static void mali_address_manager_release(mali_memory_allocation * descriptor)
-{
-	const u32 illegal_mali_address = 0xffffffff;
-	struct mali_session_data *session_data;
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	/* It is allowed to call this function several times on the same descriptor.
-	   When memory is released we set the illegal_mali_address so we can early out here. */
-	if ( illegal_mali_address == descriptor->mali_address) return;
-
-	session_data = (struct mali_session_data *)descriptor->mali_addr_mapping_info;
-	mali_mmu_pagedir_unmap(session_data->page_directory, descriptor->mali_address, descriptor->size);
-
-	descriptor->mali_address = illegal_mali_address ;
-}
-
-static _mali_osk_errcode_t mali_address_manager_map(mali_memory_allocation * descriptor, u32 offset, u32 *phys_addr, u32 size)
-{
-	struct mali_session_data *session_data;
-	u32 mali_address;
-
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-	MALI_DEBUG_ASSERT_POINTER(phys_addr);
-
-	session_data = (struct mali_session_data *)descriptor->mali_addr_mapping_info;
-	MALI_DEBUG_ASSERT_POINTER(session_data);
-
-	mali_address = descriptor->mali_address + offset;
-
-	MALI_DEBUG_PRINT(7, ("Mali map: mapping 0x%08X to Mali address 0x%08X length 0x%08X\n", *phys_addr, mali_address, size));
-
-	mali_mmu_pagedir_update(session_data->page_directory, mali_address, *phys_addr, size);
-
-	MALI_SUCCESS;
-}
-
-/* This handler registered to mali_mmap for MMU builds */
-_mali_osk_errcode_t _mali_ukk_mem_mmap( _mali_uk_mem_mmap_s *args )
-{
-	struct mali_session_data *session_data;
-	mali_memory_allocation * descriptor;
-
-	/* validate input */
-	if (NULL == args) { MALI_DEBUG_PRINT(3,("mali_ukk_mem_mmap: args was NULL\n")); MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS); }
-
-	/* Unpack arguments */
-	session_data = (struct mali_session_data *)args->ctx;
-
-	/* validate input */
-	if (NULL == session_data) { MALI_DEBUG_PRINT(3,("mali_ukk_mem_mmap: session data was NULL\n")); MALI_ERROR(_MALI_OSK_ERR_FAULT); }
-
-	descriptor = (mali_memory_allocation*) _mali_osk_calloc( 1, sizeof(mali_memory_allocation) );
-	if (NULL == descriptor) { MALI_DEBUG_PRINT(3,("mali_ukk_mem_mmap: descriptor was NULL\n")); MALI_ERROR(_MALI_OSK_ERR_NOMEM); }
-
-	descriptor->size = args->size;
-	descriptor->mali_address = args->phys_addr;
-	descriptor->mali_addr_mapping_info = (void*)session_data;
-
-	descriptor->process_addr_mapping_info = args->ukk_private; /* save to be used during physical manager callback */
-	descriptor->flags = MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE;
-	descriptor->lock = session_data->memory_lock;
-	_mali_osk_list_init( &descriptor->list );
-
-	_mali_osk_lock_wait(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (0 == mali_allocation_engine_allocate_memory(memory_engine, descriptor, physical_memory_allocators, &session_data->memory_head))
-	{
-		/* We do not FLUSH nor TLB_ZAP on MMAP, since we do both of those on job start*/
-	   	_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-
-		args->mapping = descriptor->mapping;
-		args->cookie = (u32)descriptor;
-
-		MALI_DEBUG_PRINT(7, ("MMAP OK\n"));
-		MALI_SUCCESS;
-	}
-	else
-	{
-	   	_mali_osk_lock_signal(session_data->memory_lock, _MALI_OSK_LOCKMODE_RW);
-		/* OOM, but not a fatal error */
-		MALI_DEBUG_PRINT(4, ("Memory allocation failure, OOM\n"));
-		_mali_osk_free(descriptor);
-		/* Linux will free the CPU address allocation, userspace client the Mali address allocation */
-		MALI_ERROR(_MALI_OSK_ERR_FAULT);
-	}
-}
-
-static _mali_osk_errcode_t _mali_ukk_mem_munmap_internal( _mali_uk_mem_munmap_s *args )
-{
-	struct mali_session_data *session_data;
-	mali_memory_allocation * descriptor;
-
-	u32 num_groups = mali_group_get_glob_num_groups();
-	struct mali_group *group;
-	u32 i;
-
-	descriptor = (mali_memory_allocation *)args->cookie;
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	/** @note args->context unused; we use the memory_session from the cookie */
-	/* args->mapping and args->size are also discarded. They are only necessary
-	   for certain do_munmap implementations. However, they could be used to check the
-	   descriptor at this point. */
-
-	session_data = (struct mali_session_data *)descriptor->mali_addr_mapping_info;
-	MALI_DEBUG_ASSERT_POINTER(session_data);
-
-	/* Unmapping the memory from the mali virtual address space.
-	   It is allowed to call this function severeal times, which might happen if zapping below fails. */
-	mali_allocation_engine_release_pt1_mali_pagetables_unmap(memory_engine, descriptor);
-
-#ifdef MALI_UNMAP_FLUSH_ALL_MALI_L2
-	{
-		u32 number_of_clusters = mali_cluster_get_glob_num_clusters();
-		for (i = 0; i < number_of_clusters; i++)
-		{
-			struct mali_cluster *cluster;
-			cluster = mali_cluster_get_global_cluster(i);
-			if( mali_cluster_power_is_enabled_get(cluster) )
-			{
-				mali_cluster_l2_cache_invalidate_all_force(cluster);
-			}
-		}
-	}
-#endif
-
-	for (i = 0; i < num_groups; i++)
-	{
-		group = mali_group_get_glob_group(i);
-		mali_group_lock(group);
-		mali_group_remove_session_if_unused(group, session_data);
-		if (mali_group_get_session(group) == session_data)
-		{
-			/* The Zap also does the stall and disable_stall */
-			mali_bool zap_success = mali_mmu_zap_tlb(mali_group_get_mmu(group));
-			if (MALI_TRUE != zap_success)
-			{
-				MALI_DEBUG_PRINT(2, ("Mali memory unmap failed. Doing pagefault handling.\n"));
-				mali_group_bottom_half(group, GROUP_EVENT_MMU_PAGE_FAULT);
-				/* The bottom half will also do the unlock */
-				continue;
-			}
-		}
-		mali_group_unlock(group);
-	}
-
-	/* Removes the descriptor from the session's memory list, releases physical memory, releases descriptor */
-	mali_allocation_engine_release_pt2_physical_memory_free(memory_engine, descriptor);
-
-	_mali_osk_free(descriptor);
-
-	return _MALI_OSK_ERR_OK;
-}
-
-/* Handler for unmapping memory for MMU builds */
-_mali_osk_errcode_t _mali_ukk_mem_munmap( _mali_uk_mem_munmap_s *args )
-{
-	mali_memory_allocation * descriptor;
-	_mali_osk_lock_t *descriptor_lock;
-	_mali_osk_errcode_t err;
-
-	descriptor = (mali_memory_allocation *)args->cookie;
-	MALI_DEBUG_ASSERT_POINTER(descriptor);
-
-	/** @note args->context unused; we use the memory_session from the cookie */
-	/* args->mapping and args->size are also discarded. They are only necessary
-	for certain do_munmap implementations. However, they could be used to check the
-	descriptor at this point. */
-
-	MALI_DEBUG_ASSERT_POINTER((struct mali_session_data *)descriptor->mali_addr_mapping_info);
-
-	descriptor_lock = descriptor->lock; /* should point to the session data lock... */
-
-	err = _MALI_OSK_ERR_BUSY;
-	while (err == _MALI_OSK_ERR_BUSY)
-	{
-		if (descriptor_lock)
-		{
-			_mali_osk_lock_wait( descriptor_lock, _MALI_OSK_LOCKMODE_RW );
-		}
-
-		err = _mali_ukk_mem_munmap_internal( args );
-
-		if (descriptor_lock)
-		{
-			_mali_osk_lock_signal( descriptor_lock, _MALI_OSK_LOCKMODE_RW );
-		}
-
-		if (err == _MALI_OSK_ERR_BUSY)
-		{
-			/*
-			 * Reason for this;
-			 * We where unable to stall the MMU, probably because we are in page fault handling.
-			 * Sleep for a while with the session lock released, then try again.
-			 * Abnormal termination of programs with running Mali jobs is a normal reason for this.
-			 */
-			_mali_osk_time_ubusydelay(10);
-		}
-	}
-
-	return err;
-}
-
-u32 _mali_ukk_report_memory_usage(void)
-{
-	return mali_allocation_engine_memory_usage(physical_memory_allocators);
-}
-
-_mali_osk_errcode_t mali_mmu_get_table_page(u32 *table_page, mali_io_address *mapping)
-{
-	_mali_osk_lock_wait(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (0 == _mali_osk_list_empty(&page_table_cache.partial))
-	{
-		mali_mmu_page_table_allocation * alloc = _MALI_OSK_LIST_ENTRY(page_table_cache.partial.next, mali_mmu_page_table_allocation, list);
-		int page_number = _mali_osk_find_first_zero_bit(alloc->usage_map, alloc->num_pages);
-		MALI_DEBUG_PRINT(6, ("Partial page table allocation found, using page offset %d\n", page_number));
-		_mali_osk_set_nonatomic_bit(page_number, alloc->usage_map);
-		alloc->usage_count++;
-		if (alloc->num_pages == alloc->usage_count)
-		{
-			/* full, move alloc to full list*/
-			_mali_osk_list_move(&alloc->list, &page_table_cache.full);
-		}
-		_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-
-		*table_page = (MALI_MMU_PAGE_SIZE * page_number) + alloc->pages.phys_base;
-		*mapping =  (mali_io_address)((MALI_MMU_PAGE_SIZE * page_number) + (u32)alloc->pages.mapping);
-		MALI_DEBUG_PRINT(4, ("Page table allocated for VA=0x%08X, MaliPA=0x%08X\n", *mapping, *table_page ));
-		MALI_SUCCESS;
-	}
-	else
-	{
-		mali_mmu_page_table_allocation * alloc;
-		/* no free pages, allocate a new one */
-
-		alloc = (mali_mmu_page_table_allocation *)_mali_osk_calloc(1, sizeof(mali_mmu_page_table_allocation));
-		if (NULL == alloc)
-		{
-			_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-			*table_page = MALI_INVALID_PAGE;
-			MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-		}
-
-		_MALI_OSK_INIT_LIST_HEAD(&alloc->list);
-
-		if (_MALI_OSK_ERR_OK != mali_allocation_engine_allocate_page_tables(memory_engine, &alloc->pages, physical_memory_allocators))
-		{
-			MALI_DEBUG_PRINT(1, ("No more memory for page tables\n"));
-			_mali_osk_free(alloc);
-			_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-			*table_page = MALI_INVALID_PAGE;
-			*mapping = NULL;
-			MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-		}
-
-		/* create the usage map */
-		alloc->num_pages = alloc->pages.size / MALI_MMU_PAGE_SIZE;
-		alloc->usage_count = 1;
-		MALI_DEBUG_PRINT(3, ("New page table cache expansion, %d pages in new cache allocation\n", alloc->num_pages));
-		alloc->usage_map = _mali_osk_calloc(1, ((alloc->num_pages + BITS_PER_LONG - 1) & ~(BITS_PER_LONG-1) / BITS_PER_LONG) * sizeof(unsigned long));
-		if (NULL == alloc->usage_map)
-		{
-			MALI_DEBUG_PRINT(1, ("Failed to allocate memory to describe MMU page table cache usage\n"));
-			alloc->pages.release(&alloc->pages);
-			_mali_osk_free(alloc);
-			_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-			*table_page = MALI_INVALID_PAGE;
-			*mapping = NULL;
-			MALI_ERROR(_MALI_OSK_ERR_NOMEM);
-		}
-
-		_mali_osk_set_nonatomic_bit(0, alloc->usage_map);
-
-		if (alloc->num_pages > 1)
-		{
-			_mali_osk_list_add(&alloc->list, &page_table_cache.partial);
-		}
-		else
-		{
-			_mali_osk_list_add(&alloc->list, &page_table_cache.full);
-		}
-
-		_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-		*table_page = alloc->pages.phys_base; /* return the first page */
-		*mapping = alloc->pages.mapping; /* Mapping for first page */
-		MALI_DEBUG_PRINT(4, ("Page table allocated: VA=0x%08X, MaliPA=0x%08X\n", *mapping, *table_page ));
-		MALI_SUCCESS;
-	}
-}
-
-void mali_mmu_release_table_page(u32 pa)
-{
-	mali_mmu_page_table_allocation * alloc, * temp_alloc;
-
-	MALI_DEBUG_PRINT_IF(1, pa & 4095, ("Bad page address 0x%x given to mali_mmu_release_table_page\n", (void*)pa));
-
-	MALI_DEBUG_PRINT(4, ("Releasing table page 0x%08X to the cache\n", pa));
-
-   	_mali_osk_lock_wait(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-
-	/* find the entry this address belongs to */
-	/* first check the partial list */
-	_MALI_OSK_LIST_FOREACHENTRY(alloc, temp_alloc, &page_table_cache.partial, mali_mmu_page_table_allocation, list)
-	{
-		u32 start = alloc->pages.phys_base;
-		u32 last = start + (alloc->num_pages - 1) * MALI_MMU_PAGE_SIZE;
-		if (pa >= start && pa <= last)
-		{
-			MALI_DEBUG_ASSERT(0 != _mali_osk_test_bit((pa - start)/MALI_MMU_PAGE_SIZE, alloc->usage_map));
-			_mali_osk_clear_nonatomic_bit((pa - start)/MALI_MMU_PAGE_SIZE, alloc->usage_map);
-			alloc->usage_count--;
-
-			_mali_osk_memset((void*)( ((u32)alloc->pages.mapping) + (pa - start) ), 0, MALI_MMU_PAGE_SIZE);
-
-			if (0 == alloc->usage_count)
-			{
-				/* empty, release whole page alloc */
-				_mali_osk_list_del(&alloc->list);
-				alloc->pages.release(&alloc->pages);
-				_mali_osk_free(alloc->usage_map);
-				_mali_osk_free(alloc);
-			}
-		   	_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-			MALI_DEBUG_PRINT(4, ("(partial list)Released table page 0x%08X to the cache\n", pa));
-			return;
-		}
-	}
-
-	/* the check the full list */
-	_MALI_OSK_LIST_FOREACHENTRY(alloc, temp_alloc, &page_table_cache.full, mali_mmu_page_table_allocation, list)
-	{
-		u32 start = alloc->pages.phys_base;
-		u32 last = start + (alloc->num_pages - 1) * MALI_MMU_PAGE_SIZE;
-		if (pa >= start && pa <= last)
-		{
-			_mali_osk_clear_nonatomic_bit((pa - start)/MALI_MMU_PAGE_SIZE, alloc->usage_map);
-			alloc->usage_count--;
-
-			_mali_osk_memset((void*)( ((u32)alloc->pages.mapping) + (pa - start) ), 0, MALI_MMU_PAGE_SIZE);
-
-
-			if (0 == alloc->usage_count)
-			{
-				/* empty, release whole page alloc */
-				_mali_osk_list_del(&alloc->list);
-				alloc->pages.release(&alloc->pages);
-				_mali_osk_free(alloc->usage_map);
-				_mali_osk_free(alloc);
-			}
-			else
-			{
-				/* transfer to partial list */
-				_mali_osk_list_move(&alloc->list, &page_table_cache.partial);
-			}
-
-		   	_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-			MALI_DEBUG_PRINT(4, ("(full list)Released table page 0x%08X to the cache\n", pa));
-			return;
-		}
-	}
-
-	MALI_DEBUG_PRINT(1, ("pa 0x%x not found in the page table cache\n", (void*)pa));
-
-   	_mali_osk_lock_signal(page_table_cache.lock, _MALI_OSK_LOCKMODE_RW);
-}
-
-static _mali_osk_errcode_t mali_mmu_page_table_cache_create(void)
-{
-	page_table_cache.lock = _mali_osk_lock_init( _MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_ONELOCK
-	                            | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_MEM_PT_CACHE);
-	MALI_CHECK_NON_NULL( page_table_cache.lock, _MALI_OSK_ERR_FAULT );
-	_MALI_OSK_INIT_LIST_HEAD(&page_table_cache.partial);
-	_MALI_OSK_INIT_LIST_HEAD(&page_table_cache.full);
-	MALI_SUCCESS;
-}
-
-static void mali_mmu_page_table_cache_destroy(void)
-{
-	mali_mmu_page_table_allocation * alloc, *temp;
-
-	_MALI_OSK_LIST_FOREACHENTRY(alloc, temp, &page_table_cache.partial, mali_mmu_page_table_allocation, list)
-	{
-		MALI_DEBUG_PRINT_IF(1, 0 != alloc->usage_count, ("Destroying page table cache while pages are tagged as in use. %d allocations still marked as in use.\n", alloc->usage_count));
-		_mali_osk_list_del(&alloc->list);
-		alloc->pages.release(&alloc->pages);
-		_mali_osk_free(alloc->usage_map);
-		_mali_osk_free(alloc);
-	}
-
-	MALI_DEBUG_PRINT_IF(1, 0 == _mali_osk_list_empty(&page_table_cache.full), ("Page table cache full list contains one or more elements \n"));
-
-	_MALI_OSK_LIST_FOREACHENTRY(alloc, temp, &page_table_cache.full, mali_mmu_page_table_allocation, list)
-	{
-		MALI_DEBUG_PRINT(1, ("Destroy alloc 0x%08X with usage count %d\n", (u32)alloc, alloc->usage_count));
-		_mali_osk_list_del(&alloc->list);
-		alloc->pages.release(&alloc->pages);
-		_mali_osk_free(alloc->usage_map);
-		_mali_osk_free(alloc);
-	}
-
-	_mali_osk_lock_term(page_table_cache.lock);
-}
diff --git a/drivers/gpu/mali/mali/common/mali_memory.h b/drivers/gpu/mali/mali/common/mali_memory.h
deleted file mode 100644
index 2794407..0000000
--- a/drivers/gpu/mali/mali/common/mali_memory.h
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_MEMORY_H__
-#define __MALI_MEMORY_H__
-
-#include "mali_osk.h"
-#include "mali_session.h"
-
-struct mali_cluster;
-struct mali_group;
-
-/** @brief Initialize Mali memory subsystem
- *
- * Allocate and initialize internal data structures. Must be called before
- * allocating Mali memory.
- *
- * @return On success _MALI_OSK_ERR_OK, othervise some error code describing the error.
- */
-_mali_osk_errcode_t mali_memory_initialize(void);
-
-/** @brief Terminate Mali memory system
- *
- * Clean up and release internal data structures.
- */
-void mali_memory_terminate(void);
-
-/** @brief Start new Mali memory session
- *
- * Allocate and prepare session specific memory allocation data data. The
- * session page directory, lock, and descriptor map is set up.
- *
- * @param mali_session_data pointer to the session data structure
- */
-_mali_osk_errcode_t mali_memory_session_begin(struct mali_session_data *mali_session_data);
-
-/** @brief Close a Mali memory session
- *
- * Release session specific memory allocation related data.
- *
- * @param mali_session_data pointer to the session data structure
- */
-void mali_memory_session_end(struct mali_session_data *mali_session_data);
-
-/** @brief Allocate a page table page
- *
- * Allocate a page for use as a page directory or page table. The page is
- * mapped into kernel space.
- *
- * @return _MALI_OSK_ERR_OK on success, othervise an error code
- * @param table_page GPU pointer to the allocated page
- * @param mapping CPU pointer to the mapping of the allocated page
- */
-_mali_osk_errcode_t mali_mmu_get_table_page(u32 *table_page, mali_io_address *mapping);
-
-/** @brief Release a page table page
- *
- * Release a page table page allocated through \a mali_mmu_get_table_page
- *
- * @param pa the GPU address of the page to release
- */
-void mali_mmu_release_table_page(u32 pa);
-
-
-/** @brief Parse resource and prepare the OS memory allocator
- */
-_mali_osk_errcode_t mali_memory_core_resource_os_memory(_mali_osk_resource_t * resource);
-
-/** @brief Parse resource and prepare the dedicated memory allocator
- */
-_mali_osk_errcode_t mali_memory_core_resource_dedicated_memory(_mali_osk_resource_t * resource);
-
-#endif /* __MALI_MEMORY_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_mmu.c b/drivers/gpu/mali/mali/common/mali_mmu.c
old mode 100644
new mode 100755
index e959c38..715fd09
--- a/drivers/gpu/mali/mali/common/mali_mmu.c
+++ b/drivers/gpu/mali/mali/common/mali_mmu.c
@@ -1,16 +1,15 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
 #include "mali_kernel_common.h"
 #include "mali_osk.h"
-#include "mali_osk_bitops.h"
 #include "mali_osk_list.h"
 #include "mali_ukk.h"
 
@@ -25,42 +24,11 @@
 #define MALI_MMU_REGISTERS_SIZE 0x24
 
 /**
- * MMU register numbers
- * Used in the register read/write routines.
- * See the hardware documentation for more information about each register
- */
-typedef enum mali_mmu_register {
-	MALI_MMU_REGISTER_DTE_ADDR = 0x0000, /**< Current Page Directory Pointer */
-	MALI_MMU_REGISTER_STATUS = 0x0004, /**< Status of the MMU */
-	MALI_MMU_REGISTER_COMMAND = 0x0008, /**< Command register, used to control the MMU */
-	MALI_MMU_REGISTER_PAGE_FAULT_ADDR = 0x000C, /**< Logical address of the last page fault */
-	MALI_MMU_REGISTER_ZAP_ONE_LINE = 0x010, /**< Used to invalidate the mapping of a single page from the MMU */
-	MALI_MMU_REGISTER_INT_RAWSTAT = 0x0014, /**< Raw interrupt status, all interrupts visible */
-	MALI_MMU_REGISTER_INT_CLEAR = 0x0018, /**< Indicate to the MMU that the interrupt has been received */
-	MALI_MMU_REGISTER_INT_MASK = 0x001C, /**< Enable/disable types of interrupts */
-	MALI_MMU_REGISTER_INT_STATUS = 0x0020 /**< Interrupt status based on the mask */
-} mali_mmu_register;
-
-/**
- * MMU interrupt register bits
- * Each cause of the interrupt is reported
- * through the (raw) interrupt status registers.
- * Multiple interrupts can be pending, so multiple bits
- * can be set at once.
- */
-typedef enum mali_mmu_interrupt
-{
-	MALI_MMU_INTERRUPT_PAGE_FAULT = 0x01, /**< A page fault occured */
-	MALI_MMU_INTERRUPT_READ_BUS_ERROR = 0x02 /**< A bus read error occured */
-} mali_mmu_interrupt;
-
-/**
  * MMU commands
  * These are the commands that can be sent
  * to the MMU unit.
  */
-typedef enum mali_mmu_command
-{
+typedef enum mali_mmu_command {
 	MALI_MMU_COMMAND_ENABLE_PAGING = 0x00, /**< Enable paging (memory translation) */
 	MALI_MMU_COMMAND_DISABLE_PAGING = 0x01, /**< Disable paging (memory translation) */
 	MALI_MMU_COMMAND_ENABLE_STALL = 0x02, /**<  Enable stall on page fault */
@@ -70,49 +38,6 @@ typedef enum mali_mmu_command
 	MALI_MMU_COMMAND_HARD_RESET = 0x06 /**< Reset the MMU back to power-on settings */
 } mali_mmu_command;
 
-typedef enum mali_mmu_status_bits
-{
-	MALI_MMU_STATUS_BIT_PAGING_ENABLED      = 1 << 0,
-	MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE   = 1 << 1,
-	MALI_MMU_STATUS_BIT_STALL_ACTIVE        = 1 << 2,
-	MALI_MMU_STATUS_BIT_IDLE                = 1 << 3,
-	MALI_MMU_STATUS_BIT_REPLAY_BUFFER_EMPTY = 1 << 4,
-	MALI_MMU_STATUS_BIT_PAGE_FAULT_IS_WRITE = 1 << 5,
-} mali_mmu_status_bits;
-
-/**
- * Definition of the MMU struct
- * Used to track a MMU unit in the system.
- * Contains information about the mapping of the registers
- */
-struct mali_mmu_core
-{
-	struct mali_hw_core hw_core; /**< Common for all HW cores */
-	struct mali_group *group;    /**< Parent core group */
-	_mali_osk_irq_t *irq;        /**< IRQ handler */
-};
-
-/**
- * The MMU interrupt handler
- * Upper half of the MMU interrupt processing.
- * Called by the kernel when the MMU has triggered an interrupt.
- * The interrupt function supports IRQ sharing. So it'll probe the MMU in question
- * @param irq The irq number (not used)
- * @param dev_id Points to the MMU object being handled
- * @param regs Registers of interrupted process (not used)
- * @return Standard Linux interrupt result.
- *         Subset used by the driver is IRQ_HANDLED processed
- *                                      IRQ_NONE Not processed
- */
-static _mali_osk_errcode_t mali_mmu_upper_half(void * data);
-
-/**
- * The MMU reset hander
- * Bottom half of the MMU interrupt processing for page faults and bus errors
- * @param work The item to operate on, NULL in our case
- */
-static void mali_mmu_bottom_half(void *data);
-
 static void mali_mmu_probe_trigger(void *data);
 static _mali_osk_errcode_t mali_mmu_probe_ack(void *data);
 
@@ -121,27 +46,38 @@ MALI_STATIC_INLINE _mali_osk_errcode_t mali_mmu_raw_reset(struct mali_mmu_core *
 /* page fault queue flush helper pages
  * note that the mapping pointers are currently unused outside of the initialization functions */
 static u32 mali_page_fault_flush_page_directory = MALI_INVALID_PAGE;
+static mali_io_address mali_page_fault_flush_page_directory_mapping = NULL;
 static u32 mali_page_fault_flush_page_table = MALI_INVALID_PAGE;
+static mali_io_address mali_page_fault_flush_page_table_mapping = NULL;
 static u32 mali_page_fault_flush_data_page = MALI_INVALID_PAGE;
+static mali_io_address mali_page_fault_flush_data_page_mapping = NULL;
 
 /* an empty page directory (no address valid) which is active on any MMU not currently marked as in use */
-static u32 mali_empty_page_directory = MALI_INVALID_PAGE;
+static u32 mali_empty_page_directory_phys   = MALI_INVALID_PAGE;
+static mali_io_address mali_empty_page_directory_virt = NULL;
+
 
 _mali_osk_errcode_t mali_mmu_initialize(void)
 {
 	/* allocate the helper pages */
-	mali_empty_page_directory = mali_allocate_empty_page();
-	if(0 == mali_empty_page_directory)
-	{
-		mali_empty_page_directory = MALI_INVALID_PAGE;
+	mali_empty_page_directory_phys = mali_allocate_empty_page(&mali_empty_page_directory_virt);
+	if (0 == mali_empty_page_directory_phys) {
+		MALI_DEBUG_PRINT_ERROR(("Mali MMU: Could not allocate empty page directory.\n"));
+		mali_empty_page_directory_phys = MALI_INVALID_PAGE;
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
 	if (_MALI_OSK_ERR_OK != mali_create_fault_flush_pages(&mali_page_fault_flush_page_directory,
-	                                &mali_page_fault_flush_page_table, &mali_page_fault_flush_data_page))
-	{
-		mali_free_empty_page(mali_empty_page_directory);
-		return _MALI_OSK_ERR_FAULT;
+			&mali_page_fault_flush_page_directory_mapping,
+			&mali_page_fault_flush_page_table,
+			&mali_page_fault_flush_page_table_mapping,
+			&mali_page_fault_flush_data_page,
+			&mali_page_fault_flush_data_page_mapping)) {
+		MALI_DEBUG_PRINT_ERROR(("Mali MMU: Could not allocate fault flush pages\n"));
+		mali_free_empty_page(mali_empty_page_directory_phys, mali_empty_page_directory_virt);
+		mali_empty_page_directory_phys = MALI_INVALID_PAGE;
+		mali_empty_page_directory_virt = NULL;
+		return _MALI_OSK_ERR_NOMEM;
 	}
 
 	return _MALI_OSK_ERR_OK;
@@ -152,52 +88,57 @@ void mali_mmu_terminate(void)
 	MALI_DEBUG_PRINT(3, ("Mali MMU: terminating\n"));
 
 	/* Free global helper pages */
-	mali_free_empty_page(mali_empty_page_directory);
+	mali_free_empty_page(mali_empty_page_directory_phys, mali_empty_page_directory_virt);
+	mali_empty_page_directory_phys = MALI_INVALID_PAGE;
+	mali_empty_page_directory_virt = NULL;
 
 	/* Free the page fault flush pages */
-	mali_destroy_fault_flush_pages(&mali_page_fault_flush_page_directory,
-	                            &mali_page_fault_flush_page_table, &mali_page_fault_flush_data_page);
+	mali_destroy_fault_flush_pages(&mali_page_fault_flush_page_directory, &mali_page_fault_flush_page_directory_mapping,
+				       &mali_page_fault_flush_page_table, &mali_page_fault_flush_page_table_mapping,
+				       &mali_page_fault_flush_data_page, &mali_page_fault_flush_data_page_mapping);
 }
 
-struct mali_mmu_core *mali_mmu_create(_mali_osk_resource_t *resource)
+struct mali_mmu_core *mali_mmu_create(_mali_osk_resource_t *resource, struct mali_group *group, mali_bool is_virtual)
 {
-	struct mali_mmu_core* mmu = NULL;
+	struct mali_mmu_core *mmu = NULL;
 
 	MALI_DEBUG_ASSERT_POINTER(resource);
 
 	MALI_DEBUG_PRINT(2, ("Mali MMU: Creating Mali MMU: %s\n", resource->description));
 
-	mmu = _mali_osk_calloc(1,sizeof(struct mali_mmu_core));
-	if (NULL != mmu)
-	{
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&mmu->hw_core, resource, MALI_MMU_REGISTERS_SIZE))
-		{
-			if (_MALI_OSK_ERR_OK == mali_mmu_reset(mmu))
-			{
-				/* Setup IRQ handlers (which will do IRQ probing if needed) */
-				mmu->irq = _mali_osk_irq_init(resource->irq,
-							      mali_mmu_upper_half,
-							      mali_mmu_bottom_half,
-							      mali_mmu_probe_trigger,
-							      mali_mmu_probe_ack,
-							      mmu,
-							      "mali_mmu_irq_handlers");
-				if (NULL != mmu->irq)
-				{
+	mmu = _mali_osk_calloc(1, sizeof(struct mali_mmu_core));
+	if (NULL != mmu) {
+		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&mmu->hw_core, resource, MALI_MMU_REGISTERS_SIZE)) {
+			if (_MALI_OSK_ERR_OK == mali_group_add_mmu_core(group, mmu)) {
+				if (is_virtual) {
+					/* Skip reset and IRQ setup for virtual MMU */
 					return mmu;
 				}
-				else
-				{
-					MALI_PRINT_ERROR(("Failed to setup interrupt handlers for MMU %s\n", mmu->hw_core.description));
+
+				if (_MALI_OSK_ERR_OK == mali_mmu_reset(mmu)) {
+					/* Setup IRQ handlers (which will do IRQ probing if needed) */
+					mmu->irq = _mali_osk_irq_init(resource->irq,
+								      mali_group_upper_half_mmu,
+								      group,
+								      mali_mmu_probe_trigger,
+								      mali_mmu_probe_ack,
+								      mmu,
+								      resource->description);
+					if (NULL != mmu->irq) {
+						return mmu;
+					} else {
+						MALI_PRINT_ERROR(("Mali MMU: Failed to setup interrupt handlers for MMU %s\n", mmu->hw_core.description));
+					}
 				}
+				mali_group_remove_mmu_core(group);
+			} else {
+				MALI_PRINT_ERROR(("Mali MMU: Failed to add core %s to group\n", mmu->hw_core.description));
 			}
 			mali_hw_core_delete(&mmu->hw_core);
 		}
 
 		_mali_osk_free(mmu);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Failed to allocate memory for MMU\n"));
 	}
 
@@ -206,164 +147,132 @@ struct mali_mmu_core *mali_mmu_create(_mali_osk_resource_t *resource)
 
 void mali_mmu_delete(struct mali_mmu_core *mmu)
 {
-	_mali_osk_irq_term(mmu->irq);
+	if (NULL != mmu->irq) {
+		_mali_osk_irq_term(mmu->irq);
+	}
+
 	mali_hw_core_delete(&mmu->hw_core);
 	_mali_osk_free(mmu);
 }
 
-void mali_mmu_set_group(struct mali_mmu_core *mmu, struct mali_group *group)
-{
-	mmu->group = group;
-}
-
 static void mali_mmu_enable_paging(struct mali_mmu_core *mmu)
 {
-	const int max_loop_count = 100;
-	const int delay_in_usecs = 1;
 	int i;
 
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_ENABLE_PAGING);
 
-	for (i = 0; i < max_loop_count; ++i)
-	{
-		if (mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS) & MALI_MMU_STATUS_BIT_PAGING_ENABLED)
-		{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; ++i) {
+		if (mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS) & MALI_MMU_STATUS_BIT_PAGING_ENABLED) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(delay_in_usecs);
 	}
-	if (max_loop_count == i)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Enable paging request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
 	}
 }
 
-mali_bool mali_mmu_enable_stall(struct mali_mmu_core *mmu)
+/**
+ * Issues the enable stall command to the MMU and waits for HW to complete the request
+ * @param mmu The MMU to enable paging for
+ * @return MALI_TRUE if HW stall was successfully engaged, otherwise MALI_FALSE (req timed out)
+ */
+static mali_bool mali_mmu_enable_stall(struct mali_mmu_core *mmu)
 {
-	const int max_loop_count = 100;
-	const int delay_in_usecs = 999;
 	int i;
-	u32 mmu_status;
+	u32 mmu_status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
 
-	/* There are no group when it is called from mali_mmu_create */
-	if ( mmu->group ) MALI_ASSERT_GROUP_LOCKED(mmu->group);
-
-	mmu_status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-
-	if ( 0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED) )
-	{
-		MALI_DEBUG_PRINT(4, ("MMU stall is implicit when Paging is not enebled.\n"));
+	if (0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED)) {
+		MALI_DEBUG_PRINT(4, ("MMU stall is implicit when Paging is not enabled.\n"));
 		return MALI_TRUE;
 	}
 
-	if ( mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE )
-	{
+	if (mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) {
 		MALI_DEBUG_PRINT(3, ("Aborting MMU stall request since it is in pagefault state.\n"));
 		return MALI_FALSE;
 	}
 
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_ENABLE_STALL);
 
-	for (i = 0; i < max_loop_count; ++i)
-	{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; ++i) {
 		mmu_status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-		if ( mmu_status & (MALI_MMU_STATUS_BIT_STALL_ACTIVE|MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE))
-		{
+		if (mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) {
 			break;
 		}
-		if ( 0 == (mmu_status & ( MALI_MMU_STATUS_BIT_PAGING_ENABLED )))
-		{
+		if ((mmu_status & MALI_MMU_STATUS_BIT_STALL_ACTIVE) && (0 == (mmu_status & MALI_MMU_STATUS_BIT_STALL_NOT_ACTIVE))) {
+			break;
+		}
+		if (0 == (mmu_status & (MALI_MMU_STATUS_BIT_PAGING_ENABLED))) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(delay_in_usecs);
 	}
-	if (max_loop_count == i)
-	{
-		MALI_PRINT_ERROR(("Enable stall request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
+	if (MALI_REG_POLL_COUNT_FAST == i) {
+		MALI_DEBUG_PRINT(2, ("Enable stall request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
 		return MALI_FALSE;
 	}
 
-	if ( mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE )
-	{
-		MALI_DEBUG_PRINT(3, ("Aborting MMU stall request since it has a pagefault.\n"));
+	if (mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) {
+		MALI_DEBUG_PRINT(2, ("Aborting MMU stall request since it has a pagefault.\n"));
 		return MALI_FALSE;
 	}
 
 	return MALI_TRUE;
 }
 
-void mali_mmu_disable_stall(struct mali_mmu_core *mmu)
+/**
+ * Issues the disable stall command to the MMU and waits for HW to complete the request
+ * @param mmu The MMU to enable paging for
+ */
+static void mali_mmu_disable_stall(struct mali_mmu_core *mmu)
 {
-	const int max_loop_count = 100;
-	const int delay_in_usecs = 1;
 	int i;
-	u32 mmu_status;
-	/* There are no group when it is called from mali_mmu_create */
-	if ( mmu->group ) MALI_ASSERT_GROUP_LOCKED(mmu->group);
+	u32 mmu_status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
 
-	mmu_status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-
-	if ( 0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED ))
-	{
+	if (0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED)) {
 		MALI_DEBUG_PRINT(3, ("MMU disable skipped since it was not enabled.\n"));
 		return;
 	}
-	if (mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE)
-	{
+	if (mmu_status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) {
 		MALI_DEBUG_PRINT(2, ("Aborting MMU disable stall request since it is in pagefault state.\n"));
 		return;
 	}
 
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_DISABLE_STALL);
 
-	for (i = 0; i < max_loop_count; ++i)
-	{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; ++i) {
 		u32 status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-		if ( 0 == (status & MALI_MMU_STATUS_BIT_STALL_ACTIVE) )
-		{
+		if (0 == (status & MALI_MMU_STATUS_BIT_STALL_ACTIVE)) {
 			break;
 		}
-		if ( status &  MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE )
-		{
+		if (status &  MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) {
 			break;
 		}
-		if ( 0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED ))
-		{
+		if (0 == (mmu_status & MALI_MMU_STATUS_BIT_PAGING_ENABLED)) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(delay_in_usecs);
 	}
-	if (max_loop_count == i) MALI_DEBUG_PRINT(1,("Disable stall request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
+	if (MALI_REG_POLL_COUNT_FAST == i) MALI_DEBUG_PRINT(1, ("Disable stall request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
 }
 
 void mali_mmu_page_fault_done(struct mali_mmu_core *mmu)
 {
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 	MALI_DEBUG_PRINT(4, ("Mali MMU: %s: Leaving page fault mode\n", mmu->hw_core.description));
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_PAGE_FAULT_DONE);
 }
 
 MALI_STATIC_INLINE _mali_osk_errcode_t mali_mmu_raw_reset(struct mali_mmu_core *mmu)
 {
-	const int max_loop_count = 100;
-	const int delay_in_usecs = 1;
 	int i;
-	/* The _if_ is neccessary when called from mali_mmu_create and NULL==group */
-	if (mmu->group)MALI_ASSERT_GROUP_LOCKED(mmu->group);
 
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR, 0xCAFEBABE);
+	MALI_DEBUG_ASSERT(0xCAFEB000 == mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR));
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_HARD_RESET);
 
-	for (i = 0; i < max_loop_count; ++i)
-	{
-		if (mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR) == 0)
-		{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; ++i) {
+		if (mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR) == 0) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(delay_in_usecs);
 	}
-	if (max_loop_count == i)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Reset request failed, MMU status is 0x%08X\n", mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)));
 		return _MALI_OSK_ERR_FAULT;
 	}
@@ -376,24 +285,18 @@ _mali_osk_errcode_t mali_mmu_reset(struct mali_mmu_core *mmu)
 	_mali_osk_errcode_t err = _MALI_OSK_ERR_FAULT;
 	mali_bool stall_success;
 	MALI_DEBUG_ASSERT_POINTER(mmu);
-	/* The _if_ is neccessary when called from mali_mmu_create and NULL==group */
-	if (mmu->group)
-	{
-		MALI_ASSERT_GROUP_LOCKED(mmu->group);
-	}
 
 	stall_success = mali_mmu_enable_stall(mmu);
-
-	/* The stall can not fail in current hw-state */
-	MALI_DEBUG_ASSERT(stall_success);
+	if (!stall_success) {
+		err = _MALI_OSK_ERR_BUSY;
+	}
 
 	MALI_DEBUG_PRINT(3, ("Mali MMU: mali_kernel_mmu_reset: %s\n", mmu->hw_core.description));
 
-	if (_MALI_OSK_ERR_OK == mali_mmu_raw_reset(mmu))
-	{
+	if (_MALI_OSK_ERR_OK == mali_mmu_raw_reset(mmu)) {
 		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_MASK, MALI_MMU_INTERRUPT_PAGE_FAULT | MALI_MMU_INTERRUPT_READ_BUS_ERROR);
 		/* no session is active, so just activate the empty page directory */
-		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR, mali_empty_page_directory);
+		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR, mali_empty_page_directory_phys);
 		mali_mmu_enable_paging(mmu);
 		err = _MALI_OSK_ERR_OK;
 	}
@@ -402,96 +305,13 @@ _mali_osk_errcode_t mali_mmu_reset(struct mali_mmu_core *mmu)
 	return err;
 }
 
-
-/* ------------- interrupt handling below ------------------ */
-
-static _mali_osk_errcode_t mali_mmu_upper_half(void * data)
-{
-	struct mali_mmu_core *mmu = (struct mali_mmu_core *)data;
-	u32 int_stat;
-
-	MALI_DEBUG_ASSERT_POINTER(mmu);
-
-	/* Check if it was our device which caused the interrupt (we could be sharing the IRQ line) */
-	int_stat = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_STATUS);
-	if (0 != int_stat)
-	{
-		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_MASK, 0);
-		mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-
-		if (int_stat & MALI_MMU_INTERRUPT_PAGE_FAULT)
-		{
-			_mali_osk_irq_schedulework(mmu->irq);
-		}
-
-		if (int_stat & MALI_MMU_INTERRUPT_READ_BUS_ERROR)
-		{
-			/* clear interrupt flag */
-			mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_CLEAR, MALI_MMU_INTERRUPT_READ_BUS_ERROR);
-			/* reenable it */
-			mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_MASK,
-			                            mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_MASK) | MALI_MMU_INTERRUPT_READ_BUS_ERROR);
-			MALI_PRINT_ERROR(("Mali MMU: Read bus error\n"));
-		}
-		return _MALI_OSK_ERR_OK;
-	}
-
-	return _MALI_OSK_ERR_FAULT;
-}
-
-static void mali_mmu_bottom_half(void * data)
-{
-	struct mali_mmu_core *mmu = (struct mali_mmu_core*)data;
-	u32 raw, status, fault_address;
-
-	MALI_DEBUG_ASSERT_POINTER(mmu);
-
-	MALI_DEBUG_PRINT(3, ("Mali MMU: Page fault bottom half: Locking subsystems\n"));
-
-	mali_group_lock(mmu->group); /* Unlocked in mali_group_bottom_half */
-
-	if ( MALI_FALSE == mali_group_power_is_on(mmu->group) )
-	{
-		MALI_PRINT_ERROR(("Interrupt bottom half of %s when core is OFF.",mmu->hw_core.description));
-		mali_group_unlock(mmu->group);
-		return;
-	}
-
-	raw = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_RAWSTAT);
-	status = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
-
-	if ( (0==(raw & MALI_MMU_INTERRUPT_PAGE_FAULT)) &&  (0==(status & MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE)) )
-	{
-		MALI_DEBUG_PRINT(2, ("Mali MMU: Page fault bottom half: No Irq found.\n"));
-		mali_group_unlock(mmu->group);
-		/* MALI_DEBUG_ASSERT(0); */
-		return;
-	}
-
-	/* An actual page fault has occurred. */
-
-	fault_address = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_PAGE_FAULT_ADDR);
-
-	MALI_DEBUG_PRINT(2,("Mali MMU: Page fault detected at 0x%x from bus id %d of type %s on %s\n",
-	           (void*)fault_address,
-	           (status >> 6) & 0x1F,
-	           (status & 32) ? "write" : "read",
-	           mmu->hw_core.description));
-
-	mali_group_bottom_half(mmu->group, GROUP_EVENT_MMU_PAGE_FAULT); /* Unlocks the group lock */
-}
-
 mali_bool mali_mmu_zap_tlb(struct mali_mmu_core *mmu)
 {
-	mali_bool stall_success;
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
-
-	stall_success = mali_mmu_enable_stall(mmu);
+	mali_bool stall_success = mali_mmu_enable_stall(mmu);
 
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_ZAP_CACHE);
 
-	if (MALI_FALSE == stall_success)
-	{
+	if (MALI_FALSE == stall_success) {
 		/* False means that it is in Pagefault state. Not possible to disable_stall then */
 		return MALI_FALSE;
 	}
@@ -502,75 +322,73 @@ mali_bool mali_mmu_zap_tlb(struct mali_mmu_core *mmu)
 
 void mali_mmu_zap_tlb_without_stall(struct mali_mmu_core *mmu)
 {
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_ZAP_CACHE);
 }
 
 
 void mali_mmu_invalidate_page(struct mali_mmu_core *mmu, u32 mali_address)
 {
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_ZAP_ONE_LINE, MALI_MMU_PDE_ENTRY(mali_address));
 }
 
 static void mali_mmu_activate_address_space(struct mali_mmu_core *mmu, u32 page_directory)
 {
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 	/* The MMU must be in stalled or page fault mode, for this writing to work */
-	MALI_DEBUG_ASSERT( 0 != ( mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)
-							  & (MALI_MMU_STATUS_BIT_STALL_ACTIVE|MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE) ) );
+	MALI_DEBUG_ASSERT(0 != (mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS)
+				& (MALI_MMU_STATUS_BIT_STALL_ACTIVE | MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE)));
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_DTE_ADDR, page_directory);
 	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_COMMAND, MALI_MMU_COMMAND_ZAP_CACHE);
 
 }
 
-mali_bool mali_mmu_activate_page_directory(struct mali_mmu_core *mmu, struct mali_page_directory *pagedir)
+void mali_mmu_activate_page_directory(struct mali_mmu_core *mmu, struct mali_page_directory *pagedir)
 {
 	mali_bool stall_success;
 	MALI_DEBUG_ASSERT_POINTER(mmu);
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 
 	MALI_DEBUG_PRINT(5, ("Asked to activate page directory 0x%x on MMU %s\n", pagedir, mmu->hw_core.description));
-	stall_success = mali_mmu_enable_stall(mmu);
 
-	if ( MALI_FALSE==stall_success ) return MALI_FALSE;
+	stall_success = mali_mmu_enable_stall(mmu);
+	MALI_DEBUG_ASSERT(stall_success);
+	MALI_IGNORE(stall_success);
 	mali_mmu_activate_address_space(mmu, pagedir->page_directory);
 	mali_mmu_disable_stall(mmu);
-	return MALI_TRUE;
 }
 
-void mali_mmu_activate_empty_page_directory(struct mali_mmu_core* mmu)
+void mali_mmu_activate_empty_page_directory(struct mali_mmu_core *mmu)
 {
 	mali_bool stall_success;
+
 	MALI_DEBUG_ASSERT_POINTER(mmu);
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 	MALI_DEBUG_PRINT(3, ("Activating the empty page directory on MMU %s\n", mmu->hw_core.description));
 
 	stall_success = mali_mmu_enable_stall(mmu);
+
 	/* This function can only be called when the core is idle, so it could not fail. */
-	MALI_DEBUG_ASSERT( stall_success );
-	mali_mmu_activate_address_space(mmu, mali_empty_page_directory);
+	MALI_DEBUG_ASSERT(stall_success);
+	MALI_IGNORE(stall_success);
+
+	mali_mmu_activate_address_space(mmu, mali_empty_page_directory_phys);
 	mali_mmu_disable_stall(mmu);
 }
 
-void mali_mmu_activate_fault_flush_page_directory(struct mali_mmu_core* mmu)
+void mali_mmu_activate_fault_flush_page_directory(struct mali_mmu_core *mmu)
 {
 	mali_bool stall_success;
 	MALI_DEBUG_ASSERT_POINTER(mmu);
-	MALI_ASSERT_GROUP_LOCKED(mmu->group);
 
 	MALI_DEBUG_PRINT(3, ("Activating the page fault flush page directory on MMU %s\n", mmu->hw_core.description));
 	stall_success = mali_mmu_enable_stall(mmu);
 	/* This function is expect to fail the stalling, since it might be in PageFault mode when it is called */
 	mali_mmu_activate_address_space(mmu, mali_page_fault_flush_page_directory);
-	if ( MALI_TRUE==stall_success ) mali_mmu_disable_stall(mmu);
+	if (MALI_TRUE == stall_success) mali_mmu_disable_stall(mmu);
 }
 
 /* Is called when we want the mmu to give an interrupt */
 static void mali_mmu_probe_trigger(void *data)
 {
 	struct mali_mmu_core *mmu = (struct mali_mmu_core *)data;
-	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_RAWSTAT, MALI_MMU_INTERRUPT_PAGE_FAULT|MALI_MMU_INTERRUPT_READ_BUS_ERROR);
+	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_RAWSTAT, MALI_MMU_INTERRUPT_PAGE_FAULT | MALI_MMU_INTERRUPT_READ_BUS_ERROR);
 }
 
 /* Is called when the irq probe wants the mmu to acknowledge an interrupt from the hw */
@@ -582,29 +400,22 @@ static _mali_osk_errcode_t mali_mmu_probe_ack(void *data)
 	int_stat = mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_STATUS);
 
 	MALI_DEBUG_PRINT(2, ("mali_mmu_probe_irq_acknowledge: intstat 0x%x\n", int_stat));
-	if (int_stat & MALI_MMU_INTERRUPT_PAGE_FAULT)
-	{
+	if (int_stat & MALI_MMU_INTERRUPT_PAGE_FAULT) {
 		MALI_DEBUG_PRINT(2, ("Probe: Page fault detect: PASSED\n"));
 		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_CLEAR, MALI_MMU_INTERRUPT_PAGE_FAULT);
-	}
-	else
-	{
+	} else {
 		MALI_DEBUG_PRINT(1, ("Probe: Page fault detect: FAILED\n"));
 	}
 
-	if (int_stat & MALI_MMU_INTERRUPT_READ_BUS_ERROR)
-	{
+	if (int_stat & MALI_MMU_INTERRUPT_READ_BUS_ERROR) {
 		MALI_DEBUG_PRINT(2, ("Probe: Bus read error detect: PASSED\n"));
 		mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_CLEAR, MALI_MMU_INTERRUPT_READ_BUS_ERROR);
-	}
-	else
-	{
+	} else {
 		MALI_DEBUG_PRINT(1, ("Probe: Bus read error detect: FAILED\n"));
 	}
 
-	if ( (int_stat & (MALI_MMU_INTERRUPT_PAGE_FAULT|MALI_MMU_INTERRUPT_READ_BUS_ERROR)) ==
-	                 (MALI_MMU_INTERRUPT_PAGE_FAULT|MALI_MMU_INTERRUPT_READ_BUS_ERROR))
-	{
+	if ((int_stat & (MALI_MMU_INTERRUPT_PAGE_FAULT | MALI_MMU_INTERRUPT_READ_BUS_ERROR)) ==
+	    (MALI_MMU_INTERRUPT_PAGE_FAULT | MALI_MMU_INTERRUPT_READ_BUS_ERROR)) {
 		return _MALI_OSK_ERR_OK;
 	}
 
diff --git a/drivers/gpu/mali/mali/common/mali_mmu.h b/drivers/gpu/mali/mali/common/mali_mmu.h
old mode 100644
new mode 100755
index da99026..f3040da
--- a/drivers/gpu/mali/mali/common/mali_mmu.h
+++ b/drivers/gpu/mali/mali/common/mali_mmu.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,18 +13,65 @@
 
 #include "mali_osk.h"
 #include "mali_mmu_page_directory.h"
+#include "mali_hw_core.h"
 
 /* Forward declaration from mali_group.h */
 struct mali_group;
 
-struct mali_mmu_core;
+/**
+ * MMU register numbers
+ * Used in the register read/write routines.
+ * See the hardware documentation for more information about each register
+ */
+typedef enum mali_mmu_register {
+	MALI_MMU_REGISTER_DTE_ADDR = 0x0000, /**< Current Page Directory Pointer */
+	MALI_MMU_REGISTER_STATUS = 0x0004, /**< Status of the MMU */
+	MALI_MMU_REGISTER_COMMAND = 0x0008, /**< Command register, used to control the MMU */
+	MALI_MMU_REGISTER_PAGE_FAULT_ADDR = 0x000C, /**< Logical address of the last page fault */
+	MALI_MMU_REGISTER_ZAP_ONE_LINE = 0x010, /**< Used to invalidate the mapping of a single page from the MMU */
+	MALI_MMU_REGISTER_INT_RAWSTAT = 0x0014, /**< Raw interrupt status, all interrupts visible */
+	MALI_MMU_REGISTER_INT_CLEAR = 0x0018, /**< Indicate to the MMU that the interrupt has been received */
+	MALI_MMU_REGISTER_INT_MASK = 0x001C, /**< Enable/disable types of interrupts */
+	MALI_MMU_REGISTER_INT_STATUS = 0x0020 /**< Interrupt status based on the mask */
+} mali_mmu_register;
+
+/**
+ * MMU interrupt register bits
+ * Each cause of the interrupt is reported
+ * through the (raw) interrupt status registers.
+ * Multiple interrupts can be pending, so multiple bits
+ * can be set at once.
+ */
+typedef enum mali_mmu_interrupt {
+	MALI_MMU_INTERRUPT_PAGE_FAULT = 0x01, /**< A page fault occured */
+	MALI_MMU_INTERRUPT_READ_BUS_ERROR = 0x02 /**< A bus read error occured */
+} mali_mmu_interrupt;
+
+typedef enum mali_mmu_status_bits {
+	MALI_MMU_STATUS_BIT_PAGING_ENABLED      = 1 << 0,
+	MALI_MMU_STATUS_BIT_PAGE_FAULT_ACTIVE   = 1 << 1,
+	MALI_MMU_STATUS_BIT_STALL_ACTIVE        = 1 << 2,
+	MALI_MMU_STATUS_BIT_IDLE                = 1 << 3,
+	MALI_MMU_STATUS_BIT_REPLAY_BUFFER_EMPTY = 1 << 4,
+	MALI_MMU_STATUS_BIT_PAGE_FAULT_IS_WRITE = 1 << 5,
+	MALI_MMU_STATUS_BIT_STALL_NOT_ACTIVE    = 1 << 31,
+} mali_mmu_status_bits;
+
+/**
+ * Definition of the MMU struct
+ * Used to track a MMU unit in the system.
+ * Contains information about the mapping of the registers
+ */
+struct mali_mmu_core {
+	struct mali_hw_core hw_core; /**< Common for all HW cores */
+	_mali_osk_irq_t *irq;        /**< IRQ handler */
+};
 
 _mali_osk_errcode_t mali_mmu_initialize(void);
 
 void mali_mmu_terminate(void);
 
-struct mali_mmu_core *mali_mmu_create(_mali_osk_resource_t *resource);
-void mali_mmu_set_group(struct mali_mmu_core *mmu, struct mali_group *group);
+struct mali_mmu_core *mali_mmu_create(_mali_osk_resource_t *resource, struct mali_group *group, mali_bool is_virtual);
 void mali_mmu_delete(struct mali_mmu_core *mmu);
 
 _mali_osk_errcode_t mali_mmu_reset(struct mali_mmu_core *mmu);
@@ -32,24 +79,36 @@ mali_bool mali_mmu_zap_tlb(struct mali_mmu_core *mmu);
 void mali_mmu_zap_tlb_without_stall(struct mali_mmu_core *mmu);
 void mali_mmu_invalidate_page(struct mali_mmu_core *mmu, u32 mali_address);
 
-mali_bool mali_mmu_activate_page_directory(struct mali_mmu_core* mmu, struct mali_page_directory *pagedir);
-void mali_mmu_activate_empty_page_directory(struct mali_mmu_core* mmu);
-void mali_mmu_activate_fault_flush_page_directory(struct mali_mmu_core* mmu);
+void mali_mmu_activate_page_directory(struct mali_mmu_core *mmu, struct mali_page_directory *pagedir);
+void mali_mmu_activate_empty_page_directory(struct mali_mmu_core *mmu);
+void mali_mmu_activate_fault_flush_page_directory(struct mali_mmu_core *mmu);
 
-/**
- * Issues the enable stall command to the MMU and waits for HW to complete the request
- * @param mmu The MMU to enable paging for
- * @return MALI_TRUE if HW stall was successfully engaged, otherwise MALI_FALSE (req timed out)
- */
-mali_bool mali_mmu_enable_stall(struct mali_mmu_core *mmu);
+void mali_mmu_page_fault_done(struct mali_mmu_core *mmu);
 
-/**
- * Issues the disable stall command to the MMU and waits for HW to complete the request
- * @param mmu The MMU to enable paging for
- */
-void mali_mmu_disable_stall(struct mali_mmu_core *mmu);
+/*** Register reading/writing functions ***/
+MALI_STATIC_INLINE u32 mali_mmu_get_int_status(struct mali_mmu_core *mmu)
+{
+	return mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_STATUS);
+}
 
-void mali_mmu_page_fault_done(struct mali_mmu_core *mmu);
+MALI_STATIC_INLINE u32 mali_mmu_get_rawstat(struct mali_mmu_core *mmu)
+{
+	return mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_INT_RAWSTAT);
+}
+
+MALI_STATIC_INLINE void mali_mmu_mask_all_interrupts(struct mali_mmu_core *mmu)
+{
+	mali_hw_core_register_write(&mmu->hw_core, MALI_MMU_REGISTER_INT_MASK, 0);
+}
+
+MALI_STATIC_INLINE u32 mali_mmu_get_status(struct mali_mmu_core *mmu)
+{
+	return mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_STATUS);
+}
 
+MALI_STATIC_INLINE u32 mali_mmu_get_page_fault_addr(struct mali_mmu_core *mmu)
+{
+	return mali_hw_core_register_read(&mmu->hw_core, MALI_MMU_REGISTER_PAGE_FAULT_ADDR);
+}
 
 #endif /* __MALI_MMU_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_mmu_page_directory.c b/drivers/gpu/mali/mali/common/mali_mmu_page_directory.c
old mode 100644
new mode 100755
index 383c411..b11bbe9
--- a/drivers/gpu/mali/mali/common/mali_mmu_page_directory.c
+++ b/drivers/gpu/mali/mali/common/mali_mmu_page_directory.c
@@ -1,114 +1,111 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
 #include "mali_kernel_common.h"
-#include "mali_kernel_core.h"
 #include "mali_osk.h"
+#include "mali_ukk.h"
 #include "mali_uk_types.h"
 #include "mali_mmu_page_directory.h"
 #include "mali_memory.h"
-
-#include "mali_cluster.h"
-#include "mali_group.h"
+#include "mali_l2_cache.h"
 
 static _mali_osk_errcode_t fill_page(mali_io_address mapping, u32 data);
 
-u32 mali_allocate_empty_page(void)
+u32 mali_allocate_empty_page(mali_io_address *virt_addr)
 {
 	_mali_osk_errcode_t err;
 	mali_io_address mapping;
 	u32 address;
 
-	if(_MALI_OSK_ERR_OK != mali_mmu_get_table_page(&address, &mapping))
-	{
+	if (_MALI_OSK_ERR_OK != mali_mmu_get_table_page(&address, &mapping)) {
 		/* Allocation failed */
+		MALI_DEBUG_PRINT(2, ("Mali MMU: Failed to get table page for empty pgdir\n"));
 		return 0;
 	}
 
-	MALI_DEBUG_ASSERT_POINTER( mapping );
+	MALI_DEBUG_ASSERT_POINTER(mapping);
 
 	err = fill_page(mapping, 0);
-	if (_MALI_OSK_ERR_OK != err)
-	{
-		mali_mmu_release_table_page(address);
+	if (_MALI_OSK_ERR_OK != err) {
+		mali_mmu_release_table_page(address, mapping);
+		MALI_DEBUG_PRINT(2, ("Mali MMU: Failed to zero page\n"));
+		return 0;
 	}
+
+	*virt_addr = mapping;
 	return address;
 }
 
-void mali_free_empty_page(u32 address)
+void mali_free_empty_page(u32 address, mali_io_address virt_addr)
 {
-	if (MALI_INVALID_PAGE != address)
-	{
-		mali_mmu_release_table_page(address);
+	if (MALI_INVALID_PAGE != address) {
+		mali_mmu_release_table_page(address, virt_addr);
 	}
 }
 
-_mali_osk_errcode_t mali_create_fault_flush_pages(u32 *page_directory, u32 *page_table, u32 *data_page)
+_mali_osk_errcode_t mali_create_fault_flush_pages(u32 *page_directory, mali_io_address *page_directory_mapping,
+		u32 *page_table, mali_io_address *page_table_mapping,
+		u32 *data_page, mali_io_address *data_page_mapping)
 {
 	_mali_osk_errcode_t err;
-	mali_io_address page_directory_mapping;
-	mali_io_address page_table_mapping;
-	mali_io_address data_page_mapping;
-
-	err = mali_mmu_get_table_page(data_page, &data_page_mapping);
-	if (_MALI_OSK_ERR_OK == err)
-	{
-		err = mali_mmu_get_table_page(page_table, &page_table_mapping);
-		if (_MALI_OSK_ERR_OK == err)
-		{
-			err = mali_mmu_get_table_page(page_directory, &page_directory_mapping);
-			if (_MALI_OSK_ERR_OK == err)
-			{
-				fill_page(data_page_mapping, 0);
-				fill_page(page_table_mapping, *data_page | MALI_MMU_FLAGS_WRITE_PERMISSION | MALI_MMU_FLAGS_READ_PERMISSION | MALI_MMU_FLAGS_PRESENT);
-				fill_page(page_directory_mapping, *page_table | MALI_MMU_FLAGS_PRESENT);
+
+	err = mali_mmu_get_table_page(data_page, data_page_mapping);
+	if (_MALI_OSK_ERR_OK == err) {
+		err = mali_mmu_get_table_page(page_table, page_table_mapping);
+		if (_MALI_OSK_ERR_OK == err) {
+			err = mali_mmu_get_table_page(page_directory, page_directory_mapping);
+			if (_MALI_OSK_ERR_OK == err) {
+				fill_page(*data_page_mapping, 0);
+				fill_page(*page_table_mapping, *data_page | MALI_MMU_FLAGS_DEFAULT);
+				fill_page(*page_directory_mapping, *page_table | MALI_MMU_FLAGS_PRESENT);
 				MALI_SUCCESS;
 			}
-			mali_mmu_release_table_page(*page_table);
+			mali_mmu_release_table_page(*page_table, *page_table_mapping);
 			*page_table = MALI_INVALID_PAGE;
 		}
-		mali_mmu_release_table_page(*data_page);
+		mali_mmu_release_table_page(*data_page, *data_page_mapping);
 		*data_page = MALI_INVALID_PAGE;
 	}
 	return err;
 }
 
-void mali_destroy_fault_flush_pages(u32 *page_directory, u32 *page_table, u32 *data_page)
+void mali_destroy_fault_flush_pages(u32 *page_directory, mali_io_address *page_directory_mapping,
+				    u32 *page_table, mali_io_address *page_table_mapping,
+				    u32 *data_page, mali_io_address *data_page_mapping)
 {
-	if (MALI_INVALID_PAGE != *page_directory)
-	{
-		mali_mmu_release_table_page(*page_directory);
+	if (MALI_INVALID_PAGE != *page_directory) {
+		mali_mmu_release_table_page(*page_directory, *page_directory_mapping);
 		*page_directory = MALI_INVALID_PAGE;
+		*page_directory_mapping = NULL;
 	}
 
-	if (MALI_INVALID_PAGE != *page_table)
-	{
-		mali_mmu_release_table_page(*page_table);
+	if (MALI_INVALID_PAGE != *page_table) {
+		mali_mmu_release_table_page(*page_table, *page_table_mapping);
 		*page_table = MALI_INVALID_PAGE;
+		*page_table_mapping = NULL;
 	}
 
-	if (MALI_INVALID_PAGE != *data_page)
-	{
-		mali_mmu_release_table_page(*data_page);
+	if (MALI_INVALID_PAGE != *data_page) {
+		mali_mmu_release_table_page(*data_page, *data_page_mapping);
 		*data_page = MALI_INVALID_PAGE;
+		*data_page_mapping = NULL;
 	}
 }
 
 static _mali_osk_errcode_t fill_page(mali_io_address mapping, u32 data)
 {
 	int i;
-	MALI_DEBUG_ASSERT_POINTER( mapping );
+	MALI_DEBUG_ASSERT_POINTER(mapping);
 
-	for(i = 0; i < MALI_MMU_PAGE_SIZE/4; i++)
-	{
-		_mali_osk_mem_iowrite32_relaxed( mapping, i * sizeof(u32), data);
+	for (i = 0; i < MALI_MMU_PAGE_SIZE / 4; i++) {
+		_mali_osk_mem_iowrite32_relaxed(mapping, i * sizeof(u32), data);
 	}
 	_mali_osk_mem_barrier();
 	MALI_SUCCESS;
@@ -123,31 +120,30 @@ _mali_osk_errcode_t mali_mmu_pagedir_map(struct mali_page_directory *pagedir, u3
 	u32 pde_phys;
 	int i;
 
-	for(i = first_pde; i <= last_pde; i++)
-	{
-		if(0 == (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, i*sizeof(u32)) & MALI_MMU_FLAGS_PRESENT))
-		{
+	if (last_pde < first_pde) {
+		MALI_ERROR(_MALI_OSK_ERR_INVALID_ARGS);
+	}
+
+	for (i = first_pde; i <= last_pde; i++) {
+		if (0 == (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, i * sizeof(u32)) & MALI_MMU_FLAGS_PRESENT)) {
 			/* Page table not present */
 			MALI_DEBUG_ASSERT(0 == pagedir->page_entries_usage_count[i]);
 			MALI_DEBUG_ASSERT(NULL == pagedir->page_entries_mapped[i]);
 
 			err = mali_mmu_get_table_page(&pde_phys, &pde_mapping);
-			if(_MALI_OSK_ERR_OK != err)
-			{
+			if (_MALI_OSK_ERR_OK != err) {
 				MALI_PRINT_ERROR(("Failed to allocate page table page.\n"));
 				return err;
 			}
 			pagedir->page_entries_mapped[i] = pde_mapping;
 
 			/* Update PDE, mark as present */
-			_mali_osk_mem_iowrite32_relaxed(pagedir->page_directory_mapped, i*sizeof(u32),
-			                pde_phys | MALI_MMU_FLAGS_PRESENT);
+			_mali_osk_mem_iowrite32_relaxed(pagedir->page_directory_mapped, i * sizeof(u32),
+							pde_phys | MALI_MMU_FLAGS_PRESENT);
 
 			MALI_DEBUG_ASSERT(0 == pagedir->page_entries_usage_count[i]);
 			pagedir->page_entries_usage_count[i] = 1;
-		}
-		else
-		{
+		} else {
 			pagedir->page_entries_usage_count[i]++;
 		}
 	}
@@ -162,8 +158,7 @@ MALI_STATIC_INLINE void mali_mmu_zero_pte(mali_io_address page_table, u32 mali_a
 	const int first_pte = MALI_MMU_PTE_ENTRY(mali_address);
 	const int last_pte = MALI_MMU_PTE_ENTRY(mali_address + size - 1);
 
-	for (i = first_pte; i <= last_pte; i++)
-	{
+	for (i = first_pte; i <= last_pte; i++) {
 		_mali_osk_mem_iowrite32_relaxed(page_table, i * sizeof(u32), 0);
 	}
 }
@@ -174,15 +169,13 @@ _mali_osk_errcode_t mali_mmu_pagedir_unmap(struct mali_page_directory *pagedir,
 	const int last_pde = MALI_MMU_PDE_ENTRY(mali_address + size - 1);
 	u32 left = size;
 	int i;
-#ifndef MALI_UNMAP_FLUSH_ALL_MALI_L2
 	mali_bool pd_changed = MALI_FALSE;
 	u32 pages_to_invalidate[3]; /* hard-coded to 3: max two pages from the PT level plus max one page from PD level */
 	u32 num_pages_inv = 0;
-#endif
+	mali_bool invalidate_all = MALI_FALSE; /* safety mechanism in case page_entries_usage_count is unreliable */
 
 	/* For all page directory entries in range. */
-	for (i = first_pde; i <= last_pde; i++)
-	{
+	for (i = first_pde; i <= last_pde; i++) {
 		u32 size_in_pde, offset;
 
 		MALI_DEBUG_ASSERT_POINTER(pagedir->page_entries_mapped[i]);
@@ -190,40 +183,36 @@ _mali_osk_errcode_t mali_mmu_pagedir_unmap(struct mali_page_directory *pagedir,
 
 		/* Offset into page table, 0 if mali_address is 4MiB aligned */
 		offset = (mali_address & (MALI_MMU_VIRTUAL_PAGE_SIZE - 1));
-		if (left < MALI_MMU_VIRTUAL_PAGE_SIZE - offset)
-		{
+		if (left < MALI_MMU_VIRTUAL_PAGE_SIZE - offset) {
 			size_in_pde = left;
-		}
-		else
-		{
+		} else {
 			size_in_pde = MALI_MMU_VIRTUAL_PAGE_SIZE - offset;
 		}
 
 		pagedir->page_entries_usage_count[i]--;
 
 		/* If entire page table is unused, free it */
-		if (0 == pagedir->page_entries_usage_count[i])
-		{
-			u32 page_address;
+		if (0 == pagedir->page_entries_usage_count[i]) {
+			u32 page_phys;
+			void *page_virt;
 			MALI_DEBUG_PRINT(4, ("Releasing page table as this is the last reference\n"));
 			/* last reference removed, no need to zero out each PTE  */
 
-			page_address = MALI_MMU_ENTRY_ADDRESS(_mali_osk_mem_ioread32(pagedir->page_directory_mapped, i*sizeof(u32)));
+			page_phys = MALI_MMU_ENTRY_ADDRESS(_mali_osk_mem_ioread32(pagedir->page_directory_mapped, i * sizeof(u32)));
+			page_virt = pagedir->page_entries_mapped[i];
 			pagedir->page_entries_mapped[i] = NULL;
-			_mali_osk_mem_iowrite32_relaxed(pagedir->page_directory_mapped, i*sizeof(u32), 0);
+			_mali_osk_mem_iowrite32_relaxed(pagedir->page_directory_mapped, i * sizeof(u32), 0);
 
-			mali_mmu_release_table_page(page_address);
-#ifndef MALI_UNMAP_FLUSH_ALL_MALI_L2
+			mali_mmu_release_table_page(page_phys, page_virt);
 			pd_changed = MALI_TRUE;
-#endif
-		}
-		else
-		{
-#ifndef MALI_UNMAP_FLUSH_ALL_MALI_L2
-			pages_to_invalidate[num_pages_inv] = mali_page_directory_get_phys_address(pagedir, i);
-			num_pages_inv++;
-			MALI_DEBUG_ASSERT(num_pages_inv<3);
-#endif
+		} else {
+			MALI_DEBUG_ASSERT(num_pages_inv < 2);
+			if (num_pages_inv < 2) {
+				pages_to_invalidate[num_pages_inv] = mali_page_directory_get_phys_address(pagedir, i);
+				num_pages_inv++;
+			} else {
+				invalidate_all = MALI_TRUE;
+			}
 
 			/* If part of the page table is still in use, zero the relevant PTEs */
 			mali_mmu_zero_pte(pagedir->page_entries_mapped[i], mali_address, size_in_pde);
@@ -234,20 +223,22 @@ _mali_osk_errcode_t mali_mmu_pagedir_unmap(struct mali_page_directory *pagedir,
 	}
 	_mali_osk_write_mem_barrier();
 
-#ifndef MALI_UNMAP_FLUSH_ALL_MALI_L2
 	/* L2 pages invalidation */
-	if (MALI_TRUE == pd_changed)
-	{
-		pages_to_invalidate[num_pages_inv] = pagedir->page_directory;
-		num_pages_inv++;
-		MALI_DEBUG_ASSERT(num_pages_inv<3);
+	if (MALI_TRUE == pd_changed) {
+		MALI_DEBUG_ASSERT(num_pages_inv < 3);
+		if (num_pages_inv < 3) {
+			pages_to_invalidate[num_pages_inv] = pagedir->page_directory;
+			num_pages_inv++;
+		} else {
+			invalidate_all = MALI_TRUE;
+		}
 	}
 
-	if (_MALI_PRODUCT_ID_MALI200 != mali_kernel_core_get_product_id())
-	{
-		mali_cluster_invalidate_pages(pages_to_invalidate, num_pages_inv);
+	if (invalidate_all) {
+		mali_l2_cache_invalidate_all();
+	} else {
+		mali_l2_cache_invalidate_all_pages(pages_to_invalidate, num_pages_inv);
 	}
-#endif
 
 	MALI_SUCCESS;
 }
@@ -257,13 +248,11 @@ struct mali_page_directory *mali_mmu_pagedir_alloc(void)
 	struct mali_page_directory *pagedir;
 
 	pagedir = _mali_osk_calloc(1, sizeof(struct mali_page_directory));
-	if(NULL == pagedir)
-	{
+	if (NULL == pagedir) {
 		return NULL;
 	}
 
-	if(_MALI_OSK_ERR_OK != mali_mmu_get_table_page(&pagedir->page_directory, &pagedir->page_directory_mapped))
-	{
+	if (_MALI_OSK_ERR_OK != mali_mmu_get_table_page(&pagedir->page_directory, &pagedir->page_directory_mapped)) {
 		_mali_osk_free(pagedir);
 		return NULL;
 	}
@@ -280,46 +269,42 @@ void mali_mmu_pagedir_free(struct mali_page_directory *pagedir)
 	int i;
 
 	/* Free referenced page tables and zero PDEs. */
-	for (i = 0; i < num_page_table_entries; i++)
-	{
-		if (pagedir->page_directory_mapped && (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, sizeof(u32)*i) & MALI_MMU_FLAGS_PRESENT))
-		{
-			mali_mmu_release_table_page( _mali_osk_mem_ioread32(pagedir->page_directory_mapped, i*sizeof(u32)) & ~MALI_MMU_FLAGS_MASK);
+	for (i = 0; i < num_page_table_entries; i++) {
+		if (pagedir->page_directory_mapped && (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, sizeof(u32)*i) & MALI_MMU_FLAGS_PRESENT)) {
+			u32 phys = _mali_osk_mem_ioread32(pagedir->page_directory_mapped, i * sizeof(u32)) & ~MALI_MMU_FLAGS_MASK;
 			_mali_osk_mem_iowrite32_relaxed(pagedir->page_directory_mapped, i * sizeof(u32), 0);
+			mali_mmu_release_table_page(phys, pagedir->page_entries_mapped[i]);
 		}
 	}
 	_mali_osk_write_mem_barrier();
 
 	/* Free the page directory page. */
-	mali_mmu_release_table_page(pagedir->page_directory);
+	mali_mmu_release_table_page(pagedir->page_directory, pagedir->page_directory_mapped);
 
 	_mali_osk_free(pagedir);
 }
 
 
-void mali_mmu_pagedir_update(struct mali_page_directory *pagedir, u32 mali_address, u32 phys_address, u32 size)
+void mali_mmu_pagedir_update(struct mali_page_directory *pagedir, u32 mali_address, u32 phys_address, u32 size, u32 permission_bits)
 {
 	u32 end_address = mali_address + size;
 
 	/* Map physical pages into MMU page tables */
-	for ( ; mali_address < end_address; mali_address += MALI_MMU_PAGE_SIZE, phys_address += MALI_MMU_PAGE_SIZE)
-	{
+	for (; mali_address < end_address; mali_address += MALI_MMU_PAGE_SIZE, phys_address += MALI_MMU_PAGE_SIZE) {
 		MALI_DEBUG_ASSERT_POINTER(pagedir->page_entries_mapped[MALI_MMU_PDE_ENTRY(mali_address)]);
 		_mali_osk_mem_iowrite32_relaxed(pagedir->page_entries_mapped[MALI_MMU_PDE_ENTRY(mali_address)],
-		                MALI_MMU_PTE_ENTRY(mali_address) * sizeof(u32),
-			        phys_address | MALI_MMU_FLAGS_WRITE_PERMISSION | MALI_MMU_FLAGS_READ_PERMISSION | MALI_MMU_FLAGS_PRESENT);
+						MALI_MMU_PTE_ENTRY(mali_address) * sizeof(u32),
+						phys_address | permission_bits);
 	}
-	_mali_osk_write_mem_barrier();
 }
 
 u32 mali_page_directory_get_phys_address(struct mali_page_directory *pagedir, u32 index)
 {
-	return (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, index*sizeof(u32)) & ~MALI_MMU_FLAGS_MASK);
+	return (_mali_osk_mem_ioread32(pagedir->page_directory_mapped, index * sizeof(u32)) & ~MALI_MMU_FLAGS_MASK);
 }
 
 /* For instrumented */
-struct dump_info
-{
+struct dump_info {
 	u32 buffer_left;
 	u32 register_writes_size;
 	u32 page_table_dump_size;
@@ -328,14 +313,12 @@ struct dump_info
 
 static _mali_osk_errcode_t writereg(u32 where, u32 what, const char *comment, struct dump_info *info)
 {
-	if (NULL != info)
-	{
-		info->register_writes_size += sizeof(u32)*2; /* two 32-bit words */
+	if (NULL != info) {
+		info->register_writes_size += sizeof(u32) * 2; /* two 32-bit words */
 
-		if (NULL != info->buffer)
-		{
+		if (NULL != info->buffer) {
 			/* check that we have enough space */
-			if (info->buffer_left < sizeof(u32)*2) MALI_ERROR(_MALI_OSK_ERR_NOMEM);
+			if (info->buffer_left < sizeof(u32) * 2) MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 
 			*info->buffer = where;
 			info->buffer++;
@@ -343,17 +326,16 @@ static _mali_osk_errcode_t writereg(u32 where, u32 what, const char *comment, st
 			*info->buffer = what;
 			info->buffer++;
 
-			info->buffer_left -= sizeof(u32)*2;
+			info->buffer_left -= sizeof(u32) * 2;
 		}
 	}
 
 	MALI_SUCCESS;
 }
 
-static _mali_osk_errcode_t dump_page(mali_io_address page, u32 phys_addr, struct dump_info * info)
+static _mali_osk_errcode_t mali_mmu_dump_page(mali_io_address page, u32 phys_addr, struct dump_info *info)
 {
-	if (NULL != info)
-	{
+	if (NULL != info) {
 		/* 4096 for the page and 4 bytes for the address */
 		const u32 page_size_in_elements = MALI_MMU_PAGE_SIZE / 4;
 		const u32 page_size_in_bytes = MALI_MMU_PAGE_SIZE;
@@ -361,8 +343,7 @@ static _mali_osk_errcode_t dump_page(mali_io_address page, u32 phys_addr, struct
 
 		info->page_table_dump_size += dump_size_in_bytes;
 
-		if (NULL != info->buffer)
-		{
+		if (NULL != info->buffer) {
 			if (info->buffer_left < dump_size_in_bytes) MALI_ERROR(_MALI_OSK_ERR_NOMEM);
 
 			*info->buffer = phys_addr;
@@ -378,27 +359,24 @@ static _mali_osk_errcode_t dump_page(mali_io_address page, u32 phys_addr, struct
 	MALI_SUCCESS;
 }
 
-static _mali_osk_errcode_t dump_mmu_page_table(struct mali_page_directory *pagedir, struct dump_info * info)
+static _mali_osk_errcode_t dump_mmu_page_table(struct mali_page_directory *pagedir, struct dump_info *info)
 {
 	MALI_DEBUG_ASSERT_POINTER(pagedir);
 	MALI_DEBUG_ASSERT_POINTER(info);
 
-	if (NULL != pagedir->page_directory_mapped)
-	{
+	if (NULL != pagedir->page_directory_mapped) {
 		int i;
 
 		MALI_CHECK_NO_ERROR(
-			dump_page(pagedir->page_directory_mapped, pagedir->page_directory, info)
-			);
+			mali_mmu_dump_page(pagedir->page_directory_mapped, pagedir->page_directory, info)
+		);
 
-		for (i = 0; i < 1024; i++)
-		{
-			if (NULL != pagedir->page_entries_mapped[i])
-			{
+		for (i = 0; i < 1024; i++) {
+			if (NULL != pagedir->page_entries_mapped[i]) {
 				MALI_CHECK_NO_ERROR(
-				    dump_page(pagedir->page_entries_mapped[i],
-				        _mali_osk_mem_ioread32(pagedir->page_directory_mapped,
-				        i * sizeof(u32)) & ~MALI_MMU_FLAGS_MASK, info)
+					mali_mmu_dump_page(pagedir->page_entries_mapped[i],
+							   _mali_osk_mem_ioread32(pagedir->page_directory_mapped,
+									   i * sizeof(u32)) & ~MALI_MMU_FLAGS_MASK, info)
 				);
 			}
 		}
@@ -407,22 +385,22 @@ static _mali_osk_errcode_t dump_mmu_page_table(struct mali_page_directory *paged
 	MALI_SUCCESS;
 }
 
-static _mali_osk_errcode_t dump_mmu_registers(struct mali_page_directory *pagedir, struct dump_info * info)
+static _mali_osk_errcode_t dump_mmu_registers(struct mali_page_directory *pagedir, struct dump_info *info)
 {
 	MALI_CHECK_NO_ERROR(writereg(0x00000000, pagedir->page_directory,
-	                             "set the page directory address", info));
+				     "set the page directory address", info));
 	MALI_CHECK_NO_ERROR(writereg(0x00000008, 4, "zap???", info));
 	MALI_CHECK_NO_ERROR(writereg(0x00000008, 0, "enable paging", info));
 	MALI_SUCCESS;
 }
 
-_mali_osk_errcode_t _mali_ukk_query_mmu_page_table_dump_size( _mali_uk_query_mmu_page_table_dump_size_s *args )
+_mali_osk_errcode_t _mali_ukk_query_mmu_page_table_dump_size(_mali_uk_query_mmu_page_table_dump_size_s *args)
 {
 	struct dump_info info = { 0, 0, 0, NULL };
-	struct mali_session_data * session_data;
+	struct mali_session_data *session_data;
 
 	MALI_DEBUG_ASSERT_POINTER(args);
-  	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
+	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
 
 	session_data = (struct mali_session_data *)(args->ctx);
 
@@ -432,13 +410,13 @@ _mali_osk_errcode_t _mali_ukk_query_mmu_page_table_dump_size( _mali_uk_query_mmu
 	MALI_SUCCESS;
 }
 
-_mali_osk_errcode_t _mali_ukk_dump_mmu_page_table( _mali_uk_dump_mmu_page_table_s * args )
+_mali_osk_errcode_t _mali_ukk_dump_mmu_page_table(_mali_uk_dump_mmu_page_table_s *args)
 {
 	struct dump_info info = { 0, 0, 0, NULL };
-	struct mali_session_data * session_data;
+	struct mali_session_data *session_data;
 
-  	MALI_DEBUG_ASSERT_POINTER(args);
-  	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
+	MALI_DEBUG_ASSERT_POINTER(args);
+	MALI_CHECK_NON_NULL(args->ctx, _MALI_OSK_ERR_INVALID_ARGS);
 	MALI_CHECK_NON_NULL(args->buffer, _MALI_OSK_ERR_INVALID_ARGS);
 
 	session_data = (struct mali_session_data *)(args->ctx);
diff --git a/drivers/gpu/mali/mali/common/mali_mmu_page_directory.h b/drivers/gpu/mali/mali/common/mali_mmu_page_directory.h
old mode 100644
new mode 100755
index 7b270c7..c49e93e
--- a/drivers/gpu/mali/mali/common/mali_mmu_page_directory.h
+++ b/drivers/gpu/mali/mali/common/mali_mmu_page_directory.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -45,17 +45,37 @@
 /**
  *
  */
-typedef enum mali_mmu_entry_flags
-{
+typedef enum mali_mmu_entry_flags {
 	MALI_MMU_FLAGS_PRESENT = 0x01,
 	MALI_MMU_FLAGS_READ_PERMISSION = 0x02,
 	MALI_MMU_FLAGS_WRITE_PERMISSION = 0x04,
-	MALI_MMU_FLAGS_MASK = 0x07
+	MALI_MMU_FLAGS_OVERRIDE_CACHE  = 0x8,
+	MALI_MMU_FLAGS_WRITE_CACHEABLE  = 0x10,
+	MALI_MMU_FLAGS_WRITE_ALLOCATE  = 0x20,
+	MALI_MMU_FLAGS_WRITE_BUFFERABLE  = 0x40,
+	MALI_MMU_FLAGS_READ_CACHEABLE  = 0x80,
+	MALI_MMU_FLAGS_READ_ALLOCATE  = 0x100,
+	MALI_MMU_FLAGS_MASK = 0x1FF,
 } mali_mmu_entry_flags;
 
 
-struct mali_page_directory
-{
+#define MALI_MMU_FLAGS_FORCE_GP_READ_ALLOCATE ( \
+		MALI_MMU_FLAGS_PRESENT | \
+		MALI_MMU_FLAGS_READ_PERMISSION |  \
+		MALI_MMU_FLAGS_WRITE_PERMISSION | \
+		MALI_MMU_FLAGS_OVERRIDE_CACHE | \
+		MALI_MMU_FLAGS_WRITE_CACHEABLE | \
+		MALI_MMU_FLAGS_WRITE_BUFFERABLE | \
+		MALI_MMU_FLAGS_READ_CACHEABLE | \
+		MALI_MMU_FLAGS_READ_ALLOCATE )
+
+#define MALI_MMU_FLAGS_DEFAULT ( \
+				 MALI_MMU_FLAGS_PRESENT | \
+				 MALI_MMU_FLAGS_READ_PERMISSION |  \
+				 MALI_MMU_FLAGS_WRITE_PERMISSION )
+
+
+struct mali_page_directory {
 	u32 page_directory; /**< Physical address of the memory session's page directory */
 	mali_io_address page_directory_mapped; /**< Pointer to the mapped version of the page directory into the kernel's address space */
 
@@ -68,14 +88,18 @@ _mali_osk_errcode_t mali_mmu_pagedir_map(struct mali_page_directory *pagedir, u3
 _mali_osk_errcode_t mali_mmu_pagedir_unmap(struct mali_page_directory *pagedir, u32 mali_address, u32 size);
 
 /* Back virtual address space with actual pages. Assumes input is contiguous and 4k aligned. */
-void mali_mmu_pagedir_update(struct mali_page_directory *pagedir, u32 mali_address, u32 phys_address, u32 size);
+void mali_mmu_pagedir_update(struct mali_page_directory *pagedir, u32 mali_address, u32 phys_address, u32 size, u32 cache_settings);
 
 u32 mali_page_directory_get_phys_address(struct mali_page_directory *pagedir, u32 index);
 
-u32 mali_allocate_empty_page(void);
-void mali_free_empty_page(u32 address);
-_mali_osk_errcode_t mali_create_fault_flush_pages(u32 *page_directory, u32 *page_table, u32 *data_page);
-void mali_destroy_fault_flush_pages(u32 *page_directory, u32 *page_table, u32 *data_page);
+u32 mali_allocate_empty_page(mali_io_address *virtual);
+void mali_free_empty_page(u32 address, mali_io_address virtual);
+_mali_osk_errcode_t mali_create_fault_flush_pages(u32 *page_directory, mali_io_address *page_directory_mapping,
+		u32 *page_table, mali_io_address *page_table_mapping,
+		u32 *data_page, mali_io_address *data_page_mapping);
+void mali_destroy_fault_flush_pages(u32 *page_directory, mali_io_address *page_directory_mapping,
+				    u32 *page_table, mali_io_address *page_table_mapping,
+				    u32 *data_page, mali_io_address *data_page_mapping);
 
 struct mali_page_directory *mali_mmu_pagedir_alloc(void);
 void mali_mmu_pagedir_free(struct mali_page_directory *pagedir);
diff --git a/drivers/gpu/mali/mali/common/mali_osk.h b/drivers/gpu/mali/mali/common/mali_osk.h
old mode 100644
new mode 100755
index aba5770..edff276
--- a/drivers/gpu/mali/mali/common/mali_osk.h
+++ b/drivers/gpu/mali/mali/common/mali_osk.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,9 +16,12 @@
 #ifndef __MALI_OSK_H__
 #define __MALI_OSK_H__
 
+#include "mali_osk_types.h"
+#include "mali_osk_specific.h"           /* include any per-os specifics */
+#include "mali_osk_locks.h"
+
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 /**
@@ -33,446 +36,25 @@ extern "C"
  * @{
  */
 
-/** @defgroup _mali_osk_miscellaneous OSK Miscellaneous functions, constants and types
- * @{ */
-
-/* Define integer types used by OSK. Note: these currently clash with Linux so we only define them if not defined already */
-#ifndef __KERNEL__
-	typedef unsigned char      u8;
-	typedef signed char        s8;
-	typedef unsigned short     u16;
-	typedef signed short       s16;
-	typedef unsigned int       u32;
-	typedef signed int         s32;
-	typedef unsigned long long u64;
-	#define BITS_PER_LONG (sizeof(long)*8)
-#else
-	/* Ensure Linux types u32, etc. are defined */
-	#include <linux/types.h>
-#endif
-
-/** @brief Mali Boolean type which uses MALI_TRUE and MALI_FALSE
-  */
-	typedef unsigned long mali_bool;
-
-#ifndef MALI_TRUE
-	#define MALI_TRUE ((mali_bool)1)
-#endif
-
-#ifndef MALI_FALSE
-	#define MALI_FALSE ((mali_bool)0)
-#endif
-
-/**
- * @brief OSK Error codes
- *
- * Each OS may use its own set of error codes, and may require that the
- * User/Kernel interface take certain error code. This means that the common
- * error codes need to be sufficiently rich to pass the correct error code
- * thorugh from the OSK to U/K layer, across all OSs.
- *
- * The result is that some error codes will appear redundant on some OSs.
- * Under all OSs, the OSK layer must translate native OS error codes to
- * _mali_osk_errcode_t codes. Similarly, the U/K layer must translate from
- * _mali_osk_errcode_t codes to native OS error codes.
- */
-typedef enum
-{
-    _MALI_OSK_ERR_OK = 0, /**< Success. */
-    _MALI_OSK_ERR_FAULT = -1, /**< General non-success */
-    _MALI_OSK_ERR_INVALID_FUNC = -2, /**< Invalid function requested through User/Kernel interface (e.g. bad IOCTL number) */
-    _MALI_OSK_ERR_INVALID_ARGS = -3, /**< Invalid arguments passed through User/Kernel interface */
-    _MALI_OSK_ERR_NOMEM = -4, /**< Insufficient memory */
-    _MALI_OSK_ERR_TIMEOUT = -5, /**< Timeout occurred */
-    _MALI_OSK_ERR_RESTARTSYSCALL = -6, /**< Special: On certain OSs, must report when an interruptable mutex is interrupted. Ignore otherwise. */
-    _MALI_OSK_ERR_ITEM_NOT_FOUND = -7, /**< Table Lookup failed */
-    _MALI_OSK_ERR_BUSY = -8, /**< Device/operation is busy. Try again later */
-	_MALI_OSK_ERR_UNSUPPORTED = -9, /**< Optional part of the interface used, and is unsupported */
-} _mali_osk_errcode_t;
-
-/** @} */ /* end group _mali_osk_miscellaneous */
-
-
-/** @defgroup _mali_osk_irq OSK IRQ handling
+/** @addtogroup _mali_osk_lock OSK Mutual Exclusion Locks
  * @{ */
 
-/** @brief Private type for IRQ handling objects */
-typedef struct _mali_osk_irq_t_struct _mali_osk_irq_t;
-
-/** @brief Optional function to trigger an irq from a resource
- *
- * This function is implemented by the common layer to allow probing of a resource's IRQ.
- * @param arg resource-specific data */
-typedef void  (*_mali_osk_irq_trigger_t)( void * arg );
-
-/** @brief Optional function to acknowledge an irq from a resource
- *
- * This function is implemented by the common layer to allow probing of a resource's IRQ.
- * @param arg resource-specific data
- * @return _MALI_OSK_ERR_OK if the IRQ was successful, or a suitable _mali_osk_errcode_t on failure. */
-typedef _mali_osk_errcode_t (*_mali_osk_irq_ack_t)( void * arg );
-
-/** @brief IRQ 'upper-half' handler callback.
- *
- * This function is implemented by the common layer to do the initial handling of a
- * resource's IRQ. This maps on to the concept of an ISR that does the minimum
- * work necessary before handing off to an IST.
- *
- * The communication of the resource-specific data from the ISR to the IST is
- * handled by the OSK implementation.
- *
- * On most systems, the IRQ upper-half handler executes in IRQ context.
- * Therefore, the system may have restrictions about what can be done in this
- * context
- *
- * If an IRQ upper-half handler requires more work to be done than can be
- * acheived in an IRQ context, then it may defer the work with
- * _mali_osk_irq_schedulework(). Refer to \ref _mali_osk_irq_schedulework() for
- * more information.
- *
- * @param arg resource-specific data
- * @return _MALI_OSK_ERR_OK if the IRQ was correctly handled, or a suitable
- * _mali_osk_errcode_t otherwise.
- */
-typedef _mali_osk_errcode_t  (*_mali_osk_irq_uhandler_t)( void * arg );
-
-/** @brief IRQ 'bottom-half' handler callback.
- *
- * This function is implemented by the common layer to do the deferred handling
- * of a resource's IRQ. Usually, this work cannot be carried out in IRQ context
- * by the IRQ upper-half handler.
- *
- * The IRQ bottom-half handler maps on to the concept of an IST that may
- * execute some time after the actual IRQ has fired.
- *
- * All OSK-registered IRQ bottom-half handlers will be serialized, across all
- * CPU-cores in the system.
- *
- * Refer to \ref _mali_osk_irq_schedulework() for more information on the
- * IRQ work-queue, and the calling of the IRQ bottom-half handler.
- *
- * @param arg resource-specific data
- */
-typedef void (*_mali_osk_irq_bhandler_t)( void * arg );
-/** @} */ /* end group _mali_osk_irq */
-
-
-/** @defgroup _mali_osk_atomic OSK Atomic counters
- * @{ */
-
-/** @brief Public type of atomic counters
- *
- * This is public for allocation on stack. On systems that support it, this is just a single 32-bit value.
- * On others, it could be encapsulating an object stored elsewhere.
- *
- * Regardless of implementation, the \ref _mali_osk_atomic functions \b must be used
- * for all accesses to the variable's value, even if atomicity is not required.
- * Do not access u.val or u.obj directly.
- */
-typedef struct
-{
-    union
-    {
-        u32 val;
-        void *obj;
-    } u;
-} _mali_osk_atomic_t;
-/** @} */ /* end group _mali_osk_atomic */
-
-
-/** @defgroup _mali_osk_lock OSK Mutual Exclusion Locks
- * @{ */
-
-
-/** @brief OSK Mutual Exclusion Lock ordered list
- *
- * This lists the various types of locks in the system and is used to check
- * that locks are taken in the correct order.
- *
- * Holding more than one lock of the same order at the same time is not
- * allowed.
- *
- */
-typedef enum
-{
-	_MALI_OSK_LOCK_ORDER_LAST = 0,
-
-	_MALI_OSK_LOCK_ORDER_PM_EXECUTE,
-	_MALI_OSK_LOCK_ORDER_UTILIZATION,
-	_MALI_OSK_LOCK_ORDER_L2_COUNTER,
-	_MALI_OSK_LOCK_ORDER_PROFILING,
-	_MALI_OSK_LOCK_ORDER_L2_COMMAND,
-	_MALI_OSK_LOCK_ORDER_PM_CORE_STATE,
-	_MALI_OSK_LOCK_ORDER_GROUP,
-	_MALI_OSK_LOCK_ORDER_SCHEDULER,
-
-	_MALI_OSK_LOCK_ORDER_DESCRIPTOR_MAP,
-	_MALI_OSK_LOCK_ORDER_MEM_PT_CACHE,
-	_MALI_OSK_LOCK_ORDER_MEM_INFO,
-	_MALI_OSK_LOCK_ORDER_MEM_SESSION,
-
-	_MALI_OSK_LOCK_ORDER_SESSIONS,
-
-	_MALI_OSK_LOCK_ORDER_FIRST
-} _mali_osk_lock_order_t;
-
-
-/** @brief OSK Mutual Exclusion Lock flags type
- *
- * Flags are supplied at the point where the Lock is initialized. Each flag can
- * be combined with others using bitwise OR, '|'.
- *
- * The flags must be sufficiently rich to cope with all our OSs. This means
- * that on some OSs, certain flags can be completely ignored. We define a
- * number of terms that are significant across all OSs:
- *
- * - Sleeping/non-sleeping mutexs. Sleeping mutexs can block on waiting, and so
- * schedule out the current thread. This is significant on OSs where there are
- * situations in which the current thread must not be put to sleep. On OSs
- * without this restriction, sleeping and non-sleeping mutexes can be treated
- * as the same (if that is required).
- * - Interruptable/non-interruptable mutexes. For sleeping mutexes, it may be
- * possible for the sleep to be interrupted for a reason other than the thread
- * being able to obtain the lock. OSs behaving in this way may provide a
- * mechanism to control whether sleeping mutexes can be interrupted. On OSs
- * that do not support the concept of interruption, \b or they do not support
- * control of mutex interruption, then interruptable mutexes may be treated
- * as non-interruptable.
- *
- * Some constrains apply to the lock type flags:
- *
- * - Spinlocks are by nature, non-interruptable. Hence, they must always be
- * combined with the NONINTERRUPTABLE flag, because it is meaningless to ask
- * for a spinlock that is interruptable (and this highlights its
- * non-interruptable-ness). For example, on certain OSs they should be used when
- * you must not sleep.
- * - Reader/writer is an optimization hint, and any type of lock can be
- * reader/writer. Since this is an optimization hint, the implementation need
- * not respect this for any/all types of lock. For example, on certain OSs,
- * there's no interruptable reader/writer mutex. If such a thing were requested
- * on that OS, the fact that interruptable was requested takes priority over the
- * reader/writer-ness, because reader/writer-ness is not necessary for correct
- * operation.
- * - Any lock can use the order parameter.
- * - A onelock is an optimization hint specific to certain OSs. It can be
- * specified when it is known that only one lock will be held by the thread,
- * and so can provide faster mutual exclusion. This can be safely ignored if
- * such optimization is not required/present.
- *
- * The absence of any flags (the value 0) results in a sleeping-mutex, which is interruptable.
- */
-typedef enum
-{
-	_MALI_OSK_LOCKFLAG_SPINLOCK = 0x1,          /**< Specifically, don't sleep on those architectures that require it */
-	_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE = 0x2,  /**< The mutex cannot be interrupted, e.g. delivery of signals on those architectures where this is required */
-	_MALI_OSK_LOCKFLAG_READERWRITER = 0x4,      /**< Optimise for readers/writers */
-	_MALI_OSK_LOCKFLAG_ORDERED = 0x8,           /**< Use the order parameter; otherwise use automatic ordering */
-	_MALI_OSK_LOCKFLAG_ONELOCK = 0x10,          /**< Each thread can only hold one lock at a time */
-	_MALI_OSK_LOCKFLAG_SPINLOCK_IRQ = 0x20,    /**<  IRQ version of spinlock */
-	/** @enum _mali_osk_lock_flags_t
-	 *
-	 * Flags from 0x10000--0x80000000 are RESERVED for User-mode */
-
-} _mali_osk_lock_flags_t;
-
-/** @brief Mutual Exclusion Lock Mode Optimization hint
- *
- * The lock mode is used to implement the read/write locking of locks specified
- * as _MALI_OSK_LOCKFLAG_READERWRITER. In this case, the RO mode can be used
- * to allow multiple concurrent readers, but no writers. The RW mode is used for
- * writers, and so will wait for all readers to release the lock (if any present).
- * Further readers and writers will wait until the writer releases the lock.
- *
- * The mode is purely an optimization hint: for example, it is permissible for
- * all locks to behave in RW mode, regardless of that supplied.
- *
- * It is an error to attempt to use locks in anything other that RW mode when
- * _MALI_OSK_LOCKFLAG_READERWRITER is not supplied.
- *
- */
-typedef enum
-{
-	_MALI_OSK_LOCKMODE_UNDEF = -1,  /**< Undefined lock mode. For internal use only */
-	_MALI_OSK_LOCKMODE_RW    = 0x0, /**< Read-write mode, default. All readers and writers are mutually-exclusive */
-	_MALI_OSK_LOCKMODE_RO,          /**< Read-only mode, to support multiple concurrent readers, but mutual exclusion in the presence of writers. */
-	/** @enum _mali_osk_lock_mode_t
-	 *
-	 * Lock modes 0x40--0x7F are RESERVED for User-mode */
-} _mali_osk_lock_mode_t;
-
-/** @brief Private type for Mutual Exclusion lock objects */
-typedef struct _mali_osk_lock_t_struct _mali_osk_lock_t;
-
 #ifdef DEBUG
 /** @brief Macro for asserting that the current thread holds a given lock
  */
-#define MALI_DEBUG_ASSERT_LOCK_HELD(l) MALI_DEBUG_ASSERT(_mali_osk_lock_get_owner(l) == _mali_osk_get_tid());
+#define MALI_DEBUG_ASSERT_LOCK_HELD(l) MALI_DEBUG_ASSERT(_mali_osk_lock_get_owner((_mali_osk_lock_debug_t *)l) == _mali_osk_get_tid());
 
 /** @brief returns a lock's owner (thread id) if debugging is enabled
  */
-u32 _mali_osk_lock_get_owner( _mali_osk_lock_t *lock );
+#else
+#define MALI_DEBUG_ASSERT_LOCK_HELD(l) do {} while(0)
 #endif
 
 /** @} */ /* end group _mali_osk_lock */
 
-/** @defgroup _mali_osk_low_level_memory OSK Low-level Memory Operations
- * @{ */
-
-/**
- * @brief Private data type for use in IO accesses to/from devices.
- *
- * This represents some range that is accessible from the device. Examples
- * include:
- * - Device Registers, which could be readable and/or writeable.
- * - Memory that the device has access to, for storing configuration structures.
- *
- * Access to this range must be made through the _mali_osk_mem_ioread32() and
- * _mali_osk_mem_iowrite32() functions.
- */
-typedef struct _mali_io_address * mali_io_address;
-
-/** @defgroup _MALI_OSK_CPU_PAGE CPU Physical page size macros.
- *
- * The order of the page size is supplied for
- * ease of use by algorithms that might require it, since it is easier to know
- * it ahead of time rather than calculating it.
- *
- * The Mali Page Mask macro masks off the lower bits of a physical address to
- * give the start address of the page for that physical address.
- *
- * @note The Mali device driver code is designed for systems with 4KB page size.
- * Changing these macros will not make the entire Mali device driver work with
- * page sizes other than 4KB.
- *
- * @note The CPU Physical Page Size has been assumed to be the same as the Mali
- * Physical Page Size.
- *
- * @{
- */
-
-/** CPU Page Order, as log to base 2 of the Page size. @see _MALI_OSK_CPU_PAGE_SIZE */
-#define _MALI_OSK_CPU_PAGE_ORDER ((u32)12)
-/** CPU Page Size, in bytes.               */
-#define _MALI_OSK_CPU_PAGE_SIZE (((u32)1) << (_MALI_OSK_CPU_PAGE_ORDER))
-/** CPU Page Mask, which masks off the offset within a page */
-#define _MALI_OSK_CPU_PAGE_MASK (~((((u32)1) << (_MALI_OSK_CPU_PAGE_ORDER)) - ((u32)1)))
-/** @} */ /* end of group _MALI_OSK_CPU_PAGE */
-
-/** @defgroup _MALI_OSK_MALI_PAGE Mali Physical Page size macros
- *
- * Mali Physical page size macros. The order of the page size is supplied for
- * ease of use by algorithms that might require it, since it is easier to know
- * it ahead of time rather than calculating it.
- *
- * The Mali Page Mask macro masks off the lower bits of a physical address to
- * give the start address of the page for that physical address.
- *
- * @note The Mali device driver code is designed for systems with 4KB page size.
- * Changing these macros will not make the entire Mali device driver work with
- * page sizes other than 4KB.
- *
- * @note The Mali Physical Page Size has been assumed to be the same as the CPU
- * Physical Page Size.
- *
- * @{
- */
-
-/** Mali Page Order, as log to base 2 of the Page size. @see _MALI_OSK_MALI_PAGE_SIZE */
-#define _MALI_OSK_MALI_PAGE_ORDER ((u32)12)
-/** Mali Page Size, in bytes.               */
-#define _MALI_OSK_MALI_PAGE_SIZE (((u32)1) << (_MALI_OSK_MALI_PAGE_ORDER))
-/** Mali Page Mask, which masks off the offset within a page */
-#define _MALI_OSK_MALI_PAGE_MASK (~((((u32)1) << (_MALI_OSK_MALI_PAGE_ORDER)) - ((u32)1)))
-/** @} */ /* end of group _MALI_OSK_MALI_PAGE*/
-
-/** @brief flags for mapping a user-accessible memory range
- *
- * Where a function with prefix '_mali_osk_mem_mapregion' accepts flags as one
- * of the function parameters, it will use one of these. These allow per-page
- * control over mappings. Compare with the mali_memory_allocation_flag type,
- * which acts over an entire range
- *
- * These may be OR'd together with bitwise OR (|), but must be cast back into
- * the type after OR'ing.
- */
-typedef enum
-{
-	_MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR = 0x1, /**< Physical address is OS Allocated */
-} _mali_osk_mem_mapregion_flags_t;
-/** @} */ /* end group _mali_osk_low_level_memory */
-
-/** @defgroup _mali_osk_notification OSK Notification Queues
- * @{ */
-
-/** @brief Private type for notification queue objects */
-typedef struct _mali_osk_notification_queue_t_struct _mali_osk_notification_queue_t;
-
-/** @brief Public notification data object type */
-typedef struct _mali_osk_notification_t_struct
-{
-	u32 notification_type;   /**< The notification type */
-	u32 result_buffer_size; /**< Size of the result buffer to copy to user space */
-	void * result_buffer;   /**< Buffer containing any type specific data */
-} _mali_osk_notification_t;
-
-/** @} */ /* end group _mali_osk_notification */
-
-
-/** @defgroup _mali_osk_timer OSK Timer Callbacks
- * @{ */
-
-/** @brief Function to call when a timer expires
- *
- * When a timer expires, this function is called. Note that on many systems,
- * a timer callback will be executed in IRQ context. Therefore, restrictions
- * may apply on what can be done inside the timer callback.
- *
- * If a timer requires more work to be done than can be acheived in an IRQ
- * context, then it may defer the work with a work-queue. For example, it may
- * use \ref _mali_osk_irq_schedulework() to make use of the IRQ bottom-half handler
- * to carry out the remaining work.
- *
- * Stopping the timer with \ref _mali_osk_timer_del() blocks on compeletion of
- * the callback. Therefore, the callback may not obtain any mutexes also held
- * by any callers of _mali_osk_timer_del(). Otherwise, a deadlock may occur.
- *
- * @param arg Function-specific data */
-typedef void (*_mali_osk_timer_callback_t)(void * arg );
-
-/** @brief Private type for Timer Callback Objects */
-typedef struct _mali_osk_timer_t_struct _mali_osk_timer_t;
-/** @} */ /* end group _mali_osk_timer */
-
-
-/** @addtogroup _mali_osk_list OSK Doubly-Linked Circular Lists
+/** @addtogroup _mali_osk_miscellaneous
  * @{ */
 
-/** @brief Public List objects.
- *
- * To use, add a _mali_osk_list_t member to the structure that may become part
- * of a list. When traversing the _mali_osk_list_t objects, use the
- * _MALI_OSK_CONTAINER_OF() macro to recover the structure from its
- *_mali_osk_list_t member
- *
- * Each structure may have multiple _mali_osk_list_t members, so that the
- * structure is part of multiple lists. When traversing lists, ensure that the
- * correct _mali_osk_list_t member is used, because type-checking will be
- * lost by the compiler.
- */
-typedef struct _mali_osk_list_s
-{
-	struct _mali_osk_list_s *next;
-	struct _mali_osk_list_s *prev;
-} _mali_osk_list_t;
-
-/** @brief Initialize a list to be a head of an empty list
- * @param exp the list to initialize. */
-#define _MALI_OSK_INIT_LIST_HEAD(exp) _mali_osk_list_init(exp)
-
-/** @brief Define a list variable, which is uninitialized.
- * @param exp the name of the variable that the list will be defined as. */
-#define _MALI_OSK_LIST_HEAD(exp)      _mali_osk_list_t exp
-
 /** @brief Find the containing structure of another structure
  *
  * This is the reverse of the operation 'offsetof'. This means that the
@@ -496,192 +78,73 @@ typedef struct _mali_osk_list_s
  * to by \a ptr.
  */
 #define _MALI_OSK_CONTAINER_OF(ptr, type, member) \
-             ((type *)( ((char *)ptr) - offsetof(type,member) ))
+	((type *)( ((char *)ptr) - offsetof(type,member) ))
 
-/** @brief Find the containing structure of a list
- *
- * When traversing a list, this is used to recover the containing structure,
- * given that is contains a _mali_osk_list_t member.
- *
- * Each list must be of structures of one type, and must link the same members
- * together, otherwise it will not be possible to correctly recover the
- * sturctures that the lists link.
- *
- * @note no type or memory checking occurs to ensure that a structure does in
- * fact exist for the list entry, and that it is being recovered with respect
- * to the correct list member.
- *
- * @param ptr the pointer to the _mali_osk_list_t member in this structure
- * @param type the type of the structure that contains the member
- * @param member the member of the structure that ptr points to.
- * @return a pointer to a \a type object which contains the _mali_osk_list_t
- * \a member, as pointed to by the _mali_osk_list_t \a *ptr.
- */
-#define _MALI_OSK_LIST_ENTRY(ptr, type, member) \
-            _MALI_OSK_CONTAINER_OF(ptr, type, member)
-
-/** @brief Enumerate a list safely
- *
- * With this macro, lists can be enumerated in a 'safe' manner. That is,
- * entries can be deleted from the list without causing an error during
- * enumeration. To achieve this, a 'temporary' pointer is required, which must
- * be provided to the macro.
- *
- * Use it like a 'for()', 'while()' or 'do()' construct, and so it must be
- * followed by a statement or compound-statement which will be executed for
- * each list entry.
- *
- * Upon loop completion, providing that an early out was not taken in the
- * loop body, then it is guaranteed that ptr->member == list, even if the loop
- * body never executed.
- *
- * @param ptr a pointer to an object of type 'type', which points to the
- * structure that contains the currently enumerated list entry.
- * @param tmp a pointer to an object of type 'type', which must not be used
- * inside the list-execution statement.
- * @param list a pointer to a _mali_osk_list_t, from which enumeration will
- * begin
- * @param type the type of the structure that contains the _mali_osk_list_t
- * member that is part of the list to be enumerated.
- * @param member the _mali_osk_list_t member of the structure that is part of
- * the list to be enumerated.
- */
-#define _MALI_OSK_LIST_FOREACHENTRY(ptr, tmp, list, type, member)         \
-        for (ptr = _MALI_OSK_LIST_ENTRY((list)->next, type, member),      \
-             tmp = _MALI_OSK_LIST_ENTRY(ptr->member.next, type, member); \
-             &ptr->member != (list);                                    \
-             ptr = tmp, tmp = _MALI_OSK_LIST_ENTRY(tmp->member.next, type, member))
-/** @} */ /* end group _mali_osk_list */
-
-
-/** @addtogroup _mali_osk_miscellaneous
+/** @addtogroup _mali_osk_wq
  * @{ */
 
-/** @brief The known resource types
+/** @brief Initialize work queues (for deferred work)
  *
- * @note \b IMPORTANT: these must remain fixed, and only be extended. This is
- * because not all systems use a header file for reading in their resources.
- * The resources may instead come from a data file where these resources are
- * 'hard-coded' in, because there's no easy way of transferring the enum values
- * into such data files. E.g. the C-Pre-processor does \em not process enums.
+ * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-typedef enum _mali_osk_resource_type
-{
-	RESOURCE_TYPE_FIRST =0,  /**< Duplicate resource marker for the first resource*/
-
-	MEMORY              =0,  /**< Physically contiguous memory block, not managed by the OS */
-	OS_MEMORY           =1,  /**< Memory managed by and shared with the OS */
-
-	MALI_PP             =2,  /**< Mali Pixel Processor core */
-	MALI450PP           =2,  /**< Compatibility option */
-	MALI400PP           =2,  /**< Compatibility option */
-	MALI300PP           =2,  /**< Compatibility option */
-	MALI200             =2,  /**< Compatibility option */
-
-	MALI_GP             =3,  /**< Mali Geometry Processor core */
-	MALI450GP           =3,  /**< Compatibility option */
-	MALI400GP           =3,  /**< Compatibility option */
-	MALI300GP           =3,  /**< Compatibility option */
-	MALIGP2             =3,  /**< Compatibility option */
-
-	MMU                 =4,  /**< Mali MMU (Memory Management Unit) */
-
-	FPGA_FRAMEWORK      =5,  /**< Mali registers specific to FPGA implementations */
-
-	MALI_L2             =6,  /**< Mali Level 2 cache core */
-	MALI450L2           =6,  /**< Compatibility option */
-	MALI400L2           =6,  /**< Compatibility option */
-	MALI300L2           =6,  /**< Compatibility option */
+_mali_osk_errcode_t _mali_osk_wq_init(void);
 
-	MEM_VALIDATION      =7, /**< External Memory Validator */
-
-	PMU                 =8, /**< Power Manangement Unit */
-
-	RESOURCE_TYPE_COUNT      /**< The total number of known resources */
-} _mali_osk_resource_type_t;
+/** @brief Terminate work queues (for deferred work)
+ */
+void _mali_osk_wq_term(void);
 
-/** @brief resource description struct
+/** @brief Create work in the work queue
  *
- * _mali_osk_resources_init() will enumerate objects of this type. Not all
- * members have a valid meaning across all types.
+ * Creates a work object which can be scheduled in the work queue. When
+ * scheduled, \a handler will be called with \a data as the argument.
  *
- * The mmu_id is used to group resources to a certain MMU, since there may be
- * more than one MMU in the system, and each resource may be using a different
- * MMU:
- * - For MMU resources, the setting of mmu_id is a uniquely identifying number.
- * - For Other resources, the setting of mmu_id determines which MMU the
- * resource uses.
+ * Refer to \ref _mali_osk_wq_schedule_work() for details on how work
+ * is scheduled in the queue.
+ *
+ * The returned pointer must be freed with \ref _mali_osk_wq_delete_work()
+ * when no longer needed.
  */
-typedef struct _mali_osk_resource
-{
-	_mali_osk_resource_type_t type; /**< type of the resource */
-	const char * description;       /**< short description of the resource */
-	u32 base;                       /**< Physical base address of the resource, as seen by Mali resources. */
-	s32 cpu_usage_adjust;           /**< Offset added to the base address of the resource to arrive at the CPU physical address of the resource (if different from the Mali physical address) */
-	u32 size;                       /**< Size in bytes of the resource - either the size of its register range, or the size of the memory block. */
-	u32 irq;                        /**< IRQ number delivered to the CPU, or -1 to tell the driver to probe for it (if possible) */
-	u32 flags;                      /**< Resources-specific flags. */
-	u32 mmu_id;                     /**< Identifier for Mali MMU resources. */
-	u32 alloc_order;                /**< Order in which MEMORY/OS_MEMORY resources are used */
-} _mali_osk_resource_t;
-/** @} */ /* end group _mali_osk_miscellaneous */
-
-
-#include "mali_kernel_memory_engine.h"   /* include for mali_memory_allocation and mali_physical_memory_allocation type */
-
-/** @addtogroup _mali_osk_irq
- * @{ */
+_mali_osk_wq_work_t *_mali_osk_wq_create_work(_mali_osk_wq_work_handler_t handler, void *data);
 
-/** @brief Fake IRQ number for testing purposes
+/** @brief A high priority version of \a _mali_osk_wq_create_work()
+ *
+ * Creates a work object which can be scheduled in the high priority work queue.
+ *
+ * This is unfortunately needed to get low latency scheduling of the Mali cores.  Normally we would
+ * schedule the next job in hw_irq or tasklet, but often we can't since we need to synchronously map
+ * and unmap shared memory when a job is connected to external fences (timelines). And this requires
+ * taking a mutex.
+ *
+ * We do signal a lot of other (low priority) work also as part of the job being finished, and if we
+ * don't set this Mali scheduling thread as high priority, we see that the CPU scheduler often runs
+ * random things instead of starting the next GPU job when the GPU is idle.  So setting the gpu
+ * scheduler to high priority does give a visually more responsive system.
+ *
+ * Start the high priority work with: \a _mali_osk_wq_schedule_work_high_pri()
  */
-#define _MALI_OSK_IRQ_NUMBER_FAKE ((u32)0xFFFFFFF1)
+_mali_osk_wq_work_t *_mali_osk_wq_create_work_high_pri(_mali_osk_wq_work_handler_t handler, void *data);
 
-/** @addtogroup _mali_osk_irq
- * @{ */
-
-/** @brief PMM Virtual IRQ number
+/** @brief Delete a work object
+ *
+ * This will flush the work queue to ensure that the work handler will not
+ * be called after deletion.
  */
-#define _MALI_OSK_IRQ_NUMBER_PMM ((u32)0xFFFFFFF2)
-
+void _mali_osk_wq_delete_work(_mali_osk_wq_work_t *work);
 
-/** @brief Initialize IRQ handling for a resource
- *
- * The _mali_osk_irq_t returned must be written into the resource-specific data
- * pointed to by data. This is so that the upper and lower handlers can call
- * _mali_osk_irq_schedulework().
+/** @brief Delete a work object
  *
- * @note The caller must ensure that the resource does not generate an
- * interrupt after _mali_osk_irq_init() finishes, and before the
- * _mali_osk_irq_t is written into the resource-specific data. Otherwise,
- * the upper-half handler will fail to call _mali_osk_irq_schedulework().
- *
- * @param irqnum The IRQ number that the resource uses, as seen by the CPU.
- * The value -1 has a special meaning which indicates the use of probing, and trigger_func and ack_func must be
- * non-NULL.
- * @param uhandler The upper-half handler, corresponding to a ISR handler for
- * the resource
- * @param bhandler The lower-half handler, corresponding to an IST handler for
- * the resource
- * @param trigger_func Optional: a function to trigger the resource's irq, to
- * probe for the interrupt. Use NULL if irqnum != -1.
- * @param ack_func Optional: a function to acknowledge the resource's irq, to
- * probe for the interrupt. Use NULL if irqnum != -1.
- * @param data resource-specific data, which will be passed to uhandler,
- * bhandler and (if present) trigger_func and ack_funnc
- * @param description textual description of the IRQ resource.
- * @return on success, a pointer to a _mali_osk_irq_t object, which represents
- * the IRQ handling on this resource. NULL on failure.
+ * This will NOT flush the work queue, so only call this if you are sure that the work handler will
+ * not be called after deletion.
  */
-_mali_osk_irq_t *_mali_osk_irq_init( u32 irqnum, _mali_osk_irq_uhandler_t uhandler,	_mali_osk_irq_bhandler_t bhandler, _mali_osk_irq_trigger_t trigger_func, _mali_osk_irq_ack_t ack_func, void *data, const char *description );
+void _mali_osk_wq_delete_work_nonflush(_mali_osk_wq_work_t *work);
 
-/** @brief Cause a queued, deferred call of the IRQ bottom-half.
+/** @brief Cause a queued, deferred call of the work handler
  *
- * _mali_osk_irq_schedulework provides a mechanism for enqueuing deferred calls
- * to the IRQ bottom-half handler. The queue is known as the IRQ work-queue.
- * After calling _mali_osk_irq_schedulework(), the IRQ bottom-half handler will
- * be scheduled to run at some point in the future.
+ * _mali_osk_wq_schedule_work provides a mechanism for enqueuing deferred calls
+ * to the work handler. After calling \ref _mali_osk_wq_schedule_work(), the
+ * work handler will be scheduled to run at some point in the future.
  *
- * This is called by the IRQ upper-half to defer further processing of
+ * Typically this is called by the IRQ upper-half to defer further processing of
  * IRQ-related work to the IRQ bottom-half handler. This is necessary for work
  * that cannot be done in an IRQ context by the IRQ upper-half handler. Timer
  * callbacks also use this mechanism, because they are treated as though they
@@ -694,78 +157,159 @@ _mali_osk_irq_t *_mali_osk_irq_init( u32 irqnum, _mali_osk_irq_uhandler_t uhandl
  * IRQ bottom half to hold the same mutex, with a guarantee that they will not
  * deadlock just by using this mechanism.
  *
- * _mali_osk_irq_schedulework() places deferred call requests on a queue, to
+ * _mali_osk_wq_schedule_work() places deferred call requests on a queue, to
  * allow for more than one thread to make a deferred call. Therfore, if it is
  * called 'K' times, then the IRQ bottom-half will be scheduled 'K' times too.
  * 'K' is a number that is implementation-specific.
  *
- * _mali_osk_irq_schedulework() is guaranteed to not block on:
+ * _mali_osk_wq_schedule_work() is guaranteed to not block on:
  * - enqueuing a deferred call request.
- * - the completion of the IRQ bottom-half handler.
+ * - the completion of the work handler.
  *
- * This is to prevent deadlock. For example, if _mali_osk_irq_schedulework()
+ * This is to prevent deadlock. For example, if _mali_osk_wq_schedule_work()
  * blocked, then it would cause a deadlock when the following two conditions
  * hold:
- * - The IRQ bottom-half callback (of type _mali_osk_irq_bhandler_t) locks
+ * - The work handler callback (of type _mali_osk_wq_work_handler_t) locks
  * a mutex
- * - And, at the same time, the caller of _mali_osk_irq_schedulework() also
+ * - And, at the same time, the caller of _mali_osk_wq_schedule_work() also
  * holds the same mutex
  *
  * @note care must be taken to not overflow the queue that
- * _mali_osk_irq_schedulework() operates on. Code must be structured to
+ * _mali_osk_wq_schedule_work() operates on. Code must be structured to
  * ensure that the number of requests made to the queue is bounded. Otherwise,
- * IRQs will be lost.
+ * work will be lost.
  *
- * The queue that _mali_osk_irq_schedulework implements is a FIFO of N-writer,
- * 1-reader type. The writers are the callers of _mali_osk_irq_schedulework
+ * The queue that _mali_osk_wq_schedule_work implements is a FIFO of N-writer,
+ * 1-reader type. The writers are the callers of _mali_osk_wq_schedule_work
  * (all OSK-registered IRQ upper-half handlers in the system, watchdog timers,
  * callers from a Kernel-process context). The reader is a single thread that
- * handles all OSK-registered IRQs.
+ * handles all OSK-registered work.
  *
- * The consequence of the queue being a 1-reader type is that calling
- * _mali_osk_irq_schedulework() on different _mali_osk_irq_t objects causes
- * their IRQ bottom-halves to be serialized, across all CPU-cores in the
- * system.
- *
- * @param irq a pointer to the _mali_osk_irq_t object corresponding to the
- * resource whose IRQ bottom-half must begin processing.
+ * @param work a pointer to the _mali_osk_wq_work_t object corresponding to the
+ * work to begin processing.
  */
-void _mali_osk_irq_schedulework( _mali_osk_irq_t *irq );
+void _mali_osk_wq_schedule_work(_mali_osk_wq_work_t *work);
 
-/** @brief Terminate IRQ handling on a resource.
+/** @brief Cause a queued, deferred call of the high priority work handler
+ *
+ * Function is the same as \a _mali_osk_wq_schedule_work() with the only
+ * difference that it runs in a high (real time) priority on the system.
  *
- * This will disable the interrupt from the device, and then waits for the
- * IRQ work-queue to finish the work that is currently in the queue. That is,
- * for every deferred call currently in the IRQ work-queue, it waits for each
- * of those to be processed by their respective IRQ bottom-half handler.
+ * Should only be used as a substitue for doing the same work in interrupts.
  *
- * This function is used to ensure that the bottom-half handler of the supplied
- * IRQ object will not be running at the completion of this function call.
- * However, the caller must ensure that no other sources could call the
- * _mali_osk_irq_schedulework() on the same IRQ object. For example, the
- * relevant timers must be stopped.
+ * This is allowed to sleep, but the work should be small since it will block
+ * all other applications.
+*/
+void _mali_osk_wq_schedule_work_high_pri(_mali_osk_wq_work_t *work);
+
+/** @brief Flush the work queue
  *
- * @note While this function is being called, other OSK-registered IRQs in the
- * system may enqueue work for their respective bottom-half handlers. This
- * function will not wait for those entries in the work-queue to be flushed.
+ * This will flush the OSK work queue, ensuring all work in the queue has
+ * completed before returning.
  *
- * Since this blocks on the completion of work in the IRQ work-queue, the
+ * Since this blocks on the completion of work in the work-queue, the
  * caller of this function \b must \b not hold any mutexes that are taken by
- * any OSK-registered IRQ bottom-half handler. To do so may cause a deadlock.
+ * any registered work handler. To do so may cause a deadlock.
  *
- * @param irq a pointer to the _mali_osk_irq_t object corresponding to the
- * resource whose IRQ handling is to be terminated.
  */
-void _mali_osk_irq_term( _mali_osk_irq_t *irq );
+void _mali_osk_wq_flush(void);
+
+/** @brief Create work in the delayed work queue
+ *
+ * Creates a work object which can be scheduled in the work queue. When
+ * scheduled, a timer will be start and the \a handler will be called with
+ * \a data as the argument when timer out
+ *
+ * Refer to \ref _mali_osk_wq_delayed_schedule_work() for details on how work
+ * is scheduled in the queue.
+ *
+ * The returned pointer must be freed with \ref _mali_osk_wq_delayed_delete_work_nonflush()
+ * when no longer needed.
+ */
+_mali_osk_wq_delayed_work_t *_mali_osk_wq_delayed_create_work(_mali_osk_wq_work_handler_t handler, void *data);
+
+/** @brief Delete a work object
+ *
+ * This will NOT flush the work queue, so only call this if you are sure that the work handler will
+ * not be called after deletion.
+ */
+void _mali_osk_wq_delayed_delete_work_nonflush(_mali_osk_wq_delayed_work_t *work);
+
+/** @brief Cancel a delayed work without waiting for it to finish
+ *
+ * Note that the \a work callback function may still be running on return from
+ * _mali_osk_wq_delayed_cancel_work_async().
+ *
+ * @param work The delayed work to be cancelled
+ */
+void _mali_osk_wq_delayed_cancel_work_async(_mali_osk_wq_delayed_work_t *work);
+
+/** @brief Cancel a delayed work and wait for it to finish
+ *
+ * When this function returns, the \a work was either cancelled or it finished running.
+ *
+ * @param work The delayed work to be cancelled
+ */
+void _mali_osk_wq_delayed_cancel_work_sync(_mali_osk_wq_delayed_work_t *work);
 
-/** @brief flushing workqueue.
+/** @brief Put \a work task in global workqueue after delay
+ *
+ * After waiting for a given time this puts a job in the kernel-global
+ * workqueue.
  *
- * This will flush the workqueue.
+ * If \a work was already on a queue, this function will return without doing anything
+ *
+ * @param work job to be done
+ * @param delay number of jiffies to wait or 0 for immediate execution
+ */
+void _mali_osk_wq_delayed_schedule_work(_mali_osk_wq_delayed_work_t *work, u32 delay);
+
+/** @} */ /* end group _mali_osk_wq */
+
+
+/** @addtogroup _mali_osk_irq
+ * @{ */
+
+/** @brief Initialize IRQ handling for a resource
+ *
+ * Registers an interrupt handler \a uhandler for the given IRQ number \a irqnum.
+ * \a data will be passed as argument to the handler when an interrupt occurs.
+ *
+ * If \a irqnum is -1, _mali_osk_irq_init will probe for the IRQ number using
+ * the supplied \a trigger_func and \a ack_func. These functions will also
+ * receive \a data as their argument.
+ *
+ * @param irqnum The IRQ number that the resource uses, as seen by the CPU.
+ * The value -1 has a special meaning which indicates the use of probing, and
+ * trigger_func and ack_func must be non-NULL.
+ * @param uhandler The interrupt handler, corresponding to a ISR handler for
+ * the resource
+ * @param int_data resource specific data, which will be passed to uhandler
+ * @param trigger_func Optional: a function to trigger the resource's irq, to
+ * probe for the interrupt. Use NULL if irqnum != -1.
+ * @param ack_func Optional: a function to acknowledge the resource's irq, to
+ * probe for the interrupt. Use NULL if irqnum != -1.
+ * @param probe_data resource-specific data, which will be passed to
+ * (if present) trigger_func and ack_func
+ * @param description textual description of the IRQ resource.
+ * @return on success, a pointer to a _mali_osk_irq_t object, which represents
+ * the IRQ handling on this resource. NULL on failure.
+ */
+_mali_osk_irq_t *_mali_osk_irq_init(u32 irqnum, _mali_osk_irq_uhandler_t uhandler, void *int_data, _mali_osk_irq_trigger_t trigger_func, _mali_osk_irq_ack_t ack_func, void *probe_data, const char *description);
+
+/** @brief Terminate IRQ handling on a resource.
+ *
+ * This will disable the interrupt from the device, and then waits for any
+ * currently executing IRQ handlers to complete.
+ *
+ * @note If work is deferred to an IRQ bottom-half handler through
+ * \ref _mali_osk_wq_schedule_work(), be sure to flush any remaining work
+ * with \ref _mali_osk_wq_flush() or (implicitly) with \ref _mali_osk_wq_delete_work()
  *
  * @param irq a pointer to the _mali_osk_irq_t object corresponding to the
  * resource whose IRQ handling is to be terminated.
  */
-void _mali_osk_flush_workqueue( _mali_osk_irq_t *irq );
+void _mali_osk_irq_term(_mali_osk_irq_t *irq);
 
 /** @} */ /* end group _mali_osk_irq */
 
@@ -778,25 +322,25 @@ void _mali_osk_flush_workqueue( _mali_osk_irq_t *irq );
  * @note It is an error to decrement the counter beyond -(1<<23)
  *
  * @param atom pointer to an atomic counter */
-void _mali_osk_atomic_dec( _mali_osk_atomic_t *atom );
+void _mali_osk_atomic_dec(_mali_osk_atomic_t *atom);
 
 /** @brief Decrement an atomic counter, return new value
  *
  * @param atom pointer to an atomic counter
  * @return The new value, after decrement */
-u32 _mali_osk_atomic_dec_return( _mali_osk_atomic_t *atom );
+u32 _mali_osk_atomic_dec_return(_mali_osk_atomic_t *atom);
 
 /** @brief Increment an atomic counter
  *
  * @note It is an error to increment the counter beyond (1<<23)-1
  *
  * @param atom pointer to an atomic counter */
-void _mali_osk_atomic_inc( _mali_osk_atomic_t *atom );
+void _mali_osk_atomic_inc(_mali_osk_atomic_t *atom);
 
 /** @brief Increment an atomic counter, return new value
  *
  * @param atom pointer to an atomic counter */
-u32 _mali_osk_atomic_inc_return( _mali_osk_atomic_t *atom );
+u32 _mali_osk_atomic_inc_return(_mali_osk_atomic_t *atom);
 
 /** @brief Initialize an atomic counter
  *
@@ -808,7 +352,7 @@ u32 _mali_osk_atomic_inc_return( _mali_osk_atomic_t *atom );
  * @return _MALI_OSK_ERR_OK on success, otherwise, a suitable
  * _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_osk_atomic_init( _mali_osk_atomic_t *atom, u32 val );
+_mali_osk_errcode_t _mali_osk_atomic_init(_mali_osk_atomic_t *atom, u32 val);
 
 /** @brief Read a value from an atomic counter
  *
@@ -818,13 +362,21 @@ _mali_osk_errcode_t _mali_osk_atomic_init( _mali_osk_atomic_t *atom, u32 val );
  *
  * @param atom pointer to an atomic counter
  */
-u32 _mali_osk_atomic_read( _mali_osk_atomic_t *atom );
+u32 _mali_osk_atomic_read(_mali_osk_atomic_t *atom);
 
 /** @brief Terminate an atomic counter
  *
  * @param atom pointer to an atomic counter
  */
-void _mali_osk_atomic_term( _mali_osk_atomic_t *atom );
+void _mali_osk_atomic_term(_mali_osk_atomic_t *atom);
+
+/** @brief Assign a new val to atomic counter, and return the old atomic counter
+ *
+ * @param atom pointer to an atomic counter
+ * @param val the new value assign to the atomic counter
+ * @return the old value of the atomic counter
+ */
+u32 _mali_osk_atomic_xchg(_mali_osk_atomic_t *atom, u32 val);
 /** @} */  /* end group _mali_osk_atomic */
 
 
@@ -855,7 +407,7 @@ void _mali_osk_atomic_term( _mali_osk_atomic_t *atom );
  * @param size Size of each element
  * @return On success, the zero-initialized buffer allocated. NULL on failure
  */
-void *_mali_osk_calloc( u32 n, u32 size );
+void *_mali_osk_calloc(u32 n, u32 size);
 
 /** @brief Allocate memory.
  *
@@ -881,7 +433,7 @@ void *_mali_osk_calloc( u32 n, u32 size );
  * @param size Number of bytes to allocate
  * @return On success, the buffer allocated. NULL on failure.
  */
-void *_mali_osk_malloc( u32 size );
+void *_mali_osk_malloc(u32 size);
 
 /** @brief Free memory.
  *
@@ -897,7 +449,7 @@ void *_mali_osk_malloc( u32 size );
  *
  * @param ptr Pointer to buffer to free
  */
-void _mali_osk_free( void *ptr );
+void _mali_osk_free(void *ptr);
 
 /** @brief Allocate memory.
  *
@@ -922,7 +474,7 @@ void _mali_osk_free( void *ptr );
  * @param size Number of bytes to allocate
  * @return On success, the buffer allocated. NULL on failure.
  */
-void *_mali_osk_valloc( u32 size );
+void *_mali_osk_valloc(u32 size);
 
 /** @brief Free memory.
  *
@@ -937,7 +489,7 @@ void *_mali_osk_valloc( u32 size );
  *
  * @param ptr Pointer to buffer to free
  */
-void _mali_osk_vfree( void *ptr );
+void _mali_osk_vfree(void *ptr);
 
 /** @brief Copies memory.
  *
@@ -952,7 +504,7 @@ void _mali_osk_vfree( void *ptr );
  * @param len Number of bytes to copy.
  * @return \a dst is always passed through unmodified.
  */
-void *_mali_osk_memcpy( void *dst, const void *src, u32 len );
+void *_mali_osk_memcpy(void *dst, const void *src, u32 len);
 
 /** @brief Fills memory.
  *
@@ -964,7 +516,7 @@ void *_mali_osk_memcpy( void *dst, const void *src, u32 len );
  * @param n Number of bytes to be set to the value.
  * @return \a s is always passed through unmodified
  */
-void *_mali_osk_memset( void *s, u32 c, u32 n );
+void *_mali_osk_memset(void *s, u32 c, u32 n);
 /** @} */ /* end group _mali_osk_memory */
 
 
@@ -981,88 +533,7 @@ void *_mali_osk_memset( void *s, u32 c, u32 n );
  * @return MALI_TRUE when \a max_allocated bytes are not in use yet. MALI_FALSE
  * when at least \a max_allocated bytes are in use.
  */
-mali_bool _mali_osk_mem_check_allocated( u32 max_allocated );
-
-/** @addtogroup _mali_osk_lock
- * @{ */
-
-/** @brief Initialize a Mutual Exclusion Lock
- *
- * Locks are created in the signalled (unlocked) state.
- *
- * initial must be zero, since there is currently no means of expressing
- * whether a reader/writer lock should be initially locked as a reader or
- * writer. This would require some encoding to be used.
- *
- * 'Automatic' ordering means that locks must be obtained in the order that
- * they were created. For all locks that can be held at the same time, they must
- * either all provide the order parameter, or they all must use 'automatic'
- * ordering - because there is no way of mixing 'automatic' and 'manual'
- * ordering.
- *
- * @param flags flags combined with bitwise OR ('|'), or zero. There are
- * restrictions on which flags can be combined, @see _mali_osk_lock_flags_t.
- * @param initial For future expansion into semaphores. SBZ.
- * @param order The locking order of the mutex. That is, locks obtained by the
- * same thread must have been created with an increasing order parameter, for
- * deadlock prevention. Setting to zero causes 'automatic' ordering to be used.
- * @return On success, a pointer to a _mali_osk_lock_t object. NULL on failure.
- */
-_mali_osk_lock_t *_mali_osk_lock_init( _mali_osk_lock_flags_t flags, u32 initial, u32 order );
-
-/** @brief Wait for a lock to be signalled (obtained)
-
- * After a thread has successfully waited on the lock, the lock is obtained by
- * the thread, and is marked as unsignalled. The thread releases the lock by
- * signalling it.
- *
- * In the case of Reader/Writer locks, multiple readers can obtain a lock in
- * the absence of writers, which is a performance optimization (providing that
- * the readers never write to the protected resource).
- *
- * To prevent deadlock, locks must always be obtained in the same order.
- *
- * For locks marked as _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, it is a
- * programming error for the function to exit without obtaining the lock. This
- * means that the error code must only be checked for interruptible locks.
- *
- * @param lock the lock to wait upon (obtain).
- * @param mode the mode in which the lock should be obtained. Unless the lock
- * was created with _MALI_OSK_LOCKFLAG_READERWRITER, this must be
- * _MALI_OSK_LOCKMODE_RW.
- * @return On success, _MALI_OSK_ERR_OK. For interruptible locks, a suitable
- * _mali_osk_errcode_t will be returned on failure, and the lock will not be
- * obtained. In this case, the error code must be propagated up to the U/K
- * interface.
- */
-_mali_osk_errcode_t _mali_osk_lock_wait( _mali_osk_lock_t *lock, _mali_osk_lock_mode_t mode);
-
-
-/** @brief Signal (release) a lock
- *
- * Locks may only be signalled by the thread that originally waited upon the
- * lock.
- *
- * @note In the OSU, a flag exists to allow any thread to signal a
- * lock. Such functionality is not present in the OSK.
- *
- * @param lock the lock to signal (release).
- * @param mode the mode in which the lock should be obtained. This must match
- * the mode in which the lock was waited upon.
- */
-void _mali_osk_lock_signal( _mali_osk_lock_t *lock, _mali_osk_lock_mode_t mode );
-
-/** @brief Terminate a lock
- *
- * This terminates a lock and frees all associated resources.
- *
- * It is a programming error to terminate the lock when it is held (unsignalled)
- * by a thread.
- *
- * @param lock the lock to terminate.
- */
-void _mali_osk_lock_term( _mali_osk_lock_t *lock );
-/** @} */ /* end group _mali_osk_lock */
+mali_bool _mali_osk_mem_check_allocated(u32 max_allocated);
 
 
 /** @addtogroup _mali_osk_low_level_memory
@@ -1073,14 +544,14 @@ void _mali_osk_lock_term( _mali_osk_lock_t *lock );
  * This defines an arbitrary memory barrier operation, which forces an ordering constraint
  * on memory read and write operations.
  */
-void _mali_osk_mem_barrier( void );
+void _mali_osk_mem_barrier(void);
 
 /** @brief Issue a write memory barrier
  *
  * This defines an write memory barrier operation which forces an ordering constraint
  * on memory write operations.
  */
-void _mali_osk_write_mem_barrier( void );
+void _mali_osk_write_mem_barrier(void);
 
 /** @brief Map a physically contiguous region into kernel space
  *
@@ -1097,7 +568,7 @@ void _mali_osk_write_mem_barrier( void );
  * @return On success, a Mali IO address through which the mapped-in
  * memory/registers can be accessed. NULL on failure.
  */
-mali_io_address _mali_osk_mem_mapioregion( u32 phys, u32 size, const char *description );
+mali_io_address _mali_osk_mem_mapioregion(u32 phys, u32 size, const char *description);
 
 /** @brief Unmap a physically contiguous address range from kernel space.
  *
@@ -1119,7 +590,7 @@ mali_io_address _mali_osk_mem_mapioregion( u32 phys, u32 size, const char *descr
  * @param mapping The Mali IO address through which the mapping is
  * accessed.
  */
-void _mali_osk_mem_unmapioregion( u32 phys, u32 size, mali_io_address mapping );
+void _mali_osk_mem_unmapioregion(u32 phys, u32 size, mali_io_address mapping);
 
 /** @brief Allocate and Map a physically contiguous region into kernel space
  *
@@ -1146,7 +617,7 @@ void _mali_osk_mem_unmapioregion( u32 phys, u32 size, mali_io_address mapping );
  * @return On success, a Mali IO address through which the mapped-in
  * memory/registers can be accessed. NULL on failure, and (*phys) is unmodified.
  */
-mali_io_address _mali_osk_mem_allocioregion( u32 *phys, u32 size );
+mali_io_address _mali_osk_mem_allocioregion(u32 *phys, u32 size);
 
 /** @brief Free a physically contiguous address range from kernel space.
  *
@@ -1168,7 +639,7 @@ mali_io_address _mali_osk_mem_allocioregion( u32 *phys, u32 size );
  * @param mapping The Mali IO address through which the mapping is
  * accessed.
  */
-void _mali_osk_mem_freeioregion( u32 phys, u32 size, mali_io_address mapping );
+void _mali_osk_mem_freeioregion(u32 phys, u32 size, mali_io_address mapping);
 
 /** @brief Request a region of physically contiguous memory
  *
@@ -1188,7 +659,7 @@ void _mali_osk_mem_freeioregion( u32 phys, u32 size, mali_io_address mapping );
  * @return _MALI_OSK_ERR_OK on success. Otherwise, a suitable
  * _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_osk_mem_reqregion( u32 phys, u32 size, const char *description );
+_mali_osk_errcode_t _mali_osk_mem_reqregion(u32 phys, u32 size, const char *description);
 
 /** @brief Un-request a region of physically contiguous memory
  *
@@ -1208,7 +679,7 @@ _mali_osk_errcode_t _mali_osk_mem_reqregion( u32 phys, u32 size, const char *des
  * @param size the number of bytes of physically contiguous address space to
  * un-request.
  */
-void _mali_osk_mem_unreqregion( u32 phys, u32 size );
+void _mali_osk_mem_unreqregion(u32 phys, u32 size);
 
 /** @brief Read from a location currently mapped in through
  * _mali_osk_mem_mapioregion
@@ -1222,7 +693,7 @@ void _mali_osk_mem_unreqregion( u32 phys, u32 size );
  * @param offset Byte offset from the given IO address to operate on, must be a multiple of 4
  * @return the 32-bit word from the specified location.
  */
-u32 _mali_osk_mem_ioread32( volatile mali_io_address mapping, u32 offset );
+u32 _mali_osk_mem_ioread32(volatile mali_io_address mapping, u32 offset);
 
 /** @brief Write to a location currently mapped in through
  * _mali_osk_mem_mapioregion without memory barriers
@@ -1236,7 +707,7 @@ u32 _mali_osk_mem_ioread32( volatile mali_io_address mapping, u32 offset );
  * @param offset Byte offset from the given IO address to operate on, must be a multiple of 4
  * @param val the 32-bit word to write.
  */
-void _mali_osk_mem_iowrite32_relaxed( volatile mali_io_address addr, u32 offset, u32 val );
+void _mali_osk_mem_iowrite32_relaxed(volatile mali_io_address addr, u32 offset, u32 val);
 
 /** @brief Write to a location currently mapped in through
  * _mali_osk_mem_mapioregion with write memory barrier
@@ -1250,14 +721,14 @@ void _mali_osk_mem_iowrite32_relaxed( volatile mali_io_address addr, u32 offset,
  * @param offset Byte offset from the given IO address to operate on, must be a multiple of 4
  * @param val the 32-bit word to write.
  */
-void _mali_osk_mem_iowrite32( volatile mali_io_address mapping, u32 offset, u32 val );
+void _mali_osk_mem_iowrite32(volatile mali_io_address mapping, u32 offset, u32 val);
 
 /** @brief Flush all CPU caches
  *
  * This should only be implemented if flushing of the cache is required for
  * memory mapped in through _mali_osk_mem_mapregion.
  */
-void _mali_osk_cache_flushall( void );
+void _mali_osk_cache_flushall(void);
 
 /** @brief Flush any caches necessary for the CPU and MALI to have the same view of a range of uncached mapped memory
  *
@@ -1268,7 +739,18 @@ void _mali_osk_cache_flushall( void );
  * They zero the memory through a cached mapping, then flush the inner caches but not the outer caches.
  * This is required for MALI to have the correct view of the memory.
  */
-void _mali_osk_cache_ensure_uncached_range_flushed( void *uncached_mapping, u32 offset, u32 size );
+void _mali_osk_cache_ensure_uncached_range_flushed(void *uncached_mapping, u32 offset, u32 size);
+
+/** @brief Safely copy as much data as possible from src to dest
+ *
+ * Do not crash if src or dest isn't available.
+ *
+ * @param dest Destination buffer (limited to user space mapped Mali memory)
+ * @param src Source buffer
+ * @param size Number of bytes to copy
+ * @return Number of bytes actually copied
+ */
+u32 _mali_osk_mem_write_safe(void *dest, const void *src, u32 size);
 
 /** @} */ /* end group _mali_osk_low_level_memory */
 
@@ -1333,7 +815,7 @@ void _mali_osk_cache_ensure_uncached_range_flushed( void *uncached_mapping, u32
  * @param size The size of the type specific buffer to send
  * @return Pointer to a notification object with a suitable buffer, or NULL on error.
  */
-_mali_osk_notification_t *_mali_osk_notification_create( u32 type, u32 size );
+_mali_osk_notification_t *_mali_osk_notification_create(u32 type, u32 size);
 
 /** @brief Delete a notification object
  *
@@ -1353,7 +835,7 @@ _mali_osk_notification_t *_mali_osk_notification_create( u32 type, u32 size );
  *
  * @param object the notification object to delete.
  */
-void _mali_osk_notification_delete( _mali_osk_notification_t *object );
+void _mali_osk_notification_delete(_mali_osk_notification_t *object);
 
 /** @brief Create a notification queue
  *
@@ -1369,7 +851,7 @@ void _mali_osk_notification_delete( _mali_osk_notification_t *object );
  *
  * @return Pointer to a new notification queue or NULL on error.
  */
-_mali_osk_notification_queue_t *_mali_osk_notification_queue_init( void );
+_mali_osk_notification_queue_t *_mali_osk_notification_queue_init(void);
 
 /** @brief Destroy a notification queue
  *
@@ -1399,7 +881,7 @@ _mali_osk_notification_queue_t *_mali_osk_notification_queue_init( void );
  *
  * @param queue The queue to destroy
  */
-void _mali_osk_notification_queue_term( _mali_osk_notification_queue_t *queue );
+void _mali_osk_notification_queue_term(_mali_osk_notification_queue_t *queue);
 
 /** @brief Schedule notification for delivery
  *
@@ -1420,18 +902,7 @@ void _mali_osk_notification_queue_term( _mali_osk_notification_queue_t *queue );
  * @param queue The notification queue to add this notification to
  * @param object The entry to add
  */
-void _mali_osk_notification_queue_send( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t *object );
-
-#if MALI_STATE_TRACKING
-/** @brief Receive a notification from a queue
- *
- * Check if a notification queue is empty.
- *
- * @param queue The queue to check.
- * @return MALI_TRUE if queue is empty, otherwise MALI_FALSE.
- */
-mali_bool _mali_osk_notification_queue_is_empty( _mali_osk_notification_queue_t *queue );
-#endif
+void _mali_osk_notification_queue_send(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t *object);
 
 /** @brief Receive a notification from a queue
  *
@@ -1448,7 +919,7 @@ mali_bool _mali_osk_notification_queue_is_empty( _mali_osk_notification_queue_t
  * \ref _mali_osk_notification_t object, or NULL if none were received.
  * @return _MALI_OSK_ERR_OK on success. _MALI_OSK_ERR_RESTARTSYSCALL if the sleep was interrupted.
  */
-_mali_osk_errcode_t _mali_osk_notification_queue_receive( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result );
+_mali_osk_errcode_t _mali_osk_notification_queue_receive(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result);
 
 /** @brief Dequeues a notification from a queue
  *
@@ -1463,7 +934,7 @@ _mali_osk_errcode_t _mali_osk_notification_queue_receive( _mali_osk_notification
  * \ref _mali_osk_notification_t object, or NULL if none were received.
  * @return _MALI_OSK_ERR_OK on success, _MALI_OSK_ERR_ITEM_NOT_FOUND if queue was empty.
  */
-_mali_osk_errcode_t _mali_osk_notification_queue_dequeue( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result );
+_mali_osk_errcode_t _mali_osk_notification_queue_dequeue(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result);
 
 /** @} */ /* end group _mali_osk_notification */
 
@@ -1500,27 +971,26 @@ _mali_osk_timer_t *_mali_osk_timer_init(void);
  * @param ticks_to_expire the amount of time in ticks for the timer to run
  * before triggering.
  */
-void _mali_osk_timer_add( _mali_osk_timer_t *tim, u32 ticks_to_expire );
+void _mali_osk_timer_add(_mali_osk_timer_t *tim, u32 ticks_to_expire);
 
 /** @brief Modify a timer
  *
- * Set the absolute time at which a timer will expire, and start it if it is
- * stopped. If \a expiry_tick is in the past (determined by
- * _mali_osk_time_after() ), the timer fires immediately.
+ * Set the relative time at which a timer will expire, and start it if it is
+ * stopped. If \a ticks_to_expire 0 the timer fires immediately.
  *
  * It is an error to modify a timer without setting the callback via
  *  _mali_osk_timer_setcallback().
  *
- * The timer will expire at absolute time \a expiry_tick, at which point, the
- * callback function will be invoked with the callback-specific data, as set
- * by _mali_osk_timer_setcallback().
+ * The timer will expire at \a ticks_to_expire from the time of the call, at
+ * which point, the callback function will be invoked with the
+ * callback-specific data, as set by _mali_osk_timer_setcallback().
  *
  * @param tim the timer to modify, and start if necessary
- * @param expiry_tick the \em absolute time in ticks at which this timer should
- * trigger.
+ * @param ticks_to_expire the \em absolute time in ticks at which this timer
+ * should trigger.
  *
  */
-void _mali_osk_timer_mod( _mali_osk_timer_t *tim, u32 expiry_tick);
+void _mali_osk_timer_mod(_mali_osk_timer_t *tim, u32 ticks_to_expire);
 
 /** @brief Stop a timer, and block on its completion.
  *
@@ -1532,16 +1002,36 @@ void _mali_osk_timer_mod( _mali_osk_timer_t *tim, u32 expiry_tick);
  * occur.
  *
  * @note While the callback itself is guaranteed to not be running, work
- * enqueued on the IRQ work-queue by the timer (with
- * \ref _mali_osk_irq_schedulework()) may still run. The timer callback and IRQ
- * bottom-half handler must take this into account.
+ * enqueued on the work-queue by the timer (with
+ * \ref _mali_osk_wq_schedule_work()) may still run. The timer callback and
+ * work handler must take this into account.
+ *
+ * It is legal to stop an already stopped timer.
+ *
+ * @param tim the timer to stop.
+ *
+ */
+void _mali_osk_timer_del(_mali_osk_timer_t *tim);
+
+/** @brief Stop a timer.
+ *
+ * Stop the timer. When the function returns, the timer's callback may still be
+ * running on any CPU core.
  *
  * It is legal to stop an already stopped timer.
  *
  * @param tim the timer to stop.
+ */
+void _mali_osk_timer_del_async(_mali_osk_timer_t *tim);
+
+/** @brief Check if timer is pending.
+ *
+ * Check if timer is active.
  *
+ * @param tim the timer to check
+ * @return MALI_TRUE if time is active, MALI_FALSE if it is not active
  */
-void _mali_osk_timer_del( _mali_osk_timer_t *tim );
+mali_bool _mali_osk_timer_pending(_mali_osk_timer_t *tim);
 
 /** @brief Set a timer's callback parameters.
  *
@@ -1555,7 +1045,7 @@ void _mali_osk_timer_del( _mali_osk_timer_t *tim );
  * @param callback Function to call when timer expires
  * @param data Function-specific data to supply to the function on expiry.
  */
-void _mali_osk_timer_setcallback( _mali_osk_timer_t *tim, _mali_osk_timer_callback_t callback, void *data );
+void _mali_osk_timer_setcallback(_mali_osk_timer_t *tim, _mali_osk_timer_callback_t callback, void *data);
 
 /** @brief Terminate a timer, and deallocate resources.
  *
@@ -1567,7 +1057,7 @@ void _mali_osk_timer_setcallback( _mali_osk_timer_t *tim, _mali_osk_timer_callba
  *
  * @param tim the timer to deallocate.
  */
-void _mali_osk_timer_term( _mali_osk_timer_t *tim );
+void _mali_osk_timer_term(_mali_osk_timer_t *tim);
 /** @} */ /* end group _mali_osk_timer */
 
 
@@ -1604,27 +1094,27 @@ void _mali_osk_timer_term( _mali_osk_timer_t *tim );
  * @return non-zero if ticka represents a time that occurs after tickb.
  * Zero otherwise.
  */
-int	_mali_osk_time_after( u32 ticka, u32 tickb );
+int     _mali_osk_time_after(u32 ticka, u32 tickb);
 
 /** @brief Convert milliseconds to OS 'ticks'
  *
  * @param ms time interval in milliseconds
  * @return the corresponding time interval in OS ticks.
  */
-u32	_mali_osk_time_mstoticks( u32 ms );
+u32     _mali_osk_time_mstoticks(u32 ms);
 
 /** @brief Convert OS 'ticks' to milliseconds
  *
  * @param ticks time interval in OS ticks.
  * @return the corresponding time interval in milliseconds
  */
-u32	_mali_osk_time_tickstoms( u32 ticks );
+u32     _mali_osk_time_tickstoms(u32 ticks);
 
 
 /** @brief Get the current time in OS 'ticks'.
  * @return the current time in OS 'ticks'.
  */
-u32	_mali_osk_time_tickcount( void );
+u32     _mali_osk_time_tickcount(void);
 
 /** @brief Cause a microsecond delay
  *
@@ -1638,13 +1128,13 @@ u32	_mali_osk_time_tickcount( void );
  *
  * @param usecs the number of microseconds to wait for.
  */
-void _mali_osk_time_ubusydelay( u32 usecs );
+void _mali_osk_time_ubusydelay(u32 usecs);
 
 /** @brief Return time in nano seconds, since any given reference.
  *
  * @return Time in nano seconds
  */
-u64 _mali_osk_time_get_ns( void );
+u64 _mali_osk_time_get_ns(void);
 
 
 /** @} */ /* end group _mali_osk_time */
@@ -1661,27 +1151,48 @@ u64 _mali_osk_time_get_ns( void );
  * @param val 32-bit words to count leading zeros on
  * @return the number of leading zeros.
  */
-u32 _mali_osk_clz( u32 val );
+u32 _mali_osk_clz(u32 val);
+
+/** @brief find last (most-significant) bit set
+ *
+ * @param val 32-bit words to count last bit set on
+ * @return last bit set.
+ */
+u32 _mali_osk_fls(u32 val);
+
 /** @} */ /* end group _mali_osk_math */
 
-/** @defgroup _mali_osk_wait_queue OSK Wait Queue functionality
+/** @addtogroup _mali_osk_wait_queue OSK Wait Queue functionality
  * @{ */
-/** @brief Private type for wait queue objects */
-typedef struct _mali_osk_wait_queue_t_struct _mali_osk_wait_queue_t;
 
 /** @brief Initialize an empty Wait Queue */
-_mali_osk_wait_queue_t* _mali_osk_wait_queue_init( void );
+_mali_osk_wait_queue_t *_mali_osk_wait_queue_init(void);
 
-/** @brief Sleep  if condition is false
+/** @brief Sleep if condition is false
  *
  * @param queue the queue to use
  * @param condition function pointer to a boolean function
+ * @param data data parameter for condition function
  *
- * Put thread to sleep if the given \a codition function returns false. When
+ * Put thread to sleep if the given \a condition function returns false. When
  * being asked to wake up again, the condition will be re-checked and the
  * thread only woken up if the condition is now true.
  */
-void _mali_osk_wait_queue_wait_event( _mali_osk_wait_queue_t *queue, mali_bool (*condition)(void) );
+void _mali_osk_wait_queue_wait_event(_mali_osk_wait_queue_t *queue, mali_bool(*condition)(void *), void *data);
+
+/** @brief Sleep if condition is false
+ *
+ * @param queue the queue to use
+ * @param condition function pointer to a boolean function
+ * @param data data parameter for condition function
+ * @param timeout timeout in ms
+ *
+ * Put thread to sleep if the given \a condition function returns false. When
+ * being asked to wake up again, the condition will be re-checked and the
+ * thread only woken up if the condition is now true.  Will return if time
+ * exceeds timeout.
+ */
+void _mali_osk_wait_queue_wait_event_timeout(_mali_osk_wait_queue_t *queue, mali_bool(*condition)(void *), void *data, u32 timeout);
 
 /** @brief Wake up all threads in wait queue if their respective conditions are
  * true
@@ -1690,13 +1201,13 @@ void _mali_osk_wait_queue_wait_event( _mali_osk_wait_queue_t *queue, mali_bool (
  *
  * Wake up all threads in wait queue \a queue whose condition is now true.
  */
-void _mali_osk_wait_queue_wake_up( _mali_osk_wait_queue_t *queue );
+void _mali_osk_wait_queue_wake_up(_mali_osk_wait_queue_t *queue);
 
 /** @brief terminate a wait queue
  *
  * @param queue the queue to terminate.
  */
-void _mali_osk_wait_queue_term( _mali_osk_wait_queue_t *queue );
+void _mali_osk_wait_queue_term(_mali_osk_wait_queue_t *queue);
 /** @} */ /* end group _mali_osk_wait_queue */
 
 
@@ -1711,7 +1222,7 @@ void _mali_osk_wait_queue_term( _mali_osk_wait_queue_t *queue );
  * @param fmt a _mali_osu_vsnprintf() style format string
  * @param ... a variable-number of parameters suitable for \a fmt
  */
-void _mali_osk_dbgmsg( const char *fmt, ... );
+void _mali_osk_dbgmsg(const char *fmt, ...);
 
 /** @brief Print fmt into buf.
  *
@@ -1724,7 +1235,7 @@ void _mali_osk_dbgmsg( const char *fmt, ... );
  * @param ... a variable-number of parameters suitable for \a fmt
  * @return The number of bytes written to \a buf
  */
-u32 _mali_osk_snprintf( char *buf, u32 size, const char *fmt, ... );
+u32 _mali_osk_snprintf(char *buf, u32 size, const char *fmt, ...);
 
 /** @brief Abnormal process abort.
  *
@@ -1765,13 +1276,51 @@ u32 _mali_osk_get_tid(void);
  */
 void _mali_osk_pm_dev_enable(void);
 
-/** @brief Tells the OS that device is now idle
+/** @brief Disable OS controlled runtime power management
  */
-_mali_osk_errcode_t _mali_osk_pm_dev_idle(void);
+void _mali_osk_pm_dev_disable(void);
+
 
-/** @brief Tells the OS that the device is about to become active
+/** @brief Take a reference to the power manager system for the Mali device.
+ *
+ * When function returns successfully, Mali is ON.
+ *
+ * @note Call \a _mali_osk_pm_dev_ref_dec() to release this reference.
  */
-_mali_osk_errcode_t _mali_osk_pm_dev_activate(void);
+_mali_osk_errcode_t _mali_osk_pm_dev_ref_add(void);
+
+
+/** @brief Release the reference to the power manger system for the Mali device.
+ *
+ * When reference count reach zero, the cores can be off.
+ *
+ * @note This must be used to release references taken with \a _mali_osk_pm_dev_ref_add().
+ */
+void _mali_osk_pm_dev_ref_dec(void);
+
+
+/** @brief Take a reference to the power manager system for the Mali device.
+ *
+ * Will leave the cores powered off if they are already powered off.
+ *
+ * @note Call \a _mali_osk_pm_dev_ref_dec() to release this reference.
+ *
+ * @return MALI_TRUE if the Mali GPU is powered on, otherwise MALI_FALSE.
+ */
+mali_bool _mali_osk_pm_dev_ref_add_no_power_on(void);
+
+
+/** @brief Releasing the reference to the power manger system for the Mali device.
+ *
+ * When reference count reach zero, the cores can be off.
+ *
+ * @note This must be used to release references taken with \a _mali_osk_pm_dev_ref_add_no_power_on().
+ */
+void _mali_osk_pm_dev_ref_dec_no_power_on(void);
+
+/** @brief Block untill pending PM operations are done
+ */
+void _mali_osk_pm_dev_barrier(void);
 
 /** @} */ /* end group  _mali_osk_miscellaneous */
 
@@ -1780,19 +1329,18 @@ _mali_osk_errcode_t _mali_osk_pm_dev_activate(void);
 /** @} */ /* end group uddapi */
 
 
+
 #ifdef __cplusplus
 }
 #endif
 
-#include "mali_osk_specific.h"           /* include any per-os specifics */
-
 /* Check standard inlines */
 #ifndef MALI_STATIC_INLINE
-	#error MALI_STATIC_INLINE not defined on your OS
+#error MALI_STATIC_INLINE not defined on your OS
 #endif
 
 #ifndef MALI_NON_STATIC_INLINE
-	#error MALI_NON_STATIC_INLINE not defined on your OS
+#error MALI_NON_STATIC_INLINE not defined on your OS
 #endif
 
 #endif /* __MALI_OSK_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_osk_bitops.h b/drivers/gpu/mali/mali/common/mali_osk_bitops.h
old mode 100644
new mode 100755
index d4a2907..525b944
--- a/drivers/gpu/mali/mali/common/mali_osk_bitops.h
+++ b/drivers/gpu/mali/mali/common/mali_osk_bitops.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,33 +17,32 @@
 #define __MALI_OSK_BITOPS_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
-MALI_STATIC_INLINE void _mali_internal_clear_bit( u32 bit, u32 *addr )
+MALI_STATIC_INLINE void _mali_internal_clear_bit(u32 bit, u32 *addr)
 {
-	MALI_DEBUG_ASSERT( bit < 32 );
-	MALI_DEBUG_ASSERT( NULL != addr );
+	MALI_DEBUG_ASSERT(bit < 32);
+	MALI_DEBUG_ASSERT(NULL != addr);
 
 	(*addr) &= ~(1 << bit);
 }
 
-MALI_STATIC_INLINE void _mali_internal_set_bit( u32 bit, u32 *addr )
+MALI_STATIC_INLINE void _mali_internal_set_bit(u32 bit, u32 *addr)
 {
-	MALI_DEBUG_ASSERT( bit < 32 );
-	MALI_DEBUG_ASSERT( NULL != addr );
+	MALI_DEBUG_ASSERT(bit < 32);
+	MALI_DEBUG_ASSERT(NULL != addr);
 
 	(*addr) |= (1 << bit);
 }
 
-MALI_STATIC_INLINE u32 _mali_internal_test_bit( u32 bit, u32 value )
+MALI_STATIC_INLINE u32 _mali_internal_test_bit(u32 bit, u32 value)
 {
-	MALI_DEBUG_ASSERT( bit < 32 );
+	MALI_DEBUG_ASSERT(bit < 32);
 	return value & (1 << bit);
 }
 
-MALI_STATIC_INLINE int _mali_internal_find_first_zero_bit( u32 value )
+MALI_STATIC_INLINE int _mali_internal_find_first_zero_bit(u32 value)
 {
 	u32 inverted;
 	u32 negated;
@@ -56,14 +55,14 @@ MALI_STATIC_INLINE int _mali_internal_find_first_zero_bit( u32 value )
 	 * See ARM System Developers Guide for details of count_trailing_zeros */
 
 	/* Isolate the zero: it is preceeded by a run of 1s, so add 1 to it */
-	negated = (u32)-inverted ; /* -a == ~a + 1 (mod 2^n) for n-bit numbers */
-    /* negated = xxx...x1000...0 */
+	negated = (u32) - inverted ; /* -a == ~a + 1 (mod 2^n) for n-bit numbers */
+	/* negated = xxx...x1000...0 */
 
 	isolated = negated & inverted ; /* xxx...x1000...0 & zzz...z1000...0, zs are ~xs */
 	/* And so the first zero bit is in the same position as the 1 == number of 1s that preceeded it
 	 * Note that the output is zero if value was all 1s */
 
-	leading_zeros = _mali_osk_clz( isolated );
+	leading_zeros = _mali_osk_clz(isolated);
 
 	return 31 - leading_zeros;
 }
@@ -89,12 +88,12 @@ MALI_STATIC_INLINE int _mali_internal_find_first_zero_bit( u32 value )
  * significant bit
  * @param addr starting point for counting.
  */
-MALI_STATIC_INLINE void _mali_osk_clear_nonatomic_bit( u32 nr, u32 *addr )
+MALI_STATIC_INLINE void _mali_osk_clear_nonatomic_bit(u32 nr, u32 *addr)
 {
 	addr += nr >> 5; /* find the correct word */
-	nr = nr & ((1 << 5)-1); /* The bit number within the word */
+	nr = nr & ((1 << 5) - 1); /* The bit number within the word */
 
-	_mali_internal_clear_bit( nr, addr );
+	_mali_internal_clear_bit(nr, addr);
 }
 
 /** @brief Set a bit in a sequence of 32-bit words
@@ -102,12 +101,12 @@ MALI_STATIC_INLINE void _mali_osk_clear_nonatomic_bit( u32 nr, u32 *addr )
  * significant bit
  * @param addr starting point for counting.
  */
-MALI_STATIC_INLINE void _mali_osk_set_nonatomic_bit( u32 nr, u32 *addr )
+MALI_STATIC_INLINE void _mali_osk_set_nonatomic_bit(u32 nr, u32 *addr)
 {
 	addr += nr >> 5; /* find the correct word */
-	nr = nr & ((1 << 5)-1); /* The bit number within the word */
+	nr = nr & ((1 << 5) - 1); /* The bit number within the word */
 
-	_mali_internal_set_bit( nr, addr );
+	_mali_internal_set_bit(nr, addr);
 }
 
 /** @brief Test a bit in a sequence of 32-bit words
@@ -117,12 +116,12 @@ MALI_STATIC_INLINE void _mali_osk_set_nonatomic_bit( u32 nr, u32 *addr )
  * @return zero if bit was clear, non-zero if set. Do not rely on the return
  * value being related to the actual word under test.
  */
-MALI_STATIC_INLINE u32 _mali_osk_test_bit( u32 nr, u32 *addr )
+MALI_STATIC_INLINE u32 _mali_osk_test_bit(u32 nr, u32 *addr)
 {
 	addr += nr >> 5; /* find the correct word */
-	nr = nr & ((1 << 5)-1); /* The bit number within the word */
+	nr = nr & ((1 << 5) - 1); /* The bit number within the word */
 
-	return _mali_internal_test_bit( nr, *addr );
+	return _mali_internal_test_bit(nr, *addr);
 }
 
 /* Return maxbit if not found */
@@ -132,26 +131,23 @@ MALI_STATIC_INLINE u32 _mali_osk_test_bit( u32 nr, u32 *addr )
  * @return the number of the first zero bit found, or maxbit if none were found
  * in the specified range.
  */
-MALI_STATIC_INLINE u32 _mali_osk_find_first_zero_bit( const u32 *addr, u32 maxbit )
+MALI_STATIC_INLINE u32 _mali_osk_find_first_zero_bit(const u32 *addr, u32 maxbit)
 {
 	u32 total;
 
-	for ( total = 0; total < maxbit; total += 32, ++addr )
-	{
+	for (total = 0; total < maxbit; total += 32, ++addr) {
 		int result;
-		result = _mali_internal_find_first_zero_bit( *addr );
+		result = _mali_internal_find_first_zero_bit(*addr);
 
 		/* non-negative signifies the bit was found */
-		if ( result >= 0 )
-		{
+		if (result >= 0) {
 			total += (u32)result;
 			break;
 		}
 	}
 
 	/* Now check if we reached maxbit or above */
-	if ( total >= maxbit )
-	{
+	if (total >= maxbit) {
 		total = maxbit;
 	}
 
diff --git a/drivers/gpu/mali/mali/common/mali_osk_list.h b/drivers/gpu/mali/mali/common/mali_osk_list.h
old mode 100644
new mode 100755
index 8d6f107..2cd190e
--- a/drivers/gpu/mali/mali/common/mali_osk_list.h
+++ b/drivers/gpu/mali/mali/common/mali_osk_list.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,26 +16,28 @@
 #ifndef __MALI_OSK_LIST_H__
 #define __MALI_OSK_LIST_H__
 
+#include "mali_osk.h"
+#include "mali_kernel_common.h"
+
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 MALI_STATIC_INLINE void __mali_osk_list_add(_mali_osk_list_t *new_entry, _mali_osk_list_t *prev, _mali_osk_list_t *next)
 {
-    next->prev = new_entry;
-    new_entry->next = next;
-    new_entry->prev = prev;
-    prev->next = new_entry;
+	next->prev = new_entry;
+	new_entry->next = next;
+	new_entry->prev = prev;
+	prev->next = new_entry;
 }
 
 MALI_STATIC_INLINE void __mali_osk_list_del(_mali_osk_list_t *prev, _mali_osk_list_t *next)
 {
-    next->prev = prev;
-    prev->next = next;
+	next->prev = prev;
+	prev->next = next;
 }
 
-/** @addtogroup _mali_osk_list
+/** @addtogroup _mali_osk_list OSK Doubly-Linked Circular Lists
  * @{ */
 
 /** Reference implementations of Doubly-linked Circular Lists are provided.
@@ -45,6 +47,18 @@ MALI_STATIC_INLINE void __mali_osk_list_del(_mali_osk_list_t *prev, _mali_osk_li
  * For this reason, these lists should not be mixed with OS-specific lists
  * inside the OSK/UKK implementation. */
 
+/** @brief Initialize a list to be a head of an empty list
+ * @param exp the list to initialize. */
+#define _MALI_OSK_INIT_LIST_HEAD(exp) _mali_osk_list_init(exp)
+
+/** @brief Define a list variable, which is uninitialized.
+ * @param exp the name of the variable that the list will be defined as. */
+#define _MALI_OSK_LIST_HEAD(exp) _mali_osk_list_t exp
+
+/** @brief Define a list variable, which is initialized.
+ * @param exp the name of the variable that the list will be defined as. */
+#define _MALI_OSK_LIST_HEAD_STATIC_INIT(exp) _mali_osk_list_t exp = { &exp, &exp }
+
 /** @brief Initialize a list element.
  *
  * All list elements must be initialized before use.
@@ -54,10 +68,10 @@ MALI_STATIC_INLINE void __mali_osk_list_del(_mali_osk_list_t *prev, _mali_osk_li
  *
  * @param list the list element to initialize
  */
-MALI_STATIC_INLINE void _mali_osk_list_init( _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_init(_mali_osk_list_t *list)
 {
-    list->next = list;
-    list->prev = list;
+	list->next = list;
+	list->prev = list;
 }
 
 /** @brief Insert a single list element after an entry in a list
@@ -73,9 +87,9 @@ MALI_STATIC_INLINE void _mali_osk_list_init( _mali_osk_list_t *list )
  * @param list the list in which to insert. The new element will be the next
  * entry in this list
  */
-MALI_STATIC_INLINE void _mali_osk_list_add( _mali_osk_list_t *new_entry, _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_add(_mali_osk_list_t *new_entry, _mali_osk_list_t *list)
 {
-    __mali_osk_list_add(new_entry, list, list->next);
+	__mali_osk_list_add(new_entry, list, list->next);
 }
 
 /** @brief Insert a single list element before an entry in a list
@@ -90,9 +104,9 @@ MALI_STATIC_INLINE void _mali_osk_list_add( _mali_osk_list_t *new_entry, _mali_o
  * @param list the list in which to insert. The new element will be the previous
  * entry in this list
  */
-MALI_STATIC_INLINE void _mali_osk_list_addtail( _mali_osk_list_t *new_entry, _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_addtail(_mali_osk_list_t *new_entry, _mali_osk_list_t *list)
 {
-    __mali_osk_list_add(new_entry, list->prev, list);
+	__mali_osk_list_add(new_entry, list->prev, list);
 }
 
 /** @brief Remove a single element from a list
@@ -103,9 +117,9 @@ MALI_STATIC_INLINE void _mali_osk_list_addtail( _mali_osk_list_t *new_entry, _ma
  *
  * @param list the list element to remove.
  */
-MALI_STATIC_INLINE void _mali_osk_list_del( _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_del(_mali_osk_list_t *list)
 {
-    __mali_osk_list_del(list->prev, list->next);
+	__mali_osk_list_del(list->prev, list->next);
 }
 
 /** @brief Remove a single element from a list, and re-initialize it
@@ -115,10 +129,10 @@ MALI_STATIC_INLINE void _mali_osk_list_del( _mali_osk_list_t *list )
  *
  * @param list the list element to remove and initialize.
  */
-MALI_STATIC_INLINE void _mali_osk_list_delinit( _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_delinit(_mali_osk_list_t *list)
 {
-    __mali_osk_list_del(list->prev, list->next);
-    _mali_osk_list_init(list);
+	__mali_osk_list_del(list->prev, list->next);
+	_mali_osk_list_init(list);
 }
 
 /** @brief Determine whether a list is empty.
@@ -128,9 +142,9 @@ MALI_STATIC_INLINE void _mali_osk_list_delinit( _mali_osk_list_t *list )
  * @param list the list to check.
  * @return non-zero if the list is empty, and zero otherwise.
  */
-MALI_STATIC_INLINE int _mali_osk_list_empty( _mali_osk_list_t *list )
+MALI_STATIC_INLINE mali_bool _mali_osk_list_empty(_mali_osk_list_t *list)
 {
-    return list->next == list;
+	return list->next == list;
 }
 
 /** @brief Move a list element from one list to another.
@@ -144,37 +158,112 @@ MALI_STATIC_INLINE int _mali_osk_list_empty( _mali_osk_list_t *list )
  * @param list the new list into which the element will be inserted, as the next
  * element in the list.
  */
-MALI_STATIC_INLINE void _mali_osk_list_move( _mali_osk_list_t *move_entry, _mali_osk_list_t *list )
+MALI_STATIC_INLINE void _mali_osk_list_move(_mali_osk_list_t *move_entry, _mali_osk_list_t *list)
 {
-    __mali_osk_list_del(move_entry->prev, move_entry->next);
-    _mali_osk_list_add(move_entry, list);
+	__mali_osk_list_del(move_entry->prev, move_entry->next);
+	_mali_osk_list_add(move_entry, list);
 }
 
-/** @brief Join two lists
+/** @brief Move an entire list
  *
  * The list element must be initialized.
  *
- * Allows you to join a list into another list at a specific location
+ * Allows you to move a list from one list head to another list head
  *
- * @param list the new list to add
- * @param at the location in a list to add the new list into
+ * @param old_list The existing list head
+ * @param new_list The new list head (must be an empty list)
  */
-MALI_STATIC_INLINE void _mali_osk_list_splice( _mali_osk_list_t *list, _mali_osk_list_t *at )
+MALI_STATIC_INLINE void _mali_osk_list_move_list(_mali_osk_list_t *old_list, _mali_osk_list_t *new_list)
 {
-    if (!_mali_osk_list_empty(list))
-    {
-        /* insert all items from 'list' after 'at'  */
-        _mali_osk_list_t *first = list->next;
-        _mali_osk_list_t *last = list->prev;
-        _mali_osk_list_t *split = at->next;
-
-        first->prev = at;
-        at->next = first;
-
-        last->next  = split;
-        split->prev = last;
-    }
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(new_list));
+	if (!_mali_osk_list_empty(old_list)) {
+		new_list->next = old_list->next;
+		new_list->prev = old_list->prev;
+		new_list->next->prev = new_list;
+		new_list->prev->next = new_list;
+		old_list->next = old_list;
+		old_list->prev = old_list;
+	}
 }
+
+/** @brief Find the containing structure of a list
+ *
+ * When traversing a list, this is used to recover the containing structure,
+ * given that is contains a _mali_osk_list_t member.
+ *
+ * Each list must be of structures of one type, and must link the same members
+ * together, otherwise it will not be possible to correctly recover the
+ * sturctures that the lists link.
+ *
+ * @note no type or memory checking occurs to ensure that a structure does in
+ * fact exist for the list entry, and that it is being recovered with respect
+ * to the correct list member.
+ *
+ * @param ptr the pointer to the _mali_osk_list_t member in this structure
+ * @param type the type of the structure that contains the member
+ * @param member the member of the structure that ptr points to.
+ * @return a pointer to a \a type object which contains the _mali_osk_list_t
+ * \a member, as pointed to by the _mali_osk_list_t \a *ptr.
+ */
+#define _MALI_OSK_LIST_ENTRY(ptr, type, member) \
+	_MALI_OSK_CONTAINER_OF(ptr, type, member)
+
+/** @brief Enumerate a list safely
+ *
+ * With this macro, lists can be enumerated in a 'safe' manner. That is,
+ * entries can be deleted from the list without causing an error during
+ * enumeration. To achieve this, a 'temporary' pointer is required, which must
+ * be provided to the macro.
+ *
+ * Use it like a 'for()', 'while()' or 'do()' construct, and so it must be
+ * followed by a statement or compound-statement which will be executed for
+ * each list entry.
+ *
+ * Upon loop completion, providing that an early out was not taken in the
+ * loop body, then it is guaranteed that ptr->member == list, even if the loop
+ * body never executed.
+ *
+ * @param ptr a pointer to an object of type 'type', which points to the
+ * structure that contains the currently enumerated list entry.
+ * @param tmp a pointer to an object of type 'type', which must not be used
+ * inside the list-execution statement.
+ * @param list a pointer to a _mali_osk_list_t, from which enumeration will
+ * begin
+ * @param type the type of the structure that contains the _mali_osk_list_t
+ * member that is part of the list to be enumerated.
+ * @param member the _mali_osk_list_t member of the structure that is part of
+ * the list to be enumerated.
+ */
+#define _MALI_OSK_LIST_FOREACHENTRY(ptr, tmp, list, type, member)         \
+	for (ptr = _MALI_OSK_LIST_ENTRY((list)->next, type, member),      \
+	     tmp = _MALI_OSK_LIST_ENTRY(ptr->member.next, type, member);  \
+	     &ptr->member != (list);                                      \
+	     ptr = tmp,                                                   \
+	     tmp = _MALI_OSK_LIST_ENTRY(tmp->member.next, type, member))
+
+/** @brief Enumerate a list in reverse order safely
+ *
+ * This macro is identical to @ref _MALI_OSK_LIST_FOREACHENTRY, except that
+ * entries are enumerated in reverse order.
+ *
+ * @param ptr a pointer to an object of type 'type', which points to the
+ * structure that contains the currently enumerated list entry.
+ * @param tmp a pointer to an object of type 'type', which must not be used
+ * inside the list-execution statement.
+ * @param list a pointer to a _mali_osk_list_t, from which enumeration will
+ * begin
+ * @param type the type of the structure that contains the _mali_osk_list_t
+ * member that is part of the list to be enumerated.
+ * @param member the _mali_osk_list_t member of the structure that is part of
+ * the list to be enumerated.
+ */
+#define _MALI_OSK_LIST_FOREACHENTRY_REVERSE(ptr, tmp, list, type, member) \
+	for (ptr = _MALI_OSK_LIST_ENTRY((list)->prev, type, member),      \
+	     tmp = _MALI_OSK_LIST_ENTRY(ptr->member.prev, type, member);  \
+	     &ptr->member != (list);                                      \
+	     ptr = tmp,                                                   \
+	     tmp = _MALI_OSK_LIST_ENTRY(tmp->member.prev, type, member))
+
 /** @} */ /* end group _mali_osk_list */
 
 #ifdef __cplusplus
diff --git a/drivers/gpu/mali/mali/common/mali_osk_mali.h b/drivers/gpu/mali/mali/common/mali_osk_mali.h
old mode 100644
new mode 100755
index a73f027..24356c0
--- a/drivers/gpu/mali/mali/common/mali_osk_mali.h
+++ b/drivers/gpu/mali/mali/common/mali_osk_mali.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,204 +16,48 @@
 #ifndef __MALI_OSK_MALI_H__
 #define __MALI_OSK_MALI_H__
 
+#include <linux/mali/mali_utgard.h>
 #include <mali_osk.h>
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 /** @addtogroup _mali_osk_miscellaneous
  * @{ */
 
-/** @brief Read the Mali Resource configuration
- *
- * Populates a _mali_arch_resource_t array from configuration settings, which
- * are stored in an OS-specific way.
- *
- * For example, these may be compiled in to a static structure, or read from
- * the filesystem at startup.
- *
- * On failure, do not call _mali_osk_resources_term.
- *
- * @param arch_config a pointer to the store the pointer to the resources
- * @param num_resources the number of resources read
- * @return _MALI_OSK_ERR_OK on success. _MALI_OSK_ERR_NOMEM on allocation
- * error. For other failures, a suitable _mali_osk_errcode_t is returned.
+/** @brief Struct with device specific configuration data
  */
-_mali_osk_errcode_t _mali_osk_resources_init( _mali_osk_resource_t **arch_config, u32 *num_resources );
+typedef struct mali_gpu_device_data _mali_osk_device_data;
 
-/** @brief Free resources allocated by _mali_osk_resources_init.
+/** @brief Find Mali GPU HW resource
  *
- * Frees the _mali_arch_resource_t array allocated by _mali_osk_resources_init
- *
- * @param arch_config a pointer to the stored the pointer to the resources
- * @param num_resources the number of resources in the array
+ * @param addr Address of Mali GPU resource to find
+ * @param res Storage for resource information if resource is found.
+ * @return _MALI_OSK_ERR_OK on success, _MALI_OSK_ERR_ITEM_NOT_FOUND if resource is not found
  */
-void _mali_osk_resources_term( _mali_osk_resource_t **arch_config, u32 num_resources);
-/** @} */ /* end group _mali_osk_miscellaneous */
+_mali_osk_errcode_t _mali_osk_resource_find(u32 addr, _mali_osk_resource_t *res);
 
-/** @addtogroup _mali_osk_low_level_memory
- * @{ */
 
-/** @brief Initialize a user-space accessible memory range
- *
- * This initializes a virtual address range such that it is reserved for the
- * current process, but does not map any physical pages into this range.
- *
- * This function may initialize or adjust any members of the
- * mali_memory_allocation \a descriptor supplied, before the physical pages are
- * mapped in with _mali_osk_mem_mapregion_map().
+/** @brief Find Mali GPU HW base address
  *
- * The function will always be called with MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE
- * set in \a descriptor->flags. It is an error to call this function without
- * setting this flag. Otherwise, \a descriptor->flags bits are reserved for
- * future expansion
- *
- * The \a descriptor's process_addr_mapping_info member can be modified to
- * allocate OS-specific information. Note that on input, this will be a
- * ukk_private word from the U/K inteface, as inserted by _mali_ukk_mem_mmap().
- * This is used to pass information from the U/K interface to the OSK interface,
- * if necessary. The precise usage of the process_addr_mapping_info member
- * depends on the U/K implementation of _mali_ukk_mem_mmap().
- *
- * Therefore, the U/K implementation of _mali_ukk_mem_mmap() and the OSK
- * implementation of  _mali_osk_mem_mapregion_init() must agree on the meaning and
- * usage of the ukk_private word and process_addr_mapping_info member.
- *
- * Refer to \ref u_k_api for more information on the U/K interface.
- *
- * On successful return, \a descriptor's mapping member will be correct for
- * use with _mali_osk_mem_mapregion_term() and _mali_osk_mem_mapregion_map().
- *
- * @param descriptor the mali_memory_allocation to initialize.
+ * @return 0 if resources are found, otherwise the Mali GPU component with lowest address.
  */
-_mali_osk_errcode_t _mali_osk_mem_mapregion_init( mali_memory_allocation * descriptor );
+u32 _mali_osk_resource_base_address(void);
 
-/** @brief Terminate a user-space accessible memory range
- *
- * This terminates a virtual address range reserved in the current user process,
- * where none, some or all of the virtual address ranges have mappings to
- * physical pages.
+/** @brief Retrieve the Mali GPU specific data
  *
- * It will unmap any physical pages that had been mapped into a reserved
- * virtual address range for the current process, and then releases the virtual
- * address range. Any extra book-keeping information or resources allocated
- * during _mali_osk_mem_mapregion_init() will also be released.
- *
- * The \a descriptor itself is not freed - this must be handled by the caller of
- * _mali_osk_mem_mapregion_term().
- *
- * The function will always be called with MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE
- * set in descriptor->flags. It is an error to call this function without
- * setting this flag. Otherwise, descriptor->flags bits are reserved for
- * future expansion
- *
- * @param descriptor the mali_memory_allocation to terminate.
+ * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-void _mali_osk_mem_mapregion_term( mali_memory_allocation * descriptor );
+_mali_osk_errcode_t _mali_osk_device_data_get(_mali_osk_device_data *data);
 
-/** @brief Map physical pages into a user process's virtual address range
- *
- * This is used to map a number of physically contigous pages into a
- * user-process's virtual address range, which was previously reserved by a
- * call to _mali_osk_mem_mapregion_init().
- *
- * This need not provide a mapping for the entire virtual address range
- * reserved for \a descriptor - it may be used to map single pages per call.
+/** @brief Determines if Mali GPU has been configured with shared interrupts.
  *
- * The function will always be called with MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE
- * set in \a descriptor->flags. It is an error to call this function without
- * setting this flag. Otherwise, \a descriptor->flags bits are reserved for
- * future expansion
- *
- * The function may supply \a *phys_addr == \ref MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC.
- * In this case, \a size must be set to \ref _MALI_OSK_CPU_PAGE_SIZE, and the function
- * will allocate the physical page itself. The physical address of the
- * allocated page will be returned through \a phys_addr.
- *
- * It is an error to set \a size != \ref _MALI_OSK_CPU_PAGE_SIZE while
- * \a *phys_addr == \ref MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC,
- * since it is not always possible for OSs to support such a setting through this
- * interface.
- *
- * @note \b IMPORTANT: This code must validate the input parameters. If the
- * range defined by \a offset and \a size is outside the range allocated in
- * \a descriptor, then this function \b MUST not attempt any mapping, and must
- * instead return a suitable \ref _mali_osk_errcode_t \b failure code.
- *
- * @param[in,out] descriptor the mali_memory_allocation representing the
- * user-process's virtual address range to map into.
- *
- * @param[in] offset the offset into the virtual address range. This is only added
- * to the mapping member of the \a descriptor, and not the \a phys_addr parameter.
- * It must be a multiple of \ref _MALI_OSK_CPU_PAGE_SIZE.
- *
- * @param[in,out] phys_addr a pointer to the physical base address to begin the
- * mapping from. If \a size == \ref _MALI_OSK_CPU_PAGE_SIZE and
- * \a *phys_addr == \ref MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC, then this
- * function will allocate the physical page itself, and return the
- * physical address of the page through \a phys_addr, which will be aligned to
- * \ref _MALI_OSK_CPU_PAGE_SIZE. Otherwise, \a *phys_addr must be aligned to
- * \ref _MALI_OSK_CPU_PAGE_SIZE, and is unmodified after the call.
- * \a phys_addr is unaffected by the \a offset parameter.
- *
- * @param[in] size the number of bytes to map in. This must be a multiple of
- * \ref _MALI_OSK_CPU_PAGE_SIZE.
- *
- * @return _MALI_OSK_ERR_OK on sucess, otherwise a _mali_osk_errcode_t value
- * on failure
- *
- * @note could expand to use _mali_osk_mem_mapregion_flags_t instead of
- * \ref MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC, but note that we must
- * also modify the mali process address manager in the mmu/memory engine code.
+ * @return MALI_TRUE if shared interrupts, MALI_FALSE if not.
  */
-_mali_osk_errcode_t _mali_osk_mem_mapregion_map( mali_memory_allocation * descriptor, u32 offset, u32 *phys_addr, u32 size );
-
-
-/** @brief Unmap physical pages from a user process's virtual address range
- *
- * This is used to unmap a number of physically contigous pages from a
- * user-process's virtual address range, which were previously mapped by a
- * call to _mali_osk_mem_mapregion_map(). If the range specified was allocated
- * from OS memory, then that memory will be returned to the OS. Whilst pages
- * will be mapped out, the Virtual address range remains reserved, and at the
- * same base address.
- *
- * When this function is used to unmap pages from OS memory
- * (_mali_osk_mem_mapregion_map() was called with *phys_addr ==
- * \ref MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC), then the \a flags must
- * include \ref _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR. This is because
- * it is not always easy for an OS implementation to discover whether the
- * memory was OS allocated or not (and so, how it should release the memory).
- *
- * For this reason, only a range of pages of the same allocation type (all OS
- * allocated, or none OS allocacted) may be unmapped in one call. Multiple
- * calls must be made if allocations of these different types exist across the
- * entire region described by the \a descriptor.
- *
- * The function will always be called with MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE
- * set in \a descriptor->flags. It is an error to call this function without
- * setting this flag. Otherwise, \a descriptor->flags bits are reserved for
- * future expansion
- *
- * @param[in,out] descriptor the mali_memory_allocation representing the
- * user-process's virtual address range to map into.
- *
- * @param[in] offset the offset into the virtual address range. This is only added
- * to the mapping member of the \a descriptor. \a offset must be a multiple of
- * \ref _MALI_OSK_CPU_PAGE_SIZE.
- *
- * @param[in] size the number of bytes to unmap. This must be a multiple of
- * \ref _MALI_OSK_CPU_PAGE_SIZE.
- *
- * @param[in] flags specifies how the memory should be unmapped. For a range
- * of pages that were originally OS allocated, this must have
- * \ref _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR set.
- */
-void _mali_osk_mem_mapregion_unmap( mali_memory_allocation * descriptor, u32 offset, u32 size, _mali_osk_mem_mapregion_flags_t flags );
-/** @} */ /* end group _mali_osk_low_level_memory */
+mali_bool _mali_osk_shared_interrupts(void);
 
+/** @} */ /* end group _mali_osk_miscellaneous */
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/mali/common/mali_osk_profiling.h b/drivers/gpu/mali/mali/common/mali_osk_profiling.h
old mode 100644
new mode 100755
index 27f8f81..6463177
--- a/drivers/gpu/mali/mali/common/mali_osk_profiling.h
+++ b/drivers/gpu/mali/mali/common/mali_osk_profiling.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,13 +11,11 @@
 #ifndef __MALI_OSK_PROFILING_H__
 #define __MALI_OSK_PROFILING_H__
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING) && defined (CONFIG_TRACEPOINTS)
 
-#if defined (CONFIG_TRACEPOINTS) && !MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
 #include "mali_linux_trace.h"
-#endif /* CONFIG_TRACEPOINTS && !MALI_INTERNAL_TIMELINE_PROFILING_ENABLED */
-
 #include "mali_profiling_events.h"
+#include "mali_profiling_gator_api.h"
 
 #define MALI_PROFILING_MAX_BUFFER_ENTRIES 1048576
 
@@ -46,7 +44,7 @@ void _mali_osk_profiling_term(void);
  * @param limit The desired maximum number of events to record on input, the actual maximum on output.
  * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-_mali_osk_errcode_t _mali_osk_profiling_start(u32 * limit);
+_mali_osk_errcode_t _mali_osk_profiling_start(u32 *limit);
 
 /**
  * Add an profiling event
@@ -59,13 +57,8 @@ _mali_osk_errcode_t _mali_osk_profiling_start(u32 * limit);
  * @param data4 Fifth data parameter, depending on event_id specified.
  * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-#if defined (CONFIG_TRACEPOINTS) && !MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
 /* Call Linux tracepoint directly */
 #define _mali_osk_profiling_add_event(event_id, data0, data1, data2, data3, data4) trace_mali_timeline_event((event_id), (data0), (data1), (data2), (data3), (data4))
-#else
-/* Internal profiling is handled like a plain function call */
-void _mali_osk_profiling_add_event(u32 event_id, u32 data0, u32 data1, u32 data2, u32 data3, u32 data4);
-#endif
 
 /**
  * Report a hardware counter event.
@@ -74,13 +67,8 @@ void _mali_osk_profiling_add_event(u32 event_id, u32 data0, u32 data1, u32 data2
  * @param value The value of the counter.
  */
 
-#if defined (CONFIG_TRACEPOINTS) && !MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
 /* Call Linux tracepoint directly */
 #define _mali_osk_profiling_report_hw_counter(counter_id, value) trace_mali_hw_counter(counter_id, value)
-#else
-/* Internal profiling is handled like a plain function call */
-void _mali_osk_profiling_report_hw_counter(u32 counter_id, u32 value);
-#endif
 
 /**
  * Report SW counters
@@ -95,7 +83,7 @@ void _mali_osk_profiling_report_sw_counters(u32 *counters);
  * @param count Returns the number of recorded events.
  * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-_mali_osk_errcode_t _mali_osk_profiling_stop(u32 * count);
+_mali_osk_errcode_t _mali_osk_profiling_stop(u32 *count);
 
 /**
  * Retrieves the number of events that can be retrieved
@@ -113,7 +101,7 @@ u32 _mali_osk_profiling_get_count(void);
  * @param data The 5 data values for the retrieved event will be stored here.
  * @return _MALI_OSK_ERR_OK on success, otherwise failure.
  */
-_mali_osk_errcode_t _mali_osk_profiling_get_event(u32 index, u64* timestamp, u32* event_id, u32 data[5]);
+_mali_osk_errcode_t _mali_osk_profiling_get_event(u32 index, u64 *timestamp, u32 *event_id, u32 data[5]);
 
 /**
  * Clear the recorded buffer.
@@ -140,6 +128,14 @@ mali_bool _mali_osk_profiling_have_recording(void);
 
 /** @} */ /* end group _mali_osk_profiling */
 
-#endif /* MALI_TIMELINE_PROFILING_ENABLED */
+#else /* defined(CONFIG_MALI400_PROFILING)  && defined(CONFIG_TRACEPOINTS) */
+
+/* Dummy add_event, for when profiling is disabled. */
+
+#define _mali_osk_profiling_add_event(event_id, data0, data1, data2, data3, data4)
+
+#endif /* defined(CONFIG_MALI400_PROFILING)  && defined(CONFIG_TRACEPOINTS) */
 
 #endif /* __MALI_OSK_PROFILING_H__ */
+
+
diff --git a/drivers/gpu/mali/mali/common/mali_pm.c b/drivers/gpu/mali/mali/common/mali_pm.c
old mode 100644
new mode 100755
index d692280..57c9790
--- a/drivers/gpu/mali/mali/common/mali_pm.c
+++ b/drivers/gpu/mali/mali/common/mali_pm.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,535 +13,110 @@
 #include "mali_osk.h"
 #include "mali_gp_scheduler.h"
 #include "mali_pp_scheduler.h"
-#include "mali_platform.h"
+#include "mali_scheduler.h"
 #include "mali_kernel_utilization.h"
-#include "mali_kernel_core.h"
 #include "mali_group.h"
+#include "mali_pm_domain.h"
+#include "mali_pmu.h"
 
-#define MALI_PM_LIGHT_SLEEP_TIMEOUT 1000
-
-enum mali_pm_scheme
-{
-	MALI_PM_SCHEME_DYNAMIC,
-	MALI_PM_SCHEME_OS_SUSPENDED,
-	MALI_PM_SCHEME_ALWAYS_ON
-};
-
-enum mali_pm_level
-{
-	MALI_PM_LEVEL_1_ON,
-	MALI_PM_LEVEL_2_STANDBY,
-	MALI_PM_LEVEL_3_LIGHT_SLEEP,
-	MALI_PM_LEVEL_4_DEEP_SLEEP
-};
-static _mali_osk_lock_t *mali_pm_lock_set_next_state;
-static _mali_osk_lock_t *mali_pm_lock_set_core_states;
-static _mali_osk_lock_t *mali_pm_lock_execute_state_change;
-static _mali_osk_irq_t *wq_irq;
-
-static _mali_osk_timer_t *idle_timer = NULL;
-static mali_bool idle_timer_running = MALI_FALSE;
-static u32 mali_pm_event_number     = 0;
-
-static u32 num_active_gps = 0;
-static u32 num_active_pps = 0;
-
-static enum mali_pm_scheme current_scheme = MALI_PM_SCHEME_DYNAMIC;
-static enum mali_pm_level current_level = MALI_PM_LEVEL_1_ON;
-static enum mali_pm_level next_level_dynamic = MALI_PM_LEVEL_2_STANDBY; /* Should be the state we go to when we go out of MALI_PM_SCHEME_ALWAYS_ON during init */
-
-
-
-static _mali_osk_errcode_t mali_pm_upper_half(void *data);
-static void mali_pm_bottom_half(void *data);
-static void mali_pm_powerup(void);
-static void mali_pm_powerdown(mali_power_mode power_mode);
-
-static void timeout_light_sleep(void* arg);
-#if 0
-/* Deep sleep timout not supported */
-static void timeout_deep_sleep(void* arg);
-#endif
-static u32 mali_pm_event_number_get(void);
-static void mali_pm_event(enum mali_pm_event pm_event, mali_bool schedule_work, u32 timer_time );
+static mali_bool mali_power_on = MALI_FALSE;
 
 _mali_osk_errcode_t mali_pm_initialize(void)
 {
-	mali_pm_lock_execute_state_change = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_ORDERED |_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_PM_EXECUTE);
-
-	if (NULL != mali_pm_lock_execute_state_change )
-	{
-		mali_pm_lock_set_next_state = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ONELOCK| _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ |_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_LAST);
-
-		if (NULL != mali_pm_lock_set_next_state)
-		{
-			mali_pm_lock_set_core_states = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_PM_CORE_STATE);
-
-			if (NULL != mali_pm_lock_set_core_states)
-			{
-				idle_timer = _mali_osk_timer_init();
-				if (NULL != idle_timer)
-				{
-					wq_irq = _mali_osk_irq_init(_MALI_OSK_IRQ_NUMBER_PMM,
-												mali_pm_upper_half,
-												mali_pm_bottom_half,
-												NULL,
-												NULL,
-												(void *)NULL,
-												"Mali PM deferred work");
-					if (NULL != wq_irq)
-					{
-						if (_MALI_OSK_ERR_OK == mali_platform_init())
-						{
-#if MALI_PMM_RUNTIME_JOB_CONTROL_ON
-							_mali_osk_pm_dev_enable();
-							mali_pm_powerup();
-#endif
-							return _MALI_OSK_ERR_OK;
-						}
-
-						_mali_osk_irq_term(wq_irq);
-					}
-
-					_mali_osk_timer_del(idle_timer);
-					_mali_osk_timer_term(idle_timer);
-				}
-				_mali_osk_lock_term(mali_pm_lock_set_core_states);
-			}
-			_mali_osk_lock_term(mali_pm_lock_set_next_state);
-		}
-		_mali_osk_lock_term(mali_pm_lock_execute_state_change);
-	}
-
-	return _MALI_OSK_ERR_FAULT;
+	_mali_osk_pm_dev_enable();
+	return _MALI_OSK_ERR_OK;
 }
 
 void mali_pm_terminate(void)
 {
-	mali_platform_deinit();
-	_mali_osk_irq_term(wq_irq);
-	_mali_osk_timer_del(idle_timer);
-	_mali_osk_timer_term(idle_timer);
-	_mali_osk_lock_term(mali_pm_lock_execute_state_change);
-	_mali_osk_lock_term(mali_pm_lock_set_next_state);
-	_mali_osk_lock_term(mali_pm_lock_set_core_states);
-}
-
-
-inline void mali_pm_lock(void)
-{
-	_mali_osk_lock_wait(mali_pm_lock_set_next_state, _MALI_OSK_LOCKMODE_RW);
-}
-
-inline void mali_pm_unlock(void)
-{
-	_mali_osk_lock_signal(mali_pm_lock_set_next_state, _MALI_OSK_LOCKMODE_RW);
-}
-
-inline void mali_pm_execute_state_change_lock(void)
-{
-	_mali_osk_lock_wait(mali_pm_lock_execute_state_change,_MALI_OSK_LOCKMODE_RW);
-}
-
-inline void mali_pm_execute_state_change_unlock(void)
-{
-	_mali_osk_lock_signal(mali_pm_lock_execute_state_change, _MALI_OSK_LOCKMODE_RW);
-}
-
-static void mali_pm_powerup(void)
-{
-	MALI_DEBUG_PRINT(3, ("Mali PM: Setting GPU power mode to MALI_POWER_MODE_ON\n"));
-	mali_platform_power_mode_change(MALI_POWER_MODE_ON);
-
-#if MALI_PMM_RUNTIME_JOB_CONTROL_ON
-
-	/* Aquire our reference */
-	MALI_DEBUG_PRINT(4, ("Mali PM: Getting device PM reference (=> requesting MALI_POWER_MODE_ON)\n"));
-	_mali_osk_pm_dev_activate();
-#endif
-
-	mali_group_power_on();
+	mali_pm_domain_terminate();
+	_mali_osk_pm_dev_disable();
 }
 
-static void mali_pm_powerdown(mali_power_mode power_mode)
+/* Reset GPU after power up */
+static void mali_pm_reset_gpu(void)
 {
-	if ( (MALI_PM_LEVEL_1_ON == current_level) || (MALI_PM_LEVEL_2_STANDBY == current_level) )
-	{
-		mali_group_power_off();
-	}
-	mali_platform_power_mode_change(power_mode);
+	/* Reset all L2 caches */
+	mali_l2_cache_reset_all();
 
-#if MALI_PMM_RUNTIME_JOB_CONTROL_ON
-	_mali_osk_pm_dev_idle();
-#endif
+	/* Reset all groups */
+	mali_scheduler_reset_all_groups();
 }
 
-mali_bool mali_pm_is_powered_on(void)
+void mali_pm_os_suspend(void)
 {
-	mali_bool is_on = MALI_TRUE;
-
-	if( ! (MALI_PM_SCHEME_ALWAYS_ON == current_scheme || MALI_PM_SCHEME_DYNAMIC == current_scheme) )
-	{
-		is_on = MALI_FALSE;
-	}
-	else if ( ! (MALI_PM_LEVEL_1_ON == current_level || MALI_PM_LEVEL_2_STANDBY == current_level))
-	{
-		is_on = MALI_FALSE;
-	}
-	else if ( ! (MALI_PM_LEVEL_1_ON == next_level_dynamic || MALI_PM_LEVEL_2_STANDBY == next_level_dynamic))
-	{
-		is_on = MALI_FALSE;
-	}
-
-	return is_on;
+	MALI_DEBUG_PRINT(3, ("Mali PM: OS suspend\n"));
+	mali_gp_scheduler_suspend();
+	mali_pp_scheduler_suspend();
+	mali_utilization_suspend();
+	mali_group_power_off(MALI_TRUE);
+	mali_power_on = MALI_FALSE;
 }
 
-MALI_DEBUG_CODE(
-static const char *state_as_string(enum mali_pm_level level)
-{
-	switch(level)
-	{
-		case MALI_PM_LEVEL_1_ON:
-			return "MALI_PM_LEVEL_1_ON";
-		case MALI_PM_LEVEL_2_STANDBY:
-			return "MALI_PM_LEVEL_2_STANDBY";
-		case MALI_PM_LEVEL_3_LIGHT_SLEEP:
-			return "MALI_PM_LEVEL_3_LIGHT_SLEEP";
-		case MALI_PM_LEVEL_4_DEEP_SLEEP:
-			return "MALI_PM_LEVEL_4_DEEP_SLEEP";
-		default:
-			return "UNKNOWN LEVEL";
-	}
-});
-
-/* This could be used from another thread (work queue), if we need that */
-static void mali_pm_process_next(void)
+void mali_pm_os_resume(void)
 {
-	enum mali_pm_level pm_level_to_set;
-
-	_mali_osk_lock_wait(mali_pm_lock_execute_state_change, _MALI_OSK_LOCKMODE_RW);
-
-	pm_level_to_set = current_level;
-
-	if (MALI_PM_SCHEME_DYNAMIC == current_scheme)
-	{
-		pm_level_to_set = next_level_dynamic;
-
-		MALI_DEBUG_PRINT(4, ("Mali PM: Dynamic scheme; Changing Mali GPU power state from %s to: %s\n", state_as_string(current_level), state_as_string(pm_level_to_set)));
-
-		if (current_level == pm_level_to_set)
-		{
-			goto end_function; /* early out, no change in power level */
-		}
+	struct mali_pmu_core *pmu = mali_pmu_get_global_pmu_core();
+	mali_bool do_reset = MALI_FALSE;
 
-		/* Start timers according to new state, so we get STANDBY -> LIGHT_SLEEP -> DEEP_SLEEP */
+	MALI_DEBUG_PRINT(3, ("Mali PM: OS resume\n"));
 
-		if (MALI_TRUE == idle_timer_running)
-		{
-			/* There is an existing timeout, so delete it */
-			_mali_osk_timer_del(idle_timer);
-			idle_timer_running = MALI_FALSE;
-		}
-
-		/* Making sure that we turn on through the platform file
-		   Since it was turned OFF directly through the platform file.
-		   This might lead to double turn-on, but the plaform file supports that.*/
-		if ( current_level == MALI_PM_LEVEL_4_DEEP_SLEEP)
-		{
-			mali_pm_powerup();
-			mali_kernel_core_wakeup();
-
-		}
-		if (MALI_PM_LEVEL_1_ON == pm_level_to_set)
-		{
-			if (MALI_PM_LEVEL_2_STANDBY != current_level)
-			{
-				/* We only need to do anything if we came from one of the sleeping states */
-				mali_pm_powerup();
-
-				/* Wake up Mali cores since we came from a sleep state */
-				mali_kernel_core_wakeup();
-			}
-		}
-		else if (MALI_PM_LEVEL_2_STANDBY == pm_level_to_set)
-		{
-			/* This is just an internal state, so we don't bother to report it to the platform file */
-			idle_timer_running = MALI_TRUE;
-			_mali_osk_timer_setcallback(idle_timer, timeout_light_sleep, (void*) mali_pm_event_number_get());
-			_mali_osk_timer_add(idle_timer, _mali_osk_time_mstoticks(MALI_PM_LIGHT_SLEEP_TIMEOUT));
-		}
-		else if (MALI_PM_LEVEL_3_LIGHT_SLEEP == pm_level_to_set)
-		{
-			mali_pm_powerdown(MALI_POWER_MODE_LIGHT_SLEEP);
-		}
-		else if (MALI_PM_LEVEL_4_DEEP_SLEEP == pm_level_to_set)
-		{
-			MALI_DEBUG_PRINT(2, ("Mali PM: Setting GPU power mode to MALI_POWER_MODE_DEEP_SLEEP\n"));
-			mali_pm_powerdown(MALI_POWER_MODE_DEEP_SLEEP);
-		}
-	}
-	else if (MALI_PM_SCHEME_OS_SUSPENDED == current_scheme)
-	{
-		MALI_DEBUG_PRINT(4, ("Mali PM: OS scheme; Changing Mali GPU power state from %s to: %s\n", state_as_string(current_level), state_as_string(MALI_PM_LEVEL_4_DEEP_SLEEP)));
-
-		pm_level_to_set = MALI_PM_LEVEL_4_DEEP_SLEEP;
-
-		if (current_level == pm_level_to_set)
-		{
-			goto end_function; /* early out, no change in power level */
-		}
-
-		/* Cancel any timers */
-		if (MALI_TRUE == idle_timer_running)
-		{
-			/* There is an existing timeout, so delete it */
-			_mali_osk_timer_del(idle_timer);
-			idle_timer_running = MALI_FALSE;
-		}
-
-		MALI_DEBUG_PRINT(2, ("Mali PM: Setting GPU power mode to MALI_POWER_MODE_DEEP_SLEEP\n"));
-		mali_pm_powerdown(MALI_POWER_MODE_DEEP_SLEEP);
-		next_level_dynamic = current_level;
+	if (MALI_TRUE != mali_power_on) {
+		do_reset = MALI_TRUE;
 	}
-	else if (MALI_PM_SCHEME_ALWAYS_ON == current_scheme)
-	{
-		MALI_DEBUG_PRINT(4, ("Mali PM: Always on scheme; Changing Mali GPU power state from %s to: %s\n", state_as_string(current_level), state_as_string(MALI_PM_LEVEL_1_ON)));
-
-		pm_level_to_set = MALI_PM_LEVEL_1_ON;
-		if (current_level == pm_level_to_set)
-		{
-			goto end_function; /* early out, no change in power level */
-		}
 
-		MALI_DEBUG_PRINT(2, ("Mali PM: Setting GPU power mode to MALI_POWER_MODE_ON\n"));
-		mali_pm_powerup();
-		if (MALI_PM_LEVEL_2_STANDBY != current_level)
-		{
-			/* Wake up Mali cores since we came from a sleep state */
-			mali_kernel_core_wakeup();
-		}
+	if (NULL != pmu) {
+		mali_pmu_reset(pmu);
 	}
-	else
-	{
-		MALI_PRINT_ERROR(("MALI PM: Illegal scheme"));
-	}
-
-	current_level = pm_level_to_set;
 
-end_function:
-	_mali_osk_lock_signal(mali_pm_lock_execute_state_change, _MALI_OSK_LOCKMODE_RW);
+	mali_power_on = MALI_TRUE;
+	_mali_osk_write_mem_barrier();
 
-}
-
-void mali_pm_always_on(mali_bool enable)
-{
-	if (MALI_TRUE == enable)
-	{
-		/* The event is processed in current thread synchronously */
-		mali_pm_event(MALI_PM_EVENT_SCHEME_ALWAYS_ON, MALI_FALSE, 0 );
+	if (do_reset) {
+		mali_pm_reset_gpu();
+		mali_group_power_on();
 	}
-	else
-	{
-		/* The event is processed in current thread synchronously */
-		mali_pm_event(MALI_PM_EVENT_SCHEME_DYNAMIC_CONTROLL, MALI_FALSE, 0 );
-	}
-}
 
-static _mali_osk_errcode_t mali_pm_upper_half(void *data)
-{
-	/* not used */
-	return _MALI_OSK_ERR_OK;
+	mali_gp_scheduler_resume();
+	mali_pp_scheduler_resume();
 }
 
-static void mali_pm_bottom_half(void *data)
+void mali_pm_runtime_suspend(void)
 {
-	mali_pm_process_next();
+	MALI_DEBUG_PRINT(3, ("Mali PM: Runtime suspend\n"));
+	mali_group_power_off(MALI_TRUE);
+	mali_power_on = MALI_FALSE;
 }
 
-static u32 mali_pm_event_number_get(void)
+void mali_pm_runtime_resume(void)
 {
-	u32 retval;
-
-	mali_pm_lock(); /* spinlock: mali_pm_lock_set_next_state */
-	retval = ++mali_pm_event_number;
-	if (0==retval ) retval = ++mali_pm_event_number;
-	mali_pm_unlock();
+	struct mali_pmu_core *pmu = mali_pmu_get_global_pmu_core();
+	mali_bool do_reset = MALI_FALSE;
 
-	return retval;
-}
+	MALI_DEBUG_PRINT(3, ("Mali PM: Runtime resume\n"));
 
-static void mali_pm_event(enum mali_pm_event pm_event, mali_bool schedule_work, u32 timer_time )
-{
-	mali_pm_lock(); /* spinlock: mali_pm_lock_set_next_state */
-	/* Only timer events should set this variable, all other events must set it to zero. */
-	if ( 0 != timer_time )
-	{
-		MALI_DEBUG_ASSERT( (pm_event==MALI_PM_EVENT_TIMER_LIGHT_SLEEP) || (pm_event==MALI_PM_EVENT_TIMER_DEEP_SLEEP) );
-		if ( mali_pm_event_number != timer_time )
-		{
-			/* In this case there have been processed newer events since the timer event was set up.
-			   If so we always ignore the timing event */
-			mali_pm_unlock();
-			return;
-		}
+	if (MALI_TRUE != mali_power_on) {
+		do_reset = MALI_TRUE;
 	}
-	else
-	{
-		/* Delete possible ongoing timers
-		if (  (MALI_PM_LEVEL_2_STANDBY==current_level) || (MALI_PM_LEVEL_3_LIGHT_SLEEP==current_level) )
-		{
-			_mali_osk_timer_del(idle_timer);
-		}
-		*/
-	}
-	mali_pm_event_number++;
-	switch (pm_event)
-	{
-		case MALI_PM_EVENT_CORES_WORKING:
-			next_level_dynamic = MALI_PM_LEVEL_1_ON;
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED    != current_scheme );
-			break;
-		case MALI_PM_EVENT_CORES_IDLE:
-			next_level_dynamic = MALI_PM_LEVEL_2_STANDBY;
-			/*MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED    != current_scheme );*/
-			break;
-		case MALI_PM_EVENT_TIMER_LIGHT_SLEEP:
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_ALWAYS_ON != current_scheme );
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED    != current_scheme );
-			next_level_dynamic = MALI_PM_LEVEL_3_LIGHT_SLEEP;
-			break;
-		case MALI_PM_EVENT_TIMER_DEEP_SLEEP:
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_ALWAYS_ON != current_scheme );
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED    != current_scheme );
-			next_level_dynamic = MALI_PM_LEVEL_4_DEEP_SLEEP;
-			break;
-		case MALI_PM_EVENT_OS_SUSPEND:
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_ALWAYS_ON != current_scheme );
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED    != current_scheme );
-			current_scheme = MALI_PM_SCHEME_OS_SUSPENDED;
-			next_level_dynamic = MALI_PM_LEVEL_4_DEEP_SLEEP; /* Dynamic scheme will go into level when we are resumed */
-			break;
-		case MALI_PM_EVENT_OS_RESUME:
-			MALI_DEBUG_ASSERT(MALI_PM_SCHEME_OS_SUSPENDED == current_scheme );
-			current_scheme = MALI_PM_SCHEME_DYNAMIC;
-			break;
-		case MALI_PM_EVENT_SCHEME_ALWAYS_ON:
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_OS_SUSPENDED != current_scheme );
-			current_scheme = MALI_PM_SCHEME_ALWAYS_ON;
-			break;
-		case MALI_PM_EVENT_SCHEME_DYNAMIC_CONTROLL:
-			MALI_DEBUG_ASSERT( MALI_PM_SCHEME_ALWAYS_ON == current_scheme || MALI_PM_SCHEME_DYNAMIC == current_scheme );
-			current_scheme = MALI_PM_SCHEME_DYNAMIC;
-			break;
-		default:
-			MALI_DEBUG_PRINT_ERROR(("Unknown next state."));
-			mali_pm_unlock();
-			return;
-	}
-	mali_pm_unlock();
 
-	if (MALI_TRUE == schedule_work)
-	{
-		_mali_osk_irq_schedulework(wq_irq);
-	}
-	else
-	{
-		mali_pm_process_next();
+	if (NULL != pmu) {
+		mali_pmu_reset(pmu);
 	}
-}
-
-static void timeout_light_sleep(void* arg)
-{
-	/* State change only if no newer power events have happend from the time in arg.
-	    Actual work will be scheduled on worker thread. */
-	mali_pm_event(MALI_PM_EVENT_TIMER_LIGHT_SLEEP, MALI_TRUE, (u32) arg);
-}
-
-void mali_pm_core_event(enum mali_core_event core_event)
-{
-	mali_bool transition_working = MALI_FALSE;
-	mali_bool transition_idle = MALI_FALSE;
-
-	_mali_osk_lock_wait(mali_pm_lock_set_core_states, _MALI_OSK_LOCKMODE_RW);
 
-	switch (core_event)
-	{
-		case MALI_CORE_EVENT_GP_START:
-			if (num_active_pps + num_active_gps == 0)
-			{
-				transition_working = MALI_TRUE;
-			}
-			num_active_gps++;
-			break;
-		case MALI_CORE_EVENT_GP_STOP:
-			if (num_active_pps + num_active_gps == 1)
-			{
-				transition_idle = MALI_TRUE;
-			}
-			num_active_gps--;
-			break;
-		case MALI_CORE_EVENT_PP_START:
-			if (num_active_pps + num_active_gps == 0)
-			{
-				transition_working = MALI_TRUE;
-			}
-			num_active_pps++;
-			break;
-		case MALI_CORE_EVENT_PP_STOP:
-			if (num_active_pps + num_active_gps == 1)
-			{
-				transition_idle = MALI_TRUE;
-			}
-			num_active_pps--;
-			break;
-	}
+	mali_power_on = MALI_TRUE;
+	_mali_osk_write_mem_barrier();
 
-	if (transition_working == MALI_TRUE)
-	{
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
-		mali_utilization_core_start(_mali_osk_time_get_ns());
-#endif
-		mali_pm_event(MALI_PM_EVENT_CORES_WORKING, MALI_FALSE, 0); /* process event in same thread */
-	}
-	else if (transition_idle == MALI_TRUE)
-	{
-#ifdef CONFIG_MALI400_GPU_UTILIZATION
-		mali_utilization_core_end(_mali_osk_time_get_ns());
-#endif
-		mali_pm_event(MALI_PM_EVENT_CORES_IDLE, MALI_FALSE, 0); /* process event in same thread */
+	if (do_reset) {
+		mali_pm_reset_gpu();
+		mali_group_power_on();
 	}
-
-	_mali_osk_lock_signal(mali_pm_lock_set_core_states, _MALI_OSK_LOCKMODE_RW);
-}
-
-void mali_pm_os_suspend(void)
-{
-	MALI_DEBUG_PRINT(2, ("Mali PM: OS suspending...\n"));
-
-	mali_gp_scheduler_suspend();
-	mali_pp_scheduler_suspend();
-	mali_pm_event(MALI_PM_EVENT_OS_SUSPEND, MALI_FALSE, 0); /* process event in same thread */
-
-	MALI_DEBUG_PRINT(2, ("Mali PM: OS suspend completed\n"));
-}
-
-void mali_pm_os_resume(void)
-{
-	MALI_DEBUG_PRINT(2, ("Mali PM: OS resuming...\n"));
-
-	mali_pm_event(MALI_PM_EVENT_OS_RESUME, MALI_FALSE, 0); /* process event in same thread */
-	mali_gp_scheduler_resume();
-	mali_pp_scheduler_resume();
-
-	MALI_DEBUG_PRINT(2, ("Mali PM: OS resume completed\n"));
 }
 
-void mali_pm_runtime_suspend(void)
+void mali_pm_set_power_is_on(void)
 {
-	MALI_DEBUG_PRINT(2, ("Mali PM: OS runtime suspended\n"));
+	mali_power_on = MALI_TRUE;
 }
 
-void mali_pm_runtime_resume(void)
+mali_bool mali_pm_is_power_on(void)
 {
-	MALI_DEBUG_PRINT(3, ("Mali PM: OS runtime resumed\n"));
+	return mali_power_on;
 }
diff --git a/drivers/gpu/mali/mali/common/mali_pm.h b/drivers/gpu/mali/mali/common/mali_pm.h
old mode 100644
new mode 100755
index 94973b8..4f4d036
--- a/drivers/gpu/mali/mali/common/mali_pm.h
+++ b/drivers/gpu/mali/mali/common/mali_pm.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,44 +13,16 @@
 
 #include "mali_osk.h"
 
-enum mali_core_event
-{
-	MALI_CORE_EVENT_GP_START,
-	MALI_CORE_EVENT_GP_STOP,
-	MALI_CORE_EVENT_PP_START,
-	MALI_CORE_EVENT_PP_STOP
-};
-
-enum mali_pm_event
-{
-	MALI_PM_EVENT_CORES_WORKING,
-	MALI_PM_EVENT_CORES_IDLE,
-	MALI_PM_EVENT_TIMER_LIGHT_SLEEP,
-	MALI_PM_EVENT_TIMER_DEEP_SLEEP,
-	MALI_PM_EVENT_OS_SUSPEND,
-	MALI_PM_EVENT_OS_RESUME,
-	MALI_PM_EVENT_SCHEME_ALWAYS_ON,
-	MALI_PM_EVENT_SCHEME_DYNAMIC_CONTROLL,
-};
-
 _mali_osk_errcode_t mali_pm_initialize(void);
 void mali_pm_terminate(void);
-void mali_pm_always_on(mali_bool enable);
-
-void mali_pm_lock(void);
-void mali_pm_unlock(void);
-void mali_pm_execute_state_change_lock(void);
-
-void mali_pm_execute_state_change_unlock(void);
-
-mali_bool mali_pm_is_powered_on(void);
-
-void mali_pm_core_event(enum mali_core_event core_event);
 
+/* Callback functions registered for the runtime PMM system */
 void mali_pm_os_suspend(void);
 void mali_pm_os_resume(void);
 void mali_pm_runtime_suspend(void);
 void mali_pm_runtime_resume(void);
 
+void mali_pm_set_power_is_on(void);
+mali_bool mali_pm_is_power_on(void);
 
 #endif /* __MALI_PM_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_pmu.c b/drivers/gpu/mali/mali/common/mali_pmu.c
old mode 100644
new mode 100755
index d7c0b61..d3f1472
--- a/drivers/gpu/mali/mali/common/mali_pmu.c
+++ b/drivers/gpu/mali/mali/common/mali_pmu.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,15 +17,21 @@
 #include "mali_pp.h"
 #include "mali_kernel_common.h"
 #include "mali_osk.h"
+#include "mali_pm.h"
+#include "mali_osk_mali.h"
 
-static u32 mali_pmu_detect_mask(u32 number_of_pp_cores, u32 number_of_l2_caches);
+u16 mali_pmu_global_domain_config[MALI_MAX_NUMBER_OF_DOMAINS] = {0};
+
+static u32 mali_pmu_detect_mask(void);
 
 /** @brief MALI inbuilt PMU hardware info and PMU hardware has knowledge of cores power mask
  */
-struct mali_pmu_core
-{
+struct mali_pmu_core {
 	struct mali_hw_core hw_core;
-	u32 mali_registered_cores_power_mask;
+	_mali_osk_spinlock_t *lock;
+	u32 registered_cores_mask;
+	u32 active_cores_mask;
+	u32 switch_delay;
 };
 
 static struct mali_pmu_core *mali_global_pmu_core = NULL;
@@ -37,28 +43,41 @@ typedef enum {
 	PMU_REG_ADDR_MGMT_POWER_DOWN                = 0x04,     /*< Power down register */
 	PMU_REG_ADDR_MGMT_STATUS                    = 0x08,     /*< Core sleep status register */
 	PMU_REG_ADDR_MGMT_INT_MASK                  = 0x0C,     /*< Interrupt mask register */
-	PMU_REGISTER_ADDRESS_SPACE_SIZE             = 0x10,     /*< Size of register space */
+	PMU_REG_ADDR_MGMT_INT_RAWSTAT               = 0x10,     /*< Interrupt raw status register */
+	PMU_REG_ADDR_MGMT_INT_CLEAR                 = 0x18,     /*< Interrupt clear register */
+	PMU_REG_ADDR_MGMT_SW_DELAY                  = 0x1C,     /*< Switch delay register */
+	PMU_REGISTER_ADDRESS_SPACE_SIZE             = 0x28,     /*< Size of register space */
 } pmu_reg_addr_mgmt_addr;
 
-struct mali_pmu_core *mali_pmu_create(_mali_osk_resource_t *resource, u32 number_of_pp_cores, u32 number_of_l2_caches)
+#define PMU_REG_VAL_IRQ 1
+
+struct mali_pmu_core *mali_pmu_create(_mali_osk_resource_t *resource)
 {
-	struct mali_pmu_core* pmu;
+	struct mali_pmu_core *pmu;
 
 	MALI_DEBUG_ASSERT(NULL == mali_global_pmu_core);
 	MALI_DEBUG_PRINT(2, ("Mali PMU: Creating Mali PMU core\n"));
 
 	pmu = (struct mali_pmu_core *)_mali_osk_malloc(sizeof(struct mali_pmu_core));
-	if (NULL != pmu)
-	{
-		pmu->mali_registered_cores_power_mask = mali_pmu_detect_mask(number_of_pp_cores, number_of_l2_caches);
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&pmu->hw_core, resource, PMU_REGISTER_ADDRESS_SPACE_SIZE))
-		{
-			if (_MALI_OSK_ERR_OK == mali_pmu_reset(pmu))
-			{
-				mali_global_pmu_core = pmu;
-				return pmu;
+	if (NULL != pmu) {
+		pmu->lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_PMU);
+		if (NULL != pmu->lock) {
+			pmu->registered_cores_mask = mali_pmu_detect_mask();
+			pmu->active_cores_mask = pmu->registered_cores_mask;
+
+			if (_MALI_OSK_ERR_OK == mali_hw_core_create(&pmu->hw_core, resource, PMU_REGISTER_ADDRESS_SPACE_SIZE)) {
+				_mali_osk_errcode_t err;
+				_mali_osk_device_data data = { 0, };
+
+				err = _mali_osk_device_data_get(&data);
+				if (_MALI_OSK_ERR_OK == err) {
+					pmu->switch_delay = data.pmu_switch_delay;
+					mali_global_pmu_core = pmu;
+					return pmu;
+				}
+				mali_hw_core_delete(&pmu->hw_core);
 			}
-			mali_hw_core_delete(&pmu->hw_core);
+			_mali_osk_spinlock_term(pmu->lock);
 		}
 		_mali_osk_free(pmu);
 	}
@@ -69,131 +88,319 @@ struct mali_pmu_core *mali_pmu_create(_mali_osk_resource_t *resource, u32 number
 void mali_pmu_delete(struct mali_pmu_core *pmu)
 {
 	MALI_DEBUG_ASSERT_POINTER(pmu);
+	MALI_DEBUG_ASSERT(pmu == mali_global_pmu_core);
+	MALI_DEBUG_PRINT(2, ("Mali PMU: Deleting Mali PMU core\n"));
 
+	_mali_osk_spinlock_term(pmu->lock);
 	mali_hw_core_delete(&pmu->hw_core);
 	_mali_osk_free(pmu);
-	pmu = NULL;
+	mali_global_pmu_core = NULL;
 }
 
-_mali_osk_errcode_t mali_pmu_reset(struct mali_pmu_core *pmu)
+static void mali_pmu_lock(struct mali_pmu_core *pmu)
+{
+	_mali_osk_spinlock_lock(pmu->lock);
+}
+static void mali_pmu_unlock(struct mali_pmu_core *pmu)
 {
-	/* Don't use interrupts - just poll status */
-	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_MASK, 0);
+	_mali_osk_spinlock_unlock(pmu->lock);
+}
+
+static _mali_osk_errcode_t mali_pmu_wait_for_command_finish(struct mali_pmu_core *pmu)
+{
+	u32 rawstat;
+	u32 timeout = MALI_REG_POLL_COUNT_SLOW;
+
+	MALI_DEBUG_ASSERT(pmu);
+
+	/* Wait for the command to complete */
+	do {
+		rawstat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_RAWSTAT);
+		--timeout;
+	} while (0 == (rawstat & PMU_REG_VAL_IRQ) && 0 < timeout);
+
+	MALI_DEBUG_ASSERT(0 < timeout);
+	if (0 == timeout) {
+		return _MALI_OSK_ERR_TIMEOUT;
+	}
+
+	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_CLEAR, PMU_REG_VAL_IRQ);
+
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t mali_pmu_powerdown_all(struct mali_pmu_core *pmu)
+static _mali_osk_errcode_t mali_pmu_power_up_internal(struct mali_pmu_core *pmu, const u32 mask)
 {
 	u32 stat;
-	u32 timeout;
+	_mali_osk_errcode_t err;
+#if !defined(CONFIG_MALI_PMU_PARALLEL_POWER_UP)
+	u32 current_domain;
+#endif
 
 	MALI_DEBUG_ASSERT_POINTER(pmu);
-	MALI_DEBUG_ASSERT( pmu->mali_registered_cores_power_mask != 0 );
-	MALI_DEBUG_PRINT( 4, ("Mali PMU: power down (0x%08X)\n", pmu->mali_registered_cores_power_mask) );
+	MALI_DEBUG_ASSERT(0 == (mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_RAWSTAT)
+				& PMU_REG_VAL_IRQ));
 
-	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_POWER_DOWN, pmu->mali_registered_cores_power_mask);
+	stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+	stat &= pmu->registered_cores_mask;
+	if (0 == mask || 0 == (stat & mask)) return _MALI_OSK_ERR_OK;
 
-	/* Wait for cores to be powered down (100 x 100us = 100ms) */
-	timeout = 100;
-	do
-	{
-		/* Get status of sleeping cores */
-		stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
-		stat &= pmu->mali_registered_cores_power_mask;
-		if( stat == pmu->mali_registered_cores_power_mask ) break; /* All cores we wanted are now asleep */
-		_mali_osk_time_ubusydelay(100);
-		timeout--;
-	} while( timeout > 0 );
+#if defined(CONFIG_MALI_PMU_PARALLEL_POWER_UP)
+	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_POWER_UP, mask);
 
-	if( timeout == 0 )
-	{
-		return _MALI_OSK_ERR_TIMEOUT;
+	err = mali_pmu_wait_for_command_finish(pmu);
+	if (_MALI_OSK_ERR_OK != err) {
+		return err;
 	}
+#else
+	for (current_domain = 1; current_domain <= pmu->registered_cores_mask; current_domain <<= 1) {
+		if (current_domain & mask & stat) {
+			mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_POWER_UP, current_domain);
+
+			err = mali_pmu_wait_for_command_finish(pmu);
+			if (_MALI_OSK_ERR_OK != err) {
+				return err;
+			}
+		}
+	}
+#endif
+
+#if defined(DEBUG)
+	/* Get power status of cores */
+	stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+	stat &= pmu->registered_cores_mask;
+
+	MALI_DEBUG_ASSERT(0 == (stat & mask));
+	MALI_DEBUG_ASSERT(0 == (stat & pmu->active_cores_mask));
+#endif /* defined(DEBUG) */
 
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t mali_pmu_powerup_all(struct mali_pmu_core *pmu)
+static _mali_osk_errcode_t mali_pmu_power_down_internal(struct mali_pmu_core *pmu, const u32 mask)
 {
 	u32 stat;
-	u32 timeout;
+	_mali_osk_errcode_t err;
 
 	MALI_DEBUG_ASSERT_POINTER(pmu);
-	MALI_DEBUG_ASSERT( pmu->mali_registered_cores_power_mask != 0 ); /* Shouldn't be zero */
-	MALI_DEBUG_PRINT( 4, ("Mali PMU: power up (0x%08X)\n", pmu->mali_registered_cores_power_mask) );
+	MALI_DEBUG_ASSERT(0 == (mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_RAWSTAT)
+				& PMU_REG_VAL_IRQ));
 
-	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_POWER_UP, pmu->mali_registered_cores_power_mask);
+	stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+	stat &= pmu->registered_cores_mask;
 
-	/* Wait for cores to be powered up (100 x 100us = 100ms) */
-	timeout = 100;
-	do
-	{
-		/* Get status of sleeping cores */
-		stat = mali_hw_core_register_read(&pmu->hw_core,PMU_REG_ADDR_MGMT_STATUS);
-		stat &= pmu->mali_registered_cores_power_mask;
-		if( stat == 0 ) break; /* All cores we wanted are now awake */
-		_mali_osk_time_ubusydelay(100);
-		timeout--;
-	} while( timeout > 0 );
-
-	if( timeout == 0 )
+	if (0 == mask || 0 == ((~stat) & mask)) return _MALI_OSK_ERR_OK;
+
+	mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_POWER_DOWN, mask);
+
+	/* Do not wait for interrupt on Mali-300/400 if all domains are powered off
+	 * by our power down command, because the HW will simply not generate an
+	 * interrupt in this case.*/
+	if (mali_is_mali450() || pmu->registered_cores_mask != (mask | stat)) {
+		err = mali_pmu_wait_for_command_finish(pmu);
+		if (_MALI_OSK_ERR_OK != err) {
+			return err;
+		}
+	} else {
+		mali_hw_core_register_write(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_CLEAR, PMU_REG_VAL_IRQ);
+	}
+#if defined(DEBUG)
+	/* Get power status of cores */
+	stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+	stat &= pmu->registered_cores_mask;
+
+	MALI_DEBUG_ASSERT(mask == (stat & mask));
+#endif
+
+	return _MALI_OSK_ERR_OK;
+}
+
+_mali_osk_errcode_t mali_pmu_reset(struct mali_pmu_core *pmu)
+{
+	_mali_osk_errcode_t err;
+	u32 cores_off_mask, cores_on_mask, stat;
+
+	mali_pmu_lock(pmu);
+
+	/* Setup the desired defaults */
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_MASK, 0);
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_SW_DELAY, pmu->switch_delay);
+
+	/* Get power status of cores */
+	stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+
+	cores_off_mask = pmu->registered_cores_mask & ~(stat | pmu->active_cores_mask);
+	cores_on_mask  = pmu->registered_cores_mask & (stat & pmu->active_cores_mask);
+
+	if (0 != cores_off_mask) {
+		err = mali_pmu_power_down_internal(pmu, cores_off_mask);
+		if (_MALI_OSK_ERR_OK != err) return err;
+	}
+
+	if (0 != cores_on_mask) {
+		err = mali_pmu_power_up_internal(pmu, cores_on_mask);
+		if (_MALI_OSK_ERR_OK != err) return err;
+	}
+
+#if defined(DEBUG)
 	{
-		return _MALI_OSK_ERR_TIMEOUT;
+		stat = mali_hw_core_register_read(&pmu->hw_core, PMU_REG_ADDR_MGMT_STATUS);
+		stat &= pmu->registered_cores_mask;
+
+		MALI_DEBUG_ASSERT(stat == (pmu->registered_cores_mask & ~pmu->active_cores_mask));
 	}
+#endif /* defined(DEBUG) */
+
+	mali_pmu_unlock(pmu);
 
 	return _MALI_OSK_ERR_OK;
 }
 
-struct mali_pmu_core *mali_pmu_get_global_pmu_core(void)
+_mali_osk_errcode_t mali_pmu_power_down(struct mali_pmu_core *pmu, u32 mask)
 {
-	return mali_global_pmu_core;
+	_mali_osk_errcode_t err;
+
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	MALI_DEBUG_ASSERT(pmu->registered_cores_mask != 0);
+
+	/* Make sure we have a valid power domain mask */
+	if (mask > pmu->registered_cores_mask) {
+		return _MALI_OSK_ERR_INVALID_ARGS;
+	}
+
+	mali_pmu_lock(pmu);
+
+	MALI_DEBUG_PRINT(4, ("Mali PMU: Power down (0x%08X)\n", mask));
+
+	pmu->active_cores_mask &= ~mask;
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+	if (!mali_pm_is_power_on()) {
+		/* Don't touch hardware if all of Mali is powered off. */
+		_mali_osk_pm_dev_ref_dec_no_power_on();
+		mali_pmu_unlock(pmu);
+
+		MALI_DEBUG_PRINT(4, ("Mali PMU: Skipping power down (0x%08X) since Mali is off\n", mask));
+
+		return _MALI_OSK_ERR_BUSY;
+	}
+
+	err = mali_pmu_power_down_internal(pmu, mask);
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+	mali_pmu_unlock(pmu);
+
+	return err;
 }
 
-static u32 mali_pmu_detect_mask(u32 number_of_pp_cores, u32 number_of_l2_caches)
+_mali_osk_errcode_t mali_pmu_power_up(struct mali_pmu_core *pmu, u32 mask)
 {
-	u32 mask = 0;
+	_mali_osk_errcode_t err;
 
-	if (number_of_l2_caches == 1)
-	{
-		/* Mali-300 or Mali-400 */
-		u32 i;
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	MALI_DEBUG_ASSERT(pmu->registered_cores_mask != 0);
+
+	/* Make sure we have a valid power domain mask */
+	if (mask & ~pmu->registered_cores_mask) {
+		return _MALI_OSK_ERR_INVALID_ARGS;
+	}
 
-		/* GP */
-		mask = 0x01;
+	mali_pmu_lock(pmu);
 
-		/* L2 cache */
-		mask |= 0x01<<1;
+	MALI_DEBUG_PRINT(4, ("Mali PMU: Power up (0x%08X)\n", mask));
 
-		/* Set bit for each PP core */
-		for (i = 0; i < number_of_pp_cores; i++)
-		{
-			mask |= 0x01<<(i+2);
-		}
+	pmu->active_cores_mask |= mask;
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+	if (!mali_pm_is_power_on()) {
+		/* Don't touch hardware if all of Mali is powered off. */
+		_mali_osk_pm_dev_ref_dec_no_power_on();
+		mali_pmu_unlock(pmu);
+
+		MALI_DEBUG_PRINT(4, ("Mali PMU: Skipping power up (0x%08X) since Mali is off\n", mask));
+
+		return _MALI_OSK_ERR_BUSY;
 	}
-	else if (number_of_l2_caches > 1)
-	{
-		/* Mali-450 */
 
-		/* GP (including its L2 cache) */
-		mask = 0x01;
+	err = mali_pmu_power_up_internal(pmu, mask);
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+	mali_pmu_unlock(pmu);
+
+	return err;
+}
 
-		/* There is always at least one PP (including its L2 cache) */
-		mask |= 0x01<<1;
+_mali_osk_errcode_t mali_pmu_power_down_all(struct mali_pmu_core *pmu)
+{
+	_mali_osk_errcode_t err;
+
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	MALI_DEBUG_ASSERT(pmu->registered_cores_mask != 0);
 
-		/* Additional PP cores in same L2 cache */
-		if (number_of_pp_cores >= 2)
-		{
-			mask |= 0x01<<2;
+	mali_pmu_lock(pmu);
+
+	/* Setup the desired defaults in case we were called before mali_pmu_reset() */
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_MASK, 0);
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_SW_DELAY, pmu->switch_delay);
+
+	err = mali_pmu_power_down_internal(pmu, pmu->registered_cores_mask);
+
+	mali_pmu_unlock(pmu);
+
+	return err;
+}
+
+_mali_osk_errcode_t mali_pmu_power_up_all(struct mali_pmu_core *pmu)
+{
+	_mali_osk_errcode_t err;
+
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	MALI_DEBUG_ASSERT(pmu->registered_cores_mask != 0);
+
+	mali_pmu_lock(pmu);
+
+	/* Setup the desired defaults in case we were called before mali_pmu_reset() */
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_INT_MASK, 0);
+	mali_hw_core_register_write_relaxed(&pmu->hw_core, PMU_REG_ADDR_MGMT_SW_DELAY, pmu->switch_delay);
+
+	err = mali_pmu_power_up_internal(pmu, pmu->active_cores_mask);
+
+	mali_pmu_unlock(pmu);
+	return err;
+}
+
+struct mali_pmu_core *mali_pmu_get_global_pmu_core(void)
+{
+	return mali_global_pmu_core;
+}
+
+static u32 mali_pmu_detect_mask(void)
+{
+	int dynamic_config_pp = 0;
+	int dynamic_config_l2 = 0;
+	int i = 0;
+	u32 mask = 0;
+
+	/* Check if PM domain compatible with actually pp core and l2 cache and collection info about domain */
+	mask = mali_pmu_get_domain_mask(MALI_GP_DOMAIN_INDEX);
+
+	for (i = MALI_PP0_DOMAIN_INDEX; i <= MALI_PP7_DOMAIN_INDEX; i++) {
+		mask |= mali_pmu_get_domain_mask(i);
+
+		if (0x0 != mali_pmu_get_domain_mask(i)) {
+			dynamic_config_pp++;
 		}
+	}
+
+	for (i = MALI_L20_DOMAIN_INDEX; i <= MALI_L22_DOMAIN_INDEX; i++) {
+		mask |= mali_pmu_get_domain_mask(i);
 
-		/* Additional PP cores in a third L2 cache */
-		if (number_of_pp_cores >= 5)
-		{
-			mask |= 0x01<<3;
+		if (0x0 != mali_pmu_get_domain_mask(i)) {
+			dynamic_config_l2++;
 		}
 	}
 
-	MALI_DEBUG_PRINT(4, ("Mali PMU: Power mask is 0x%08X (%u + %u)\n", mask, number_of_pp_cores, number_of_l2_caches));
+	MALI_DEBUG_PRINT(2, ("Mali PMU: mask 0x%x, pp_core %d, l2_core %d \n", mask, dynamic_config_pp, dynamic_config_l2));
 
 	return mask;
 }
diff --git a/drivers/gpu/mali/mali/common/mali_pmu.h b/drivers/gpu/mali/mali/common/mali_pmu.h
old mode 100644
new mode 100755
index 0e06df2..55715f0
--- a/drivers/gpu/mali/mali/common/mali_pmu.h
+++ b/drivers/gpu/mali/mali/common/mali_pmu.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,8 +13,48 @@
  * Platform specific Mali driver functions
  */
 
+#ifndef __MALI_PMU_H__
+#define __MALI_PMU_H__
+
 #include "mali_osk.h"
 
+#define MALI_GP_DOMAIN_INDEX    0
+#define MALI_PP0_DOMAIN_INDEX   1
+#define MALI_PP1_DOMAIN_INDEX   2
+#define MALI_PP2_DOMAIN_INDEX   3
+#define MALI_PP3_DOMAIN_INDEX   4
+#define MALI_PP4_DOMAIN_INDEX   5
+#define MALI_PP5_DOMAIN_INDEX   6
+#define MALI_PP6_DOMAIN_INDEX   7
+#define MALI_PP7_DOMAIN_INDEX   8
+#define MALI_L20_DOMAIN_INDEX   9
+#define MALI_L21_DOMAIN_INDEX   10
+#define MALI_L22_DOMAIN_INDEX   11
+
+#define MALI_MAX_NUMBER_OF_DOMAINS      12
+
+/* Record the domain config from the customer or default config */
+extern u16 mali_pmu_global_domain_config[];
+
+static inline u16 mali_pmu_get_domain_mask(u32 index)
+{
+	MALI_DEBUG_ASSERT(MALI_MAX_NUMBER_OF_DOMAINS > index);
+
+	return mali_pmu_global_domain_config[index];
+}
+
+static inline void mali_pmu_set_domain_mask(u32 index, u16 value)
+{
+	MALI_DEBUG_ASSERT(MALI_MAX_NUMBER_OF_DOMAINS > index);
+
+	mali_pmu_global_domain_config[index] = value;
+}
+
+static inline void mali_pmu_copy_domain_mask(void *src, u32 len)
+{
+	_mali_osk_memcpy(mali_pmu_global_domain_config, src, len);
+}
+
 struct mali_pmu_core;
 
 /** @brief Initialisation of MALI PMU
@@ -26,7 +66,7 @@ struct mali_pmu_core;
  * @param number_of_l2_caches Number of found L2 cache resources in configuration
  * @return The created PMU object, or NULL in case of failure.
  */
-struct mali_pmu_core *mali_pmu_create(_mali_osk_resource_t *resource, u32 number_of_pp_cores, u32 number_of_l2_caches);
+struct mali_pmu_core *mali_pmu_create(_mali_osk_resource_t *resource);
 
 /** @brief It deallocates the PMU resource
  *
@@ -45,13 +85,36 @@ _mali_osk_errcode_t mali_pmu_reset(struct mali_pmu_core *pmu);
 
 /** @brief MALI GPU power down using MALI in-built PMU
  *
- * called to power down all cores
+ * Called to power down the specified cores. The mask will be saved so that \a
+ * mali_pmu_power_up_all will bring the PMU back to the previous state set with
+ * this function or \a mali_pmu_power_up.
  *
  * @param pmu Pointer to PMU core object to power down
+ * @param mask Mask specifying which power domains to power down
+ * @return _MALI_OSK_ERR_OK on success otherwise, a suitable _mali_osk_errcode_t error.
+ */
+_mali_osk_errcode_t mali_pmu_power_down(struct mali_pmu_core *pmu, u32 mask);
+
+/** @brief MALI GPU power up using MALI in-built PMU
+ *
+ * Called to power up the specified cores. The mask will be saved so that \a
+ * mali_pmu_power_up_all will bring the PMU back to the previous state set with
+ * this function or \a mali_pmu_power_down.
+ *
+ * @param pmu Pointer to PMU core object to power up
+ * @param mask Mask specifying which power domains to power up
  * @return _MALI_OSK_ERR_OK on success otherwise, a suitable _mali_osk_errcode_t error.
  */
-_mali_osk_errcode_t mali_pmu_powerdown_all(struct mali_pmu_core *pmu);
+_mali_osk_errcode_t mali_pmu_power_up(struct mali_pmu_core *pmu, u32 mask);
 
+/** @brief MALI GPU power down using MALI in-built PMU
+ *
+ * called to power down all cores
+ *
+ * @param pmu Pointer to PMU core object to power down
+ * @return _MALI_OSK_ERR_OK on success otherwise, a suitable _mali_osk_errcode_t error.
+ */
+_mali_osk_errcode_t mali_pmu_power_down_all(struct mali_pmu_core *pmu);
 
 /** @brief MALI GPU power up using MALI in-built PMU
  *
@@ -60,11 +123,12 @@ _mali_osk_errcode_t mali_pmu_powerdown_all(struct mali_pmu_core *pmu);
  * @param pmu Pointer to PMU core object to power up
  * @return _MALI_OSK_ERR_OK on success otherwise, a suitable _mali_osk_errcode_t error.
  */
-_mali_osk_errcode_t mali_pmu_powerup_all(struct mali_pmu_core *pmu);
-
+_mali_osk_errcode_t mali_pmu_power_up_all(struct mali_pmu_core *pmu);
 
 /** @brief Retrieves the Mali PMU core object (if any)
  *
  * @return The Mali PMU object, or NULL if no PMU exists.
  */
 struct mali_pmu_core *mali_pmu_get_global_pmu_core(void);
+
+#endif /* __MALI_PMU_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_pp.c b/drivers/gpu/mali/mali/common/mali_pp.c
old mode 100644
new mode 100755
index 42e325c..cd17220
--- a/drivers/gpu/mali/mali/common/mali_pp.c
+++ b/drivers/gpu/mali/mali/common/mali_pp.c
@@ -1,135 +1,94 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
+#include "mali_pp_job.h"
 #include "mali_pp.h"
 #include "mali_hw_core.h"
 #include "mali_group.h"
-#include "mali_osk.h"
 #include "regs/mali_200_regs.h"
 #include "mali_kernel_common.h"
 #include "mali_kernel_core.h"
-#if MALI_TIMELINE_PROFILING_ENABLED
+#include "mali_dma.h"
+#if defined(CONFIG_MALI400_PROFILING)
 #include "mali_osk_profiling.h"
 #endif
 
-/* See mali_gp.c file for description on how to handle the interrupt mask.
- * This is how to do it on PP: mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
- */
-
-#define MALI_MAX_NUMBER_OF_PP_CORES        8
+/* Number of frame registers on Mali-200 */
+#define MALI_PP_MALI200_NUM_FRAME_REGISTERS ((0x04C/4)+1)
+/* Number of frame registers on Mali-300 and later */
+#define MALI_PP_MALI400_NUM_FRAME_REGISTERS ((0x058/4)+1)
 
-/**
- * Definition of the PP core struct
- * Used to track a PP core in the system.
- */
-struct mali_pp_core
-{
-	struct mali_hw_core  hw_core;           /**< Common for all HW cores */
-	struct mali_group   *group;             /**< Parent group for this core */
-	_mali_osk_irq_t     *irq;               /**< IRQ handler */
-	u32                  core_id;           /**< Unique core ID */
-	struct mali_pp_job  *running_job;       /**< Current running (super) job */
-	u32                  running_sub_job;   /**< Current running sub job */
-	_mali_osk_timer_t   *timeout_timer;     /**< timeout timer for this core */
-	u32                  timeout_job_id;    /**< job id for the timed out job - relevant only if pp_core_timed_out == MALI_TRUE */
-	mali_bool            core_timed_out;    /**< if MALI_TRUE, this pp core has timed out; if MALI_FALSE, no timeout on this pp core */
-	u32                  counter_src0;      /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
-	u32                  counter_src1;      /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
-	u32                  counter_src0_used; /**< The selected performance counter 0 when a job is running */
-	u32                  counter_src1_used; /**< The selected performance counter 1 when a job is running */
-};
-
-static struct mali_pp_core* mali_global_pp_cores[MALI_MAX_NUMBER_OF_PP_CORES];
+static struct mali_pp_core *mali_global_pp_cores[MALI_MAX_NUMBER_OF_PP_CORES] = { NULL };
 static u32 mali_global_num_pp_cores = 0;
 
 /* Interrupt handlers */
-static _mali_osk_errcode_t mali_pp_upper_half(void *data);
-static void mali_pp_bottom_half(void *data);
 static void mali_pp_irq_probe_trigger(void *data);
 static _mali_osk_errcode_t mali_pp_irq_probe_ack(void *data);
-static void mali_pp_post_process_job(struct mali_pp_core *core);
-static void mali_pp_timeout(void *data);
 
-struct mali_pp_core *mali_pp_create(const _mali_osk_resource_t *resource, struct mali_group *group)
+struct mali_pp_core *mali_pp_create(const _mali_osk_resource_t *resource, struct mali_group *group, mali_bool is_virtual, u32 bcast_id)
 {
-	struct mali_pp_core* core = NULL;
+	struct mali_pp_core *core = NULL;
 
 	MALI_DEBUG_PRINT(2, ("Mali PP: Creating Mali PP core: %s\n", resource->description));
 	MALI_DEBUG_PRINT(2, ("Mali PP: Base address of PP core: 0x%x\n", resource->base));
 
-	if (mali_global_num_pp_cores >= MALI_MAX_NUMBER_OF_PP_CORES)
-	{
+	if (mali_global_num_pp_cores >= MALI_MAX_NUMBER_OF_PP_CORES) {
 		MALI_PRINT_ERROR(("Mali PP: Too many PP core objects created\n"));
 		return NULL;
 	}
 
 	core = _mali_osk_malloc(sizeof(struct mali_pp_core));
-	if (NULL != core)
-	{
-		core->group = group;
+	if (NULL != core) {
 		core->core_id = mali_global_num_pp_cores;
-		core->running_job = NULL;
-		core->counter_src0 = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src1 = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src0_used = MALI_HW_CORE_NO_COUNTER;
-		core->counter_src1_used = MALI_HW_CORE_NO_COUNTER;
-		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALI200_REG_SIZEOF_REGISTER_BANK))
-		{
+		core->bcast_id = bcast_id;
+
+		if (_MALI_OSK_ERR_OK == mali_hw_core_create(&core->hw_core, resource, MALI200_REG_SIZEOF_REGISTER_BANK)) {
 			_mali_osk_errcode_t ret;
 
-			mali_group_lock(group);
-			ret = mali_pp_reset(core);
-			mali_group_unlock(group);
-
-			if (_MALI_OSK_ERR_OK == ret)
-			{
-				/* Setup IRQ handlers (which will do IRQ probing if needed) */
-				core->irq = _mali_osk_irq_init(resource->irq,
-				                               mali_pp_upper_half,
-				                               mali_pp_bottom_half,
-				                               mali_pp_irq_probe_trigger,
-				                               mali_pp_irq_probe_ack,
-				                               core,
-				                               "mali_pp_irq_handlers");
-				if (NULL != core->irq)
-				{
-					/* Initialise the timeout timer */
-					core->timeout_timer = _mali_osk_timer_init();
-					if(NULL != core->timeout_timer)
-					{
-						_mali_osk_timer_setcallback(core->timeout_timer, mali_pp_timeout, (void *)core);
+			if (!is_virtual) {
+				ret = mali_pp_reset(core);
+			} else {
+				ret = _MALI_OSK_ERR_OK;
+			}
 
+			if (_MALI_OSK_ERR_OK == ret) {
+				ret = mali_group_add_pp_core(group, core);
+				if (_MALI_OSK_ERR_OK == ret) {
+					/* Setup IRQ handlers (which will do IRQ probing if needed) */
+					MALI_DEBUG_ASSERT(!is_virtual || -1 != resource->irq);
+
+					core->irq = _mali_osk_irq_init(resource->irq,
+								       mali_group_upper_half_pp,
+								       group,
+								       mali_pp_irq_probe_trigger,
+								       mali_pp_irq_probe_ack,
+								       core,
+								       resource->description);
+					if (NULL != core->irq) {
 						mali_global_pp_cores[mali_global_num_pp_cores] = core;
 						mali_global_num_pp_cores++;
 
 						return core;
+					} else {
+						MALI_PRINT_ERROR(("Mali PP: Failed to setup interrupt handlers for PP core %s\n", core->hw_core.description));
 					}
-					else
-					{
-						MALI_PRINT_ERROR(("Failed to setup timeout timer for PP core %s\n", core->hw_core.description));
-						/* Release IRQ handlers */
-						_mali_osk_irq_term(core->irq);
-					}
-				}
-				else
-				{
-					MALI_PRINT_ERROR(("Mali PP: Failed to setup interrupt handlers for PP core %s\n", core->hw_core.description));
+					mali_group_remove_pp_core(group);
+				} else {
+					MALI_PRINT_ERROR(("Mali PP: Failed to add core %s to group\n", core->hw_core.description));
 				}
 			}
 			mali_hw_core_delete(&core->hw_core);
 		}
 
 		_mali_osk_free(core);
-	}
-	else
-	{
+	} else {
 		MALI_PRINT_ERROR(("Mali PP: Failed to allocate memory for PP core\n"));
 	}
 
@@ -142,17 +101,22 @@ void mali_pp_delete(struct mali_pp_core *core)
 
 	MALI_DEBUG_ASSERT_POINTER(core);
 
-	_mali_osk_timer_term(core->timeout_timer);
 	_mali_osk_irq_term(core->irq);
 	mali_hw_core_delete(&core->hw_core);
 
 	/* Remove core from global list */
-	for (i = 0; i < mali_global_num_pp_cores; i++)
-	{
-		if (mali_global_pp_cores[i] == core)
-		{
+	for (i = 0; i < mali_global_num_pp_cores; i++) {
+		if (mali_global_pp_cores[i] == core) {
 			mali_global_pp_cores[i] = NULL;
 			mali_global_num_pp_cores--;
+
+			if (i != mali_global_num_pp_cores) {
+				/* We removed a PP core from the middle of the array -- move the last
+				 * PP core to the current position to close the gap */
+				mali_global_pp_cores[i] = mali_global_pp_cores[mali_global_num_pp_cores];
+				mali_global_pp_cores[mali_global_num_pp_cores] = NULL;
+			}
+
 			break;
 		}
 	}
@@ -170,63 +134,98 @@ void mali_pp_stop_bus(struct mali_pp_core *core)
 _mali_osk_errcode_t mali_pp_stop_bus_wait(struct mali_pp_core *core)
 {
 	int i;
-	const int request_loop_count = 20;
 
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_ASSERT_GROUP_LOCKED(core->group);
 
 	/* Send the stop bus command. */
 	mali_pp_stop_bus(core);
 
 	/* Wait for bus to be stopped */
-	for (i = 0; i < request_loop_count; i++)
-	{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
 		if (mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS) & MALI200_REG_VAL_STATUS_BUS_STOPPED)
 			break;
-		_mali_osk_time_ubusydelay(10);
 	}
 
-	if (request_loop_count == i)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Mali PP: Failed to stop bus on %s. Status: 0x%08x\n", core->hw_core.description, mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS)));
 		return _MALI_OSK_ERR_FAULT;
 	}
 	return _MALI_OSK_ERR_OK;
 }
 
+/* Frame register reset values.
+ * Taken from the Mali400 TRM, 3.6. Pixel processor control register summary */
+static const u32 mali_frame_registers_reset_values[_MALI_PP_MAX_FRAME_REGISTERS] = {
+	0x0, /* Renderer List Address Register */
+	0x0, /* Renderer State Word Base Address Register */
+	0x0, /* Renderer Vertex Base Register */
+	0x2, /* Feature Enable Register */
+	0x0, /* Z Clear Value Register */
+	0x0, /* Stencil Clear Value Register */
+	0x0, /* ABGR Clear Value 0 Register */
+	0x0, /* ABGR Clear Value 1 Register */
+	0x0, /* ABGR Clear Value 2 Register */
+	0x0, /* ABGR Clear Value 3 Register */
+	0x0, /* Bounding Box Left Right Register */
+	0x0, /* Bounding Box Bottom Register */
+	0x0, /* FS Stack Address Register */
+	0x0, /* FS Stack Size and Initial Value Register */
+	0x0, /* Reserved */
+	0x0, /* Reserved */
+	0x0, /* Origin Offset X Register */
+	0x0, /* Origin Offset Y Register */
+	0x75, /* Subpixel Specifier Register */
+	0x0, /* Tiebreak mode Register */
+	0x0, /* Polygon List Format Register */
+	0x0, /* Scaling Register */
+	0x0 /* Tilebuffer configuration Register */
+};
+
+/* WBx register reset values */
+static const u32 mali_wb_registers_reset_values[_MALI_PP_MAX_WB_REGISTERS] = {
+	0x0, /* WBx Source Select Register */
+	0x0, /* WBx Target Address Register */
+	0x0, /* WBx Target Pixel Format Register */
+	0x0, /* WBx Target AA Format Register */
+	0x0, /* WBx Target Layout */
+	0x0, /* WBx Target Scanline Length */
+	0x0, /* WBx Target Flags Register */
+	0x0, /* WBx MRT Enable Register */
+	0x0, /* WBx MRT Offset Register */
+	0x0, /* WBx Global Test Enable Register */
+	0x0, /* WBx Global Test Reference Value Register */
+	0x0  /* WBx Global Test Compare Function Register */
+};
+
+/* Performance Counter 0 Enable Register reset value */
+static const u32 mali_perf_cnt_enable_reset_value = 0;
+
 _mali_osk_errcode_t mali_pp_hard_reset(struct mali_pp_core *core)
 {
 	/* Bus must be stopped before calling this function */
-	const int reset_finished_loop_count = 15;
 	const u32 reset_invalid_value = 0xC0FFE000;
 	const u32 reset_check_value = 0xC01A0000;
 	int i;
 
 	MALI_DEBUG_ASSERT_POINTER(core);
 	MALI_DEBUG_PRINT(2, ("Mali PP: Hard reset of core %s\n", core->hw_core.description));
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	mali_pp_post_process_job(core); /* @@@@ is there some cases where it is unsafe to post process the job here? */
 
 	/* Set register to a bogus value. The register will be used to detect when reset is complete */
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_WRITE_BOUNDARY_LOW, reset_invalid_value);
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_WRITE_BOUNDARY_LOW, reset_invalid_value);
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_NONE);
 
 	/* Force core to reset */
 	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI200_REG_VAL_CTRL_MGMT_FORCE_RESET);
 
 	/* Wait for reset to be complete */
-	for (i = 0; i < reset_finished_loop_count; i++)
-	{
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
 		mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_WRITE_BOUNDARY_LOW, reset_check_value);
-		if (reset_check_value == mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_WRITE_BOUNDARY_LOW))
-		{
+		if (reset_check_value == mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_WRITE_BOUNDARY_LOW)) {
 			break;
 		}
-		_mali_osk_time_ubusydelay(10);
 	}
 
-	if (i == reset_finished_loop_count)
-	{
+	if (MALI_REG_POLL_COUNT_FAST == i) {
 		MALI_PRINT_ERROR(("Mali PP: The hard reset loop didn't work, unable to recover\n"));
 	}
 
@@ -238,173 +237,216 @@ _mali_osk_errcode_t mali_pp_hard_reset(struct mali_pp_core *core)
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t mali_pp_reset(struct mali_pp_core *core)
+void mali_pp_reset_async(struct mali_pp_core *core)
 {
-	int i;
-	const int request_loop_count = 20;
-
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_DEBUG_PRINT(4, ("Mali PP: Reset of core %s\n", core->hw_core.description));
-	MALI_ASSERT_GROUP_LOCKED(core->group);
 
-	mali_pp_post_process_job(core); /* @@@@ is there some cases where it is unsafe to post process the job here? */
+	MALI_DEBUG_PRINT(4, ("Mali PP: Reset of core %s\n", core->hw_core.description));
 
 	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, 0); /* disable the IRQs */
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT, MALI200_REG_VAL_IRQ_MASK_ALL);
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI400PP_REG_VAL_CTRL_MGMT_SOFT_RESET);
+}
 
-#if defined(USING_MALI200)
-
-	/* On Mali-200, stop the  bus, then do a hard reset of the core */
-
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI200_REG_VAL_CTRL_MGMT_STOP_BUS);
+_mali_osk_errcode_t mali_pp_reset_wait(struct mali_pp_core *core)
+{
+	int i;
+	u32 rawstat = 0;
 
-	for (i = 0; i < request_loop_count; i++)
-	{
-		if (mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS) & MALI200_REG_VAL_STATUS_BUS_STOPPED)
-		{
-			break;
+	for (i = 0; i < MALI_REG_POLL_COUNT_FAST; i++) {
+		if (!(mali_pp_read_status(core) & MALI200_REG_VAL_STATUS_RENDERING_ACTIVE)) {
+			rawstat = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT);
+			if (rawstat == MALI400PP_REG_VAL_IRQ_RESET_COMPLETED) {
+				break;
+			}
 		}
-		_mali_osk_time_ubusydelay(10);
 	}
 
-	if (request_loop_count == i)
-	{
-		MALI_PRINT_ERROR(("Mali PP: Failed to stop bus for core %s, unable to recover\n", core->hw_core.description));
-		return _MALI_OSK_ERR_FAULT ;
+	if (i == MALI_REG_POLL_COUNT_FAST) {
+		MALI_PRINT_ERROR(("Mali PP: Failed to reset core %s, rawstat: 0x%08x\n",
+				  core->hw_core.description, rawstat));
+		return _MALI_OSK_ERR_FAULT;
 	}
 
-	/* the bus was stopped OK, do the hard reset */
-	mali_pp_hard_reset(core);
+	/* Re-enable interrupts */
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI200_REG_VAL_IRQ_MASK_ALL);
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
 
-#elif defined(USING_MALI400)
+	return _MALI_OSK_ERR_OK;
+}
 
-	/* Mali-300 and Mali-400 have a safe reset command which we use */
+_mali_osk_errcode_t mali_pp_reset(struct mali_pp_core *core)
+{
+	mali_pp_reset_async(core);
+	return mali_pp_reset_wait(core);
+}
 
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI400PP_REG_VAL_IRQ_RESET_COMPLETED);
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI400PP_REG_VAL_CTRL_MGMT_SOFT_RESET);
+void mali_pp_job_dma_cmd_prepare(struct mali_pp_core *core, struct mali_pp_job *job, u32 sub_job,
+				 mali_dma_cmd_buf *buf)
+{
+	u32 relative_address;
+	u32 start_index;
+	u32 nr_of_regs;
+	u32 *frame_registers = mali_pp_job_get_frame_registers(job);
+	u32 *wb0_registers = mali_pp_job_get_wb0_registers(job);
+	u32 *wb1_registers = mali_pp_job_get_wb1_registers(job);
+	u32 *wb2_registers = mali_pp_job_get_wb2_registers(job);
+	u32 counter_src0 = mali_pp_job_get_perf_counter_src0(job, sub_job);
+	u32 counter_src1 = mali_pp_job_get_perf_counter_src1(job, sub_job);
 
-	for (i = 0; i < request_loop_count; i++)
-	{
-		if (mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT) & MALI400PP_REG_VAL_IRQ_RESET_COMPLETED)
-		{
-			break;
-		}
-		_mali_osk_time_ubusydelay(10);
+	MALI_DEBUG_ASSERT_POINTER(core);
+
+	/* Write registers between MALI200_REG_ADDR_FRAME and MALI200_REG_ADDR_STACK */
+	relative_address = MALI200_REG_ADDR_RSW;
+	start_index = MALI200_REG_ADDR_RSW / sizeof(u32);
+	nr_of_regs = (MALI200_REG_ADDR_STACK - MALI200_REG_ADDR_RSW) / sizeof(u32);
+
+	mali_dma_write_array_conditional(buf, &core->hw_core,
+					 relative_address, &frame_registers[start_index],
+					 nr_of_regs, &mali_frame_registers_reset_values[start_index]);
+
+	/* MALI200_REG_ADDR_STACK_SIZE */
+	relative_address = MALI200_REG_ADDR_STACK_SIZE;
+	start_index = MALI200_REG_ADDR_STACK_SIZE / sizeof(u32);
+
+	mali_dma_write_conditional(buf, &core->hw_core,
+				   relative_address, frame_registers[start_index],
+				   mali_frame_registers_reset_values[start_index]);
+
+	/* Skip 2 reserved registers */
+
+	/* Write remaining registers */
+	relative_address = MALI200_REG_ADDR_ORIGIN_OFFSET_X;
+	start_index = MALI200_REG_ADDR_ORIGIN_OFFSET_X / sizeof(u32);
+	nr_of_regs = MALI_PP_MALI400_NUM_FRAME_REGISTERS - MALI200_REG_ADDR_ORIGIN_OFFSET_X / sizeof(u32);
+
+	mali_dma_write_array_conditional(buf, &core->hw_core,
+					 relative_address, &frame_registers[start_index],
+					 nr_of_regs, &mali_frame_registers_reset_values[start_index]);
+
+	/* Write WBx registers */
+	if (wb0_registers[0]) { /* M200_WB0_REG_SOURCE_SELECT register */
+		mali_dma_write_array_conditional(buf, &core->hw_core, MALI200_REG_ADDR_WB0, wb0_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
 	}
 
-	if (request_loop_count == i)
-	{
-		MALI_DEBUG_PRINT(2, ("Mali PP: Failed to reset core %s, Status: 0x%08x\n", core->hw_core.description, mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS)));
-		return _MALI_OSK_ERR_FAULT;
+	if (wb1_registers[0]) { /* M200_WB1_REG_SOURCE_SELECT register */
+		mali_dma_write_array_conditional(buf, &core->hw_core, MALI200_REG_ADDR_WB1, wb1_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
 	}
-#else
-#error "no supported mali core defined"
-#endif
 
-	/* Re-enable interrupts */
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI200_REG_VAL_IRQ_MASK_ALL);
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
+	if (wb2_registers[0]) { /* M200_WB2_REG_SOURCE_SELECT register */
+		mali_dma_write_array_conditional(buf, &core->hw_core, MALI200_REG_ADDR_WB2, wb2_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
+	}
 
-	return _MALI_OSK_ERR_OK;
+	if (MALI_HW_CORE_NO_COUNTER != counter_src0) {
+		mali_dma_write(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_SRC, counter_src0);
+		mali_dma_write_conditional(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE, mali_perf_cnt_enable_reset_value);
+	}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src1) {
+		mali_dma_write(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_SRC, counter_src1);
+		mali_dma_write_conditional(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE, mali_perf_cnt_enable_reset_value);
+	}
+
+	/* This is the command that starts the core.
+	 *
+	 * Don't actually run the job if PROFILING_SKIP_PP_JOBS are set, just
+	 * force core to assert the completion interrupt.
+	 */
+#if !defined(PROFILING_SKIP_PP_JOBS)
+	mali_dma_write(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI200_REG_VAL_CTRL_MGMT_START_RENDERING);
+#else
+	mali_dma_write(buf, &core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT, MALI200_REG_VAL_IRQ_END_OF_FRAME);
+#endif
 }
 
 void mali_pp_job_start(struct mali_pp_core *core, struct mali_pp_job *job, u32 sub_job)
 {
+	u32 relative_address;
+	u32 start_index;
+	u32 nr_of_regs;
 	u32 *frame_registers = mali_pp_job_get_frame_registers(job);
 	u32 *wb0_registers = mali_pp_job_get_wb0_registers(job);
 	u32 *wb1_registers = mali_pp_job_get_wb1_registers(job);
 	u32 *wb2_registers = mali_pp_job_get_wb2_registers(job);
-	core->counter_src0_used = core->counter_src0;
-	core->counter_src1_used = core->counter_src1;
+	u32 counter_src0 = mali_pp_job_get_perf_counter_src0(job, sub_job);
+	u32 counter_src1 = mali_pp_job_get_perf_counter_src1(job, sub_job);
 
 	MALI_DEBUG_ASSERT_POINTER(core);
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	mali_hw_core_register_write_array_relaxed(&core->hw_core, MALI200_REG_ADDR_FRAME, frame_registers, MALI200_NUM_REGS_FRAME);
-	if (0 != sub_job)
-	{
-		/*
-		 * There are two frame registers which are different for each sub job.
-		 * For the first sub job, these are correctly represented in the frame register array,
-		 * but we need to patch these for all other sub jobs
-		 */
-		mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_FRAME, mali_pp_job_get_addr_frame(job, sub_job));
-		mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_STACK, mali_pp_job_get_addr_stack(job, sub_job));
-	}
 
-	if (wb0_registers[0]) /* M200_WB0_REG_SOURCE_SELECT register */
-	{
-		mali_hw_core_register_write_array_relaxed(&core->hw_core, MALI200_REG_ADDR_WB0, wb0_registers, MALI200_NUM_REGS_WBx);
+	/* Write registers between MALI200_REG_ADDR_FRAME and MALI200_REG_ADDR_STACK */
+	relative_address = MALI200_REG_ADDR_RSW;
+	start_index = MALI200_REG_ADDR_RSW / sizeof(u32);
+	nr_of_regs = (MALI200_REG_ADDR_STACK - MALI200_REG_ADDR_RSW) / sizeof(u32);
+
+	mali_hw_core_register_write_array_relaxed_conditional(&core->hw_core,
+			relative_address, &frame_registers[start_index],
+			nr_of_regs, &mali_frame_registers_reset_values[start_index]);
+
+	/* MALI200_REG_ADDR_STACK_SIZE */
+	relative_address = MALI200_REG_ADDR_STACK_SIZE;
+	start_index = MALI200_REG_ADDR_STACK_SIZE / sizeof(u32);
+
+	mali_hw_core_register_write_relaxed_conditional(&core->hw_core,
+			relative_address, frame_registers[start_index],
+			mali_frame_registers_reset_values[start_index]);
+
+	/* Skip 2 reserved registers */
+
+	/* Write remaining registers */
+	relative_address = MALI200_REG_ADDR_ORIGIN_OFFSET_X;
+	start_index = MALI200_REG_ADDR_ORIGIN_OFFSET_X / sizeof(u32);
+	nr_of_regs = MALI_PP_MALI400_NUM_FRAME_REGISTERS - MALI200_REG_ADDR_ORIGIN_OFFSET_X / sizeof(u32);
+
+	mali_hw_core_register_write_array_relaxed_conditional(&core->hw_core,
+			relative_address, &frame_registers[start_index],
+			nr_of_regs, &mali_frame_registers_reset_values[start_index]);
+
+	/* Write WBx registers */
+	if (wb0_registers[0]) { /* M200_WB0_REG_SOURCE_SELECT register */
+		mali_hw_core_register_write_array_relaxed_conditional(&core->hw_core, MALI200_REG_ADDR_WB0, wb0_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
 	}
 
-	if (wb1_registers[0]) /* M200_WB1_REG_SOURCE_SELECT register */
-	{
-		mali_hw_core_register_write_array_relaxed(&core->hw_core, MALI200_REG_ADDR_WB1, wb1_registers, MALI200_NUM_REGS_WBx);
+	if (wb1_registers[0]) { /* M200_WB1_REG_SOURCE_SELECT register */
+		mali_hw_core_register_write_array_relaxed_conditional(&core->hw_core, MALI200_REG_ADDR_WB1, wb1_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
 	}
 
-	if (wb2_registers[0]) /* M200_WB2_REG_SOURCE_SELECT register */
-	{
-		mali_hw_core_register_write_array_relaxed(&core->hw_core, MALI200_REG_ADDR_WB2, wb2_registers, MALI200_NUM_REGS_WBx);
+	if (wb2_registers[0]) { /* M200_WB2_REG_SOURCE_SELECT register */
+		mali_hw_core_register_write_array_relaxed_conditional(&core->hw_core, MALI200_REG_ADDR_WB2, wb2_registers, _MALI_PP_MAX_WB_REGISTERS, mali_wb_registers_reset_values);
 	}
 
-	/* This selects which performance counters we are reading */
-	if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used || MALI_HW_CORE_NO_COUNTER != core->counter_src1_used)
-	{
-		/* global_config has enabled HW counters, this will override anything specified by user space */
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used)
-		{
-			mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_SRC, core->counter_src0_used);
-			mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE);
-		}
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src1_used)
-		{
-			mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_SRC, core->counter_src1_used);
-			mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE);
-		}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src0) {
+		mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_SRC, counter_src0);
+		mali_hw_core_register_write_relaxed_conditional(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE, mali_perf_cnt_enable_reset_value);
+	}
+	if (MALI_HW_CORE_NO_COUNTER != counter_src1) {
+		mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_SRC, counter_src1);
+		mali_hw_core_register_write_relaxed_conditional(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE, mali_perf_cnt_enable_reset_value);
 	}
-	else
-	{
-		/* Use HW counters from job object, if any */
-		u32 perf_counter_flag = mali_pp_job_get_perf_counter_flag(job);
-		if (0 != perf_counter_flag)
-		{
-			if (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE)
-			{
-				core->counter_src0_used = mali_pp_job_get_perf_counter_src0(job);
-				mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_SRC, core->counter_src0_used);
-				mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE);
-			}
 
-			if (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE)
-			{
-				core->counter_src1_used = mali_pp_job_get_perf_counter_src1(job);
-				mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_SRC, core->counter_src1_used);
-				mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_ENABLE, MALI200_REG_VAL_PERF_CNT_ENABLE);
-			}
-		}
+#ifdef CONFIG_MALI400_HEATMAPS_ENABLED
+	if (job->uargs.perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_HEATMAP_ENABLE) {
+		mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_PERFMON_CONTR, ((job->uargs.tilesx & 0x3FF) << 16) | 1);
+		mali_hw_core_register_write_relaxed(&core->hw_core,  MALI200_REG_ADDR_MGMT_PERFMON_BASE, job->uargs.heatmap_mem & 0xFFFFFFF8);
 	}
+#endif /* CONFIG_MALI400_HEATMAPS_ENABLED */
 
 	MALI_DEBUG_PRINT(3, ("Mali PP: Starting job 0x%08X part %u/%u on PP core %s\n", job, sub_job + 1, mali_pp_job_get_sub_job_count(job), core->hw_core.description));
 
 	/* Adding barrier to make sure all rester writes are finished */
 	_mali_osk_write_mem_barrier();
 
-	/* This is the command that starts the core. */
+	/* This is the command that starts the core.
+	 *
+	 * Don't actually run the job if PROFILING_SKIP_PP_JOBS are set, just
+	 * force core to assert the completion interrupt.
+	 */
+#if !defined(PROFILING_SKIP_PP_JOBS)
 	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_CTRL_MGMT, MALI200_REG_VAL_CTRL_MGMT_START_RENDERING);
+#else
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT, MALI200_REG_VAL_IRQ_END_OF_FRAME);
+#endif
 
 	/* Adding barrier to make sure previous rester writes is finished */
 	_mali_osk_write_mem_barrier();
-
-	/* Setup the timeout timer value and save the job id for the job running on the pp core */
-	_mali_osk_timer_add(core->timeout_timer, _mali_osk_time_mstoticks(mali_max_job_runtime));
-	core->timeout_job_id = mali_pp_job_get_id(job);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE | MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(core->core_id) | MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH, job->frame_builder_id, job->flush_id, 0, 0, 0);
-	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_START|MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(core->core_id), job->pid, job->tid, 0, 0, 0);
-#endif
-
-	core->running_job = job;
-	core->running_sub_job = sub_job;
 }
 
 u32 mali_pp_core_get_version(struct mali_pp_core *core)
@@ -413,44 +455,9 @@ u32 mali_pp_core_get_version(struct mali_pp_core *core)
 	return mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_VERSION);
 }
 
-u32 mali_pp_core_get_id(struct mali_pp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	return core->core_id;
-}
-
-mali_bool mali_pp_core_set_counter_src0(struct mali_pp_core *core, u32 counter)
+struct mali_pp_core *mali_pp_get_global_pp_core(u32 index)
 {
-	MALI_DEBUG_ASSERT_POINTER(core);
-
-	core->counter_src0 = counter;
-	return MALI_TRUE;
-}
-
-mali_bool mali_pp_core_set_counter_src1(struct mali_pp_core *core, u32 counter)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-
-	core->counter_src1 = counter;
-	return MALI_TRUE;
-}
-
-u32 mali_pp_core_get_counter_src0(struct mali_pp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	return core->counter_src0;
-}
-
-u32 mali_pp_core_get_counter_src1(struct mali_pp_core *core)
-{
-	MALI_DEBUG_ASSERT_POINTER(core);
-	return core->counter_src1;
-}
-
-struct mali_pp_core* mali_pp_get_global_pp_core(u32 index)
-{
-	if (MALI_MAX_NUMBER_OF_PP_CORES > index)
-	{
+	if (mali_global_num_pp_cores > index) {
 		return mali_global_pp_cores[index];
 	}
 
@@ -462,121 +469,11 @@ u32 mali_pp_get_glob_num_pp_cores(void)
 	return mali_global_num_pp_cores;
 }
 
-u32 mali_pp_get_max_num_pp_cores(void)
-{
-	return MALI_MAX_NUMBER_OF_PP_CORES;
-}
-
 /* ------------- interrupt handling below ------------------ */
-static _mali_osk_errcode_t mali_pp_upper_half(void *data)
-{
-	struct mali_pp_core *core = (struct mali_pp_core *)data;
-	u32 irq_readout;
-
-	irq_readout = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_STATUS);
-	if (MALI200_REG_VAL_IRQ_MASK_NONE != irq_readout)
-	{
-		/* Mask out all IRQs from this core until IRQ is handled */
-		mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_NONE);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE|MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(core->core_id)|MALI_PROFILING_EVENT_REASON_SINGLE_HW_INTERRUPT, irq_readout, 0, 0, 0, 0);
-#endif
-
-		/* We do need to handle this in a bottom half */
-		_mali_osk_irq_schedulework(core->irq);
-		return _MALI_OSK_ERR_OK;
-	}
-
-	return _MALI_OSK_ERR_FAULT;
-}
-
-static void mali_pp_bottom_half(void *data)
-{
-	struct mali_pp_core *core = (struct mali_pp_core *)data;
-	u32 irq_readout;
-	u32 irq_errors;
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-#if 0  /* Bottom half TLP logging is currently not supported */
-	_mali_osk_profiling_add_event( MALI_PROFILING_EVENT_TYPE_START| MALI_PROFILING_EVENT_CHANNEL_SOFTWARE ,  _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
-#endif
-#endif
-
-	mali_group_lock(core->group); /* Group lock grabbed in core handlers, but released in common group handler */
-
-	if ( MALI_FALSE == mali_group_power_is_on(core->group) )
-	{
-		MALI_PRINT_ERROR(("Interrupt bottom half of %s when core is OFF.", core->hw_core.description));
-		mali_group_unlock(core->group);
-		return;
-	}
-
-	irq_readout = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT) & MALI200_REG_VAL_IRQ_MASK_USED;
-
-	MALI_DEBUG_PRINT(4, ("Mali PP: Bottom half IRQ 0x%08X from core %s\n", irq_readout, core->hw_core.description));
-
-	if (irq_readout & MALI200_REG_VAL_IRQ_END_OF_FRAME)
-	{
-		mali_pp_post_process_job(core);
-		MALI_DEBUG_PRINT(3, ("Mali PP: Job completed, calling group handler\n"));
-		mali_group_bottom_half(core->group, GROUP_EVENT_PP_JOB_COMPLETED); /* Will release group lock */
-		return;
-	}
-
-	/*
-	 * Now lets look at the possible error cases (IRQ indicating error or timeout)
-	 * END_OF_FRAME and HANG interrupts are not considered error.
-	 */
-	irq_errors = irq_readout & ~(MALI200_REG_VAL_IRQ_END_OF_FRAME|MALI200_REG_VAL_IRQ_HANG);
-	if (0 != irq_errors)
-	{
-		mali_pp_post_process_job(core);
-		MALI_PRINT_ERROR(("Mali PP: Unknown interrupt 0x%08X from core %s, aborting job\n",
-		                  irq_readout, core->hw_core.description));
-		mali_group_bottom_half(core->group, GROUP_EVENT_PP_JOB_FAILED); /* Will release group lock */
-		return;
-	}
-	else if (MALI_TRUE == core->core_timed_out) /* SW timeout */
-	{
-		if (core->timeout_job_id == mali_pp_job_get_id(core->running_job))
-		{
-			mali_pp_post_process_job(core);
-			MALI_DEBUG_PRINT(2, ("Mali PP: Job %d timed out on core %s\n",
-			                 mali_pp_job_get_id(core->running_job), core->hw_core.description));
-			mali_group_bottom_half(core->group, GROUP_EVENT_PP_JOB_TIMED_OUT); /* Will release group lock */
-		}
-		else
-		{
-			mali_group_unlock(core->group);
-		}
-		core->core_timed_out = MALI_FALSE;
-		return;
-	}
-	else if (irq_readout & MALI200_REG_VAL_IRQ_HANG)
-	{
-		/* Just ignore hang interrupts, the job timer will detect hanging jobs anyways */
-		mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI200_REG_VAL_IRQ_HANG);
-	}
-
-	/*
-	 * The only way to get here is if we got a HANG interrupt, which we ignore.
-	 * Re-enable interrupts and let core continue to run
-	 */
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
-	mali_group_unlock(core->group);
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-#if 0   /* Bottom half TLP logging is currently not supported */
-	_mali_osk_profiling_add_event( MALI_PROFILING_EVENT_TYPE_STOP| MALI_PROFILING_EVENT_CHANNEL_SOFTWARE ,  _mali_osk_get_pid(), _mali_osk_get_tid(), 0, 0, 0);
-#endif
-#endif
-}
-
 static void mali_pp_irq_probe_trigger(void *data)
 {
 	struct mali_pp_core *core = (struct mali_pp_core *)data;
-	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);     /* @@@@ This should not be needed */
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
 	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT, MALI200_REG_VAL_IRQ_FORCE_HANG);
 	_mali_osk_mem_barrier();
 }
@@ -587,8 +484,7 @@ static _mali_osk_errcode_t mali_pp_irq_probe_ack(void *data)
 	u32 irq_readout;
 
 	irq_readout = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_STATUS);
-	if (MALI200_REG_VAL_IRQ_FORCE_HANG & irq_readout)
-	{
+	if (MALI200_REG_VAL_IRQ_FORCE_HANG & irq_readout) {
 		mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI200_REG_VAL_IRQ_FORCE_HANG);
 		_mali_osk_mem_barrier();
 		return _MALI_OSK_ERR_OK;
@@ -598,80 +494,6 @@ static _mali_osk_errcode_t mali_pp_irq_probe_ack(void *data)
 }
 
 
-/* ------ local helper functions below --------- */
-static void mali_pp_post_process_job(struct mali_pp_core *core)
-{
-	MALI_ASSERT_GROUP_LOCKED(core->group);
-
-	if (NULL != core->running_job)
-	{
-		u32 val0 = 0;
-		u32 val1 = 0;
-#if MALI_TIMELINE_PROFILING_ENABLED
-		int counter_index = COUNTER_FP0_C0 + (2 * core->core_id);
-#endif
-
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src0_used)
-		{
-			val0 = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_VALUE);
-			if (mali_pp_job_get_perf_counter_flag(core->running_job) &&
-			    _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE && mali_pp_job_get_perf_counter_src0(core->running_job) == core->counter_src0_used)
-			{
-				/* We retrieved the counter that user space asked for, so return the value through the job object */
-				mali_pp_job_set_perf_counter_value0(core->running_job, core->running_sub_job, val0);
-			}
-			else
-			{
-				/* User space asked for a counter, but this is not what we retrived (overridden by counter src set on core) */
-				mali_pp_job_set_perf_counter_value0(core->running_job, core->running_sub_job, MALI_HW_CORE_INVALID_VALUE);
-			}
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-			_mali_osk_profiling_report_hw_counter(counter_index, val0);
-#endif
-		}
-
-		if (MALI_HW_CORE_NO_COUNTER != core->counter_src1_used)
-		{
-			val1 = mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_VALUE);
-			if (mali_pp_job_get_perf_counter_flag(core->running_job) &&
-			    _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE && mali_pp_job_get_perf_counter_src1(core->running_job) == core->counter_src1_used)
-			{
-				/* We retrieved the counter that user space asked for, so return the value through the job object */
-				mali_pp_job_set_perf_counter_value1(core->running_job, core->running_sub_job, val1);
-			}
-			else
-			{
-				/* User space asked for a counter, but this is not what we retrived (overridden by counter src set on core) */
-				mali_pp_job_set_perf_counter_value1(core->running_job, core->running_sub_job, MALI_HW_CORE_INVALID_VALUE);
-			}
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-			_mali_osk_profiling_report_hw_counter(counter_index + 1, val1);
-#endif
-		}
-
-#if MALI_TIMELINE_PROFILING_ENABLED
-		_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_STOP|MALI_PROFILING_MAKE_EVENT_CHANNEL_PP(core->core_id),
-		                          val0, val1, core->counter_src0_used | (core->counter_src1_used << 8), 0, 0);
-#endif
-
-		/* We are no longer running a job... */
-		core->running_job = NULL;
-		_mali_osk_timer_del(core->timeout_timer);
-	}
-}
-
-/* callback function for pp core timeout */
-static void mali_pp_timeout(void *data)
-{
-	struct mali_pp_core * core = ((struct mali_pp_core *)data);
-
-	MALI_DEBUG_PRINT(3, ("Mali PP: TIMEOUT callback \n"));
-	core->core_timed_out = MALI_TRUE;
-	_mali_osk_irq_schedulework(core->irq);
-}
-
 #if 0
 static void mali_pp_print_registers(struct mali_pp_core *core)
 {
@@ -694,10 +516,39 @@ static void mali_pp_print_registers(struct mali_pp_core *core)
 #if 0
 void mali_pp_print_state(struct mali_pp_core *core)
 {
-	MALI_DEBUG_PRINT(2, ("Mali PP: State: 0x%08x\n", mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS) ));
+	MALI_DEBUG_PRINT(2, ("Mali PP: State: 0x%08x\n", mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS)));
 }
 #endif
 
+void mali_pp_update_performance_counters(struct mali_pp_core *parent, struct mali_pp_core *child, struct mali_pp_job *job, u32 subjob)
+{
+	u32 val0 = 0;
+	u32 val1 = 0;
+	u32 counter_src0 = mali_pp_job_get_perf_counter_src0(job, subjob);
+	u32 counter_src1 = mali_pp_job_get_perf_counter_src1(job, subjob);
+#if defined(CONFIG_MALI400_PROFILING)
+	int counter_index = COUNTER_FP_0_C0 + (2 * child->core_id);
+#endif
+
+	if (MALI_HW_CORE_NO_COUNTER != counter_src0) {
+		val0 = mali_hw_core_register_read(&child->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_0_VALUE);
+		mali_pp_job_set_perf_counter_value0(job, subjob, val0);
+
+#if defined(CONFIG_MALI400_PROFILING)
+		_mali_osk_profiling_report_hw_counter(counter_index, val0);
+#endif
+	}
+
+	if (MALI_HW_CORE_NO_COUNTER != counter_src1) {
+		val1 = mali_hw_core_register_read(&child->hw_core, MALI200_REG_ADDR_MGMT_PERF_CNT_1_VALUE);
+		mali_pp_job_set_perf_counter_value1(job, subjob, val1);
+
+#if defined(CONFIG_MALI400_PROFILING)
+		_mali_osk_profiling_report_hw_counter(counter_index + 1, val1);
+#endif
+	}
+}
+
 #if MALI_STATE_TRACKING
 u32 mali_pp_dump_state(struct mali_pp_core *core, char *buf, u32 size)
 {
diff --git a/drivers/gpu/mali/mali/common/mali_pp.h b/drivers/gpu/mali/mali/common/mali_pp.h
old mode 100644
new mode 100755
index fc80dd9..42a1253
--- a/drivers/gpu/mali/mali/common/mali_pp.h
+++ b/drivers/gpu/mali/mali/common/mali_pp.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,35 +13,127 @@
 
 #include "mali_osk.h"
 #include "mali_pp_job.h"
+#include "mali_hw_core.h"
+#include "mali_dma.h"
 
-struct mali_pp_core;
 struct mali_group;
 
+#define MALI_MAX_NUMBER_OF_PP_CORES        9
+
+/**
+ * Definition of the PP core struct
+ * Used to track a PP core in the system.
+ */
+struct mali_pp_core {
+	struct mali_hw_core  hw_core;           /**< Common for all HW cores */
+	_mali_osk_irq_t     *irq;               /**< IRQ handler */
+	u32                  core_id;           /**< Unique core ID */
+	u32                  bcast_id;          /**< The "flag" value used by the Mali-450 broadcast and DLBU unit */
+};
+
 _mali_osk_errcode_t mali_pp_initialize(void);
 void mali_pp_terminate(void);
 
-struct mali_pp_core *mali_pp_create(const _mali_osk_resource_t * resource, struct mali_group *group);
+struct mali_pp_core *mali_pp_create(const _mali_osk_resource_t *resource, struct mali_group *group, mali_bool is_virtual, u32 bcast_id);
 void mali_pp_delete(struct mali_pp_core *core);
 
 void mali_pp_stop_bus(struct mali_pp_core *core);
 _mali_osk_errcode_t mali_pp_stop_bus_wait(struct mali_pp_core *core);
+void mali_pp_reset_async(struct mali_pp_core *core);
+_mali_osk_errcode_t mali_pp_reset_wait(struct mali_pp_core *core);
 _mali_osk_errcode_t mali_pp_reset(struct mali_pp_core *core);
 _mali_osk_errcode_t mali_pp_hard_reset(struct mali_pp_core *core);
 
 void mali_pp_job_start(struct mali_pp_core *core, struct mali_pp_job *job, u32 sub_job);
 
+/**
+ * @brief Add commands to DMA command buffer to start PP job on core.
+ */
+void mali_pp_job_dma_cmd_prepare(struct mali_pp_core *core, struct mali_pp_job *job, u32 sub_job,
+				 mali_dma_cmd_buf *buf);
+
 u32 mali_pp_core_get_version(struct mali_pp_core *core);
 
-u32 mali_pp_core_get_id(struct mali_pp_core *core);
+MALI_STATIC_INLINE u32 mali_pp_core_get_id(struct mali_pp_core *core)
+{
+	MALI_DEBUG_ASSERT_POINTER(core);
+	return core->core_id;
+}
+
+MALI_STATIC_INLINE u32 mali_pp_core_get_bcast_id(struct mali_pp_core *core)
+{
+	MALI_DEBUG_ASSERT_POINTER(core);
+	return core->bcast_id;
+}
 
-mali_bool mali_pp_core_set_counter_src0(struct mali_pp_core *core, u32 counter);
-mali_bool mali_pp_core_set_counter_src1(struct mali_pp_core *core, u32 counter);
-u32 mali_pp_core_get_counter_src0(struct mali_pp_core *core);
-u32 mali_pp_core_get_counter_src1(struct mali_pp_core *core);
-struct mali_pp_core* mali_pp_get_global_pp_core(u32 index);
+struct mali_pp_core *mali_pp_get_global_pp_core(u32 index);
 u32 mali_pp_get_glob_num_pp_cores(void);
-u32 mali_pp_get_max_num_pp_cores(void);
+
 /* Debug */
 u32 mali_pp_dump_state(struct mali_pp_core *core, char *buf, u32 size);
 
+/**
+ * Put instrumented HW counters from the core(s) to the job object (if enabled)
+ *
+ * parent and child is always the same, except for virtual jobs on Mali-450.
+ * In this case, the counters will be enabled on the virtual core (parent),
+ * but values need to be read from the child cores.
+ *
+ * @param parent The core used to see if the counters was enabled
+ * @param child The core to actually read the values from
+ * @job Job object to update with counter values (if enabled)
+ * @subjob Which subjob the counters are applicable for (core ID for virtual jobs)
+ */
+void mali_pp_update_performance_counters(struct mali_pp_core *parent, struct mali_pp_core *child, struct mali_pp_job *job, u32 subjob);
+
+MALI_STATIC_INLINE const char *mali_pp_get_hw_core_desc(struct mali_pp_core *core)
+{
+	return core->hw_core.description;
+}
+
+/*** Register reading/writing functions ***/
+MALI_STATIC_INLINE u32 mali_pp_get_int_stat(struct mali_pp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_STATUS);
+}
+
+MALI_STATIC_INLINE u32 mali_pp_read_rawstat(struct mali_pp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_RAWSTAT) & MALI200_REG_VAL_IRQ_MASK_USED;
+}
+
+MALI_STATIC_INLINE u32 mali_pp_read_status(struct mali_pp_core *core)
+{
+	return mali_hw_core_register_read(&core->hw_core, MALI200_REG_ADDR_MGMT_STATUS);
+}
+
+MALI_STATIC_INLINE void mali_pp_mask_all_interrupts(struct mali_pp_core *core)
+{
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_NONE);
+}
+
+MALI_STATIC_INLINE void mali_pp_clear_hang_interrupt(struct mali_pp_core *core)
+{
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_CLEAR, MALI200_REG_VAL_IRQ_HANG);
+}
+
+MALI_STATIC_INLINE void mali_pp_enable_interrupts(struct mali_pp_core *core)
+{
+	mali_hw_core_register_write(&core->hw_core, MALI200_REG_ADDR_MGMT_INT_MASK, MALI200_REG_VAL_IRQ_MASK_USED);
+}
+
+MALI_STATIC_INLINE void mali_pp_write_addr_renderer_list(struct mali_pp_core *core,
+		struct mali_pp_job *job, u32 subjob)
+{
+	u32 addr = mali_pp_job_get_addr_frame(job, subjob);
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_FRAME, addr);
+}
+
+
+MALI_STATIC_INLINE void mali_pp_write_addr_stack(struct mali_pp_core *core, struct mali_pp_job *job, u32 subjob)
+{
+	u32 addr = mali_pp_job_get_addr_stack(job, subjob);
+	mali_hw_core_register_write_relaxed(&core->hw_core, MALI200_REG_ADDR_STACK, addr);
+}
+
 #endif /* __MALI_PP_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_pp_job.c b/drivers/gpu/mali/mali/common/mali_pp_job.c
old mode 100644
new mode 100755
index 37bb44a..f000df2
--- a/drivers/gpu/mali/mali/common/mali_pp_job.c
+++ b/drivers/gpu/mali/mali/common/mali_pp_job.c
@@ -1,92 +1,278 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
+#include "mali_pp.h"
 #include "mali_pp_job.h"
+#include "mali_dma.h"
 #include "mali_osk.h"
 #include "mali_osk_list.h"
 #include "mali_kernel_common.h"
 #include "mali_uk_types.h"
+#include "mali_pp_scheduler.h"
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+#include "linux/mali_memory_dma_buf.h"
+#endif
 
-struct mali_pp_job *mali_pp_job_create(struct mali_session_data *session, _mali_uk_pp_start_job_s *args, u32 id)
+static u32 pp_counter_src0 = MALI_HW_CORE_NO_COUNTER;   /**< Performance counter 0, MALI_HW_CORE_NO_COUNTER for disabled */
+static u32 pp_counter_src1 = MALI_HW_CORE_NO_COUNTER;   /**< Performance counter 1, MALI_HW_CORE_NO_COUNTER for disabled */
+static _mali_osk_atomic_t pp_counter_per_sub_job_count; /**< Number of values in the two arrays which is != MALI_HW_CORE_NO_COUNTER */
+static u32 pp_counter_per_sub_job_src0[_MALI_PP_MAX_SUB_JOBS] = { MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER };
+static u32 pp_counter_per_sub_job_src1[_MALI_PP_MAX_SUB_JOBS] = { MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER, MALI_HW_CORE_NO_COUNTER };
+
+void mali_pp_job_initialize(void)
+{
+	_mali_osk_atomic_init(&pp_counter_per_sub_job_count, 0);
+}
+
+void mali_pp_job_terminate(void)
+{
+	_mali_osk_atomic_term(&pp_counter_per_sub_job_count);
+}
+
+struct mali_pp_job *mali_pp_job_create(struct mali_session_data *session, _mali_uk_pp_start_job_s *uargs, u32 id)
 {
 	struct mali_pp_job *job;
+	u32 perf_counter_flag;
 
-	if (args->num_cores > _MALI_PP_MAX_SUB_JOBS)
-	{
-		MALI_PRINT_ERROR(("Mali PP job: Too many sub jobs specified in job object\n"));
-		return NULL;
-	}
+	job = _mali_osk_calloc(1, sizeof(struct mali_pp_job));
+	if (NULL != job) {
+		if (0 != _mali_osk_copy_from_user(&job->uargs, uargs, sizeof(_mali_uk_pp_start_job_s))) {
+			goto fail;
+		}
+
+		if (job->uargs.num_cores > _MALI_PP_MAX_SUB_JOBS) {
+			MALI_PRINT_ERROR(("Mali PP job: Too many sub jobs specified in job object\n"));
+			goto fail;
+		}
+
+		if (!mali_pp_job_use_no_notification(job)) {
+			job->finished_notification = _mali_osk_notification_create(_MALI_NOTIFICATION_PP_FINISHED, sizeof(_mali_uk_pp_job_finished_s));
+			if (NULL == job->finished_notification) goto fail;
+		}
+
+		perf_counter_flag = mali_pp_job_get_perf_counter_flag(job);
+
+		/* case when no counters came from user space
+		 * so pass the debugfs / DS-5 provided global ones to the job object */
+		if (!((perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE) ||
+		      (perf_counter_flag & _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE))) {
+			u32 sub_job_count = _mali_osk_atomic_read(&pp_counter_per_sub_job_count);
+
+			/* These counters apply for all virtual jobs, and where no per sub job counter is specified */
+			job->uargs.perf_counter_src0 = pp_counter_src0;
+			job->uargs.perf_counter_src1 = pp_counter_src1;
+
+			/* We only copy the per sub job array if it is enabled with at least one counter */
+			if (0 < sub_job_count) {
+				job->perf_counter_per_sub_job_count = sub_job_count;
+				_mali_osk_memcpy(job->perf_counter_per_sub_job_src0, pp_counter_per_sub_job_src0, sizeof(pp_counter_per_sub_job_src0));
+				_mali_osk_memcpy(job->perf_counter_per_sub_job_src1, pp_counter_per_sub_job_src1, sizeof(pp_counter_per_sub_job_src1));
+			}
+		}
 
-	job = _mali_osk_malloc(sizeof(struct mali_pp_job));
-	if (NULL != job)
-	{
-		u32 i;
 		_mali_osk_list_init(&job->list);
 		job->session = session;
+		_mali_osk_list_init(&job->session_list);
 		job->id = id;
-		job->user_id = args->user_job_ptr;
-		_mali_osk_memcpy(job->frame_registers, args->frame_registers, sizeof(job->frame_registers));
-		_mali_osk_memcpy(job->frame_registers_addr_frame, args->frame_registers_addr_frame, sizeof(job->frame_registers_addr_frame));
-		_mali_osk_memcpy(job->frame_registers_addr_stack, args->frame_registers_addr_stack, sizeof(job->frame_registers_addr_stack));
-
-		/* Only copy write back registers for the units that are enabled */
-		job->wb0_registers[0] = 0;
-		job->wb1_registers[0] = 0;
-		job->wb2_registers[0] = 0;
-		if (args->wb0_registers[0]) /* M200_WB0_REG_SOURCE_SELECT register */
-		{
-			_mali_osk_memcpy(job->wb0_registers, args->wb0_registers, sizeof(job->wb0_registers));
-		}
-		if (args->wb1_registers[0]) /* M200_WB1_REG_SOURCE_SELECT register */
-		{
-			_mali_osk_memcpy(job->wb1_registers, args->wb1_registers, sizeof(job->wb1_registers));
+
+		job->sub_jobs_num = job->uargs.num_cores ? job->uargs.num_cores : 1;
+		job->pid = _mali_osk_get_pid();
+		job->tid = _mali_osk_get_tid();
+
+		job->num_memory_cookies = job->uargs.num_memory_cookies;
+		if (job->num_memory_cookies > 0) {
+			u32 size;
+
+			if (job->uargs.num_memory_cookies > session->descriptor_mapping->current_nr_mappings) {
+				MALI_PRINT_ERROR(("Mali PP job: Too many memory cookies specified in job object\n"));
+				goto fail;
+			}
+
+			size = sizeof(*job->uargs.memory_cookies) * job->num_memory_cookies;
+
+			job->memory_cookies = _mali_osk_malloc(size);
+			if (NULL == job->memory_cookies) {
+				MALI_PRINT_ERROR(("Mali PP job: Failed to allocate %d bytes of memory cookies!\n", size));
+				goto fail;
+			}
+
+			if (0 != _mali_osk_copy_from_user(job->memory_cookies, job->uargs.memory_cookies, size)) {
+				MALI_PRINT_ERROR(("Mali PP job: Failed to copy %d bytes of memory cookies from user!\n", size));
+				goto fail;
+			}
+
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+			job->num_dma_bufs = job->num_memory_cookies;
+			job->dma_bufs = _mali_osk_calloc(job->num_dma_bufs, sizeof(struct mali_dma_buf_attachment *));
+			if (NULL == job->dma_bufs) {
+				MALI_PRINT_ERROR(("Mali PP job: Failed to allocate dma_bufs array!\n"));
+				goto fail;
+			}
+#endif
 		}
-		if (args->wb2_registers[0]) /* M200_WB2_REG_SOURCE_SELECT register */
-		{
-			_mali_osk_memcpy(job->wb2_registers, args->wb2_registers, sizeof(job->wb2_registers));
+
+		/* Prepare DMA command buffer to start job, if it is virtual. */
+		if (mali_pp_job_is_virtual_group_job(job)) {
+			struct mali_pp_core *core;
+			_mali_osk_errcode_t err =  mali_dma_get_cmd_buf(&job->dma_cmd_buf);
+
+			if (_MALI_OSK_ERR_OK != err) {
+				MALI_PRINT_ERROR(("Mali PP job: Failed to allocate DMA command buffer\n"));
+				goto fail;
+			}
+
+			core = mali_pp_scheduler_get_virtual_pp();
+			MALI_DEBUG_ASSERT_POINTER(core);
+
+			mali_pp_job_dma_cmd_prepare(core, job, 0, &job->dma_cmd_buf);
 		}
 
-		job->perf_counter_flag = args->perf_counter_flag;
-		job->perf_counter_src0 = args->perf_counter_src0;
-		job->perf_counter_src1 = args->perf_counter_src1;
-		for (i = 0; i < args->num_cores; i++)
-		{
-			job->perf_counter_value0[i] = 0;
-			job->perf_counter_value1[i] = 0;
+		if (_MALI_OSK_ERR_OK != mali_pp_job_check(job)) {
+			/* Not a valid job. */
+			goto fail;
 		}
-		job->sub_job_count = args->num_cores;
-		job->sub_jobs_started = 0;
-		job->sub_jobs_completed = 0;
-		job->sub_job_errors = 0;
 
-		job->pid = _mali_osk_get_pid();
-		job->tid = _mali_osk_get_tid();
-		job->frame_builder_id = args->frame_builder_id;
-		job->flush_id = args->flush_id;
+		mali_timeline_tracker_init(&job->tracker, MALI_TIMELINE_TRACKER_PP, NULL, job);
+		mali_timeline_fence_copy_uk_fence(&(job->tracker.fence), &(job->uargs.fence));
 
 		return job;
 	}
 
+fail:
+	if (NULL != job) {
+		mali_pp_job_delete(job);
+	}
+
 	return NULL;
 }
 
 void mali_pp_job_delete(struct mali_pp_job *job)
 {
+	mali_dma_put_cmd_buf(&job->dma_cmd_buf);
+	if (NULL != job->finished_notification) {
+		_mali_osk_notification_delete(job->finished_notification);
+	}
+
+	_mali_osk_free(job->memory_cookies);
+
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+	/* Unmap buffers attached to job */
+	if (0 < job->num_dma_bufs) {
+		mali_dma_buf_unmap_job(job);
+	}
+
+	_mali_osk_free(job->dma_bufs);
+#endif /* CONFIG_DMA_SHARED_BUFFER */
+
 	_mali_osk_free(job);
 }
 
-_mali_osk_errcode_t mali_pp_job_check(struct mali_pp_job *job)
+u32 mali_pp_job_get_perf_counter_src0(struct mali_pp_job *job, u32 sub_job)
+{
+	/* Virtual jobs always use the global job counter (or if there are per sub job counters at all) */
+	if (mali_pp_job_is_virtual_group_job(job) || 0 == job->perf_counter_per_sub_job_count) {
+		return job->uargs.perf_counter_src0;
+	}
+
+	/* Use per sub job counter if enabled... */
+	if (MALI_HW_CORE_NO_COUNTER != job->perf_counter_per_sub_job_src0[sub_job]) {
+		return job->perf_counter_per_sub_job_src0[sub_job];
+	}
+
+	/* ...else default to global job counter */
+	return job->uargs.perf_counter_src0;
+}
+
+u32 mali_pp_job_get_perf_counter_src1(struct mali_pp_job *job, u32 sub_job)
+{
+	/* Virtual jobs always use the global job counter (or if there are per sub job counters at all) */
+	if (mali_pp_job_is_virtual_group_job(job) || 0 == job->perf_counter_per_sub_job_count) {
+		/* Virtual jobs always use the global job counter */
+		return job->uargs.perf_counter_src1;
+	}
+
+	/* Use per sub job counter if enabled... */
+	if (MALI_HW_CORE_NO_COUNTER != job->perf_counter_per_sub_job_src1[sub_job]) {
+		return job->perf_counter_per_sub_job_src1[sub_job];
+	}
+
+	/* ...else default to global job counter */
+	return job->uargs.perf_counter_src1;
+}
+
+void mali_pp_job_set_pp_counter_global_src0(u32 counter)
+{
+	pp_counter_src0 = counter;
+}
+
+void mali_pp_job_set_pp_counter_global_src1(u32 counter)
+{
+	pp_counter_src1 = counter;
+}
+
+void mali_pp_job_set_pp_counter_sub_job_src0(u32 sub_job, u32 counter)
+{
+	MALI_DEBUG_ASSERT(sub_job < _MALI_PP_MAX_SUB_JOBS);
+
+	if (MALI_HW_CORE_NO_COUNTER == pp_counter_per_sub_job_src0[sub_job]) {
+		/* increment count since existing counter was disabled */
+		_mali_osk_atomic_inc(&pp_counter_per_sub_job_count);
+	}
+
+	if (MALI_HW_CORE_NO_COUNTER == counter) {
+		/* decrement count since new counter is disabled */
+		_mali_osk_atomic_dec(&pp_counter_per_sub_job_count);
+	}
+
+	/* PS: A change from MALI_HW_CORE_NO_COUNTER to MALI_HW_CORE_NO_COUNTER will inc and dec, result will be 0 change */
+
+	pp_counter_per_sub_job_src0[sub_job] = counter;
+}
+
+void mali_pp_job_set_pp_counter_sub_job_src1(u32 sub_job, u32 counter)
 {
-	if ((0 == job->frame_registers[0]) || (0 == job->frame_registers[1]))
-	{
-		return _MALI_OSK_ERR_FAULT;
+	MALI_DEBUG_ASSERT(sub_job < _MALI_PP_MAX_SUB_JOBS);
+
+	if (MALI_HW_CORE_NO_COUNTER == pp_counter_per_sub_job_src1[sub_job]) {
+		/* increment count since existing counter was disabled */
+		_mali_osk_atomic_inc(&pp_counter_per_sub_job_count);
 	}
-	return _MALI_OSK_ERR_OK;
+
+	if (MALI_HW_CORE_NO_COUNTER == counter) {
+		/* decrement count since new counter is disabled */
+		_mali_osk_atomic_dec(&pp_counter_per_sub_job_count);
+	}
+
+	/* PS: A change from MALI_HW_CORE_NO_COUNTER to MALI_HW_CORE_NO_COUNTER will inc and dec, result will be 0 change */
+
+	pp_counter_per_sub_job_src1[sub_job] = counter;
+}
+
+u32 mali_pp_job_get_pp_counter_global_src0(void)
+{
+	return pp_counter_src0;
+}
+
+u32 mali_pp_job_get_pp_counter_global_src1(void)
+{
+	return pp_counter_src1;
+}
+
+u32 mali_pp_job_get_pp_counter_sub_job_src0(u32 sub_job)
+{
+	MALI_DEBUG_ASSERT(sub_job < _MALI_PP_MAX_SUB_JOBS);
+	return pp_counter_per_sub_job_src0[sub_job];
+}
+
+u32 mali_pp_job_get_pp_counter_sub_job_src1(u32 sub_job)
+{
+	MALI_DEBUG_ASSERT(sub_job < _MALI_PP_MAX_SUB_JOBS);
+	return pp_counter_per_sub_job_src1[sub_job];
 }
diff --git a/drivers/gpu/mali/mali/common/mali_pp_job.h b/drivers/gpu/mali/mali/common/mali_pp_job.h
old mode 100644
new mode 100755
index 2a87c0e..978eadd
--- a/drivers/gpu/mali/mali/common/mali_pp_job.h
+++ b/drivers/gpu/mali/mali/common/mali_pp_job.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,82 +17,139 @@
 #include "mali_session.h"
 #include "mali_kernel_common.h"
 #include "regs/mali_200_regs.h"
+#include "mali_kernel_core.h"
+#include "mali_dma.h"
+#include "mali_dlbu.h"
+#include "mali_timeline.h"
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+#include "linux/mali_memory_dma_buf.h"
+#endif
 
 /**
- * The structure represends a PP job, including all sub-jobs
- * (This struct unfortunatly needs to be public because of how the _mali_osk_list_*
+ * The structure represents a PP job, including all sub-jobs
+ * (This struct unfortunately needs to be public because of how the _mali_osk_list_*
  * mechanism works)
  */
-struct mali_pp_job
-{
+struct mali_pp_job {
 	_mali_osk_list_t list;                             /**< Used to link jobs together in the scheduler queue */
 	struct mali_session_data *session;                 /**< Session which submitted this job */
-	u32 id;                                            /**< identifier for this job in kernel space (sequencial numbering) */
-	u32 user_id;                                       /**< identifier for the job in user space */
-	u32 frame_registers[_MALI_PP_MAX_FRAME_REGISTERS]; /**< core specific registers associated with this job, see ARM DDI0415A */
-    u32 frame_registers_addr_frame[_MALI_PP_MAX_SUB_JOBS - 1]; /**< ADDR_FRAME registers for sub job 1-7 */
-    u32 frame_registers_addr_stack[_MALI_PP_MAX_SUB_JOBS - 1]; /**< ADDR_STACK registers for sub job 1-7 */
-	u32 wb0_registers[_MALI_PP_MAX_WB_REGISTERS];      /**< Write back unit 0 registers */
-	u32 wb1_registers[_MALI_PP_MAX_WB_REGISTERS];      /**< Write back unit 1 registers */
-	u32 wb2_registers[_MALI_PP_MAX_WB_REGISTERS];      /**< Write back unit 2 registers */
-	u32 perf_counter_flag;                             /**< bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
-	u32 perf_counter_src0;                             /**< Source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
-	u32 perf_counter_src1;                             /**< Source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
+	_mali_osk_list_t session_list;                     /**< Used to link jobs together in the session job list */
+	_mali_osk_list_t session_fb_lookup_list;           /**< Used to link jobs together from the same frame builder in the session */
+	_mali_uk_pp_start_job_s uargs;                     /**< Arguments from user space */
+	mali_dma_cmd_buf dma_cmd_buf;                      /**< Command buffer for starting job using Mali-450 DMA unit */
+	u32 id;                                            /**< Identifier for this job in kernel space (sequential numbering) */
+	u32 cache_order;                                   /**< Cache order used for L2 cache flushing (sequential numbering) */
 	u32 perf_counter_value0[_MALI_PP_MAX_SUB_JOBS];    /**< Value of performance counter 0 (to be returned to user space), one for each sub job */
-	u32 perf_counter_value1[_MALI_PP_MAX_SUB_JOBS];     /**< Value of performance counter 1 (to be returned to user space), one for each sub job */
-	u32 sub_job_count;                                 /**< Total number of sub-jobs in this superjob */
+	u32 perf_counter_value1[_MALI_PP_MAX_SUB_JOBS];    /**< Value of performance counter 1 (to be returned to user space), one for each sub job */
+	u32 sub_jobs_num;                                  /**< Number of subjobs; set to 1 for Mali-450 if DLBU is used, otherwise equals number of PP cores */
 	u32 sub_jobs_started;                              /**< Total number of sub-jobs started (always started in ascending order) */
 	u32 sub_jobs_completed;                            /**< Number of completed sub-jobs in this superjob */
 	u32 sub_job_errors;                                /**< Bitfield with errors (errors for each single sub-job is or'ed together) */
 	u32 pid;                                           /**< Process ID of submitting process */
 	u32 tid;                                           /**< Thread ID of submitting thread */
-	u32 frame_builder_id;                              /**< id of the originating frame builder */
-	u32 flush_id;                                      /**< flush id within the originating frame builder */
+	_mali_osk_notification_t *finished_notification;   /**< Notification sent back to userspace on job complete */
+	u32 num_memory_cookies;                            /**< Number of memory cookies attached to job */
+	u32 *memory_cookies;                               /**< Memory cookies attached to job */
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+	struct mali_dma_buf_attachment **dma_bufs;         /**< Array of DMA-bufs used by job */
+	u32 num_dma_bufs;                                  /**< Number of DMA-bufs used by job */
+#endif
+	struct mali_timeline_tracker tracker;              /**< Timeline tracker for this job */
+	u32 perf_counter_per_sub_job_count;                /**< Number of values in the two arrays which is != MALI_HW_CORE_NO_COUNTER */
+	u32 perf_counter_per_sub_job_src0[_MALI_PP_MAX_SUB_JOBS]; /**< Per sub job counters src0 */
+	u32 perf_counter_per_sub_job_src1[_MALI_PP_MAX_SUB_JOBS]; /**< Per sub job counters src1 */
 };
 
-struct mali_pp_job *mali_pp_job_create(struct mali_session_data *session, _mali_uk_pp_start_job_s *args, u32 id);
+void mali_pp_job_initialize(void);
+void mali_pp_job_terminate(void);
+
+struct mali_pp_job *mali_pp_job_create(struct mali_session_data *session, _mali_uk_pp_start_job_s *uargs, u32 id);
 void mali_pp_job_delete(struct mali_pp_job *job);
 
-_mali_osk_errcode_t mali_pp_job_check(struct mali_pp_job *job);
+u32 mali_pp_job_get_perf_counter_src0(struct mali_pp_job *job, u32 sub_job);
+u32 mali_pp_job_get_perf_counter_src1(struct mali_pp_job *job, u32 sub_job);
+
+void mali_pp_job_set_pp_counter_global_src0(u32 counter);
+void mali_pp_job_set_pp_counter_global_src1(u32 counter);
+void mali_pp_job_set_pp_counter_sub_job_src0(u32 sub_job, u32 counter);
+void mali_pp_job_set_pp_counter_sub_job_src1(u32 sub_job, u32 counter);
 
-/******************************************************
- * simple utility functions for dealing with pp jobs:
- *****************************************************/
+u32 mali_pp_job_get_pp_counter_global_src0(void);
+u32 mali_pp_job_get_pp_counter_global_src1(void);
+u32 mali_pp_job_get_pp_counter_sub_job_src0(u32 sub_job);
+u32 mali_pp_job_get_pp_counter_sub_job_src1(u32 sub_job);
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_id(struct mali_pp_job *job)
 {
 	return (NULL == job) ? 0 : job->id;
 }
 
+MALI_STATIC_INLINE u32 mali_pp_job_get_cache_order(struct mali_pp_job *job)
+{
+	return (NULL == job) ? 0 : job->cache_order;
+}
+
 MALI_STATIC_INLINE u32 mali_pp_job_get_user_id(struct mali_pp_job *job)
 {
-	return job->user_id;
+	return job->uargs.user_job_ptr;
 }
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_frame_builder_id(struct mali_pp_job *job)
 {
-	return job->frame_builder_id;
+	return job->uargs.frame_builder_id;
 }
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_flush_id(struct mali_pp_job *job)
 {
-	return job->flush_id;
+	return job->uargs.flush_id;
 }
 
-MALI_STATIC_INLINE u32* mali_pp_job_get_frame_registers(struct mali_pp_job *job)
+MALI_STATIC_INLINE u32 mali_pp_job_get_pid(struct mali_pp_job *job)
 {
-	return job->frame_registers;
+	return job->pid;
 }
 
-MALI_STATIC_INLINE u32 mali_pp_job_get_addr_frame(struct mali_pp_job *job, u32 sub_job)
+MALI_STATIC_INLINE u32 mali_pp_job_get_tid(struct mali_pp_job *job)
+{
+	return job->tid;
+}
+
+MALI_STATIC_INLINE u32 *mali_pp_job_get_frame_registers(struct mali_pp_job *job)
 {
-	if (sub_job == 0)
-	{
-		return job->frame_registers[MALI200_REG_ADDR_FRAME / sizeof(u32)];
+	return job->uargs.frame_registers;
+}
+
+MALI_STATIC_INLINE u32 *mali_pp_job_get_dlbu_registers(struct mali_pp_job *job)
+{
+	return job->uargs.dlbu_registers;
+}
+
+MALI_STATIC_INLINE mali_bool mali_pp_job_is_virtual_group_job(struct mali_pp_job *job)
+{
+	if (mali_is_mali450()) {
+		return 1 != job->uargs.num_cores;
 	}
-	else if (sub_job < _MALI_PP_MAX_SUB_JOBS)
-	{
-		return job->frame_registers_addr_frame[sub_job - 1];
+
+	return MALI_FALSE;
+}
+
+MALI_STATIC_INLINE mali_bool mali_pp_job_is_with_dlbu(struct mali_pp_job *job)
+{
+#if defined(CONFIG_MALI450)
+	return 0 == job->uargs.num_cores;
+#else
+	return MALI_FALSE;
+#endif
+}
+
+MALI_STATIC_INLINE u32 mali_pp_job_get_addr_frame(struct mali_pp_job *job, u32 sub_job)
+{
+	if (mali_pp_job_is_with_dlbu(job)) {
+		return MALI_DLBU_VIRT_ADDR;
+	} else if (0 == sub_job) {
+		return job->uargs.frame_registers[MALI200_REG_ADDR_FRAME / sizeof(u32)];
+	} else if (sub_job < _MALI_PP_MAX_SUB_JOBS) {
+		return job->uargs.frame_registers_addr_frame[sub_job - 1];
 	}
 
 	return 0;
@@ -100,46 +157,66 @@ MALI_STATIC_INLINE u32 mali_pp_job_get_addr_frame(struct mali_pp_job *job, u32 s
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_addr_stack(struct mali_pp_job *job, u32 sub_job)
 {
-	if (sub_job == 0)
-	{
-		return job->frame_registers[MALI200_REG_ADDR_STACK / sizeof(u32)];
-	}
-	else if (sub_job < _MALI_PP_MAX_SUB_JOBS)
-	{
-		return job->frame_registers_addr_stack[sub_job - 1];
+	if (0 == sub_job) {
+		return job->uargs.frame_registers[MALI200_REG_ADDR_STACK / sizeof(u32)];
+	} else if (sub_job < _MALI_PP_MAX_SUB_JOBS) {
+		return job->uargs.frame_registers_addr_stack[sub_job - 1];
 	}
 
 	return 0;
 }
 
-MALI_STATIC_INLINE u32* mali_pp_job_get_wb0_registers(struct mali_pp_job *job)
+MALI_STATIC_INLINE u32 *mali_pp_job_get_wb0_registers(struct mali_pp_job *job)
 {
-	return job->wb0_registers;
+	return job->uargs.wb0_registers;
 }
 
-MALI_STATIC_INLINE u32* mali_pp_job_get_wb1_registers(struct mali_pp_job *job)
+MALI_STATIC_INLINE u32 *mali_pp_job_get_wb1_registers(struct mali_pp_job *job)
 {
-	return job->wb1_registers;
+	return job->uargs.wb1_registers;
 }
 
-MALI_STATIC_INLINE u32* mali_pp_job_get_wb2_registers(struct mali_pp_job *job)
+MALI_STATIC_INLINE u32 *mali_pp_job_get_wb2_registers(struct mali_pp_job *job)
 {
-	return job->wb2_registers;
+	return job->uargs.wb2_registers;
 }
 
 MALI_STATIC_INLINE void mali_pp_job_disable_wb0(struct mali_pp_job *job)
 {
-	job->wb0_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
+	job->uargs.wb0_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
 }
 
 MALI_STATIC_INLINE void mali_pp_job_disable_wb1(struct mali_pp_job *job)
 {
-	job->wb1_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
+	job->uargs.wb1_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
 }
 
 MALI_STATIC_INLINE void mali_pp_job_disable_wb2(struct mali_pp_job *job)
 {
-	job->wb2_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
+	job->uargs.wb2_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] = 0;
+}
+
+MALI_STATIC_INLINE mali_bool mali_pp_job_all_writeback_unit_disabled(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	if (job->uargs.wb0_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] ||
+	    job->uargs.wb1_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT] ||
+	    job->uargs.wb2_registers[MALI200_REG_ADDR_WB_SOURCE_SELECT]
+	   ) {
+		/* At least one output unit active */
+		return MALI_FALSE;
+	}
+
+	/* All outputs are disabled - we can abort the job */
+	return MALI_TRUE;
+}
+
+MALI_STATIC_INLINE u32 mali_pp_job_get_fb_lookup_id(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	return MALI_PP_JOB_FB_LOOKUP_LIST_MASK & job->uargs.frame_builder_id;
 }
 
 MALI_STATIC_INLINE struct mali_session_data *mali_pp_job_get_session(struct mali_pp_job *job)
@@ -149,37 +226,29 @@ MALI_STATIC_INLINE struct mali_session_data *mali_pp_job_get_session(struct mali
 
 MALI_STATIC_INLINE mali_bool mali_pp_job_has_unstarted_sub_jobs(struct mali_pp_job *job)
 {
-	return (job->sub_jobs_started < job->sub_job_count) ? MALI_TRUE : MALI_FALSE;
+	return (job->sub_jobs_started < job->sub_jobs_num) ? MALI_TRUE : MALI_FALSE;
 }
 
 /* Function used when we are terminating a session with jobs. Return TRUE if it has a rendering job.
-   Makes sure that no new subjobs is started. */
-MALI_STATIC_INLINE mali_bool mali_pp_job_is_currently_rendering_and_if_so_abort_new_starts(struct mali_pp_job *job)
-{
-	/* All can not be started, since then it would not be in the job queue */
-	MALI_DEBUG_ASSERT( job->sub_jobs_started != job->sub_job_count );
-
-	/* If at least one job is started */
-	if (  (job->sub_jobs_started > 0)  )
-	{
-		/* If at least one job is currently being rendered, and thus assigned to a group and core */
-		if (job->sub_jobs_started > job->sub_jobs_completed )
-		{
-			u32 jobs_remaining = job->sub_job_count - job->sub_jobs_started;
-			job->sub_jobs_started   += jobs_remaining;
-			job->sub_jobs_completed += jobs_remaining;
-			job->sub_job_errors     += jobs_remaining;
-			/* Returning TRUE indicating that we can not delete this job which is being redered */
-			return MALI_TRUE;
-		}
-	}
-	/* The job is not being rendered to at the moment and can then safely be deleted */
-	return MALI_FALSE;
+   Makes sure that no new subjobs are started. */
+MALI_STATIC_INLINE void mali_pp_job_mark_unstarted_failed(struct mali_pp_job *job)
+{
+	u32 jobs_remaining = job->sub_jobs_num - job->sub_jobs_started;
+	job->sub_jobs_started   += jobs_remaining;
+	job->sub_jobs_completed += jobs_remaining;
+	job->sub_job_errors     += jobs_remaining;
+}
+
+MALI_STATIC_INLINE void mali_pp_job_mark_unstarted_success(struct mali_pp_job *job)
+{
+	u32 jobs_remaining = job->sub_jobs_num - job->sub_jobs_started;
+	job->sub_jobs_started   += jobs_remaining;
+	job->sub_jobs_completed += jobs_remaining;
 }
 
 MALI_STATIC_INLINE mali_bool mali_pp_job_is_complete(struct mali_pp_job *job)
 {
-	return (job->sub_job_count == job->sub_jobs_completed) ? MALI_TRUE : MALI_FALSE;
+	return (job->sub_jobs_num == job->sub_jobs_completed) ? MALI_TRUE : MALI_FALSE;
 }
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_first_unstarted_sub_job(struct mali_pp_job *job)
@@ -189,48 +258,56 @@ MALI_STATIC_INLINE u32 mali_pp_job_get_first_unstarted_sub_job(struct mali_pp_jo
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_sub_job_count(struct mali_pp_job *job)
 {
-	return job->sub_job_count;
+	return job->sub_jobs_num;
+}
+
+MALI_STATIC_INLINE mali_bool mali_pp_job_needs_dma_buf_mapping(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT(job);
+
+	if (0 != job->num_memory_cookies) {
+		return MALI_TRUE;
+	}
+
+	return MALI_FALSE;
 }
 
 MALI_STATIC_INLINE void mali_pp_job_mark_sub_job_started(struct mali_pp_job *job, u32 sub_job)
 {
+	MALI_DEBUG_ASSERT_POINTER(job);
+
 	/* Assert that we are marking the "first unstarted sub job" as started */
 	MALI_DEBUG_ASSERT(job->sub_jobs_started == sub_job);
+
 	job->sub_jobs_started++;
 }
 
 MALI_STATIC_INLINE void mali_pp_job_mark_sub_job_completed(struct mali_pp_job *job, mali_bool success)
 {
 	job->sub_jobs_completed++;
-	if ( MALI_FALSE == success )
-	{
+	if (MALI_FALSE == success) {
 		job->sub_job_errors++;
 	}
 }
 
 MALI_STATIC_INLINE mali_bool mali_pp_job_was_success(struct mali_pp_job *job)
 {
-	if ( 0 == job->sub_job_errors )
-	{
+	if (0 == job->sub_job_errors) {
 		return MALI_TRUE;
 	}
 	return MALI_FALSE;
 }
 
-MALI_STATIC_INLINE u32 mali_pp_job_get_perf_counter_flag(struct mali_pp_job *job)
+MALI_STATIC_INLINE mali_bool mali_pp_job_use_no_notification(struct mali_pp_job *job)
 {
-	return job->perf_counter_flag;
+	return job->uargs.flags & _MALI_PP_JOB_FLAG_NO_NOTIFICATION ? MALI_TRUE : MALI_FALSE;
 }
 
-MALI_STATIC_INLINE u32 mali_pp_job_get_perf_counter_src0(struct mali_pp_job *job)
+MALI_STATIC_INLINE u32 mali_pp_job_get_perf_counter_flag(struct mali_pp_job *job)
 {
-	return job->perf_counter_src0;
+	return job->uargs.perf_counter_flag;
 }
 
-MALI_STATIC_INLINE u32 mali_pp_job_get_perf_counter_src1(struct mali_pp_job *job)
-{
-	return job->perf_counter_src1;
-}
 
 MALI_STATIC_INLINE u32 mali_pp_job_get_perf_counter_value0(struct mali_pp_job *job, u32 sub_job)
 {
@@ -252,4 +329,65 @@ MALI_STATIC_INLINE void mali_pp_job_set_perf_counter_value1(struct mali_pp_job *
 	job->perf_counter_value1[sub_job] = value;
 }
 
+MALI_STATIC_INLINE _mali_osk_errcode_t mali_pp_job_check(struct mali_pp_job *job)
+{
+	if (mali_pp_job_is_with_dlbu(job) && job->sub_jobs_num != 1) {
+		return _MALI_OSK_ERR_FAULT;
+	}
+	return _MALI_OSK_ERR_OK;
+}
+
+/**
+ * Returns MALI_TRUE if first job should be started after second job.
+ *
+ * @param first First job.
+ * @param second Second job.
+ * @return MALI_TRUE if first job should be started after second job, MALI_FALSE if not.
+ */
+MALI_STATIC_INLINE mali_bool mali_pp_job_should_start_after(struct mali_pp_job *first, struct mali_pp_job *second)
+{
+	MALI_DEBUG_ASSERT_POINTER(first);
+	MALI_DEBUG_ASSERT_POINTER(second);
+
+	/* First job should be started after second job if second job is in progress. */
+	if (0 < second->sub_jobs_started) {
+		return MALI_TRUE;
+	}
+
+	/* First job should be started after second job if first job has a higher job id.  A span is
+	   used to handle job id wrapping. */
+	if ((mali_pp_job_get_id(first) - mali_pp_job_get_id(second)) < MALI_SCHEDULER_JOB_ID_SPAN) {
+		return MALI_TRUE;
+	}
+
+	/* Second job should be started after first job. */
+	return MALI_FALSE;
+}
+
+/**
+ * Returns MALI_TRUE if this job has more than two sub jobs and all sub jobs are unstarted.
+ *
+ * @param job Job to check.
+ * @return MALI_TRUE if job has more than two sub jobs and all sub jobs are unstarted, MALI_FALSE if not.
+ */
+MALI_STATIC_INLINE mali_bool mali_pp_job_is_large_and_unstarted(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT(!mali_pp_job_is_virtual_group_job(job));
+
+	return (0 == job->sub_jobs_started && 2 < job->sub_jobs_num);
+}
+
+/**
+ * Get PP job's Timeline tracker.
+ *
+ * @param job PP job.
+ * @return Pointer to Timeline tracker for the job.
+ */
+MALI_STATIC_INLINE struct mali_timeline_tracker *mali_pp_job_get_tracker(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
+	return &(job->tracker);
+}
+
 #endif /* __MALI_PP_JOB_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_pp_scheduler.c b/drivers/gpu/mali/mali/common/mali_pp_scheduler.c
old mode 100644
new mode 100755
index 8245d1a..993f6d8
--- a/drivers/gpu/mali/mali/common/mali_pp_scheduler.c
+++ b/drivers/gpu/mali/mali/common/mali_pp_scheduler.c
@@ -1,542 +1,2127 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
 #include "mali_pp_scheduler.h"
 #include "mali_kernel_common.h"
+#include "mali_kernel_core.h"
 #include "mali_osk.h"
 #include "mali_osk_list.h"
 #include "mali_scheduler.h"
 #include "mali_pp.h"
 #include "mali_pp_job.h"
 #include "mali_group.h"
-#include "mali_cluster.h"
+#include "mali_pm.h"
+#include "mali_timeline.h"
+#include "mali_osk_profiling.h"
+#include "mali_kernel_utilization.h"
+#include "mali_session.h"
+#include "mali_pm_domain.h"
+#include "linux/mali/mali_utgard.h"
+
+#if defined(CONFIG_DMA_SHARED_BUFFER)
+#include "mali_memory_dma_buf.h"
+#endif
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+#include <linux/sched.h>
+#include <trace/events/gpu.h>
+#endif
 
-/* Maximum of 8 PP cores (a group can only have maximum of 1 PP core) */
-#define MALI_MAX_NUMBER_OF_PP_GROUPS 8
+/* Queue type used for physical and virtual job queues. */
+struct mali_pp_scheduler_job_queue {
+	_MALI_OSK_LIST_HEAD(normal_pri); /* List of jobs with some unscheduled work. */
+	_MALI_OSK_LIST_HEAD(high_pri);   /* List of high priority jobs with some unscheduled work. */
+	u32 depth;                       /* Depth of combined queues. */
+};
 
-static mali_bool mali_pp_scheduler_is_suspended(void);
+/* If dma_buf with map on demand is used, we defer job deletion and job queue if in atomic context,
+ * since both might sleep. */
+#if defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH)
+#define MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE 1
+#define MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE 1
+#endif /* !defined(CONFIG_DMA_SHARED_BUFFER) && !defined(CONFIG_MALI_DMA_BUF_MAP_ON_ATTACH) */
 
-enum mali_pp_slot_state
-{
-	MALI_PP_SLOT_STATE_IDLE,
-	MALI_PP_SLOT_STATE_WORKING,
-};
+static void mali_pp_scheduler_job_queued(void);
+static void mali_pp_scheduler_job_completed(void);
 
-/* A render slot is an entity which jobs can be scheduled onto */
-struct mali_pp_slot
-{
-	struct mali_group *group;
-	/*
-	 * We keep track of the state here as well as in the group object
-	 * so we don't need to take the group lock so often (and also avoid clutter with the working lock)
-	 */
-	enum mali_pp_slot_state state;
-};
+/* Maximum of 8 PP cores (a group can only have maximum of 1 PP core) */
+#define MALI_MAX_NUMBER_OF_PP_GROUPS 9
+
+static mali_bool mali_pp_scheduler_is_suspended(void *data);
 
 static u32 pp_version = 0;
-static _MALI_OSK_LIST_HEAD(job_queue);                          /* List of jobs with some unscheduled work */
-static struct mali_pp_slot slots[MALI_MAX_NUMBER_OF_PP_GROUPS];
-static u32 num_slots = 0;
-static u32 num_slots_idle = 0;
 
-/* Variables to allow safe pausing of the scheduler */
-static _mali_osk_wait_queue_t *pp_scheduler_working_wait_queue = NULL;
-static u32 pause_count = 0;
+/* Physical job queue */
+static struct mali_pp_scheduler_job_queue job_queue;
 
-static _mali_osk_lock_t *pp_scheduler_lock = NULL;
-/* Contains tid of thread that locked the scheduler or 0, if not locked */
-MALI_DEBUG_CODE(static u32 pp_scheduler_lock_owner = 0);
+/* Physical groups */
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(group_list_working);     /* List of physical groups with working jobs on the pp core */
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(group_list_idle);        /* List of physical groups with idle jobs on the pp core */
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(group_list_disabled);    /* List of disabled physical groups */
 
-_mali_osk_errcode_t mali_pp_scheduler_initialize(void)
-{
-	u32 i;
+/* Virtual job queue (Mali-450 only) */
+static struct mali_pp_scheduler_job_queue virtual_group_job_queue;
 
-	_MALI_OSK_INIT_LIST_HEAD(&job_queue);
+/**
+ * Add job to scheduler queue.
+ *
+ * @param job Job to queue.
+ * @return Schedule mask.
+ */
+static mali_scheduler_mask mali_pp_scheduler_queue_job(struct mali_pp_job *job);
+
+/* Virtual group (Mali-450 only) */
+static struct mali_group *virtual_group = NULL;                 /* Virtual group (if any) */
+static enum {
+	VIRTUAL_GROUP_IDLE,
+	VIRTUAL_GROUP_WORKING,
+	VIRTUAL_GROUP_DISABLED,
+}
+virtual_group_state = VIRTUAL_GROUP_IDLE;            /* Flag which indicates whether the virtual group is working or idle */
 
-	pp_scheduler_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED |_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_SCHEDULER);
-	if (NULL == pp_scheduler_lock)
-	{
-		return _MALI_OSK_ERR_NOMEM;
-	}
+/* Number of physical cores */
+static u32 num_cores = 0;
 
-	pp_scheduler_working_wait_queue = _mali_osk_wait_queue_init();
-	if (NULL == pp_scheduler_working_wait_queue)
-	{
-		_mali_osk_lock_term(pp_scheduler_lock);
-		return _MALI_OSK_ERR_NOMEM;
-	}
+/* Number of physical cores which are enabled */
+static u32 enabled_cores = 0;
 
-	/* Find all the available PP cores */
-	for (i = 0; i < mali_cluster_get_glob_num_clusters(); i++)
-	{
-		u32 group_id = 0;
-		struct mali_cluster *curr_cluster = mali_cluster_get_global_cluster(i);
-		struct mali_group *group = mali_cluster_get_group(curr_cluster, group_id);
-		while (NULL != group)
-		{
-			struct mali_pp_core *pp_core = mali_group_get_pp_core(group);
-			if (NULL != pp_core)
-			{
-				if (0 == pp_version)
-				{
-					/* Retrieve PP version from first avaiable PP core */
-					pp_version = mali_pp_core_get_version(pp_core);
-				}
-				slots[num_slots].group = group;
-				slots[num_slots].state = MALI_PP_SLOT_STATE_IDLE;
-				num_slots++;
-				num_slots_idle++;
-			}
-			group_id++;
-			group = mali_cluster_get_group(curr_cluster, group_id);
-		}
-	}
+/* Enable or disable core scaling */
+static mali_bool core_scaling_enabled = MALI_TRUE;
 
-	return _MALI_OSK_ERR_OK;
-}
+/* Variables to allow safe pausing of the scheduler */
+static _mali_osk_wait_queue_t *pp_scheduler_working_wait_queue = NULL;
+static u32 pause_count = 0;
 
-void mali_pp_scheduler_terminate(void)
-{
-	_mali_osk_wait_queue_term(pp_scheduler_working_wait_queue);
-	_mali_osk_lock_term(pp_scheduler_lock);
-}
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+static _mali_osk_spinlock_irq_t *pp_scheduler_lock = NULL;
+#else
+static _mali_osk_spinlock_t *pp_scheduler_lock = NULL;
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 
 MALI_STATIC_INLINE void mali_pp_scheduler_lock(void)
 {
-	if(_MALI_OSK_ERR_OK != _mali_osk_lock_wait(pp_scheduler_lock, _MALI_OSK_LOCKMODE_RW))
-	{
-		/* Non-interruptable lock failed: this should never happen. */
-		MALI_DEBUG_ASSERT(0);
-	}
-	MALI_DEBUG_PRINT(5, ("Mali PP scheduler: PP scheduler lock taken\n"));
-	MALI_DEBUG_ASSERT(0 == pp_scheduler_lock_owner);
-	MALI_DEBUG_CODE(pp_scheduler_lock_owner = _mali_osk_get_tid());
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_lock(pp_scheduler_lock);
+#else
+	_mali_osk_spinlock_lock(pp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
+	MALI_DEBUG_PRINT(5, ("Mali PP scheduler: PP scheduler lock taken.\n"));
 }
 
 MALI_STATIC_INLINE void mali_pp_scheduler_unlock(void)
 {
-	MALI_DEBUG_PRINT(5, ("Mali PP scheduler: Releasing PP scheduler lock\n"));
-	MALI_DEBUG_ASSERT(_mali_osk_get_tid() == pp_scheduler_lock_owner);
-	MALI_DEBUG_CODE(pp_scheduler_lock_owner = 0);
-	_mali_osk_lock_signal(pp_scheduler_lock, _MALI_OSK_LOCKMODE_RW);
+	MALI_DEBUG_PRINT(5, ("Mali PP scheduler: Releasing PP scheduler lock.\n"));
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_unlock(pp_scheduler_lock);
+#else
+	_mali_osk_spinlock_unlock(pp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 }
 
-#ifdef DEBUG
-MALI_STATIC_INLINE void mali_pp_scheduler_assert_locked(void)
+#if defined(DEBUG)
+#define MALI_ASSERT_PP_SCHEDULER_LOCKED() MALI_DEBUG_ASSERT_LOCK_HELD(pp_scheduler_lock)
+#else
+#define MALI_ASSERT_PP_SCHEDULER_LOCKED() do {} while (0)
+#endif /* defined(DEBUG) */
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+
+static _mali_osk_wq_work_t *pp_scheduler_wq_job_delete = NULL;
+static _mali_osk_spinlock_irq_t *pp_scheduler_job_delete_lock = NULL;
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(pp_scheduler_job_deletion_queue);
+
+static void mali_pp_scheduler_deferred_job_delete(struct mali_pp_job *job)
 {
-	MALI_DEBUG_ASSERT(_mali_osk_get_tid() == pp_scheduler_lock_owner);
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	_mali_osk_spinlock_irq_lock(pp_scheduler_job_delete_lock);
+
+	/* This job object should not be on any lists. */
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->list));
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_list));
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_fb_lookup_list));
+
+	_mali_osk_list_addtail(&job->list, &pp_scheduler_job_deletion_queue);
+
+	_mali_osk_spinlock_irq_unlock(pp_scheduler_job_delete_lock);
+
+	_mali_osk_wq_schedule_work(pp_scheduler_wq_job_delete);
 }
-#define MALI_ASSERT_PP_SCHEDULER_LOCKED() mali_pp_scheduler_assert_locked()
-#else
-#define MALI_ASSERT_PP_SCHEDULER_LOCKED()
-#endif
 
-static void mali_pp_scheduler_schedule(void)
+static void mali_pp_scheduler_do_job_delete(void *arg)
 {
-	u32 i;
+	_MALI_OSK_LIST_HEAD_STATIC_INIT(list);
 	struct mali_pp_job *job;
-#if MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS
-	struct mali_session_data * session;
-#endif
+	struct mali_pp_job *tmp;
 
-	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_IGNORE(arg);
 
-	if (0 < pause_count || 0 == num_slots_idle || _mali_osk_list_empty(&job_queue))
-	{
-		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Nothing to schedule (paused=%u, idle slots=%u)\n",
-		                     pause_count, num_slots_idle));
-		return; /* Nothing to do, so early out */
-	}
+	_mali_osk_spinlock_irq_lock(pp_scheduler_job_delete_lock);
+
+	/*
+	 * Quickly "unhook" the jobs pending to be deleted, so we can release the lock before
+	 * we start deleting the job objects (without any locks held
+	 */
+	_mali_osk_list_move_list(&pp_scheduler_job_deletion_queue, &list);
 
+	_mali_osk_spinlock_irq_unlock(pp_scheduler_job_delete_lock);
 
-#if MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP
-	if ( num_slots_idle < num_slots )
-	{
-		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Job not started, since only %d/%d cores are available\n", num_slots_idle,num_slots));
-		return;
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &list, struct mali_pp_job, list) {
+		mali_pp_job_delete(job); /* delete the job object itself */
 	}
-#endif
+}
 
-#if MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS
-	/* Finding initial session for the PP cores */
-	job = _MALI_OSK_LIST_ENTRY(job_queue.next, struct mali_pp_job, list);
-	session = job->session;
-	if ( num_slots != num_slots_idle )
-	{
-		for (i = 0; (i < num_slots) ; i++)
-		{
-			if ( slots[i].state == MALI_PP_SLOT_STATE_IDLE )
-			{
-				continue;
-			}
-			session = mali_group_get_session(slots[i].group);
-			break;
-		}
-	}
-#endif
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE) */
 
-	for (i = 0; (i < num_slots) && (0 < num_slots_idle); i++)
-	{
-		u32 sub_job;
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
 
-		if (_mali_osk_list_empty(&job_queue)) /* move this check down to where we know we have started all sub jobs for this job??? */
-		{
-			break; /* No more jobs to schedule, so early out */
-		}
+static _mali_osk_wq_work_t *pp_scheduler_wq_job_queue = NULL;
+static _mali_osk_spinlock_irq_t *pp_scheduler_job_queue_lock = NULL;
+static _MALI_OSK_LIST_HEAD_STATIC_INIT(pp_scheduler_job_queue_list);
 
-		if (MALI_PP_SLOT_STATE_IDLE != slots[i].state)
-		{
-			continue;
-		}
+static void mali_pp_scheduler_deferred_job_queue(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
 
-		job = _MALI_OSK_LIST_ENTRY(job_queue.next, struct mali_pp_job, list);
-		MALI_DEBUG_ASSERT(mali_pp_job_has_unstarted_sub_jobs(job)); /* All jobs on the job_queue should have unstarted sub jobs */
+	_mali_osk_spinlock_irq_lock(pp_scheduler_job_queue_lock);
+	_mali_osk_list_addtail(&job->list, &pp_scheduler_job_queue_list);
+	_mali_osk_spinlock_irq_unlock(pp_scheduler_job_queue_lock);
 
-		#if MALI_PP_SCHEDULER_KEEP_SUB_JOB_STARTS_ALIGNED
-		if ( (0==job->sub_jobs_started) && (num_slots_idle < num_slots) && (job->sub_job_count > num_slots_idle))
-		{
-			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Job with %d subjobs not started, since only %d/%d cores are available\n", job->sub_job_count, num_slots_idle,num_slots));
-			return;
-		}
-		#endif
+	_mali_osk_wq_schedule_work(pp_scheduler_wq_job_queue);
+}
 
-		#if MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP_BETWEEN_APPS
-		if ( job->session != session )
-		{
-			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Job not started since existing job is from another application\n"));
-			return;
-		}
-		#endif
+static void mali_pp_scheduler_do_job_queue(void *arg)
+{
+	_MALI_OSK_LIST_HEAD_STATIC_INIT(list);
+	struct mali_pp_job *job;
+	struct mali_pp_job *tmp;
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
 
-		sub_job = mali_pp_job_get_first_unstarted_sub_job(job);
+	MALI_IGNORE(arg);
 
-		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Starting job %u (0x%08X) part %u/%u\n", mali_pp_job_get_id(job), job, sub_job + 1, mali_pp_job_get_sub_job_count(job)));
-		if (_MALI_OSK_ERR_OK == mali_group_start_pp_job(slots[i].group, job, sub_job))
-		{
-			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Job %u (0x%08X) part %u/%u started\n", mali_pp_job_get_id(job), job, sub_job + 1, mali_pp_job_get_sub_job_count(job)));
+	_mali_osk_spinlock_irq_lock(pp_scheduler_job_queue_lock);
 
-			/* Mark this sub job as started */
-			mali_pp_job_mark_sub_job_started(job, sub_job);
+	/*
+	 * Quickly "unhook" the jobs pending to be queued, so we can release the lock before
+	 * we start queueing the job objects (without any locks held)
+	 */
+	_mali_osk_list_move_list(&pp_scheduler_job_queue_list, &list);
 
-			/* Mark slot as busy */
-			slots[i].state = MALI_PP_SLOT_STATE_WORKING;
-			num_slots_idle--;
-
-			if (!mali_pp_job_has_unstarted_sub_jobs(job))
-			{
-				/*
-				* All sub jobs have now started for this job, remove this job from the job queue.
-				* The job will now only be referred to by the slots which are running it.
-				* The last slot to complete will make sure it is returned to user space.
-				*/
-				_mali_osk_list_del(&job->list);
-#if MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP
-				MALI_DEBUG_PRINT(6, ("Mali PP scheduler: Skip scheduling more jobs when MALI_PP_SCHEDULER_FORCE_NO_JOB_OVERLAP is set.\n"));
-				return;
-#endif
-			}
-		}
-		else
-		{
-			MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Failed to start PP job\n"));
-			return;
-		}
+	_mali_osk_spinlock_irq_unlock(pp_scheduler_job_queue_lock);
+
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &list, struct mali_pp_job, list) {
+		_mali_osk_list_delinit(&job->list);
+		schedule_mask |= mali_pp_scheduler_queue_job(job);
 	}
+
+	mali_scheduler_schedule_from_mask(schedule_mask, MALI_FALSE);
 }
 
-static void mali_pp_scheduler_return_job_to_user(struct mali_pp_job *job)
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
+
+MALI_STATIC_INLINE mali_bool mali_pp_scheduler_has_virtual_group(void)
 {
-	_mali_osk_notification_t *notobj = _mali_osk_notification_create(_MALI_NOTIFICATION_PP_FINISHED, sizeof(_mali_uk_pp_job_finished_s));
-	if (NULL != notobj)
-	{
-		u32 i;
-		u32 sub_jobs = mali_pp_job_get_sub_job_count(job);
-		mali_bool success = mali_pp_job_was_success(job);
+#if defined(CONFIG_MALI450)
+	return NULL != virtual_group;
+#else
+	return MALI_FALSE;
+#endif /* defined(CONFIG_MALI450) */
+}
 
-		_mali_uk_pp_job_finished_s *jobres = notobj->result_buffer;
-		_mali_osk_memset(jobres, 0, sizeof(_mali_uk_pp_job_finished_s)); /* @@@@ can be removed once we initialize all members in this struct */
-		jobres->user_job_ptr = mali_pp_job_get_user_id(job);
-		if (MALI_TRUE == success)
-		{
-			jobres->status = _MALI_UK_JOB_STATUS_END_SUCCESS;
-		}
-		else
-		{
-			jobres->status = _MALI_UK_JOB_STATUS_END_UNKNOWN_ERR;
-		}
+_mali_osk_errcode_t mali_pp_scheduler_initialize(void)
+{
+	_MALI_OSK_INIT_LIST_HEAD(&job_queue.normal_pri);
+	_MALI_OSK_INIT_LIST_HEAD(&job_queue.high_pri);
+	job_queue.depth = 0;
 
-		for (i = 0; i < sub_jobs; i++)
-		{
-			jobres->perf_counter0[i] = mali_pp_job_get_perf_counter_value0(job, i);
-			jobres->perf_counter1[i] = mali_pp_job_get_perf_counter_value1(job, i);
-		}
+	_MALI_OSK_INIT_LIST_HEAD(&virtual_group_job_queue.normal_pri);
+	_MALI_OSK_INIT_LIST_HEAD(&virtual_group_job_queue.high_pri);
+	virtual_group_job_queue.depth = 0;
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	pp_scheduler_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER);
+#else
+	pp_scheduler_lock = _mali_osk_spinlock_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
+	if (NULL == pp_scheduler_lock) goto cleanup;
+
+	pp_scheduler_working_wait_queue = _mali_osk_wait_queue_init();
+	if (NULL == pp_scheduler_working_wait_queue) goto cleanup;
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+	pp_scheduler_wq_job_delete = _mali_osk_wq_create_work(mali_pp_scheduler_do_job_delete, NULL);
+	if (NULL == pp_scheduler_wq_job_delete) goto cleanup;
+
+	pp_scheduler_job_delete_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER_DEFERRED);
+	if (NULL == pp_scheduler_job_delete_lock) goto cleanup;
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE) */
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
+	pp_scheduler_wq_job_queue = _mali_osk_wq_create_work(mali_pp_scheduler_do_job_queue, NULL);
+	if (NULL == pp_scheduler_wq_job_queue) goto cleanup;
 
-		mali_session_send_notification(mali_pp_job_get_session(job), notobj);
+	pp_scheduler_job_queue_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SCHEDULER_DEFERRED);
+	if (NULL == pp_scheduler_job_queue_lock) goto cleanup;
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
+
+	return _MALI_OSK_ERR_OK;
+
+cleanup:
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
+	if (NULL != pp_scheduler_job_queue_lock) {
+		_mali_osk_spinlock_irq_term(pp_scheduler_job_queue_lock);
+		pp_scheduler_job_queue_lock = NULL;
+	}
+
+	if (NULL != pp_scheduler_wq_job_queue) {
+		_mali_osk_wq_delete_work(pp_scheduler_wq_job_queue);
+		pp_scheduler_wq_job_queue = NULL;
 	}
-	else
-	{
-		MALI_PRINT_ERROR(("Mali PP scheduler: Unable to allocate notification object\n"));
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+	if (NULL != pp_scheduler_job_delete_lock) {
+		_mali_osk_spinlock_irq_term(pp_scheduler_job_delete_lock);
+		pp_scheduler_job_delete_lock = NULL;
 	}
 
-	mali_pp_job_delete(job);
+	if (NULL != pp_scheduler_wq_job_delete) {
+		_mali_osk_wq_delete_work(pp_scheduler_wq_job_delete);
+		pp_scheduler_wq_job_delete = NULL;
+	}
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE) */
+
+	if (NULL != pp_scheduler_working_wait_queue) {
+		_mali_osk_wait_queue_term(pp_scheduler_working_wait_queue);
+		pp_scheduler_working_wait_queue = NULL;
+	}
+
+	if (NULL != pp_scheduler_lock) {
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+		_mali_osk_spinlock_irq_term(pp_scheduler_lock);
+#else
+		_mali_osk_spinlock_term(pp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
+		pp_scheduler_lock = NULL;
+	}
+
+	return _MALI_OSK_ERR_NOMEM;
 }
 
-void mali_pp_scheduler_do_schedule(void)
+void mali_pp_scheduler_terminate(void)
 {
-	mali_pp_scheduler_lock();
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
+	_mali_osk_spinlock_irq_term(pp_scheduler_job_queue_lock);
+	_mali_osk_wq_delete_work(pp_scheduler_wq_job_queue);
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
 
-	mali_pp_scheduler_schedule();
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+	_mali_osk_spinlock_irq_term(pp_scheduler_job_delete_lock);
+	_mali_osk_wq_delete_work(pp_scheduler_wq_job_delete);
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE) */
 
-	mali_pp_scheduler_unlock();
+	_mali_osk_wait_queue_term(pp_scheduler_working_wait_queue);
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	_mali_osk_spinlock_irq_term(pp_scheduler_lock);
+#else
+	_mali_osk_spinlock_term(pp_scheduler_lock);
+#endif /* defined(MALI_UPPER_HALF_SCHEDULING) */
 }
 
-void mali_pp_scheduler_job_done(struct mali_group *group, struct mali_pp_job *job, u32 sub_job, mali_bool success)
+void mali_pp_scheduler_populate(void)
 {
+	struct mali_group *group;
+	struct mali_pp_core *pp_core;
+	u32 num_groups;
 	u32 i;
-	mali_bool job_is_done;
 
-	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Job %u (0x%08X) part %u/%u completed (%s)\n", mali_pp_job_get_id(job), job, sub_job + 1, mali_pp_job_get_sub_job_count(job), success ? "success" : "failure"));
+	num_groups = mali_group_get_glob_num_groups();
 
-	mali_pp_scheduler_lock();
+	/* Do we have a virtual group? */
+	for (i = 0; i < num_groups; i++) {
+		group = mali_group_get_glob_group(i);
 
-	/* Find slot which was running this job */
-	for (i = 0; i < num_slots; i++)
-	{
-		if (slots[i].group == group)
-		{
-			MALI_DEBUG_ASSERT(MALI_PP_SLOT_STATE_WORKING == slots[i].state);
-			slots[i].state = MALI_PP_SLOT_STATE_IDLE;
-			num_slots_idle++;
-			mali_pp_job_mark_sub_job_completed(job, success);
+		if (mali_group_is_virtual(group)) {
+			MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Found virtual group %p.\n", group));
+
+			virtual_group = group;
+			break;
 		}
 	}
 
-	/* If paused, then this was the last job, so wake up sleeping workers */
-	if (pause_count > 0)
-	{
-		/* Wake up sleeping workers. Their wake-up condition is that
-		 * num_slots == num_slots_idle, so unless we are done working, no
-		 * threads will actually be woken up.
-		 */
-		_mali_osk_wait_queue_wake_up(pp_scheduler_working_wait_queue);
-	}
-	else
-	{
-		mali_pp_scheduler_schedule();
+	/* Find all the available PP cores */
+	for (i = 0; i < num_groups; i++) {
+		group = mali_group_get_glob_group(i);
+		pp_core = mali_group_get_pp_core(group);
+
+		if (NULL != pp_core && !mali_group_is_virtual(group)) {
+			if (0 == pp_version) {
+				/* Retrieve PP version from the first available PP core */
+				pp_version = mali_pp_core_get_version(pp_core);
+			}
+
+			if (mali_pp_scheduler_has_virtual_group()) {
+				/* Add all physical PP cores to the virtual group */
+				mali_group_lock(virtual_group);
+				group->state = MALI_GROUP_STATE_JOINING_VIRTUAL;
+				mali_group_add_group(virtual_group, group, MALI_TRUE);
+				mali_group_unlock(virtual_group);
+			} else {
+				_mali_osk_list_add(&group->pp_scheduler_list, &group_list_idle);
+			}
+
+			num_cores++;
+		}
 	}
 
-	job_is_done = mali_pp_job_is_complete(job);
+	enabled_cores = num_cores;
+}
 
-	mali_pp_scheduler_unlock();
+void mali_pp_scheduler_depopulate(void)
+{
+	struct mali_group *group, *temp;
+
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&group_list_working));
+	MALI_DEBUG_ASSERT(VIRTUAL_GROUP_WORKING != virtual_group_state);
 
-	if (job_is_done)
-	{
-		/* Send notification back to user space */
-		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: All parts completed for job %u (0x%08X)\n", mali_pp_job_get_id(job), job));
-		mali_pp_scheduler_return_job_to_user(job);
+	/* Delete all groups owned by scheduler */
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_group_delete(virtual_group);
+	}
+
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_idle, struct mali_group, pp_scheduler_list) {
+		mali_group_delete(group);
+	}
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_disabled, struct mali_group, pp_scheduler_list) {
+		mali_group_delete(group);
 	}
 }
 
-void mali_pp_scheduler_suspend(void)
+MALI_STATIC_INLINE void mali_pp_scheduler_disable_empty_virtual(void)
 {
-	mali_pp_scheduler_lock();
-	pause_count++; /* Increment the pause_count so that no more jobs will be scheduled */
-	mali_pp_scheduler_unlock();
+	MALI_ASSERT_GROUP_LOCKED(virtual_group);
 
-	/*mali_pp_scheduler_working_lock();*/
-	/* We have now aquired the working lock, which means that we have successfully paused the scheduler */
-	/*mali_pp_scheduler_working_unlock();*/
+	if (mali_group_virtual_disable_if_empty(virtual_group)) {
+		MALI_DEBUG_PRINT(4, ("Disabling empty virtual group\n"));
 
-	/* go to sleep. When woken up again (in mali_pp_scheduler_job_done), the
-	 * mali_pp_scheduler_suspended() function will be called. This will return true
-	 * iff state is idle and pause_count > 0, so if the core is active this
-	 * will not do anything.
-	 */
-	_mali_osk_wait_queue_wait_event(pp_scheduler_working_wait_queue, mali_pp_scheduler_is_suspended);
+		MALI_DEBUG_ASSERT(VIRTUAL_GROUP_IDLE == virtual_group_state);
+
+		virtual_group_state = VIRTUAL_GROUP_DISABLED;
+	}
 }
 
-void mali_pp_scheduler_resume(void)
+MALI_STATIC_INLINE void mali_pp_scheduler_enable_empty_virtual(void)
 {
-	mali_pp_scheduler_lock();
-	pause_count--; /* Decrement pause_count to allow scheduling again (if it reaches 0) */
-	if (0 == pause_count)
-	{
-		mali_pp_scheduler_schedule();
+	MALI_ASSERT_GROUP_LOCKED(virtual_group);
+
+	if (mali_group_virtual_enable_if_empty(virtual_group)) {
+		MALI_DEBUG_PRINT(4, ("Re-enabling empty virtual group\n"));
+
+		MALI_DEBUG_ASSERT(VIRTUAL_GROUP_DISABLED == virtual_group_state);
+
+		virtual_group_state = VIRTUAL_GROUP_IDLE;
 	}
-	mali_pp_scheduler_unlock();
 }
 
-_mali_osk_errcode_t _mali_ukk_pp_start_job(_mali_uk_pp_start_job_s *args)
+static struct mali_pp_job *mali_pp_scheduler_get_job(struct mali_pp_scheduler_job_queue *queue)
 {
-	struct mali_session_data *session;
-	struct mali_pp_job *job;
-
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_DEBUG_ASSERT_POINTER(args->ctx);
+	struct mali_pp_job *job = NULL;
 
-	session = (struct mali_session_data*)args->ctx;
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT_POINTER(queue);
 
-	job = mali_pp_job_create(session, args, mali_scheduler_get_new_id());
-	if (NULL == job)
-	{
-		return _MALI_OSK_ERR_NOMEM;
+	/* Check if we have a normal priority job. */
+	if (!_mali_osk_list_empty(&queue->normal_pri)) {
+		MALI_DEBUG_ASSERT(queue->depth > 0);
+		job = _MALI_OSK_LIST_ENTRY(queue->normal_pri.next, struct mali_pp_job, list);
 	}
 
-	if (_MALI_OSK_ERR_OK != mali_pp_job_check(job))
-	{
-		/* Not a valid job, return to user immediately */
-		mali_pp_job_mark_sub_job_completed(job, MALI_FALSE); /* Flagging the job as failed. */
-		mali_pp_scheduler_return_job_to_user(job); /* This will also delete the job object */
-		return _MALI_OSK_ERR_OK; /* User is notified via a notification, so this call is ok */
+	/* Prefer normal priority job if it is in progress. */
+	if (NULL != job && 0 < job->sub_jobs_started) {
+		return job;
 	}
 
-	mali_pp_scheduler_lock();
+	/* Check if we have a high priority job. */
+	if (!_mali_osk_list_empty(&queue->high_pri)) {
+		MALI_DEBUG_ASSERT(queue->depth > 0);
+		job = _MALI_OSK_LIST_ENTRY(queue->high_pri.next, struct mali_pp_job, list);
+	}
 
-	_mali_osk_list_addtail(&job->list, &job_queue);
+	return job;
+}
 
-	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Job %u (0x%08X) with %u parts queued\n", mali_pp_job_get_id(job), job, mali_pp_job_get_sub_job_count(job)));
+/**
+ * Returns a physical job if a physical job is ready to run
+ */
+MALI_STATIC_INLINE struct mali_pp_job *mali_pp_scheduler_get_physical_job(void)
+{
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	return mali_pp_scheduler_get_job(&job_queue);
+}
 
-	mali_pp_scheduler_schedule();
+MALI_STATIC_INLINE void mali_pp_scheduler_dequeue_physical_job(struct mali_pp_job *job)
+{
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT(job_queue.depth > 0);
 
-	mali_pp_scheduler_unlock();
+	/* Remove job from queue */
+	if (!mali_pp_job_has_unstarted_sub_jobs(job)) {
+		/* All sub jobs have been started: remove job from queue */
+		_mali_osk_list_delinit(&job->list);
+		_mali_osk_list_delinit(&job->session_fb_lookup_list);
+	}
 
-	return _MALI_OSK_ERR_OK;
+	--job_queue.depth;
 }
 
-_mali_osk_errcode_t _mali_ukk_get_pp_number_of_cores(_mali_uk_get_pp_number_of_cores_s *args)
+/**
+ * Returns a virtual job if a virtual job is ready to run
+ */
+MALI_STATIC_INLINE struct mali_pp_job *mali_pp_scheduler_get_virtual_group_job(void)
 {
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_DEBUG_ASSERT_POINTER(args->ctx);
-	args->number_of_cores = num_slots;
-	return _MALI_OSK_ERR_OK;
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT_POINTER(virtual_group);
+	return mali_pp_scheduler_get_job(&virtual_group_job_queue);
 }
 
-_mali_osk_errcode_t _mali_ukk_get_pp_core_version(_mali_uk_get_pp_core_version_s *args)
+static void mali_pp_scheduler_dequeue_virtual_group_job(struct mali_pp_job *job)
 {
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_DEBUG_ASSERT_POINTER(args->ctx);
-	args->version = pp_version;
-	return _MALI_OSK_ERR_OK;
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT(virtual_group_job_queue.depth > 0);
+
+	/* Remove job from queue */
+	if (!mali_pp_job_has_unstarted_sub_jobs(job)) {
+		_mali_osk_list_delinit(&job->list);
+		_mali_osk_list_delinit(&job->session_fb_lookup_list);
+		--virtual_group_job_queue.depth;
+	}
 }
 
-void _mali_ukk_pp_job_disable_wb(_mali_uk_pp_disable_wb_s *args)
+MALI_STATIC_INLINE void mali_pp_scheduler_pick_virtual_group_job(struct mali_pp_job *job,
+		u32 *first_subjob, u32 *last_subjob)
 {
-	struct mali_session_data *session;
-	struct mali_pp_job *job;
-	struct mali_pp_job *tmp;
+	MALI_ASSERT_GROUP_LOCKED(virtual_group);
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
 
-	MALI_DEBUG_ASSERT_POINTER(args);
-	MALI_DEBUG_ASSERT_POINTER(args->ctx);
+	MALI_DEBUG_ASSERT(VIRTUAL_GROUP_IDLE == virtual_group_state);
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT(mali_pp_job_is_virtual_group_job(job));
 
-	session = (struct mali_session_data*)args->ctx;
+	MALI_DEBUG_ASSERT_POINTER(first_subjob);
+	MALI_DEBUG_ASSERT_POINTER(last_subjob);
 
-	mali_pp_scheduler_lock();
+	MALI_DEBUG_ASSERT(virtual_group_job_queue.depth > 0);
 
-	/* Check queue for jobs that match */
-	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &job_queue, struct mali_pp_job, list)
-	{
-		if (mali_pp_job_get_session(job) == session &&
-		    mali_pp_job_get_frame_builder_id(job) == (u32)args->fb_id &&
-		    mali_pp_job_get_flush_id(job) == (u32)args->flush_id)
-		{
-			if (args->wbx & _MALI_UK_PP_JOB_WB0)
-			{
-				mali_pp_job_disable_wb0(job);
-			}
-			if (args->wbx & _MALI_UK_PP_JOB_WB1)
-			{
-				mali_pp_job_disable_wb1(job);
-			}
-			if (args->wbx & _MALI_UK_PP_JOB_WB2)
-			{
-				mali_pp_job_disable_wb2(job);
+	MALI_DEBUG_ASSERT(mali_pp_job_has_unstarted_sub_jobs(job));
+
+	*first_subjob = *last_subjob =
+				mali_pp_job_get_first_unstarted_sub_job(job);
+
+	if (mali_pp_job_is_with_dlbu(job)) {
+		MALI_DEBUG_ASSERT(1 == mali_pp_job_get_sub_job_count(job));
+		mali_pp_job_mark_sub_job_started(job, 0);
+	} else {
+		struct mali_group *child, *temp;
+		_MALI_OSK_LIST_FOREACHENTRY(child, temp,
+					    &virtual_group->group_list, struct mali_group, group_list) {
+			if (mali_pp_job_has_unstarted_sub_jobs(job)) {
+				*last_subjob = mali_pp_job_get_first_unstarted_sub_job(job);
+				mali_pp_job_mark_sub_job_started(job, *last_subjob);
+			} else {
+				break;
 			}
-			break;
 		}
 	}
 
-	mali_pp_scheduler_unlock();
+	/* Virtual group is now working. */
+	virtual_group_state = VIRTUAL_GROUP_WORKING;
+
+	mali_pp_scheduler_dequeue_virtual_group_job(job);
 }
 
-void mali_pp_scheduler_abort_session(struct mali_session_data *session)
+
+/**
+ * Checks if the criteria is met for removing a physical core from virtual group
+ */
+MALI_STATIC_INLINE mali_bool mali_pp_scheduler_can_move_virtual_to_physical(void)
 {
-	struct mali_pp_job *job, *tmp;
-	int i;
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+	MALI_DEBUG_ASSERT(mali_pp_scheduler_has_virtual_group());
+	MALI_ASSERT_GROUP_LOCKED(virtual_group);
+	/*
+	 * The criteria for taking out a physical group from a virtual group are the following:
+	 * - There virtual group is idle
+	 * - There are currently no physical groups (idle and working)
+	 * - There are physical jobs to be scheduled
+	 */
+	return (VIRTUAL_GROUP_IDLE == virtual_group_state) &&
+	       _mali_osk_list_empty(&group_list_idle) &&
+	       _mali_osk_list_empty(&group_list_working) &&
+	       (NULL != mali_pp_scheduler_get_physical_job());
+}
 
-	mali_pp_scheduler_lock();
-	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Aborting all jobs from session 0x%08x\n", session));
-
-	/* Check queue for jobs and remove */
-	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &job_queue, struct mali_pp_job, list)
-	{
-		if (mali_pp_job_get_session(job) == session)
-		{
-			_mali_osk_list_del(&(job->list));
-
-			if ( mali_pp_job_is_currently_rendering_and_if_so_abort_new_starts(job) )
-			{
-				/* The job is in the render pipeline, we can not delete it yet. */
-				/* It will be deleted in the mali_group_abort_session() call below */
-				MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Keeping partially started PP job 0x%08x in queue\n", job));
-				continue;
+MALI_STATIC_INLINE struct mali_group *mali_pp_scheduler_acquire_physical_group(void)
+{
+	MALI_ASSERT_PP_SCHEDULER_LOCKED();
+
+	if (!_mali_osk_list_empty(&group_list_idle)) {
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Acquiring physical group from idle list.\n"));
+		return _MALI_OSK_LIST_ENTRY(group_list_idle.next, struct mali_group, pp_scheduler_list);
+	} else if (mali_pp_scheduler_has_virtual_group()) {
+		MALI_ASSERT_GROUP_LOCKED(virtual_group);
+		if (mali_pp_scheduler_can_move_virtual_to_physical()) {
+			struct mali_group *group;
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Acquiring physical group from virtual group.\n"));
+			group = mali_group_acquire_group(virtual_group);
+
+			if (mali_pp_scheduler_has_virtual_group()) {
+				mali_pp_scheduler_disable_empty_virtual();
 			}
-			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Removing PP job 0x%08x from queue\n", job));
-			mali_pp_job_delete(job);
+
+			return group;
 		}
 	}
 
-	mali_pp_scheduler_unlock();
-
-	/* Abort running jobs from this session */
-	for (i = 0; i < num_slots; i++)
-	{
-		struct mali_group *group = slots[i].group;
+	return NULL;
+}
 
-		MALI_DEBUG_PRINT(5, ("PP sched abort: Looking at group 0x%08x\n", group));
+static void mali_pp_scheduler_return_job_to_user(struct mali_pp_job *job, mali_bool deferred)
+{
+	if (MALI_FALSE == mali_pp_job_use_no_notification(job)) {
+		u32 i;
+		u32 num_counters_to_copy;
+		mali_bool success = mali_pp_job_was_success(job);
 
-		if (MALI_PP_SLOT_STATE_WORKING == slots[i].state)
-		{
-			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Aborting session 0x%08x from group 0x%08x\n", session, group));
+		_mali_uk_pp_job_finished_s *jobres = job->finished_notification->result_buffer;
+		_mali_osk_memset(jobres, 0, sizeof(_mali_uk_pp_job_finished_s)); /* @@@@ can be removed once we initialize all members in this struct */
+		jobres->user_job_ptr = mali_pp_job_get_user_id(job);
+		if (MALI_TRUE == success) {
+			jobres->status = _MALI_UK_JOB_STATUS_END_SUCCESS;
+		} else {
+			jobres->status = _MALI_UK_JOB_STATUS_END_UNKNOWN_ERR;
+		}
+
+		if (mali_pp_job_is_with_dlbu(job)) {
+			num_counters_to_copy = num_cores; /* Number of physical cores available */
+		} else {
+			num_counters_to_copy = mali_pp_job_get_sub_job_count(job);
+		}
+
+		for (i = 0; i < num_counters_to_copy; i++) {
+			jobres->perf_counter0[i] = mali_pp_job_get_perf_counter_value0(job, i);
+			jobres->perf_counter1[i] = mali_pp_job_get_perf_counter_value1(job, i);
+			jobres->perf_counter_src0 = mali_pp_job_get_pp_counter_global_src0();
+			jobres->perf_counter_src1 = mali_pp_job_get_pp_counter_global_src1();
+		}
+
+		mali_session_send_notification(mali_pp_job_get_session(job), job->finished_notification);
+		job->finished_notification = NULL;
+	}
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+	if (MALI_TRUE == deferred) {
+		/* The deletion of the job object (releasing sync refs etc) must be done in a different context */
+		mali_pp_scheduler_deferred_job_delete(job);
+	} else {
+		mali_pp_job_delete(job);
+	}
+#else
+	MALI_DEBUG_ASSERT(MALI_FALSE == deferred); /* no use cases need this in this configuration */
+	mali_pp_job_delete(job);
+#endif
+}
+
+static void mali_pp_scheduler_finalize_job(struct mali_pp_job *job)
+{
+	/* This job object should not be on any lists. */
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->list));
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_list));
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_fb_lookup_list));
+
+	/* Send notification back to user space */
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+	mali_pp_scheduler_return_job_to_user(job, MALI_TRUE);
+#else
+	mali_pp_scheduler_return_job_to_user(job, MALI_FALSE);
+#endif
+
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	if (_MALI_PP_JOB_FLAG_IS_WINDOW_SURFACE & job->uargs.flags) {
+		_mali_osk_atomic_inc(&job->session->number_of_window_jobs);
+	}
+#endif
+
+	mali_pp_scheduler_job_completed();
+}
+
+void mali_pp_scheduler_schedule(void)
+{
+	struct mali_group *physical_groups_to_start[MALI_MAX_NUMBER_OF_PP_GROUPS - 1];
+	struct mali_pp_job *physical_jobs_to_start[MALI_MAX_NUMBER_OF_PP_GROUPS - 1];
+	u32 physical_sub_jobs_to_start[MALI_MAX_NUMBER_OF_PP_GROUPS - 1];
+	int num_physical_jobs_to_start = 0;
+	int i;
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		/* Lock the virtual group since we might have to grab physical groups. */
+		mali_group_lock(virtual_group);
+	}
+
+	mali_pp_scheduler_lock();
+	if (pause_count > 0) {
+		/* Scheduler is suspended, don't schedule any jobs. */
+		mali_pp_scheduler_unlock();
+		if (mali_pp_scheduler_has_virtual_group()) {
+			mali_group_unlock(virtual_group);
+		}
+		return;
+	}
+
+	/* Find physical job(s) to schedule first. */
+	while (1) {
+		struct mali_group *group;
+		struct mali_pp_job *job;
+		u32 sub_job;
+
+		job = mali_pp_scheduler_get_physical_job();
+		if (NULL == job) {
+			break; /* No job, early out. */
+		}
+
+		if (mali_scheduler_hint_is_enabled(MALI_SCHEDULER_HINT_GP_BOUND) &&
+		    mali_pp_job_is_large_and_unstarted(job) && !_mali_osk_list_empty(&group_list_working)) {
+			/* Since not all groups are idle, don't schedule yet. */
+			break;
+		}
+
+		MALI_DEBUG_ASSERT(!mali_pp_job_is_virtual_group_job(job));
+		MALI_DEBUG_ASSERT(mali_pp_job_has_unstarted_sub_jobs(job));
+		MALI_DEBUG_ASSERT(1 <= mali_pp_job_get_sub_job_count(job));
+
+		/* Acquire a physical group, either from the idle list or from the virtual group.
+		 * In case the group was acquired from the virtual group, it's state will be
+		 * LEAVING_VIRTUAL and must be set to IDLE before it can be used. */
+		group = mali_pp_scheduler_acquire_physical_group();
+		if (NULL == group) {
+			/* Could not get a group to run the job on, early out. */
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: No more physical groups available.\n"));
+			break;
+		}
+
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Acquired physical group %p.\n", group));
+
+		/* Mark sub job as started. */
+		sub_job = mali_pp_job_get_first_unstarted_sub_job(job);
+		mali_pp_job_mark_sub_job_started(job, sub_job);
+
+		/* Remove job from queue (if this was the last sub job). */
+		mali_pp_scheduler_dequeue_physical_job(job);
+
+		/* Move group to working list. */
+		_mali_osk_list_move(&(group->pp_scheduler_list), &group_list_working);
+
+		/* Keep track of this group, so that we actually can start the job once we are done with the scheduler lock we are now holding. */
+		physical_groups_to_start[num_physical_jobs_to_start] = group;
+		physical_jobs_to_start[num_physical_jobs_to_start] = job;
+		physical_sub_jobs_to_start[num_physical_jobs_to_start] = sub_job;
+		++num_physical_jobs_to_start;
+
+		MALI_DEBUG_ASSERT(num_physical_jobs_to_start < MALI_MAX_NUMBER_OF_PP_GROUPS);
+	}
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		if (VIRTUAL_GROUP_IDLE == virtual_group_state) {
+			/* We have a virtual group and it is idle. */
+
+			struct mali_pp_job *job;
+
+			/* Find a virtual job we can start. */
+			job = mali_pp_scheduler_get_virtual_group_job();
+
+			if (NULL != job) {
+				u32 first_subjob, last_subjob;
+
+				/* To mark necessary subjobs status of this job and remove the job from job queue
+				 * when all the subjobs will be run by this virtual group in one go
+				 */
+				mali_pp_scheduler_pick_virtual_group_job(job, &first_subjob, &last_subjob);
+
+				/* We no longer need the scheduler lock, but we still need the virtual lock
+				 * in order to start the virtual job.
+				 */
+				mali_pp_scheduler_unlock();
+
+				/* Start job. */
+				mali_group_start_job_on_virtual(virtual_group, job, first_subjob, last_subjob);
+			} else {
+				/* No virtual job to start. */
+				mali_pp_scheduler_unlock();
+			}
+		} else {
+			/* We have a virtual group, but it is busy or disabled. */
+			MALI_DEBUG_ASSERT(VIRTUAL_GROUP_IDLE != virtual_group_state);
+
+			mali_pp_scheduler_unlock();
+		}
+		mali_group_unlock(virtual_group);
+	} else {
+		/* There is no virtual group. */
+		mali_pp_scheduler_unlock();
+	}
+
+	/* We have now released the scheduler lock, and we are ready to start the physical jobs.
+	 * The reason we want to wait until we have released the scheduler lock is that job start
+	 * may take quite a bit of time (many registers have to be written). This will allow new
+	 * jobs from user space to come in, and post-processing of other PP jobs to happen at the
+	 * same time as we start jobs. */
+	for (i = 0; i < num_physical_jobs_to_start; i++) {
+		struct mali_group *group = physical_groups_to_start[i];
+		struct mali_pp_job *job  = physical_jobs_to_start[i];
+		u32 sub_job              = physical_sub_jobs_to_start[i];
+
+		MALI_DEBUG_ASSERT_POINTER(group);
+		MALI_DEBUG_ASSERT_POINTER(job);
+		MALI_DEBUG_ASSERT(!mali_group_is_virtual(group));
+		MALI_DEBUG_ASSERT(!mali_pp_job_is_virtual_group_job(job));
+
+		mali_group_lock(group);
+
+		/* Set state to IDLE if group was acquired from the virtual group. */
+		group->state = MALI_GROUP_STATE_IDLE;
+
+		mali_group_start_job_on_group(group, job, sub_job);
+
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Physical job %u (0x%08X) part %u/%u started (from schedule).\n",
+				     mali_pp_job_get_id(job), job, sub_job + 1,
+				     mali_pp_job_get_sub_job_count(job)));
+
+		mali_group_unlock(group);
+	}
+}
+
+/**
+ * Set group idle.
+ *
+ * If @ref group is the virtual group, nothing is done since the virtual group should be idle
+ * already.
+ *
+ * If @ref group is a physical group we rejoin the virtual group, if it exists.  If not, we move the
+ * physical group to the idle list.
+ *
+ * @note The group and the scheduler must both be locked when entering this function.  Both will be
+ * unlocked before exiting.
+ *
+ * @param group The group to set idle.
+ */
+static void mali_pp_scheduler_set_group_idle_and_unlock(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT_LOCK_HELD(pp_scheduler_lock);
+
+	if (mali_group_is_virtual(group)) {
+		/* The virtual group should have been set to non-working already. */
+		MALI_DEBUG_ASSERT(VIRTUAL_GROUP_IDLE == virtual_group_state);
+
+		mali_pp_scheduler_unlock();
+		mali_group_unlock(group);
+
+		return;
+	} else {
+		if (mali_pp_scheduler_has_virtual_group()) {
+			/* Rejoin virtual group. */
+
+			/* We're no longer needed on the scheduler list. */
+			_mali_osk_list_delinit(&(group->pp_scheduler_list));
+
+			/* Make sure no interrupts are handled for this group during the transition
+			 * from physical to virtual. */
+			group->state = MALI_GROUP_STATE_JOINING_VIRTUAL;
+
+			mali_pp_scheduler_unlock();
+			mali_group_unlock(group);
+
+			mali_group_lock(virtual_group);
+
+			if (mali_pp_scheduler_has_virtual_group()) {
+				mali_pp_scheduler_enable_empty_virtual();
+			}
+
+			/* We need to recheck the group state since it is possible that someone has
+			 * modified the group before we locked the virtual group. */
+			if (MALI_GROUP_STATE_JOINING_VIRTUAL == group->state) {
+				mali_group_add_group(virtual_group, group, MALI_TRUE);
+			}
+
+			mali_group_unlock(virtual_group);
+		} else {
+			/* Move physical group back to idle list. */
+			_mali_osk_list_move(&(group->pp_scheduler_list), &group_list_idle);
+
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+			trace_gpu_sched_switch(mali_pp_get_hw_core_desc(group->pp_core), sched_clock(), 0, 0, 0);
+#endif
+
+			mali_pp_scheduler_unlock();
+			mali_group_unlock(group);
+		}
+	}
+}
+
+/**
+ * Schedule job on locked group.
+ *
+ * @note The group and the scheduler must both be locked when entering this function.  Both will be
+ * unlocked before exiting.
+ *
+ * @param group The group to schedule on.
+ */
+static void mali_pp_scheduler_schedule_on_group_and_unlock(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	MALI_DEBUG_ASSERT_LOCK_HELD(pp_scheduler_lock);
+
+	if (mali_group_is_virtual(group)) {
+		/* Now that the virtual group is idle, check if we should reconfigure. */
+
+		struct mali_pp_job *virtual_job = NULL;
+		struct mali_pp_job *physical_job = NULL;
+		struct mali_group *physical_group = NULL;
+		u32 physical_sub_job = 0;
+
+		MALI_DEBUG_ASSERT(VIRTUAL_GROUP_IDLE == virtual_group_state);
+
+		if (mali_pp_scheduler_can_move_virtual_to_physical()) {
+			/* There is a runnable physical job and we can acquire a physical group. */
+			physical_job = mali_pp_scheduler_get_physical_job();
+			MALI_DEBUG_ASSERT_POINTER(physical_job);
+			MALI_DEBUG_ASSERT(mali_pp_job_has_unstarted_sub_jobs(physical_job));
+
+			/* Mark sub job as started. */
+			physical_sub_job = mali_pp_job_get_first_unstarted_sub_job(physical_job);
+			mali_pp_job_mark_sub_job_started(physical_job, physical_sub_job);
+
+			/* Remove job from queue (if this was the last sub job). */
+			mali_pp_scheduler_dequeue_physical_job(physical_job);
+
+			/* Acquire a physical group from the virtual group.  Its state will
+			 * be LEAVING_VIRTUAL and must be set to IDLE before it can be
+			 * used. */
+			physical_group = mali_group_acquire_group(virtual_group);
+
+			/* Move physical group to the working list, as we will soon start a job on it. */
+			_mali_osk_list_move(&(physical_group->pp_scheduler_list), &group_list_working);
+
+			mali_pp_scheduler_disable_empty_virtual();
+		}
+
+		/* Get next virtual job. */
+		virtual_job = mali_pp_scheduler_get_virtual_group_job();
+		if (NULL != virtual_job && VIRTUAL_GROUP_IDLE == virtual_group_state) {
+			u32 first_subjob, last_subjob;
+			/* To mark necessary subjobs status of this job and remove the job from job queue
+			 * when all the subjobs will be run by this virtual group in one go
+			 */
+			mali_pp_scheduler_pick_virtual_group_job(virtual_job, &first_subjob, &last_subjob);
+
+			/* We no longer need the scheduler lock, but we still need the virtual lock
+			 * in order to start the virtual job.
+			 */
+			mali_pp_scheduler_unlock();
+
+			/* Start job. */
+			mali_group_start_job_on_virtual(group, virtual_job, first_subjob, last_subjob);
+
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Virtual job %u (0x%08X) part %u/%u started (from job_done).\n",
+					     mali_pp_job_get_id(virtual_job), virtual_job, 1,
+					     mali_pp_job_get_sub_job_count(virtual_job)));
+		} else {
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+			trace_gpu_sched_switch("Mali_Virtual_PP", sched_clock(), 0, 0, 0);
+#endif
+
+			mali_pp_scheduler_unlock();
+		}
+
+		/* Releasing the virtual group lock that was held when entering the function. */
+		mali_group_unlock(group);
+
+		/* Start a physical job (if we acquired a physical group earlier). */
+		if (NULL != physical_job && NULL != physical_group) {
+			mali_group_lock(physical_group);
+
+			/* Change the group state from LEAVING_VIRTUAL to IDLE to complete the transition. */
+			physical_group->state = MALI_GROUP_STATE_IDLE;
+
+			/* Start job. */
+			mali_group_start_job_on_group(physical_group, physical_job, physical_sub_job);
+
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Physical job %u (0x%08X) part %u/%u started (from job_done).\n",
+					     mali_pp_job_get_id(physical_job), physical_job, physical_sub_job + 1,
+					     mali_pp_job_get_sub_job_count(physical_job)));
+
+			mali_group_unlock(physical_group);
+		}
+	} else {
+		/* Physical group. */
+		struct mali_pp_job *job = NULL;
+		u32 sub_job = 0;
+
+		job = mali_pp_scheduler_get_physical_job();
+		if (NULL != job) {
+			/* There is a runnable physical job. */
+			MALI_DEBUG_ASSERT(mali_pp_job_has_unstarted_sub_jobs(job));
+
+			/* Mark sub job as started. */
+			sub_job = mali_pp_job_get_first_unstarted_sub_job(job);
+			mali_pp_job_mark_sub_job_started(job, sub_job);
+
+			/* Remove job from queue (if this was the last sub job). */
+			mali_pp_scheduler_dequeue_physical_job(job);
+
+			mali_pp_scheduler_unlock();
+
+			/* Group is already on the working list, so start the new job. */
+			mali_group_start_job_on_group(group, job, sub_job);
+
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Physical job %u (0x%08X) part %u/%u started (from job_done).\n",
+					     mali_pp_job_get_id(job), job, sub_job + 1, mali_pp_job_get_sub_job_count(job)));
+
+			mali_group_unlock(group);
+		} else {
+			mali_pp_scheduler_set_group_idle_and_unlock(group);
+		}
+	}
+}
+
+void mali_pp_scheduler_job_done(struct mali_group *group, struct mali_pp_job *job, u32 sub_job, mali_bool success, mali_bool in_upper_half)
+{
+	mali_bool job_is_done = MALI_FALSE;
+	mali_bool schedule_on_group = MALI_FALSE;
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+
+	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: %s job %u (0x%08X) part %u/%u completed (%s).\n",
+			     mali_pp_job_is_virtual_group_job(job) ? "Virtual Group" : "Physical",
+			     mali_pp_job_get_id(job),
+			     job, sub_job + 1,
+			     mali_pp_job_get_sub_job_count(job),
+			     success ? "success" : "failure"));
+
+	MALI_ASSERT_GROUP_LOCKED(group);
+	mali_pp_scheduler_lock();
+
+	if (mali_group_is_virtual(group) && !mali_pp_job_is_with_dlbu(job)) {
+		u32 subjobs;
+
+		/* Get how many subjobs are running parallel in this virtual group */
+		subjobs = mali_pp_job_get_first_unstarted_sub_job(job) - group->pp_running_sub_job;
+		MALI_DEBUG_ASSERT(subjobs > 0);
+
+		for (; 0 < subjobs; subjobs--) {
+			mali_pp_job_mark_sub_job_completed(job, success);
+		}
+
+		mali_group_non_dlbu_job_done_virtual(group);
+	} else {
+		mali_pp_job_mark_sub_job_completed(job, success);
+	}
+
+	MALI_DEBUG_ASSERT(mali_pp_job_is_virtual_group_job(job) == mali_group_is_virtual(group));
+
+	job_is_done = mali_pp_job_is_complete(job);
+
+	if (job_is_done) {
+		/* Some groups added into the virtual group may take some subjobs to run but
+		 * without dequeuing the job, here do necessary dequeue under scheduler lock
+		 */
+		if (mali_group_is_virtual(group) && !mali_pp_job_is_with_dlbu(job)) {
+			if (!_mali_osk_list_empty(&job->list)) {
+				mali_pp_scheduler_dequeue_virtual_group_job(job);
+			}
+		}
+
+		MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->list));
+		MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_fb_lookup_list));
+
+		/* Remove job from session list. */
+		_mali_osk_list_delinit(&job->session_list);
+
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: All parts completed for %s job %u (0x%08X).\n",
+				     mali_pp_job_is_virtual_group_job(job) ? "virtual group" : "physical",
+				     mali_pp_job_get_id(job), job));
+
+		mali_pp_scheduler_unlock();
+
+		/* Release tracker.  If other trackers are waiting on this tracker, this could
+		 * trigger activation.  The returned scheduling mask can be used to determine if we
+		 * have to schedule GP, PP or both. */
+		schedule_mask = mali_timeline_tracker_release(&job->tracker);
+
+		mali_pp_scheduler_lock();
+	}
+
+	if (mali_group_is_virtual(group)) {
+		/* Obey the policy. */
+		virtual_group_state = VIRTUAL_GROUP_IDLE;
+	}
+
+	/* If paused, then this was the last job, so wake up sleeping workers and return. */
+	if (pause_count > 0) {
+		/* Wake up sleeping workers. Their wake-up condition is that
+		 * num_slots == num_slots_idle, so unless we are done working, no
+		 * threads will actually be woken up.
+		 */
+		if (!mali_group_is_virtual(group)) {
+			/* Move physical group to idle list. */
+			_mali_osk_list_move(&(group->pp_scheduler_list), &group_list_idle);
+		}
+
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+		trace_gpu_sched_switch(mali_pp_get_hw_core_desc(group->pp_core), sched_clock(), 0, 0, 0);
+#endif
+
+		_mali_osk_wait_queue_wake_up(pp_scheduler_working_wait_queue);
+
+		mali_pp_scheduler_unlock();
+		mali_group_unlock(group);
+
+		if (job_is_done) {
+			/* Return job to user and delete it. */
+			mali_pp_scheduler_finalize_job(job);
+		}
+
+		/* A GP job might be queued by tracker release above,
+		 * make sure GP scheduler has a chance to schedule this (if possible)
+		 */
+		mali_scheduler_schedule_from_mask(schedule_mask & ~MALI_SCHEDULER_MASK_PP, in_upper_half);
+
+		return;
+	}
+
+	/* Since this group just finished running a job, we can reschedule a new job on it
+	 * immediately. */
+
+	/* By default, don't schedule on group. */
+	schedule_on_group = MALI_FALSE;
+
+	if (mali_group_is_virtual(group)) {
+		/* Always schedule immediately on virtual group. */
+		schedule_mask &= ~MALI_SCHEDULER_MASK_PP;
+		schedule_on_group = MALI_TRUE;
+	} else if (0 < job_queue.depth && (!mali_scheduler_mask_is_set(schedule_mask, MALI_SCHEDULER_MASK_PP) || _mali_osk_list_empty(&group_list_idle))) {
+		struct mali_pp_job *next_job = NULL;
+
+		next_job = mali_pp_scheduler_get_physical_job();
+		MALI_DEBUG_ASSERT_POINTER(next_job);
+
+		/* If no new jobs have been queued or if this group is the only idle group, we can
+		 * schedule immediately on this group, unless we are GP bound and the next job would
+		 * benefit from all its sub jobs being started concurrently. */
+
+		if (mali_scheduler_hint_is_enabled(MALI_SCHEDULER_HINT_GP_BOUND) && mali_pp_job_is_large_and_unstarted(next_job)) {
+			/* We are GP bound and the job would benefit from all sub jobs being started
+			 * concurrently.  Postpone scheduling until after group has been unlocked. */
+			schedule_mask |= MALI_SCHEDULER_MASK_PP;
+			schedule_on_group = MALI_FALSE;
+		} else {
+			/* Schedule job immediately since we are not GP bound. */
+			schedule_mask &= ~MALI_SCHEDULER_MASK_PP;
+			schedule_on_group = MALI_TRUE;
+		}
+	} else if ((0 < virtual_group_job_queue.depth) && (!mali_scheduler_mask_is_set(schedule_mask, MALI_SCHEDULER_MASK_PP))) {
+		/* This case is rare, only in virtual job has sub jobs case,
+		 * the last "pilot job" here might not be the real pilot job,
+		 * it may be a real pp job with only 1 subjob i.e. only 1 region inform,
+		 * so this job may not trigger any virtual job queued in virtual queue,
+		 * so it may suspend the pp scheduler, even when there are already
+		 * some jobs in the virtual queue, so in this case we need to explicit
+		 * set the schedule_mask */
+		schedule_mask |= MALI_SCHEDULER_MASK_PP;
+	}
+
+	if (schedule_on_group) {
+		/* Schedule a new job on this group. */
+		mali_pp_scheduler_schedule_on_group_and_unlock(group);
+	} else {
+		/* Set group idle.  Will rejoin virtual group, under appropriate conditions. */
+		mali_pp_scheduler_set_group_idle_and_unlock(group);
+	}
+
+	if (!schedule_on_group || MALI_SCHEDULER_MASK_EMPTY != schedule_mask) {
+		if (MALI_SCHEDULER_MASK_PP & schedule_mask) {
+			/* Schedule PP directly. */
+			mali_pp_scheduler_schedule();
+			schedule_mask &= ~MALI_SCHEDULER_MASK_PP;
+		}
+
+		/* Schedule other jobs that were activated. */
+		mali_scheduler_schedule_from_mask(schedule_mask, in_upper_half);
+	}
+
+	if (job_is_done) {
+		/* Return job to user and delete it. */
+		mali_pp_scheduler_finalize_job(job);
+	}
+}
+
+void mali_pp_scheduler_suspend(void)
+{
+	mali_pp_scheduler_lock();
+	pause_count++; /* Increment the pause_count so that no more jobs will be scheduled */
+	mali_pp_scheduler_unlock();
+
+	/* Go to sleep. When woken up again (in mali_pp_scheduler_job_done), the
+	 * mali_pp_scheduler_suspended() function will be called. This will return true
+	 * if state is idle and pause_count > 0, so if the core is active this
+	 * will not do anything.
+	 */
+	_mali_osk_wait_queue_wait_event(pp_scheduler_working_wait_queue, mali_pp_scheduler_is_suspended, NULL);
+}
+
+void mali_pp_scheduler_resume(void)
+{
+	mali_pp_scheduler_lock();
+	pause_count--; /* Decrement pause_count to allow scheduling again (if it reaches 0) */
+	mali_pp_scheduler_unlock();
+	if (0 == pause_count) {
+		mali_pp_scheduler_schedule();
+	}
+}
+
+static mali_timeline_point mali_pp_scheduler_submit_job(struct mali_session_data *session, struct mali_pp_job *job)
+{
+	mali_timeline_point point;
+	u32 fb_lookup_id = 0;
+
+	MALI_DEBUG_ASSERT_POINTER(session);
+	MALI_DEBUG_ASSERT_POINTER(job);
+
+	mali_pp_scheduler_lock();
+
+	fb_lookup_id = mali_pp_job_get_fb_lookup_id(job);
+	MALI_DEBUG_ASSERT(MALI_PP_JOB_FB_LOOKUP_LIST_SIZE > fb_lookup_id);
+
+	/* Adding job to the lookup list used to quickly discard writeback units of queued jobs. */
+	_mali_osk_list_addtail(&job->session_fb_lookup_list, &session->pp_job_fb_lookup_list[fb_lookup_id]);
+
+	mali_pp_scheduler_unlock();
+
+	/* We hold a PM reference for every job we hold queued (and running) */
+	_mali_osk_pm_dev_ref_add();
+
+	/* Add job to Timeline system. */
+	point = mali_timeline_system_add_tracker(session->timeline_system, &job->tracker, MALI_TIMELINE_PP);
+
+	return point;
+}
+
+_mali_osk_errcode_t _mali_ukk_pp_start_job(void *ctx, _mali_uk_pp_start_job_s *uargs)
+{
+	struct mali_session_data *session;
+	struct mali_pp_job *job;
+	mali_timeline_point point;
+	u32 __user *timeline_point_ptr = NULL;
+
+	MALI_DEBUG_ASSERT_POINTER(uargs);
+	MALI_DEBUG_ASSERT_POINTER(ctx);
+
+	session = (struct mali_session_data *)ctx;
+
+	job = mali_pp_job_create(session, uargs, mali_scheduler_get_new_id());
+	if (NULL == job) {
+		MALI_PRINT_ERROR(("Failed to create PP job.\n"));
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
+	timeline_point_ptr = (u32 __user *) job->uargs.timeline_point_ptr;
+
+	point = mali_pp_scheduler_submit_job(session, job);
+	job = NULL;
+
+	if (0 != _mali_osk_put_user(((u32) point), timeline_point_ptr)) {
+		/* Let user space know that something failed after the job was started. */
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
+	}
+
+	return _MALI_OSK_ERR_OK;
+}
+
+_mali_osk_errcode_t _mali_ukk_pp_and_gp_start_job(void *ctx, _mali_uk_pp_and_gp_start_job_s *uargs)
+{
+	struct mali_session_data *session;
+	_mali_uk_pp_and_gp_start_job_s kargs;
+	struct mali_pp_job *pp_job;
+	struct mali_gp_job *gp_job;
+	u32 __user *timeline_point_ptr = NULL;
+	mali_timeline_point point;
+
+	MALI_DEBUG_ASSERT_POINTER(ctx);
+	MALI_DEBUG_ASSERT_POINTER(uargs);
+
+	session = (struct mali_session_data *) ctx;
+
+	if (0 != _mali_osk_copy_from_user(&kargs, uargs, sizeof(_mali_uk_pp_and_gp_start_job_s))) {
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
+	pp_job = mali_pp_job_create(session, kargs.pp_args, mali_scheduler_get_new_id());
+	if (NULL == pp_job) {
+		MALI_PRINT_ERROR(("Failed to create PP job.\n"));
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
+	gp_job = mali_gp_job_create(session, kargs.gp_args, mali_scheduler_get_new_id(), mali_pp_job_get_tracker(pp_job));
+	if (NULL == gp_job) {
+		MALI_PRINT_ERROR(("Failed to create GP job.\n"));
+		mali_pp_job_delete(pp_job);
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
+	timeline_point_ptr = (u32 __user *) pp_job->uargs.timeline_point_ptr;
+
+	/* Submit GP job. */
+	mali_gp_scheduler_submit_job(session, gp_job);
+	gp_job = NULL;
+
+	/* Submit PP job. */
+	point = mali_pp_scheduler_submit_job(session, pp_job);
+	pp_job = NULL;
+
+	if (0 != _mali_osk_put_user(((u32) point), timeline_point_ptr)) {
+		/* Let user space know that something failed after the jobs were started. */
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
+	}
+
+	return _MALI_OSK_ERR_OK;
+}
+
+_mali_osk_errcode_t _mali_ukk_get_pp_number_of_cores(_mali_uk_get_pp_number_of_cores_s *args)
+{
+	MALI_DEBUG_ASSERT_POINTER(args);
+	MALI_DEBUG_ASSERT_POINTER(args->ctx);
+	args->number_of_total_cores = num_cores;
+	args->number_of_enabled_cores = enabled_cores;
+	return _MALI_OSK_ERR_OK;
+}
+
+u32 mali_pp_scheduler_get_num_cores_total(void)
+{
+	return num_cores;
+}
+
+u32 mali_pp_scheduler_get_num_cores_enabled(void)
+{
+	return enabled_cores;
+}
+
+_mali_osk_errcode_t _mali_ukk_get_pp_core_version(_mali_uk_get_pp_core_version_s *args)
+{
+	MALI_DEBUG_ASSERT_POINTER(args);
+	MALI_DEBUG_ASSERT_POINTER(args->ctx);
+	args->version = pp_version;
+	return _MALI_OSK_ERR_OK;
+}
+
+void _mali_ukk_pp_job_disable_wb(_mali_uk_pp_disable_wb_s *args)
+{
+	struct mali_session_data *session;
+	struct mali_pp_job *job;
+	struct mali_pp_job *tmp;
+	u32 fb_lookup_id;
+
+	MALI_DEBUG_ASSERT_POINTER(args);
+	MALI_DEBUG_ASSERT_POINTER(args->ctx);
+
+	session = (struct mali_session_data *)args->ctx;
+
+	fb_lookup_id = args->fb_id & MALI_PP_JOB_FB_LOOKUP_LIST_MASK;
+
+	mali_pp_scheduler_lock();
+
+	/* Iterate over all jobs for given frame builder_id. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp, &session->pp_job_fb_lookup_list[fb_lookup_id], struct mali_pp_job, session_fb_lookup_list) {
+		MALI_DEBUG_CODE(u32 disable_mask = 0);
+
+		if (mali_pp_job_get_frame_builder_id(job) == (u32) args->fb_id) {
+			MALI_DEBUG_CODE(disable_mask |= 0xD << (4 * 3));
+			if (args->wb0_memory == job->uargs.wb0_registers[MALI200_REG_ADDR_WB_SOURCE_ADDR / sizeof(u32)]) {
+				MALI_DEBUG_CODE(disable_mask |= 0x1 << (4 * 1));
+				mali_pp_job_disable_wb0(job);
+			}
+			if (args->wb1_memory == job->uargs.wb1_registers[MALI200_REG_ADDR_WB_SOURCE_ADDR / sizeof(u32)]) {
+				MALI_DEBUG_CODE(disable_mask |= 0x2 << (4 * 2));
+				mali_pp_job_disable_wb1(job);
+			}
+			if (args->wb2_memory == job->uargs.wb2_registers[MALI200_REG_ADDR_WB_SOURCE_ADDR / sizeof(u32)]) {
+				MALI_DEBUG_CODE(disable_mask |= 0x3 << (4 * 3));
+				mali_pp_job_disable_wb2(job);
+			}
+			MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Disable WB: 0x%X.\n", disable_mask));
+		} else {
+			MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Disable WB mismatching FB.\n"));
+		}
+	}
+
+	mali_pp_scheduler_unlock();
+}
+
+void mali_pp_scheduler_abort_session(struct mali_session_data *session)
+{
+	u32 i = 0;
+	struct mali_pp_job *job, *tmp_job;
+	struct mali_group *group, *tmp_group;
+	struct mali_group *groups[MALI_MAX_NUMBER_OF_GROUPS];
+	_MALI_OSK_LIST_HEAD_STATIC_INIT(removed_jobs);
+
+	MALI_DEBUG_ASSERT_POINTER(session);
+	MALI_DEBUG_ASSERT(session->is_aborting);
+
+	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Aborting all jobs from session 0x%08X.\n", session));
+
+	mali_pp_scheduler_lock();
+
+	/* Find all jobs from the aborting session. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp_job, &session->pp_job_list, struct mali_pp_job, session_list) {
+		/* Remove job from queue. */
+		if (mali_pp_job_is_virtual_group_job(job)) {
+			if (mali_pp_job_has_unstarted_sub_jobs(job))
+				--virtual_group_job_queue.depth;
+		} else {
+			job_queue.depth -= mali_pp_job_get_sub_job_count(job) - mali_pp_job_get_first_unstarted_sub_job(job);
+		}
+
+		_mali_osk_list_delinit(&job->list);
+		_mali_osk_list_delinit(&job->session_fb_lookup_list);
+
+		mali_pp_job_mark_unstarted_failed(job);
+
+		if (mali_pp_job_is_complete(job)) {
+			/* Job is complete, remove from session list. */
+			_mali_osk_list_delinit(&job->session_list);
+
+			/* Move job to local list for release and deletion. */
+			_mali_osk_list_add(&job->list, &removed_jobs);
+
+			MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Aborted PP job %u (0x%08X).\n", mali_pp_job_get_id(job), job));
+		} else {
+			MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Keeping partially started PP job %u (0x%08X) in session.\n", mali_pp_job_get_id(job), job));
+		}
+	}
+
+	_MALI_OSK_LIST_FOREACHENTRY(group, tmp_group, &group_list_working, struct mali_group, pp_scheduler_list) {
+		groups[i++] = group;
+	}
+
+	_MALI_OSK_LIST_FOREACHENTRY(group, tmp_group, &group_list_idle, struct mali_group, pp_scheduler_list) {
+		groups[i++] = group;
+	}
+
+	mali_pp_scheduler_unlock();
+
+	/* Release and delete all found jobs from the aborting session. */
+	_MALI_OSK_LIST_FOREACHENTRY(job, tmp_job, &removed_jobs, struct mali_pp_job, list) {
+		mali_timeline_tracker_release(&job->tracker);
+		mali_pp_job_delete(job);
+		mali_pp_scheduler_job_completed();
+	}
+
+	/* Abort any running jobs from the session. */
+	while (i > 0) {
+		mali_group_abort_session(groups[--i], session);
+	}
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_group_abort_session(virtual_group, session);
+	}
+}
+
+static mali_bool mali_pp_scheduler_is_suspended(void *data)
+{
+	mali_bool ret;
+
+	/* This callback does not use the data pointer. */
+	MALI_IGNORE(data);
+
+	mali_pp_scheduler_lock();
+
+	ret = pause_count > 0
+	      && _mali_osk_list_empty(&group_list_working)
+	      && VIRTUAL_GROUP_WORKING != virtual_group_state;
+
+	mali_pp_scheduler_unlock();
+
+	return ret;
+}
+
+struct mali_pp_core *mali_pp_scheduler_get_virtual_pp(void)
+{
+	if (mali_pp_scheduler_has_virtual_group()) {
+		return mali_group_get_pp_core(virtual_group);
+	} else {
+		return NULL;
+	}
+}
+
+#if MALI_STATE_TRACKING
+u32 mali_pp_scheduler_dump_state(char *buf, u32 size)
+{
+	int n = 0;
+	struct mali_group *group;
+	struct mali_group *temp;
+
+	n += _mali_osk_snprintf(buf + n, size - n, "PP:\n");
+	n += _mali_osk_snprintf(buf + n, size - n, "\tQueue is %s\n", _mali_osk_list_empty(&job_queue.normal_pri) ? "empty" : "not empty");
+	n += _mali_osk_snprintf(buf + n, size - n, "\tHigh priority queue is %s\n", _mali_osk_list_empty(&job_queue.high_pri) ? "empty" : "not empty");
+	n += _mali_osk_snprintf(buf + n, size - n, "\n");
+
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_working, struct mali_group, pp_scheduler_list) {
+		n += mali_group_dump_state(group, buf + n, size - n);
+	}
 
-			mali_group_abort_session(group, session);
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_idle, struct mali_group, pp_scheduler_list) {
+		n += mali_group_dump_state(group, buf + n, size - n);
+	}
+
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_disabled, struct mali_group, pp_scheduler_list) {
+		n += mali_group_dump_state(group, buf + n, size - n);
+	}
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		n += mali_group_dump_state(virtual_group, buf + n, size - n);
+	}
+
+	n += _mali_osk_snprintf(buf + n, size - n, "\n");
+	return n;
+}
+#endif
+
+/* This function is intended for power on reset of all cores.
+ * No locking is done for the list iteration, which can only be safe if the
+ * scheduler is paused and all cores idle. That is always the case on init and
+ * power on. */
+void mali_pp_scheduler_reset_all_groups(void)
+{
+	struct mali_group *group, *temp;
+	struct mali_group *groups[MALI_MAX_NUMBER_OF_GROUPS];
+	s32 i = 0;
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_group_lock(virtual_group);
+		mali_group_reset(virtual_group);
+		mali_group_unlock(virtual_group);
+	}
+
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&group_list_working));
+	MALI_DEBUG_ASSERT(VIRTUAL_GROUP_WORKING != virtual_group_state);
+	mali_pp_scheduler_lock();
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_idle, struct mali_group, pp_scheduler_list) {
+		groups[i++] = group;
+	}
+	mali_pp_scheduler_unlock();
+
+	while (i > 0) {
+		group = groups[--i];
+
+		mali_group_lock(group);
+		mali_group_reset(group);
+		mali_group_unlock(group);
+	}
+}
+
+void mali_pp_scheduler_zap_all_active(struct mali_session_data *session)
+{
+	struct mali_group *group, *temp;
+	struct mali_group *groups[MALI_MAX_NUMBER_OF_GROUPS];
+	s32 i = 0;
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_group_zap_session(virtual_group, session);
+	}
+
+	mali_pp_scheduler_lock();
+	_MALI_OSK_LIST_FOREACHENTRY(group, temp, &group_list_working, struct mali_group, pp_scheduler_list) {
+		groups[i++] = group;
+	}
+	mali_pp_scheduler_unlock();
+
+	while (i > 0) {
+		mali_group_zap_session(groups[--i], session);
+	}
+}
+
+/* A pm reference must be taken with _mali_osk_pm_dev_ref_add_no_power_on
+ * before calling this function to avoid Mali powering down as HW is accessed.
+ */
+static void mali_pp_scheduler_enable_group_internal(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	mali_group_lock(group);
+
+	if (MALI_GROUP_STATE_DISABLED != group->state) {
+		mali_group_unlock(group);
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: PP group %p already enabled.\n", group));
+		return;
+	}
+
+	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Enabling PP group %p.\n", group));
+
+	mali_pp_scheduler_lock();
+
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_DISABLED == group->state);
+	++enabled_cores;
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_bool update_hw;
+
+		/* Add group to virtual group. */
+		_mali_osk_list_delinit(&(group->pp_scheduler_list));
+		group->state = MALI_GROUP_STATE_JOINING_VIRTUAL;
+
+		mali_pp_scheduler_unlock();
+		mali_group_unlock(group);
+
+		mali_group_lock(virtual_group);
+
+		update_hw = mali_pm_is_power_on();
+		/* Get ref of group domain */
+		mali_group_get_pm_domain_ref(group);
+
+		MALI_DEBUG_ASSERT(NULL == group->pm_domain ||
+				  MALI_PM_DOMAIN_ON == mali_pm_domain_state_get(group->pm_domain));
+
+		if (update_hw) {
+			mali_group_lock(group);
+			mali_group_power_on_group(group);
+			mali_group_reset(group);
+			mali_group_unlock(group);
+		}
+
+		mali_pp_scheduler_enable_empty_virtual();
+		mali_group_add_group(virtual_group, group, update_hw);
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Done enabling group %p. Added to virtual group.\n", group));
+
+		mali_group_unlock(virtual_group);
+	} else {
+		/* Get ref of group domain */
+		mali_group_get_pm_domain_ref(group);
+
+		MALI_DEBUG_ASSERT(NULL == group->pm_domain ||
+				  MALI_PM_DOMAIN_ON == mali_pm_domain_state_get(group->pm_domain));
+
+		/* Put group on idle list. */
+		if (mali_pm_is_power_on()) {
+			mali_group_power_on_group(group);
+			mali_group_reset(group);
 		}
+
+		_mali_osk_list_move(&(group->pp_scheduler_list), &group_list_idle);
+		group->state = MALI_GROUP_STATE_IDLE;
+
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Done enabling group %p. Now on idle list.\n", group));
+		mali_pp_scheduler_unlock();
+		mali_group_unlock(group);
 	}
 }
 
-static mali_bool mali_pp_scheduler_is_suspended(void)
+void mali_pp_scheduler_enable_group(struct mali_group *group)
 {
-	mali_bool ret;
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+
+	mali_pp_scheduler_enable_group_internal(group);
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+
+	/* Pick up any jobs that might have been queued if all PP groups were disabled. */
+	mali_pp_scheduler_schedule();
+}
 
+static void mali_pp_scheduler_disable_group_internal(struct mali_group *group)
+{
+	if (mali_pp_scheduler_has_virtual_group()) {
+		mali_group_lock(virtual_group);
+
+		MALI_DEBUG_ASSERT(VIRTUAL_GROUP_WORKING != virtual_group_state);
+		if (MALI_GROUP_STATE_JOINING_VIRTUAL == group->state) {
+			/* The group was in the process of being added to the virtual group.  We
+			 * only need to change the state to reverse this. */
+			group->state = MALI_GROUP_STATE_LEAVING_VIRTUAL;
+		} else if (MALI_GROUP_STATE_IN_VIRTUAL == group->state) {
+			/* Remove group from virtual group.  The state of the group will be
+			 * LEAVING_VIRTUAL and the group will not be on any scheduler list. */
+			mali_group_remove_group(virtual_group, group);
+
+			mali_pp_scheduler_disable_empty_virtual();
+		}
+
+		mali_group_unlock(virtual_group);
+	}
+
+	mali_group_lock(group);
 	mali_pp_scheduler_lock();
-	ret = pause_count > 0 && num_slots == num_slots_idle;
+
+	MALI_DEBUG_ASSERT(MALI_GROUP_STATE_IDLE            == group->state
+			  || MALI_GROUP_STATE_LEAVING_VIRTUAL == group->state
+			  || MALI_GROUP_STATE_DISABLED        == group->state);
+
+	if (MALI_GROUP_STATE_DISABLED == group->state) {
+		MALI_DEBUG_PRINT(4, ("Mali PP scheduler: PP group %p already disabled.\n", group));
+	} else {
+		MALI_DEBUG_PRINT(3, ("Mali PP scheduler: Disabling PP group %p.\n", group));
+
+		--enabled_cores;
+		_mali_osk_list_move(&(group->pp_scheduler_list), &group_list_disabled);
+		group->state = MALI_GROUP_STATE_DISABLED;
+
+		mali_group_power_off_group(group, MALI_TRUE);
+		mali_group_put_pm_domain_ref(group);
+	}
+
 	mali_pp_scheduler_unlock();
+	mali_group_unlock(group);
+}
 
-	return ret;
+void mali_pp_scheduler_disable_group(struct mali_group *group)
+{
+	MALI_DEBUG_ASSERT_POINTER(group);
+
+	mali_pp_scheduler_suspend();
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+
+	mali_pp_scheduler_disable_group_internal(group);
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+
+	mali_pp_scheduler_resume();
 }
 
-#if MALI_STATE_TRACKING
-u32 mali_pp_scheduler_dump_state(char *buf, u32 size)
+static void mali_pp_scheduler_notify_core_change(u32 num_cores)
 {
-	int n = 0;
-	int i;
+	mali_bool done = MALI_FALSE;
 
-	n += _mali_osk_snprintf(buf + n, size - n, "PP:\n");
-	n += _mali_osk_snprintf(buf + n, size - n, "\tQueue is %s\n", _mali_osk_list_empty(&job_queue) ? "empty" : "not empty");
-	n += _mali_osk_snprintf(buf + n, size - n, "\n");
+	if (mali_is_mali450()) {
+		return;
+	}
+
+	/*
+	 * This function gets a bit complicated because we can't hold the session lock while
+	 * allocating notification objects.
+	 */
+
+	while (!done) {
+		u32 i;
+		u32 num_sessions_alloc;
+		u32 num_sessions_with_lock;
+		u32 used_notification_objects = 0;
+		_mali_osk_notification_t **notobjs;
+
+		/* Pre allocate the number of notifications objects we need right now (might change after lock has been taken) */
+		num_sessions_alloc = mali_session_get_count();
+		if (0 == num_sessions_alloc) {
+			/* No sessions to report to */
+			return;
+		}
+
+		notobjs = (_mali_osk_notification_t **)_mali_osk_malloc(sizeof(_mali_osk_notification_t *) * num_sessions_alloc);
+		if (NULL == notobjs) {
+			MALI_PRINT_ERROR(("Failed to notify user space session about num PP core change (alloc failure)\n"));
+			/* there is probably no point in trying again, system must be really low on memory and probably unusable now anyway */
+			return;
+		}
+
+		for (i = 0; i < num_sessions_alloc; i++) {
+			notobjs[i] = _mali_osk_notification_create(_MALI_NOTIFICATION_PP_NUM_CORE_CHANGE, sizeof(_mali_uk_pp_num_cores_changed_s));
+			if (NULL != notobjs[i]) {
+				_mali_uk_pp_num_cores_changed_s *data = notobjs[i]->result_buffer;
+				data->number_of_enabled_cores = num_cores;
+			} else {
+				MALI_PRINT_ERROR(("Failed to notify user space session about num PP core change (alloc failure %u)\n", i));
+			}
+		}
+
+		mali_session_lock();
+
+		/* number of sessions will not change while we hold the lock */
+		num_sessions_with_lock = mali_session_get_count();
+
+		if (num_sessions_alloc >= num_sessions_with_lock) {
+			/* We have allocated enough notification objects for all the sessions atm */
+			struct mali_session_data *session, *tmp;
+			MALI_SESSION_FOREACH(session, tmp, link) {
+				MALI_DEBUG_ASSERT(used_notification_objects < num_sessions_alloc);
+				if (NULL != notobjs[used_notification_objects]) {
+					mali_session_send_notification(session, notobjs[used_notification_objects]);
+					notobjs[used_notification_objects] = NULL; /* Don't track this notification object any more */
+				}
+				used_notification_objects++;
+			}
+			done = MALI_TRUE;
+		}
+
+		mali_session_unlock();
+
+		/* Delete any remaining/unused notification objects */
+		for (; used_notification_objects < num_sessions_alloc; used_notification_objects++) {
+			if (NULL != notobjs[used_notification_objects]) {
+				_mali_osk_notification_delete(notobjs[used_notification_objects]);
+			}
+		}
 
-	for (i = 0; i < num_slots; i++)
-	{
-		n += mali_group_dump_state(slots[i].group, buf + n, size - n);
-		n += _mali_osk_snprintf(buf + n, size - n, "\t\tState: %d\n", slots[i].state);
+		_mali_osk_free(notobjs);
 	}
+}
 
-	return n;
+static void mali_pp_scheduler_core_scale_up(unsigned int target_core_nr)
+{
+	MALI_DEBUG_PRINT(2, ("Requesting %d cores: enabling %d cores\n", target_core_nr, target_core_nr - enabled_cores));
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+	_mali_osk_pm_dev_barrier();
+
+	while (target_core_nr > enabled_cores) {
+		/*
+		 * If there are any cores which do not belong to any domain,
+		 * then these will always be found at the head of the list and
+		 * we'll thus enabled these first.
+		 */
+
+		mali_pp_scheduler_lock();
+
+		if (!_mali_osk_list_empty(&group_list_disabled)) {
+			struct mali_group *group;
+
+			group = _MALI_OSK_LIST_ENTRY(group_list_disabled.next, struct mali_group, pp_scheduler_list);
+
+			MALI_DEBUG_ASSERT_POINTER(group);
+			MALI_DEBUG_ASSERT(MALI_GROUP_STATE_DISABLED == group->state);
+
+			mali_pp_scheduler_unlock();
+
+			mali_pp_scheduler_enable_group_internal(group);
+		} else {
+			mali_pp_scheduler_unlock();
+			break; /* no more groups on disabled list */
+		}
+	}
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+
+	mali_pp_scheduler_schedule();
+}
+
+static void mali_pp_scheduler_core_scale_down(unsigned int target_core_nr)
+{
+	MALI_DEBUG_PRINT(2, ("Requesting %d cores: disabling %d cores\n", target_core_nr, enabled_cores - target_core_nr));
+
+	mali_pp_scheduler_suspend();
+
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&group_list_working));
+
+	_mali_osk_pm_dev_ref_add_no_power_on();
+
+	if (NULL != mali_pmu_get_global_pmu_core()) {
+		int i;
+
+		for (i = MALI_MAX_NUMBER_OF_DOMAINS - 1; i >= 0; i--) {
+			if (target_core_nr < enabled_cores) {
+				struct mali_pm_domain *domain;
+
+				domain = mali_pm_domain_get_from_index(i);
+
+				/* Domain is valid and has pp cores */
+				if ((NULL != domain) && (NULL != domain->group_list)) {
+					struct mali_group *group;
+
+					MALI_PM_DOMAIN_FOR_EACH_GROUP(group, domain) {
+						/* If group is pp core */
+						if (NULL != mali_group_get_pp_core(group)) {
+							mali_pp_scheduler_disable_group_internal(group);
+							if (target_core_nr >= enabled_cores) {
+								break;
+							}
+						}
+					}
+				}
+			} else {
+				break;
+			}
+		}
+	}
+
+	/*
+	 * Didn't find enough cores associated with a power domain,
+	 * so we need to disable cores which we can't power off with the PMU.
+	 * Start with physical groups used by the scheduler,
+	 * then remove physical from virtual if even more groups are needed.
+	 */
+
+	while (target_core_nr < enabled_cores) {
+		mali_pp_scheduler_lock();
+		if (!_mali_osk_list_empty(&group_list_idle)) {
+			struct mali_group *group;
+
+			group = _MALI_OSK_LIST_ENTRY(group_list_idle.next, struct mali_group, pp_scheduler_list);
+			MALI_DEBUG_ASSERT_POINTER(group);
+
+			mali_pp_scheduler_unlock();
+
+			mali_pp_scheduler_disable_group_internal(group);
+		} else {
+			mali_pp_scheduler_unlock();
+			break; /* No more physical groups */
+		}
+	}
+
+	if (mali_pp_scheduler_has_virtual_group()) {
+		while (target_core_nr < enabled_cores) {
+			mali_group_lock(virtual_group);
+			if (!_mali_osk_list_empty(&virtual_group->group_list)) {
+				struct mali_group *group;
+
+				group = _MALI_OSK_LIST_ENTRY(virtual_group->group_list.next, struct mali_group, group_list);
+				MALI_DEBUG_ASSERT_POINTER(group);
+
+				mali_group_unlock(virtual_group);
+
+				mali_pp_scheduler_disable_group_internal(group);
+			} else {
+				mali_group_unlock(virtual_group);
+				break; /* No more physical groups in virtual group */
+			}
+		}
+	}
+
+	_mali_osk_pm_dev_ref_dec_no_power_on();
+
+	mali_pp_scheduler_resume();
+}
+
+int mali_pp_scheduler_set_perf_level(unsigned int target_core_nr, mali_bool override)
+{
+	if (target_core_nr == enabled_cores) return 0;
+	if (MALI_FALSE == core_scaling_enabled && MALI_FALSE == override) return -EPERM;
+	if (target_core_nr > num_cores) return -EINVAL;
+	if (0 == target_core_nr) return -EINVAL;
+
+	if (target_core_nr > enabled_cores) {
+		mali_pp_scheduler_core_scale_up(target_core_nr);
+	} else if (target_core_nr < enabled_cores) {
+		mali_pp_scheduler_core_scale_down(target_core_nr);
+	}
+
+	if (target_core_nr != enabled_cores) {
+		MALI_DEBUG_PRINT(2, ("Core scaling failed, target number: %d, actual number: %d\n", target_core_nr, enabled_cores));
+	}
+
+	mali_pp_scheduler_notify_core_change(enabled_cores);
+
+	return 0;
+}
+
+void mali_pp_scheduler_core_scaling_enable(void)
+{
+	/* PS: Core scaling is by default enabled */
+	core_scaling_enabled = MALI_TRUE;
+}
+
+void mali_pp_scheduler_core_scaling_disable(void)
+{
+	core_scaling_enabled = MALI_FALSE;
+}
+
+mali_bool mali_pp_scheduler_core_scaling_is_enabled(void)
+{
+	return core_scaling_enabled;
+}
+
+static void mali_pp_scheduler_job_queued(void)
+{
+	if (mali_utilization_enabled()) {
+		/*
+		 * We cheat a little bit by counting the PP as busy from the time a PP job is queued.
+		 * This will be fine because we only loose the tiny idle gap between jobs, but
+		 * we will instead get less utilization work to do (less locks taken)
+		 */
+		mali_utilization_pp_start();
+	}
+}
+
+static void mali_pp_scheduler_job_completed(void)
+{
+	/* Release the PM reference we got in the mali_pp_scheduler_job_queued() function */
+	_mali_osk_pm_dev_ref_dec();
+
+	if (mali_utilization_enabled()) {
+		mali_utilization_pp_end();
+	}
+}
+
+static void mali_pp_scheduler_abort_job_and_unlock_scheduler(struct mali_pp_job *job)
+{
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT_LOCK_HELD(pp_scheduler_lock);
+
+	/* This job should not be on any lists. */
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->list));
+	MALI_DEBUG_ASSERT(_mali_osk_list_empty(&job->session_list));
+
+	_mali_osk_list_delinit(&job->session_fb_lookup_list);
+
+	mali_pp_scheduler_unlock();
+
+	/* Release tracker. */
+	mali_timeline_tracker_release(&job->tracker);
 }
+
+static mali_scheduler_mask mali_pp_scheduler_queue_job(struct mali_pp_job *job)
+{
+	_mali_osk_list_t *queue = NULL;
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+	struct mali_pp_job *iter, *tmp;
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT_POINTER(job->session);
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
+	if (mali_pp_job_needs_dma_buf_mapping(job)) {
+		mali_dma_buf_map_job(job);
+	}
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
+
+	mali_pp_scheduler_lock();
+
+	if (unlikely(job->session->is_aborting)) {
+		/* Before checking if the session is aborting, the scheduler must be locked. */
+		MALI_DEBUG_ASSERT_LOCK_HELD(pp_scheduler_lock);
+
+		MALI_DEBUG_PRINT(2, ("Mali PP scheduler: Job %u (0x%08X) queued while session is aborting.\n", mali_pp_job_get_id(job), job));
+
+		mali_pp_scheduler_abort_job_and_unlock_scheduler(job);
+
+		/* Delete job. */
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE)
+		mali_pp_scheduler_deferred_job_delete(job);
+#else
+		mali_pp_job_delete(job);
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_DELETE) */
+
+		/* Release the PM reference taken for the job in
+		 * mali_pp_scheduler_submit_job(). */
+		_mali_osk_pm_dev_ref_dec();
+
+		/* Since we are aborting we ignore the scheduler mask. */
+		return MALI_SCHEDULER_MASK_EMPTY;
+	}
+
+	mali_pp_scheduler_job_queued();
+
+#if defined(CONFIG_GPU_TRACEPOINTS) && defined(CONFIG_TRACEPOINTS)
+	trace_gpu_job_enqueue(mali_pp_job_get_tid(job), mali_pp_job_get_id(job), "PP");
 #endif
+
+	_mali_osk_profiling_add_event(MALI_PROFILING_EVENT_TYPE_SINGLE | MALI_PROFILING_EVENT_CHANNEL_SOFTWARE | MALI_PROFILING_EVENT_REASON_SINGLE_SW_PP_ENQUEUE, job->pid, job->tid, job->uargs.frame_builder_id, job->uargs.flush_id, 0);
+
+	job->cache_order = mali_scheduler_get_new_cache_order();
+
+	/* Determine which queue the job should be added to. */
+	if (mali_pp_job_is_virtual_group_job(job)) {
+		if (job->session->use_high_priority_job_queue) {
+			queue = &virtual_group_job_queue.high_pri;
+		} else {
+			queue = &virtual_group_job_queue.normal_pri;
+		}
+
+		virtual_group_job_queue.depth += 1;
+
+		/* Set schedule bitmask if the virtual group is idle. */
+		if (VIRTUAL_GROUP_IDLE == virtual_group_state) {
+			schedule_mask |= MALI_SCHEDULER_MASK_PP;
+		}
+	} else {
+		if (job->session->use_high_priority_job_queue) {
+			queue = &job_queue.high_pri;
+		} else {
+			queue = &job_queue.normal_pri;
+		}
+
+		job_queue.depth += mali_pp_job_get_sub_job_count(job);
+
+		/* Set schedule bitmask if there are physical PP cores available, or if there is an
+		 * idle virtual group. */
+		if (!_mali_osk_list_empty(&group_list_idle)
+		    || (mali_pp_scheduler_has_virtual_group()
+			&& (VIRTUAL_GROUP_IDLE == virtual_group_state))) {
+			schedule_mask |= MALI_SCHEDULER_MASK_PP;
+		}
+	}
+
+	/* Find position in queue where job should be added. */
+	_MALI_OSK_LIST_FOREACHENTRY_REVERSE(iter, tmp, queue, struct mali_pp_job, list) {
+		if (mali_pp_job_should_start_after(job, iter)) {
+			break;
+		}
+	}
+
+	/* Add job to queue. */
+	_mali_osk_list_add(&job->list, &iter->list);
+
+	/* Add job to session list. */
+	_mali_osk_list_addtail(&job->session_list, &(job->session->pp_job_list));
+
+	MALI_DEBUG_PRINT(3, ("Mali PP scheduler: %s job %u (0x%08X) with %u parts queued.\n",
+			     mali_pp_job_is_virtual_group_job(job) ? "Virtual Group" : "Physical",
+			     mali_pp_job_get_id(job), job, mali_pp_job_get_sub_job_count(job)));
+
+	mali_pp_scheduler_unlock();
+
+	return schedule_mask;
+}
+
+mali_scheduler_mask mali_pp_scheduler_activate_job(struct mali_pp_job *job)
+{
+	mali_scheduler_mask schedule_mask = MALI_SCHEDULER_MASK_EMPTY;
+
+	MALI_DEBUG_ASSERT_POINTER(job);
+	MALI_DEBUG_ASSERT_POINTER(job->session);
+
+	MALI_DEBUG_PRINT(4, ("Mali PP scheduler: Timeline activation for job %u (0x%08X).\n", mali_pp_job_get_id(job), job));
+
+	if (MALI_TIMELINE_ACTIVATION_ERROR_FATAL_BIT & job->tracker.activation_error) {
+		MALI_DEBUG_PRINT(2, ("Mali PP scheduler: Job %u (0x%08X) activated with error, aborting.\n", mali_pp_job_get_id(job), job));
+
+		mali_pp_scheduler_lock();
+		mali_pp_scheduler_abort_job_and_unlock_scheduler(job);
+
+		mali_pp_job_mark_sub_job_completed(job, MALI_FALSE); /* Flagging the job as failed. */
+		mali_pp_scheduler_finalize_job(job);
+
+		return MALI_SCHEDULER_MASK_EMPTY;
+	}
+
+	/* PP job is ready to run, queue it. */
+
+#if defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE)
+	if (mali_pp_job_needs_dma_buf_mapping(job)) {
+		mali_pp_scheduler_deferred_job_queue(job);
+
+		return MALI_SCHEDULER_MASK_EMPTY;
+	}
+#endif /* defined(MALI_PP_SCHEDULER_USE_DEFERRED_JOB_QUEUE) */
+
+	schedule_mask = mali_pp_scheduler_queue_job(job);
+
+	return schedule_mask;
+}
diff --git a/drivers/gpu/mali/mali/common/mali_pp_scheduler.h b/drivers/gpu/mali/mali/common/mali_pp_scheduler.h
old mode 100644
new mode 100755
index 388d542..618152a
--- a/drivers/gpu/mali/mali/common/mali_pp_scheduler.h
+++ b/drivers/gpu/mali/mali/common/mali_pp_scheduler.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,27 +12,119 @@
 #define __MALI_PP_SCHEDULER_H__
 
 #include "mali_osk.h"
-#include "mali_cluster.h"
 #include "mali_pp_job.h"
+#include "mali_group.h"
+#include "linux/mali/mali_utgard.h"
 
+/** Initalize the HW independent parts of the  PP scheduler
+ */
 _mali_osk_errcode_t mali_pp_scheduler_initialize(void);
 void mali_pp_scheduler_terminate(void);
 
-void mali_pp_scheduler_do_schedule(void);
-void mali_pp_scheduler_job_done(struct mali_group *group, struct mali_pp_job *job, u32 sub_job, mali_bool success);
+/** Poplulate the PP scheduler with groups
+ */
+void mali_pp_scheduler_populate(void);
+void mali_pp_scheduler_depopulate(void);
+
+/**
+ * @brief Handle job completion.
+ *
+ * Will attempt to start a new job on the locked group.
+ *
+ * If all sub jobs have completed the job's tracker will be released, any other resources associated
+ * with the job will be freed.  A notification will also be sent to user space.
+ *
+ * Releasing the tracker might activate other jobs, so if appropriate we also schedule them.
+ *
+ * @note Group must be locked when entering this function.  Will be unlocked before exiting.
+ *
+ * @param group The group that completed the job.
+ * @param job The job that is done.
+ * @param sub_job Sub job of job.
+ * @param success MALI_TRUE if job completed successfully, MALI_FALSE if not.
+ * @param in_upper_half MALI_TRUE if called from upper half, MALI_FALSE if not.
+ */
+void mali_pp_scheduler_job_done(struct mali_group *group, struct mali_pp_job *job, u32 sub_job, mali_bool success, mali_bool in_upper_half);
 
 void mali_pp_scheduler_suspend(void);
 void mali_pp_scheduler_resume(void);
 
-/** @brief Abort all PP jobs from session running or queued
+/**
+ * @brief Abort all running and queued PP jobs from session.
  *
- * This functions aborts all PP jobs from the specified session. Queued jobs are removed from the queue and jobs
- * currently running on a core will be aborted.
+ * This functions aborts all PP jobs from the specified session. Queued jobs are removed from the
+ * queue and jobs currently running on a core will be aborted.
  *
- * @param session Pointer to session whose jobs should be aborted
+ * @param session Session that is aborting.
  */
 void mali_pp_scheduler_abort_session(struct mali_session_data *session);
 
+/**
+ * @brief Reset all groups
+ *
+ * This function resets all groups known by the PP scheuduler. This must be
+ * called after the Mali HW has been powered on in order to reset the HW.
+ *
+ * This function is intended for power on reset of all cores.
+ * No locking is done, which can only be safe if the scheduler is paused and
+ * all cores idle. That is always the case on init and power on.
+ */
+void mali_pp_scheduler_reset_all_groups(void);
+
+/**
+ * @brief Zap TLB on all groups with \a session active
+ *
+ * The scheculer will zap the session on all groups it owns.
+ */
+void mali_pp_scheduler_zap_all_active(struct mali_session_data *session);
+
+/**
+ * @brief Get the virtual PP core
+ *
+ * The returned PP core may only be used to prepare DMA command buffers for the
+ * PP core. Other actions must go through the PP scheduler, or the virtual
+ * group.
+ *
+ * @return Pointer to the virtual PP core, NULL if this doesn't exist
+ */
+struct mali_pp_core *mali_pp_scheduler_get_virtual_pp(void);
+
 u32 mali_pp_scheduler_dump_state(char *buf, u32 size);
 
+void mali_pp_scheduler_enable_group(struct mali_group *group);
+void mali_pp_scheduler_disable_group(struct mali_group *group);
+
+/**
+ * @brief Used by the Timeline system to queue a PP job.
+ *
+ * @note @ref mali_scheduler_schedule_from_mask() should be called if this function returns non-zero.
+ *
+ * @param job The PP job that is being activated.
+ *
+ * @return A scheduling bitmask that can be used to decide if scheduling is necessary after this
+ * call.
+ */
+mali_scheduler_mask mali_pp_scheduler_activate_job(struct mali_pp_job *job);
+
+/**
+ * @brief Schedule queued jobs on idle cores.
+ */
+void mali_pp_scheduler_schedule(void);
+
+int mali_pp_scheduler_set_perf_level(u32 cores, mali_bool override);
+
+void mali_pp_scheduler_core_scaling_enable(void);
+void mali_pp_scheduler_core_scaling_disable(void);
+mali_bool mali_pp_scheduler_core_scaling_is_enabled(void);
+
+u32 mali_pp_scheduler_get_num_cores_total(void);
+u32 mali_pp_scheduler_get_num_cores_enabled(void);
+
+/**
+ * @brief Returns the number of Pixel Processors in the system irrespective of the context
+ *
+ * @return number of physical Pixel Processor cores in the system
+ */
+u32 mali_pp_scheduler_get_num_cores_total(void);
+
 #endif /* __MALI_PP_SCHEDULER_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_scheduler.c b/drivers/gpu/mali/mali/common/mali_scheduler.c
old mode 100644
new mode 100755
index 78cc249..8940653
--- a/drivers/gpu/mali/mali/common/mali_scheduler.c
+++ b/drivers/gpu/mali/mali/common/mali_scheduler.c
@@ -1,36 +1,112 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
+#include "mali_scheduler.h"
+
 #include "mali_kernel_common.h"
 #include "mali_osk.h"
 
-static _mali_osk_atomic_t mali_job_autonumber;
+mali_bool mali_scheduler_hints[MALI_SCHEDULER_HINT_MAX];
+
+static _mali_osk_atomic_t mali_job_id_autonumber;
+static _mali_osk_atomic_t mali_job_cache_order_autonumber;
+
+static _mali_osk_wq_work_t *pp_scheduler_wq_high_pri = NULL;
+static _mali_osk_wq_work_t *gp_scheduler_wq_high_pri = NULL;
+
+static void mali_scheduler_wq_schedule_pp(void *arg)
+{
+	MALI_IGNORE(arg);
+
+	mali_pp_scheduler_schedule();
+}
+
+static void mali_scheduler_wq_schedule_gp(void *arg)
+{
+	MALI_IGNORE(arg);
+
+	mali_gp_scheduler_schedule();
+}
 
 _mali_osk_errcode_t mali_scheduler_initialize(void)
 {
-	if ( _MALI_OSK_ERR_OK != _mali_osk_atomic_init(&mali_job_autonumber, 0))
-	{
-		MALI_DEBUG_PRINT(1,  ("Initialization of atomic job id counter failed.\n"));
+	if (_MALI_OSK_ERR_OK != _mali_osk_atomic_init(&mali_job_id_autonumber, 0)) {
+		MALI_DEBUG_PRINT(1, ("Initialization of atomic job id counter failed.\n"));
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	if (_MALI_OSK_ERR_OK != _mali_osk_atomic_init(&mali_job_cache_order_autonumber, 0)) {
+		MALI_DEBUG_PRINT(1, ("Initialization of atomic job cache order counter failed.\n"));
+		_mali_osk_atomic_term(&mali_job_id_autonumber);
 		return _MALI_OSK_ERR_FAULT;
 	}
 
+	pp_scheduler_wq_high_pri = _mali_osk_wq_create_work_high_pri(mali_scheduler_wq_schedule_pp, NULL);
+	if (NULL == pp_scheduler_wq_high_pri) {
+		_mali_osk_atomic_term(&mali_job_cache_order_autonumber);
+		_mali_osk_atomic_term(&mali_job_id_autonumber);
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
+	gp_scheduler_wq_high_pri = _mali_osk_wq_create_work_high_pri(mali_scheduler_wq_schedule_gp, NULL);
+	if (NULL == gp_scheduler_wq_high_pri) {
+		_mali_osk_wq_delete_work(pp_scheduler_wq_high_pri);
+		_mali_osk_atomic_term(&mali_job_cache_order_autonumber);
+		_mali_osk_atomic_term(&mali_job_id_autonumber);
+		return _MALI_OSK_ERR_NOMEM;
+	}
+
 	return _MALI_OSK_ERR_OK;
 }
 
 void mali_scheduler_terminate(void)
 {
-	_mali_osk_atomic_term(&mali_job_autonumber);
+	_mali_osk_wq_delete_work(gp_scheduler_wq_high_pri);
+	_mali_osk_wq_delete_work(pp_scheduler_wq_high_pri);
+	_mali_osk_atomic_term(&mali_job_cache_order_autonumber);
+	_mali_osk_atomic_term(&mali_job_id_autonumber);
 }
 
 u32 mali_scheduler_get_new_id(void)
 {
-	u32 job_id = _mali_osk_atomic_inc_return(&mali_job_autonumber);
+	u32 job_id = _mali_osk_atomic_inc_return(&mali_job_id_autonumber);
 	return job_id;
 }
+
+u32 mali_scheduler_get_new_cache_order(void)
+{
+	u32 job_cache_order = _mali_osk_atomic_inc_return(&mali_job_cache_order_autonumber);
+	return job_cache_order;
+}
+
+void mali_scheduler_schedule_from_mask(mali_scheduler_mask mask, mali_bool deferred_schedule)
+{
+	if (MALI_SCHEDULER_MASK_GP & mask) {
+		/* GP needs scheduling. */
+		if (deferred_schedule) {
+			/* Schedule GP deferred. */
+			_mali_osk_wq_schedule_work_high_pri(gp_scheduler_wq_high_pri);
+		} else {
+			/* Schedule GP now. */
+			mali_gp_scheduler_schedule();
+		}
+	}
+
+	if (MALI_SCHEDULER_MASK_PP & mask) {
+		/* PP needs scheduling. */
+		if (deferred_schedule) {
+			/* Schedule PP deferred. */
+			_mali_osk_wq_schedule_work_high_pri(pp_scheduler_wq_high_pri);
+		} else {
+			/* Schedule PP now. */
+			mali_pp_scheduler_schedule();
+		}
+	}
+}
diff --git a/drivers/gpu/mali/mali/common/mali_scheduler.h b/drivers/gpu/mali/mali/common/mali_scheduler.h
old mode 100644
new mode 100755
index 9b0cc71..73eb53e
--- a/drivers/gpu/mali/mali/common/mali_scheduler.h
+++ b/drivers/gpu/mali/mali/common/mali_scheduler.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,10 +12,79 @@
 #define __MALI_SCHEDULER_H__
 
 #include "mali_osk.h"
+#include "mali_scheduler_types.h"
+#include "mali_gp_scheduler.h"
+#include "mali_pp_scheduler.h"
 
 _mali_osk_errcode_t mali_scheduler_initialize(void);
 void mali_scheduler_terminate(void);
 
 u32 mali_scheduler_get_new_id(void);
+u32 mali_scheduler_get_new_cache_order(void);
+
+/**
+ * @brief Reset all groups
+ *
+ * This function resets all groups known by the both the PP and GP scheuduler.
+ * This must be called after the Mali HW has been powered on in order to reset
+ * the HW.
+ */
+MALI_STATIC_INLINE void mali_scheduler_reset_all_groups(void)
+{
+	mali_gp_scheduler_reset_all_groups();
+	mali_pp_scheduler_reset_all_groups();
+}
+
+/**
+ * @brief Zap TLB on all active groups running \a session
+ *
+ * @param session Pointer to the session to zap
+ */
+MALI_STATIC_INLINE void mali_scheduler_zap_all_active(struct mali_session_data *session)
+{
+	mali_gp_scheduler_zap_all_active(session);
+	mali_pp_scheduler_zap_all_active(session);
+}
+
+/**
+ * Check if bit is set in scheduler mask.
+ *
+ * @param mask Scheduler mask to check.
+ * @param bit Bit to check.
+ * @return MALI_TRUE if bit is set in scheduler mask, MALI_FALSE if not.
+ */
+MALI_STATIC_INLINE mali_bool mali_scheduler_mask_is_set(mali_scheduler_mask mask, mali_scheduler_mask bit)
+{
+	return MALI_SCHEDULER_MASK_EMPTY != (bit & mask);
+}
+
+/**
+ * Schedule GP and PP according to bitmask.
+ *
+ * @param mask A scheduling bitmask.
+ * @param deferred_schedule MALI_TRUE if schedule should be deferred, MALI_FALSE if not.
+ */
+void mali_scheduler_schedule_from_mask(mali_scheduler_mask mask, mali_bool deferred_schedule);
+
+/* Enable or disable scheduler hint. */
+extern mali_bool mali_scheduler_hints[MALI_SCHEDULER_HINT_MAX];
+
+MALI_STATIC_INLINE void mali_scheduler_hint_enable(mali_scheduler_hint hint)
+{
+	MALI_DEBUG_ASSERT(hint < MALI_SCHEDULER_HINT_MAX);
+	mali_scheduler_hints[hint] = MALI_TRUE;
+}
+
+MALI_STATIC_INLINE void mali_scheduler_hint_disable(mali_scheduler_hint hint)
+{
+	MALI_DEBUG_ASSERT(hint < MALI_SCHEDULER_HINT_MAX);
+	mali_scheduler_hints[hint] = MALI_FALSE;
+}
+
+MALI_STATIC_INLINE mali_bool mali_scheduler_hint_is_enabled(mali_scheduler_hint hint)
+{
+	MALI_DEBUG_ASSERT(hint < MALI_SCHEDULER_HINT_MAX);
+	return mali_scheduler_hints[hint];
+}
 
 #endif /* __MALI_SCHEDULER_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_session.c b/drivers/gpu/mali/mali/common/mali_session.c
old mode 100644
new mode 100755
index 05af4a1..6e9c2c1
--- a/drivers/gpu/mali/mali/common/mali_session.c
+++ b/drivers/gpu/mali/mali/common/mali_session.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,14 +13,15 @@
 #include "mali_session.h"
 
 _MALI_OSK_LIST_HEAD(mali_sessions);
+static u32 mali_session_count = 0;
 
-_mali_osk_lock_t *mali_sessions_lock;
+_mali_osk_spinlock_irq_t *mali_sessions_lock;
 
 _mali_osk_errcode_t mali_session_initialize(void)
 {
 	_MALI_OSK_INIT_LIST_HEAD(&mali_sessions);
 
-	mali_sessions_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_READERWRITER | _MALI_OSK_LOCKFLAG_ORDERED, 0, _MALI_OSK_LOCK_ORDER_SESSIONS);
+	mali_sessions_lock = _mali_osk_spinlock_irq_init(_MALI_OSK_LOCKFLAG_ORDERED, _MALI_OSK_LOCK_ORDER_SESSIONS);
 
 	if (NULL == mali_sessions_lock) return _MALI_OSK_ERR_NOMEM;
 
@@ -29,13 +30,14 @@ _mali_osk_errcode_t mali_session_initialize(void)
 
 void mali_session_terminate(void)
 {
-	_mali_osk_lock_term(mali_sessions_lock);
+	_mali_osk_spinlock_irq_term(mali_sessions_lock);
 }
 
 void mali_session_add(struct mali_session_data *session)
 {
 	mali_session_lock();
 	_mali_osk_list_add(&session->link, &mali_sessions);
+	mali_session_count++;
 	mali_session_unlock();
 }
 
@@ -43,5 +45,37 @@ void mali_session_remove(struct mali_session_data *session)
 {
 	mali_session_lock();
 	_mali_osk_list_delinit(&session->link);
+	mali_session_count--;
 	mali_session_unlock();
 }
+
+u32 mali_session_get_count(void)
+{
+	return mali_session_count;
+}
+
+/*
+ * Get the max completed window jobs from all active session,
+ * which will be used in window render frame per sec calculate
+ */
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+u32 mali_session_max_window_num(void)
+{
+	struct mali_session_data *session, *tmp;
+	u32 max_window_num = 0;
+	u32 tmp_number = 0;
+
+	mali_session_lock();
+
+	MALI_SESSION_FOREACH(session, tmp, link) {
+		tmp_number = _mali_osk_atomic_xchg(&session->number_of_window_jobs, 0);
+		if (max_window_num < tmp_number) {
+			max_window_num = tmp_number;
+		}
+	}
+
+	mali_session_unlock();
+
+	return max_window_num;
+}
+#endif
diff --git a/drivers/gpu/mali/mali/common/mali_session.h b/drivers/gpu/mali/mali/common/mali_session.h
old mode 100644
new mode 100755
index f8b5d58..d1a1a1b
--- a/drivers/gpu/mali/mali/common/mali_session.h
+++ b/drivers/gpu/mali/mali/common/mali_session.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,17 +16,36 @@
 #include "mali_osk.h"
 #include "mali_osk_list.h"
 
-struct mali_session_data
-{
-	_mali_osk_notification_queue_t * ioctl_queue;
+struct mali_timeline_system;
+struct mali_soft_system;
+
+/* Number of frame builder job lists per session. */
+#define MALI_PP_JOB_FB_LOOKUP_LIST_SIZE 16
+#define MALI_PP_JOB_FB_LOOKUP_LIST_MASK (MALI_PP_JOB_FB_LOOKUP_LIST_SIZE - 1)
+
+struct mali_session_data {
+	_mali_osk_notification_queue_t *ioctl_queue;
 
-	_mali_osk_lock_t *memory_lock; /**< Lock protecting the vm manipulation */
-	mali_descriptor_mapping * descriptor_mapping; /**< Mapping between userspace descriptors and our pointers */
+	_mali_osk_mutex_t *memory_lock; /**< Lock protecting the vm manipulation */
+	mali_descriptor_mapping *descriptor_mapping;  /**< Mapping between userspace descriptors and our pointers */
 	_mali_osk_list_t memory_head; /**< Track all the memory allocated in this session, for freeing on abnormal termination */
 
 	struct mali_page_directory *page_directory; /**< MMU page directory for this session */
 
 	_MALI_OSK_LIST_HEAD(link); /**< Link for list of all sessions */
+	_MALI_OSK_LIST_HEAD(pp_job_list); /**< List of all PP jobs on this session */
+
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	_mali_osk_atomic_t number_of_window_jobs; /**< Record the window jobs completed on this session in a period */
+#endif
+
+	_mali_osk_list_t pp_job_fb_lookup_list[MALI_PP_JOB_FB_LOOKUP_LIST_SIZE]; /**< List of PP job lists per frame builder id.  Used to link jobs from same frame builder. */
+
+	struct mali_soft_job_system *soft_job_system; /**< Soft job system for this session. */
+	struct mali_timeline_system *timeline_system; /**< Timeline system for this session. */
+
+	mali_bool is_aborting; /**< MALI_TRUE if the session is aborting, MALI_FALSE if not. */
+	mali_bool use_high_priority_job_queue; /**< If MALI_TRUE, jobs added from this session will use the high priority job queues. */
 };
 
 _mali_osk_errcode_t mali_session_initialize(void);
@@ -35,20 +54,22 @@ void mali_session_terminate(void);
 /* List of all sessions. Actual list head in mali_kernel_core.c */
 extern _mali_osk_list_t mali_sessions;
 /* Lock to protect modification and access to the mali_sessions list */
-extern _mali_osk_lock_t *mali_sessions_lock;
+extern _mali_osk_spinlock_irq_t *mali_sessions_lock;
 
 MALI_STATIC_INLINE void mali_session_lock(void)
 {
-	_mali_osk_lock_wait(mali_sessions_lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_spinlock_irq_lock(mali_sessions_lock);
 }
 
 MALI_STATIC_INLINE void mali_session_unlock(void)
 {
-	_mali_osk_lock_signal(mali_sessions_lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_spinlock_irq_unlock(mali_sessions_lock);
 }
 
 void mali_session_add(struct mali_session_data *session);
 void mali_session_remove(struct mali_session_data *session);
+u32 mali_session_get_count(void);
+
 #define MALI_SESSION_FOREACH(session, tmp, link) \
 	_MALI_OSK_LIST_FOREACHENTRY(session, tmp, &mali_sessions, struct mali_session_data, link)
 
@@ -62,4 +83,12 @@ MALI_STATIC_INLINE void mali_session_send_notification(struct mali_session_data
 	_mali_osk_notification_queue_send(session->ioctl_queue, object);
 }
 
+/*
+ * Get the max completed window jobs from all active session,
+ * which will be used in  window render frame per sec calculate
+ */
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+u32 mali_session_max_window_num(void);
+#endif
+
 #endif /* __MALI_SESSION_H__ */
diff --git a/drivers/gpu/mali/mali/common/mali_ukk.h b/drivers/gpu/mali/mali/common/mali_ukk.h
old mode 100644
new mode 100755
index 5e0f1bb..65858dc
--- a/drivers/gpu/mali/mali/common/mali_ukk.h
+++ b/drivers/gpu/mali/mali/common/mali_ukk.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,8 +20,7 @@
 #include "mali_uk_types.h"
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 /**
@@ -193,7 +192,7 @@ extern "C"
  * @param context pointer to storage to return a (void*)context handle.
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_open( void **context );
+_mali_osk_errcode_t _mali_ukk_open(void **context);
 
 /** @brief End a Mali Device Driver session
  *
@@ -204,7 +203,7 @@ _mali_osk_errcode_t _mali_ukk_open( void **context );
  * @param context pointer to a stored (void*)context handle.
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_close( void **context );
+_mali_osk_errcode_t _mali_ukk_close(void **context);
 
 /** @} */ /* end group _mali_uk_context */
 
@@ -218,55 +217,6 @@ _mali_osk_errcode_t _mali_ukk_close( void **context );
  *
  * @{ */
 
-/** @brief Returns the size of the buffer needed for a _mali_ukk_get_system_info call
- *
- * This function must be called before a call is made to
- * _mali_ukk_get_system_info, so that memory of the correct size can be
- * allocated, and a pointer to this memory written into the system_info member
- * of _mali_uk_get_system_info_s.
- *
- * @param args see _mali_uk_get_system_info_size_s in "mali_utgard_uk_types.h"
- * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
- */
-_mali_osk_errcode_t _mali_ukk_get_system_info_size( _mali_uk_get_system_info_size_s *args );
-
-/** @brief Returns information about the system (cores and memory banks)
- *
- * A buffer for this needs to be allocated by the caller. The size of the buffer required is returned by
- * _mali_ukk_get_system_info_size(). The user is responsible for freeing the buffer.
- *
- * The _mali_system_info structure will be written to the start of this buffer,
- * and the core_info and mem_info lists will be written to locations inside
- * the buffer, and will be suitably aligned.
- *
- * Under OS implementations of the U/K interface we need to pack/unpack
- * pointers across the user/kernel boundary. This has required that we malloc()
- * an intermediate buffer inside the kernel-side U/K interface, and free it
- * before returning to user-side. To avoid modifying common code, we do the
- * following pseudo-code, which we shall call 'pointer switching':
- *
- * @code
- * {
- *     Copy_From_User(kargs, args, ... );
- *     void __user * local_ptr = kargs->system_info;
- *     kargs->system_info = _mali_osk_malloc( ... );
- *     _mali_ukk_get_system_info( kargs );
- *     Copy_To_User( local_ptr, kargs->system_info, ... );
- *     _mali_osk_free( kargs->system_info );
- * }
- * @endcode
- * @note The user-side's args->system_info members was unmodified here.
- *
- * However, the current implementation requires an extra ukk_private word so that the common code can work out
- * how to patch pointers to user-mode for an OS's U/K implementation, this should be set to the user-space
- * destination address for pointer-patching to occur. When NULL, it is unused, an no pointer-patching occurs in the
- * common code.
- *
- * @param args see _mali_uk_get_system_info_s in "mali_utgard_uk_types.h"
- * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
- */
-_mali_osk_errcode_t _mali_ukk_get_system_info( _mali_uk_get_system_info_s *args );
-
 /** @brief Waits for a job notification.
  *
  * Sleeps until notified or a timeout occurs. Returns information about the notification.
@@ -274,34 +224,43 @@ _mali_osk_errcode_t _mali_ukk_get_system_info( _mali_uk_get_system_info_s *args
  * @param args see _mali_uk_wait_for_notification_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_wait_for_notification( _mali_uk_wait_for_notification_s *args );
+_mali_osk_errcode_t _mali_ukk_wait_for_notification(_mali_uk_wait_for_notification_s *args);
 
 /** @brief Post a notification to the notification queue of this application.
  *
  * @param args see _mali_uk_post_notification_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_post_notification( _mali_uk_post_notification_s *args );
+_mali_osk_errcode_t _mali_ukk_post_notification(_mali_uk_post_notification_s *args);
 
 /** @brief Verifies if the user and kernel side of this API are compatible.
  *
  * @param args see _mali_uk_get_api_version_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_get_api_version( _mali_uk_get_api_version_s *args );
+_mali_osk_errcode_t _mali_ukk_get_api_version(_mali_uk_get_api_version_s *args);
 
 /** @brief Get the user space settings applicable for calling process.
  *
  * @param args see _mali_uk_get_user_settings_s in "mali_utgard_uk_types.h"
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
 _mali_osk_errcode_t _mali_ukk_get_user_settings(_mali_uk_get_user_settings_s *args);
 
 /** @brief Get a user space setting applicable for calling process.
  *
  * @param args see _mali_uk_get_user_setting_s in "mali_utgard_uk_types.h"
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
 _mali_osk_errcode_t _mali_ukk_get_user_setting(_mali_uk_get_user_setting_s *args);
 
+/* @brief Grant or deny high priority scheduling for this session.
+ *
+ * @param args see _mali_uk_request_high_priority_s in "mali_utgard_uk_types.h"
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
+ */
+_mali_osk_errcode_t _mali_ukk_request_high_priority(_mali_uk_request_high_priority_s *args);
+
 /** @} */ /* end group _mali_uk_core */
 
 
@@ -320,37 +279,6 @@ _mali_osk_errcode_t _mali_ukk_get_user_setting(_mali_uk_get_user_setting_s *args
  *
  * @{ */
 
-/**
- * @brief Initialize the Mali-MMU Memory system
- *
- * For Mali-MMU builds of the drivers, this function must be called before any
- * other functions in the \ref _mali_uk_memory group are called.
- *
- * @note This function is for Mali-MMU builds \b only. It should not be called
- * when the drivers are built without Mali-MMU support.
- *
- * @param args see \ref _mali_uk_init_mem_s in mali_utgard_uk_types.h
- * @return _MALI_OSK_ERR_OK on success, otherwise a suitable
- * _mali_osk_errcode_t on failure.
- */
-_mali_osk_errcode_t _mali_ukk_init_mem( _mali_uk_init_mem_s *args );
-
-/**
- * @brief Terminate the MMU Memory system
- *
- * For Mali-MMU builds of the drivers, this function must be called when
- * functions in the \ref _mali_uk_memory group will no longer be called. This
- * function must be called before the application terminates.
- *
- * @note This function is for Mali-MMU builds \b only. It should not be called
- * when the drivers are built without Mali-MMU support.
- *
- * @param args see \ref _mali_uk_term_mem_s in mali_utgard_uk_types.h
- * @return _MALI_OSK_ERR_OK on success, otherwise a suitable
- * _mali_osk_errcode_t on failure.
- */
-_mali_osk_errcode_t _mali_ukk_term_mem( _mali_uk_term_mem_s *args );
-
 /** @brief Map Mali Memory into the current user process
  *
  * Maps Mali memory into the current user process in a generic way.
@@ -383,7 +311,7 @@ _mali_osk_errcode_t _mali_ukk_term_mem( _mali_uk_term_mem_s *args );
  * @param args see _mali_uk_mem_mmap_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_mem_mmap( _mali_uk_mem_mmap_s *args );
+_mali_osk_errcode_t _mali_ukk_mem_mmap(_mali_uk_mem_mmap_s *args);
 
 /** @brief Unmap Mali Memory from the current user process
  *
@@ -393,43 +321,49 @@ _mali_osk_errcode_t _mali_ukk_mem_mmap( _mali_uk_mem_mmap_s *args );
  * @param args see _mali_uk_mem_munmap_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_mem_munmap( _mali_uk_mem_munmap_s *args );
+_mali_osk_errcode_t _mali_ukk_mem_munmap(_mali_uk_mem_munmap_s *args);
 
 /** @brief Determine the buffer size necessary for an MMU page table dump.
  * @param args see _mali_uk_query_mmu_page_table_dump_size_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_query_mmu_page_table_dump_size( _mali_uk_query_mmu_page_table_dump_size_s *args );
+_mali_osk_errcode_t _mali_ukk_query_mmu_page_table_dump_size(_mali_uk_query_mmu_page_table_dump_size_s *args);
 /** @brief Dump MMU Page tables.
  * @param args see _mali_uk_dump_mmu_page_table_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_dump_mmu_page_table( _mali_uk_dump_mmu_page_table_s * args );
+_mali_osk_errcode_t _mali_ukk_dump_mmu_page_table(_mali_uk_dump_mmu_page_table_s *args);
+
+/** @brief Write user data to specified Mali memory without causing segfaults.
+ * @param args see _mali_uk_mem_write_safe_s in mali_utgard_uk_types.h
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
+ */
+_mali_osk_errcode_t _mali_ukk_mem_write_safe(_mali_uk_mem_write_safe_s *args);
 
 /** @brief Map a physically contiguous range of memory into Mali
  * @param args see _mali_uk_map_external_mem_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_map_external_mem( _mali_uk_map_external_mem_s *args );
+_mali_osk_errcode_t _mali_ukk_map_external_mem(_mali_uk_map_external_mem_s *args);
 
 /** @brief Unmap a physically contiguous range of memory from Mali
  * @param args see _mali_uk_unmap_external_mem_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_unmap_external_mem( _mali_uk_unmap_external_mem_s *args );
+_mali_osk_errcode_t _mali_ukk_unmap_external_mem(_mali_uk_unmap_external_mem_s *args);
 
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
+#if defined(CONFIG_MALI400_UMP)
 /** @brief Map UMP memory into Mali
  * @param args see _mali_uk_attach_ump_mem_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_attach_ump_mem( _mali_uk_attach_ump_mem_s *args );
+_mali_osk_errcode_t _mali_ukk_attach_ump_mem(_mali_uk_attach_ump_mem_s *args);
 /** @brief Unmap UMP memory from Mali
  * @param args see _mali_uk_release_ump_mem_s in mali_utgard_uk_types.h
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_release_ump_mem( _mali_uk_release_ump_mem_s *args );
-#endif /* MALI_USE_UNIFIED_MEMORY_PROVIDER */
+_mali_osk_errcode_t _mali_ukk_release_ump_mem(_mali_uk_release_ump_mem_s *args);
+#endif /* CONFIG_MALI400_UMP */
 
 /** @brief Determine virtual-to-physical mapping of a contiguous memory range
  * (optional)
@@ -472,7 +406,7 @@ _mali_osk_errcode_t _mali_ukk_release_ump_mem( _mali_uk_release_ump_mem_s *args
  * @param args see _mali_uk_va_to_mali_pa_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_va_to_mali_pa( _mali_uk_va_to_mali_pa_s * args );
+_mali_osk_errcode_t _mali_ukk_va_to_mali_pa(_mali_uk_va_to_mali_pa_s *args);
 
 /** @} */ /* end group _mali_uk_memory */
 
@@ -498,17 +432,29 @@ _mali_osk_errcode_t _mali_ukk_va_to_mali_pa( _mali_uk_va_to_mali_pa_s * args );
  *
  * Job completion can be awaited with _mali_ukk_wait_for_notification().
  *
- * @param args see _mali_uk_pp_start_job_s in "mali_utgard_uk_types.h"
+ * @param ctx user-kernel context (mali_session)
+ * @param uargs see _mali_uk_pp_start_job_s in "mali_utgard_uk_types.h". Use _mali_osk_copy_from_user to retrieve data!
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_pp_start_job( _mali_uk_pp_start_job_s *args );
+_mali_osk_errcode_t _mali_ukk_pp_start_job(void *ctx, _mali_uk_pp_start_job_s *uargs);
+
+/**
+ * @brief Issue a request to start new jobs on both Vertex Processor and Fragment Processor.
+ *
+ * @note Will call into @ref _mali_ukk_pp_start_job and @ref _mali_ukk_gp_start_job.
+ *
+ * @param ctx user-kernel context (mali_session)
+ * @param uargs see _mali_uk_pp_and_gp_start_job_s in "mali_utgard_uk_types.h". Use _mali_osk_copy_from_user to retrieve data!
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
+ */
+_mali_osk_errcode_t _mali_ukk_pp_and_gp_start_job(void *ctx, _mali_uk_pp_and_gp_start_job_s *uargs);
 
 /** @brief Returns the number of Fragment Processors in the system
  *
  * @param args see _mali_uk_get_pp_number_of_cores_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_get_pp_number_of_cores( _mali_uk_get_pp_number_of_cores_s *args );
+_mali_osk_errcode_t _mali_ukk_get_pp_number_of_cores(_mali_uk_get_pp_number_of_cores_s *args);
 
 /** @brief Returns the version that all Fragment Processor cores are compatible with.
  *
@@ -518,7 +464,7 @@ _mali_osk_errcode_t _mali_ukk_get_pp_number_of_cores( _mali_uk_get_pp_number_of_
  * @param args see _mali_uk_get_pp_core_version_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_get_pp_core_version( _mali_uk_get_pp_core_version_s *args );
+_mali_osk_errcode_t _mali_ukk_get_pp_core_version(_mali_uk_get_pp_core_version_s *args);
 
 /** @brief Disable Write-back unit(s) on specified job
  *
@@ -551,17 +497,18 @@ void _mali_ukk_pp_job_disable_wb(_mali_uk_pp_disable_wb_s *args);
  *
  * Job completion can be awaited with _mali_ukk_wait_for_notification().
  *
- * @param args see _mali_uk_gp_start_job_s in "mali_utgard_uk_types.h"
+ * @param ctx user-kernel context (mali_session)
+ * @param uargs see _mali_uk_gp_start_job_s in "mali_utgard_uk_types.h". Use _mali_osk_copy_from_user to retrieve data!
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_gp_start_job( _mali_uk_gp_start_job_s *args );
+_mali_osk_errcode_t _mali_ukk_gp_start_job(void *ctx, _mali_uk_gp_start_job_s *uargs);
 
 /** @brief Returns the number of Vertex Processors in the system.
  *
  * @param args see _mali_uk_get_gp_number_of_cores_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_get_gp_number_of_cores( _mali_uk_get_gp_number_of_cores_s *args );
+_mali_osk_errcode_t _mali_ukk_get_gp_number_of_cores(_mali_uk_get_gp_number_of_cores_s *args);
 
 /** @brief Returns the version that all Vertex Processor cores are compatible with.
  *
@@ -571,7 +518,7 @@ _mali_osk_errcode_t _mali_ukk_get_gp_number_of_cores( _mali_uk_get_gp_number_of_
  * @param args see _mali_uk_get_gp_core_version_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_get_gp_core_version( _mali_uk_get_gp_core_version_s *args );
+_mali_osk_errcode_t _mali_ukk_get_gp_core_version(_mali_uk_get_gp_core_version_s *args);
 
 /** @brief Resume or abort suspended Vertex Processor jobs.
  *
@@ -581,11 +528,11 @@ _mali_osk_errcode_t _mali_ukk_get_gp_core_version( _mali_uk_get_gp_core_version_
  * @param args see _mali_uk_gp_suspend_response_s in "mali_utgard_uk_types.h"
  * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
  */
-_mali_osk_errcode_t _mali_ukk_gp_suspend_response( _mali_uk_gp_suspend_response_s *args );
+_mali_osk_errcode_t _mali_ukk_gp_suspend_response(_mali_uk_gp_suspend_response_s *args);
 
 /** @} */ /* end group _mali_uk_gp */
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_PROFILING)
 /** @addtogroup _mali_uk_profiling U/K Timeline profiling module
  * @{ */
 
@@ -619,6 +566,13 @@ _mali_osk_errcode_t _mali_ukk_profiling_get_event(_mali_uk_profiling_get_event_s
  */
 _mali_osk_errcode_t _mali_ukk_profiling_clear(_mali_uk_profiling_clear_s *args);
 
+/** @brief Return the total memory usage
+ *
+ * @param args see _mali_uk_profiling_memory_usage_get_s in "mali_utgard_uk_types.h"
+ * @return _MALI_OSK_ERR_OK on success, otherwise a suitable _mali_osk_errcode_t on failure.
+ */
+_mali_osk_errcode_t _mali_ukk_profiling_memory_usage_get(_mali_uk_profiling_memory_usage_get_s *args);
+
 /** @} */ /* end group _mali_uk_profiling */
 #endif
 
@@ -654,6 +608,12 @@ _mali_osk_errcode_t _mali_ukk_sw_counters_report(_mali_uk_sw_counters_report_s *
 
 u32 _mali_ukk_report_memory_usage(void);
 
+u32 _mali_ukk_utilization_gp_pp(void);
+
+u32 _mali_ukk_utilization_gp(void);
+
+u32 _mali_ukk_utilization_pp(void);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/drivers/gpu/mali/mali/common/mali_user_settings_db.c b/drivers/gpu/mali/mali/common/mali_user_settings_db.c
old mode 100644
new mode 100755
index e37e6c3..b5d6521
--- a/drivers/gpu/mali/mali/common/mali_user_settings_db.c
+++ b/drivers/gpu/mali/mali/common/mali_user_settings_db.c
@@ -1,15 +1,16 @@
 /**
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
-#include "mali_osk.h"
 #include "mali_kernel_common.h"
+#include "mali_osk.h"
+#include "mali_ukk.h"
 #include "mali_uk_types.h"
 #include "mali_user_settings_db.h"
 #include "mali_session.h"
@@ -19,43 +20,104 @@ const char *_mali_uk_user_setting_descriptions[] = _MALI_UK_USER_SETTING_DESCRIP
 
 static void mali_user_settings_notify(_mali_uk_user_setting_t setting, u32 value)
 {
-	struct mali_session_data *session, *tmp;
-
-	mali_session_lock();
-	MALI_SESSION_FOREACH(session, tmp, link)
-	{
-		_mali_osk_notification_t *notobj = _mali_osk_notification_create(_MALI_NOTIFICATION_SETTINGS_CHANGED, sizeof(_mali_uk_settings_changed_s));
-		_mali_uk_settings_changed_s *data = notobj->result_buffer;
-		data->setting = setting;
-		data->value = value;
-
-		mali_session_send_notification(session, notobj);
+	mali_bool done = MALI_FALSE;
+
+	/*
+	 * This function gets a bit complicated because we can't hold the session lock while
+	 * allocating notification objects.
+	 */
+
+	while (!done) {
+		u32 i;
+		u32 num_sessions_alloc;
+		u32 num_sessions_with_lock;
+		u32 used_notification_objects = 0;
+		_mali_osk_notification_t **notobjs;
+
+		/* Pre allocate the number of notifications objects we need right now (might change after lock has been taken) */
+		num_sessions_alloc = mali_session_get_count();
+		if (0 == num_sessions_alloc) {
+			/* No sessions to report to */
+			return;
+		}
+
+		notobjs = (_mali_osk_notification_t **)_mali_osk_malloc(sizeof(_mali_osk_notification_t *) * num_sessions_alloc);
+		if (NULL == notobjs) {
+			MALI_PRINT_ERROR(("Failed to notify user space session about num PP core change (alloc failure)\n"));
+			return;
+		}
+
+		for (i = 0; i < num_sessions_alloc; i++) {
+			notobjs[i] = _mali_osk_notification_create(_MALI_NOTIFICATION_SETTINGS_CHANGED,
+					sizeof(_mali_uk_settings_changed_s));
+			if (NULL != notobjs[i]) {
+				_mali_uk_settings_changed_s *data;
+				data = notobjs[i]->result_buffer;
+
+				data->setting = setting;
+				data->value = value;
+			} else {
+				MALI_PRINT_ERROR(("Failed to notify user space session about setting change (alloc failure %u)\n", i));
+			}
+		}
+
+		mali_session_lock();
+
+		/* number of sessions will not change while we hold the lock */
+		num_sessions_with_lock = mali_session_get_count();
+
+		if (num_sessions_alloc >= num_sessions_with_lock) {
+			/* We have allocated enough notification objects for all the sessions atm */
+			struct mali_session_data *session, *tmp;
+			MALI_SESSION_FOREACH(session, tmp, link) {
+				MALI_DEBUG_ASSERT(used_notification_objects < num_sessions_alloc);
+				if (NULL != notobjs[used_notification_objects]) {
+					mali_session_send_notification(session, notobjs[used_notification_objects]);
+					notobjs[used_notification_objects] = NULL; /* Don't track this notification object any more */
+				}
+				used_notification_objects++;
+			}
+			done = MALI_TRUE;
+		}
+
+		mali_session_unlock();
+
+		/* Delete any remaining/unused notification objects */
+		for (; used_notification_objects < num_sessions_alloc; used_notification_objects++) {
+			if (NULL != notobjs[used_notification_objects]) {
+				_mali_osk_notification_delete(notobjs[used_notification_objects]);
+			}
+		}
+
+		_mali_osk_free(notobjs);
 	}
-	mali_session_unlock();
 }
 
 void mali_set_user_setting(_mali_uk_user_setting_t setting, u32 value)
 {
 	mali_bool notify = MALI_FALSE;
 
-	MALI_DEBUG_ASSERT(setting < _MALI_UK_USER_SETTING_MAX && setting >= 0);
+	if (setting >= _MALI_UK_USER_SETTING_MAX) {
+		MALI_DEBUG_PRINT_ERROR(("Invalid user setting %ud\n"));
+		return;
+	}
 
-	if (mali_user_settings[setting] != value)
-	{
+	if (mali_user_settings[setting] != value) {
 		notify = MALI_TRUE;
 	}
 
 	mali_user_settings[setting] = value;
 
-	if (notify)
-	{
+	if (notify) {
 		mali_user_settings_notify(setting, value);
 	}
 }
 
 u32 mali_get_user_setting(_mali_uk_user_setting_t setting)
 {
-	MALI_DEBUG_ASSERT(setting < _MALI_UK_USER_SETTING_MAX && setting >= 0);
+	if (setting >= _MALI_UK_USER_SETTING_MAX) {
+		return 0;
+	}
 
 	return mali_user_settings[setting];
 }
@@ -67,13 +129,10 @@ _mali_osk_errcode_t _mali_ukk_get_user_setting(_mali_uk_get_user_setting_s *args
 
 	setting = args->setting;
 
-	if (0 <= setting && _MALI_UK_USER_SETTING_MAX > setting)
-	{
+	if (_MALI_UK_USER_SETTING_MAX > setting) {
 		args->value = mali_user_settings[setting];
 		return _MALI_OSK_ERR_OK;
-	}
-	else
-	{
+	} else {
 		return _MALI_OSK_ERR_INVALID_ARGS;
 	}
 }
@@ -82,7 +141,7 @@ _mali_osk_errcode_t _mali_ukk_get_user_settings(_mali_uk_get_user_settings_s *ar
 {
 	MALI_DEBUG_ASSERT_POINTER(args);
 
-	_mali_osk_memcpy(args->settings, mali_user_settings, (sizeof(u32) * _MALI_UK_USER_SETTING_MAX));
+	_mali_osk_memcpy(args->settings, mali_user_settings, sizeof(mali_user_settings));
 
 	return _MALI_OSK_ERR_OK;
 }
diff --git a/drivers/gpu/mali/mali/common/mali_user_settings_db.h b/drivers/gpu/mali/mali/common/mali_user_settings_db.h
old mode 100644
new mode 100755
index 21edcc3..824e3e1
--- a/drivers/gpu/mali/mali/common/mali_user_settings_db.h
+++ b/drivers/gpu/mali/mali/common/mali_user_settings_db.h
@@ -1,9 +1,9 @@
 /**
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,8 +12,7 @@
 #define __MALI_USER_SETTINGS_DB_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 #include "mali_uk_types.h"
diff --git a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard.h b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard.h
old mode 100644
new mode 100755
index 8b94118..8a0e280
--- a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard.h
+++ b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard.h
@@ -1,15 +1,384 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 
+/**
+ * @file mali_utgard.h
+ * Defines types and interface exposed by the Mali Utgard device driver
+ */
+
 #ifndef __MALI_UTGARD_H__
-#define	__MALI_UTGARD_H__
+#define __MALI_UTGARD_H__
+
+#include "mali_osk_types.h"
+
+#define MALI_GPU_NAME_UTGARD "mali-utgard"
+
+/* Mali-200 */
+
+#define MALI_GPU_RESOURCES_MALI200(base_addr, gp_irq, pp_irq, mmu_irq) \
+	MALI_GPU_RESOURCE_PP(base_addr + 0x0000, pp_irq) \
+	MALI_GPU_RESOURCE_GP(base_addr + 0x2000, gp_irq) \
+	MALI_GPU_RESOURCE_MMU(base_addr + 0x3000, mmu_irq)
+
+/* Mali-300 */
+
+#define MALI_GPU_RESOURCES_MALI300(base_addr, gp_irq, gp_mmu_irq, pp_irq, pp_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP1(base_addr, gp_irq, gp_mmu_irq, pp_irq, pp_mmu_irq)
+
+#define MALI_GPU_RESOURCES_MALI300_PMU(base_addr, gp_irq, gp_mmu_irq, pp_irq, pp_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP1_PMU(base_addr, gp_irq, gp_mmu_irq, pp_irq, pp_mmu_irq)
+
+/* Mali-400 */
+
+#define MALI_GPU_RESOURCES_MALI400_MP1(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x1000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x0000, gp_irq, base_addr + 0x3000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x8000, pp0_irq, base_addr + 0x4000, pp0_mmu_irq)
+
+#define MALI_GPU_RESOURCES_MALI400_MP1_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP1(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000)
+
+#define MALI_GPU_RESOURCES_MALI400_MP2(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x1000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x0000, gp_irq, base_addr + 0x3000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x8000, pp0_irq, base_addr + 0x4000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0xA000, pp1_irq, base_addr + 0x5000, pp1_mmu_irq)
+
+#define MALI_GPU_RESOURCES_MALI400_MP2_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP2(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000)
+
+#define MALI_GPU_RESOURCES_MALI400_MP3(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x1000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x0000, gp_irq, base_addr + 0x3000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x8000, pp0_irq, base_addr + 0x4000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0xA000, pp1_irq, base_addr + 0x5000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0xC000, pp2_irq, base_addr + 0x6000, pp2_mmu_irq)
+
+#define MALI_GPU_RESOURCES_MALI400_MP3_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP3(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000)
+
+#define MALI_GPU_RESOURCES_MALI400_MP4(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x1000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x0000, gp_irq, base_addr + 0x3000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x8000, pp0_irq, base_addr + 0x4000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0xA000, pp1_irq, base_addr + 0x5000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0xC000, pp2_irq, base_addr + 0x6000, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(3, base_addr + 0xE000, pp3_irq, base_addr + 0x7000, pp3_mmu_irq)
+
+#define MALI_GPU_RESOURCES_MALI400_MP4_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq) \
+	MALI_GPU_RESOURCES_MALI400_MP4(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000)
+
+/* Mali-450 */
+#define MALI_GPU_RESOURCES_MALI450_MP2(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x10000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x00000, gp_irq, base_addr + 0x03000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x01000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x08000, pp0_irq, base_addr + 0x04000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0x0A000, pp1_irq, base_addr + 0x05000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_BCAST(base_addr + 0x13000) \
+	MALI_GPU_RESOURCE_DLBU(base_addr + 0x14000) \
+	MALI_GPU_RESOURCE_PP_BCAST(base_addr + 0x16000, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PP_MMU_BCAST(base_addr + 0x15000) \
+	MALI_GPU_RESOURCE_DMA(base_addr + 0x12000)
+
+#define MALI_GPU_RESOURCES_MALI450_MP2_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCES_MALI450_MP2(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000) \
+	 
+#define MALI_GPU_RESOURCES_MALI450_MP3(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x10000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x00000, gp_irq, base_addr + 0x03000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x01000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x08000, pp0_irq, base_addr + 0x04000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0x0A000, pp1_irq, base_addr + 0x05000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0x0C000, pp2_irq, base_addr + 0x06000, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_BCAST(base_addr + 0x13000) \
+	MALI_GPU_RESOURCE_DLBU(base_addr + 0x14000) \
+	MALI_GPU_RESOURCE_PP_BCAST(base_addr + 0x16000, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PP_MMU_BCAST(base_addr + 0x15000)
+
+#define MALI_GPU_RESOURCES_MALI450_MP3_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCES_MALI450_MP3(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000) \
+	 
+#define MALI_GPU_RESOURCES_MALI450_MP4(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x10000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x00000, gp_irq, base_addr + 0x03000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x01000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x08000, pp0_irq, base_addr + 0x04000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0x0A000, pp1_irq, base_addr + 0x05000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0x0C000, pp2_irq, base_addr + 0x06000, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(3, base_addr + 0x0E000, pp3_irq, base_addr + 0x07000, pp3_mmu_irq) \
+	MALI_GPU_RESOURCE_BCAST(base_addr + 0x13000) \
+	MALI_GPU_RESOURCE_DLBU(base_addr + 0x14000) \
+	MALI_GPU_RESOURCE_PP_BCAST(base_addr + 0x16000, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PP_MMU_BCAST(base_addr + 0x15000) \
+	MALI_GPU_RESOURCE_DMA(base_addr + 0x12000)
+
+#define MALI_GPU_RESOURCES_MALI450_MP4_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCES_MALI450_MP4(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000) \
+	 
+#define MALI_GPU_RESOURCES_MALI450_MP6(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x10000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x00000, gp_irq, base_addr + 0x03000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x01000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x08000, pp0_irq, base_addr + 0x04000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0x0A000, pp1_irq, base_addr + 0x05000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0x0C000, pp2_irq, base_addr + 0x06000, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x11000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(3, base_addr + 0x28000, pp3_irq, base_addr + 0x1C000, pp3_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(4, base_addr + 0x2A000, pp4_irq, base_addr + 0x1D000, pp4_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(5, base_addr + 0x2C000, pp5_irq, base_addr + 0x1E000, pp5_mmu_irq) \
+	MALI_GPU_RESOURCE_BCAST(base_addr + 0x13000) \
+	MALI_GPU_RESOURCE_DLBU(base_addr + 0x14000) \
+	MALI_GPU_RESOURCE_PP_BCAST(base_addr + 0x16000, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PP_MMU_BCAST(base_addr + 0x15000) \
+	MALI_GPU_RESOURCE_DMA(base_addr + 0x12000)
+
+#define MALI_GPU_RESOURCES_MALI450_MP6_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCES_MALI450_MP6(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000) \
+	 
+#define MALI_GPU_RESOURCES_MALI450_MP8(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp6_irq, pp6_mmu_irq, pp7_irq, pp7_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x10000) \
+	MALI_GPU_RESOURCE_GP_WITH_MMU(base_addr + 0x00000, gp_irq, base_addr + 0x03000, gp_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x01000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(0, base_addr + 0x08000, pp0_irq, base_addr + 0x04000, pp0_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(1, base_addr + 0x0A000, pp1_irq, base_addr + 0x05000, pp1_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(2, base_addr + 0x0C000, pp2_irq, base_addr + 0x06000, pp2_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(3, base_addr + 0x0E000, pp3_irq, base_addr + 0x07000, pp3_mmu_irq) \
+	MALI_GPU_RESOURCE_L2(base_addr + 0x11000) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(4, base_addr + 0x28000, pp4_irq, base_addr + 0x1C000, pp4_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(5, base_addr + 0x2A000, pp5_irq, base_addr + 0x1D000, pp5_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(6, base_addr + 0x2C000, pp6_irq, base_addr + 0x1E000, pp6_mmu_irq) \
+	MALI_GPU_RESOURCE_PP_WITH_MMU(7, base_addr + 0x2E000, pp7_irq, base_addr + 0x1F000, pp7_mmu_irq) \
+	MALI_GPU_RESOURCE_BCAST(base_addr + 0x13000) \
+	MALI_GPU_RESOURCE_DLBU(base_addr + 0x14000) \
+	MALI_GPU_RESOURCE_PP_BCAST(base_addr + 0x16000, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PP_MMU_BCAST(base_addr + 0x15000) \
+	MALI_GPU_RESOURCE_DMA(base_addr + 0x12000)
+
+#define MALI_GPU_RESOURCES_MALI450_MP8_PMU(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp6_irq, pp6_mmu_irq, pp7_irq, pp7_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCES_MALI450_MP8(base_addr, gp_irq, gp_mmu_irq, pp0_irq, pp0_mmu_irq, pp1_irq, pp1_mmu_irq, pp2_irq, pp2_mmu_irq, pp3_irq, pp3_mmu_irq, pp4_irq, pp4_mmu_irq, pp5_irq, pp5_mmu_irq, pp6_irq, pp6_mmu_irq, pp7_irq, pp7_mmu_irq, pp_bcast_irq) \
+	MALI_GPU_RESOURCE_PMU(base_addr + 0x2000) \
+	 
+#define MALI_GPU_RESOURCE_L2(addr) \
+	{ \
+		.name = "Mali_L2", \
+			.flags = IORESOURCE_MEM, \
+				 .start = addr, \
+					  .end   = addr + 0x200, \
+	},
+
+#define MALI_GPU_RESOURCE_GP(gp_addr, gp_irq) \
+	{ \
+		.name = "Mali_GP", \
+			.flags = IORESOURCE_MEM, \
+				 .start = gp_addr, \
+					  .end =   gp_addr + 0x100, \
+	}, \
+	{ \
+		.name = "Mali_GP_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = gp_irq, \
+					  .end   = gp_irq, \
+	}, \
+	 
+#define MALI_GPU_RESOURCE_GP_WITH_MMU(gp_addr, gp_irq, gp_mmu_addr, gp_mmu_irq) \
+	{ \
+		.name = "Mali_GP", \
+			.flags = IORESOURCE_MEM, \
+				 .start = gp_addr, \
+					  .end =   gp_addr + 0x100, \
+	}, \
+	{ \
+		.name = "Mali_GP_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = gp_irq, \
+					  .end   = gp_irq, \
+	}, \
+	{ \
+		.name = "Mali_GP_MMU", \
+			.flags = IORESOURCE_MEM, \
+				 .start = gp_mmu_addr, \
+					  .end =   gp_mmu_addr + 0x100, \
+	}, \
+	{ \
+		.name = "Mali_GP_MMU_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = gp_mmu_irq, \
+					  .end =   gp_mmu_irq, \
+	},
+
+#define MALI_GPU_RESOURCE_PP(pp_addr, pp_irq) \
+	{ \
+		.name = "Mali_PP", \
+			.flags = IORESOURCE_MEM, \
+				 .start = pp_addr, \
+					  .end =   pp_addr + 0x1100, \
+	}, \
+	{ \
+		.name = "Mali_PP_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = pp_irq, \
+					  .end =   pp_irq, \
+	}, \
+	 
+#define MALI_GPU_RESOURCE_PP_WITH_MMU(id, pp_addr, pp_irq, pp_mmu_addr, pp_mmu_irq) \
+	{ \
+		.name = "Mali_PP" #id, \
+			.flags = IORESOURCE_MEM, \
+				 .start = pp_addr, \
+					  .end =   pp_addr + 0x1100, \
+	}, \
+	{ \
+		.name = "Mali_PP" #id "_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = pp_irq, \
+					  .end =   pp_irq, \
+	}, \
+	{ \
+		.name = "Mali_PP" #id "_MMU", \
+			.flags = IORESOURCE_MEM, \
+				 .start = pp_mmu_addr, \
+					  .end =   pp_mmu_addr + 0x100, \
+	}, \
+	{ \
+		.name = "Mali_PP" #id "_MMU_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = pp_mmu_irq, \
+					  .end =   pp_mmu_irq, \
+	},
+
+#define MALI_GPU_RESOURCE_MMU(mmu_addr, mmu_irq) \
+	{ \
+		.name = "Mali_MMU", \
+			.flags = IORESOURCE_MEM, \
+				 .start = mmu_addr, \
+					  .end =   mmu_addr + 0x100, \
+	}, \
+	{ \
+		.name = "Mali_MMU_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = mmu_irq, \
+					  .end =   mmu_irq, \
+	},
+
+#define MALI_GPU_RESOURCE_PMU(pmu_addr) \
+	{ \
+		.name = "Mali_PMU", \
+			.flags = IORESOURCE_MEM, \
+				 .start = pmu_addr, \
+					  .end =   pmu_addr + 0x100, \
+	},
+
+#define MALI_GPU_RESOURCE_DMA(dma_addr) \
+	{ \
+		.name = "Mali_DMA", \
+			.flags = IORESOURCE_MEM, \
+				 .start = dma_addr, \
+					  .end = dma_addr + 0x100, \
+	},
+
+#define MALI_GPU_RESOURCE_DLBU(dlbu_addr) \
+	{ \
+		.name = "Mali_DLBU", \
+			.flags = IORESOURCE_MEM, \
+				 .start = dlbu_addr, \
+					  .end = dlbu_addr + 0x100, \
+	},
+
+#define MALI_GPU_RESOURCE_BCAST(bcast_addr) \
+	{ \
+		.name = "Mali_Broadcast", \
+			.flags = IORESOURCE_MEM, \
+				 .start = bcast_addr, \
+					  .end = bcast_addr + 0x100, \
+	},
+
+#define MALI_GPU_RESOURCE_PP_BCAST(pp_addr, pp_irq) \
+	{ \
+		.name = "Mali_PP_Broadcast", \
+			.flags = IORESOURCE_MEM, \
+				 .start = pp_addr, \
+					  .end =   pp_addr + 0x1100, \
+	}, \
+	{ \
+		.name = "Mali_PP_Broadcast_IRQ", \
+			.flags = IORESOURCE_IRQ, \
+				 .start = pp_irq, \
+					  .end =   pp_irq, \
+	}, \
+	 
+#define MALI_GPU_RESOURCE_PP_MMU_BCAST(pp_mmu_bcast_addr) \
+	{ \
+		.name = "Mali_PP_MMU_Broadcast", \
+			.flags = IORESOURCE_MEM, \
+				 .start = pp_mmu_bcast_addr, \
+					  .end = pp_mmu_bcast_addr + 0x100, \
+	},
+
+struct mali_gpu_utilization_data {
+	unsigned int utilization_gpu; /* Utilization for GP and all PP cores combined, 0 = no utilization, 256 = full utilization */
+	unsigned int utilization_gp;  /* Utilization for GP core only, 0 = no utilization, 256 = full utilization */
+	unsigned int utilization_pp;  /* Utilization for all PP cores combined, 0 = no utilization, 256 = full utilization */
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+	unsigned int number_of_window_jobs;
+	unsigned int number_of_window_jobs_under_pressure;
+#endif
+};
+
+struct mali_gpu_device_data {
+	/* Dedicated GPU memory range (physical). */
+	unsigned long dedicated_mem_start;
+	unsigned long dedicated_mem_size;
+
+	/* Shared GPU memory */
+	unsigned long shared_mem_size;
+
+	/* Frame buffer memory to be accessible by Mali GPU (physical) */
+	unsigned long fb_start;
+	unsigned long fb_size;
+
+	/* Max runtime [ms] for jobs */
+	int max_job_runtime;
+
+	/* Report GPU utilization in this interval (specified in ms) */
+	unsigned long utilization_interval;
+
+	/* Function that will receive periodic GPU utilization numbers */
+	void (*utilization_callback)(struct mali_gpu_utilization_data *data);
+
+	/*
+	 * Mali PMU switch delay.
+	 * Only needed if the power gates are connected to the PMU in a high fanout
+	 * network. This value is the number of Mali clock cycles it takes to
+	 * enable the power gates and turn on the power mesh.
+	 * This value will have no effect if a daisy chain implementation is used.
+	 */
+	u32 pmu_switch_delay;
+
+
+	/* Mali Dynamic power domain configuration in sequence from 0-11
+	 *  GP  PP0 PP1  PP2  PP3  PP4  PP5  PP6  PP7, L2$0 L2$1 L2$2
+	 */
+	u16 pmu_domain_config[12];
+
+	/* Fuction that platform callback for freq tunning, needed when POWER_PERFORMANCE_POLICY enabled*/
+	int (*set_freq_callback)(unsigned int mhz);
+};
 
 /** @brief MALI GPU power down using MALI in-built PMU
  *
@@ -24,4 +393,26 @@ int mali_pmu_powerdown(void);
  */
 int mali_pmu_powerup(void);
 
-#endif /* __MALI_UTGARD_H__ */
+/**
+ * Pause the scheduling and power state changes of Mali device driver.
+ * mali_dev_resume() must always be called as soon as possible after this function
+ * in order to resume normal operation of the Mali driver.
+ */
+void mali_dev_pause(void);
+
+/**
+ * Resume scheduling and allow power changes in Mali device driver.
+ * This must always be called after mali_dev_pause().
+ */
+void mali_dev_resume(void);
+
+/** @brief Set the desired number of PP cores to use.
+ *
+ * The internal Mali PMU will be used, if present, to physically power off the PP cores.
+ *
+ * @param num_cores The number of desired cores
+ * @return 0 on success, otherwise error. -EINVAL means an invalid number of cores was specified.
+ */
+int mali_perf_set_num_pp_cores(unsigned int num_cores);
+
+#endif
diff --git a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_counters.h b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_counters.h
old mode 100644
new mode 100755
index 832e5d4..b3caaa1
--- a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_counters.h
+++ b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_counters.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,13 +11,11 @@
 #ifndef _MALI_UTGARD_COUNTERS_H_
 #define _MALI_UTGARD_COUNTERS_H_
 
-typedef struct
-{
+typedef struct {
 	void *unused;
 } mali_cinstr_counter_info;
 
-typedef enum
-{
+typedef enum {
 	MALI_CINSTR_COUNTER_SOURCE_EGL      =     0,
 	MALI_CINSTR_COUNTER_SOURCE_OPENGLES =  1000,
 	MALI_CINSTR_COUNTER_SOURCE_OPENVG   =  2000,
@@ -41,8 +39,7 @@ typedef enum
 #define MALI_CINSTR_PP_LAST_COUNTER (MALI_CINSTR_COUNTER_SOURCE_PP + 999)
 
 
-typedef enum
-{
+typedef enum {
 	/* EGL counters */
 
 	MALI_CINSTR_EGL_BLIT_TIME                                            = MALI_CINSTR_COUNTER_SOURCE_EGL + 0,
@@ -212,7 +209,7 @@ typedef enum
 	MALI_CINSTR_PP_RSW_READS                                             = MALI_CINSTR_COUNTER_SOURCE_PP + 15,
 	MALI_CINSTR_PP_VERTEX_CACHE_READS                                    = MALI_CINSTR_COUNTER_SOURCE_PP + 16,
 	MALI_CINSTR_PP_UNIFORM_REMAPPING_READS                               = MALI_CINSTR_COUNTER_SOURCE_PP + 17,
-	MALI_CINSTR_PP_PROGRAM_CACHE_READS                                   = MALI_CINSTR_COUNTER_SOURCE_PP + 19,
+	MALI_CINSTR_PP_PROGRAM_CACHE_READS                                   = MALI_CINSTR_COUNTER_SOURCE_PP + 18,
 	MALI_CINSTR_PP_VARYING_READS                                         = MALI_CINSTR_COUNTER_SOURCE_PP + 19,
 	MALI_CINSTR_PP_TEXTURE_DESCRIPTORS_READS                             = MALI_CINSTR_COUNTER_SOURCE_PP + 20,
 	MALI_CINSTR_PP_TEXTURE_DESCRIPTORS_REMAPPING_READS                   = MALI_CINSTR_COUNTER_SOURCE_PP + 21,
diff --git a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_ioctl.h b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_ioctl.h
old mode 100644
new mode 100755
index 01bb9d6..a72129e
--- a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_ioctl.h
+++ b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_ioctl.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,8 +16,7 @@
 #include <linux/fs.h>       /* file system operations */
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 /**
@@ -39,31 +38,40 @@ extern "C"
 #define MALI_IOC_PROFILING_BASE (_MALI_UK_PROFILING_SUBSYSTEM + MALI_IOC_BASE)
 #define MALI_IOC_VSYNC_BASE     (_MALI_UK_VSYNC_SUBSYSTEM + MALI_IOC_BASE)
 
-#define MALI_IOC_GET_SYSTEM_INFO_SIZE       _IOR (MALI_IOC_CORE_BASE, _MALI_UK_GET_SYSTEM_INFO_SIZE, _mali_uk_get_system_info_s *)
-#define MALI_IOC_GET_SYSTEM_INFO            _IOR (MALI_IOC_CORE_BASE, _MALI_UK_GET_SYSTEM_INFO, _mali_uk_get_system_info_s *)
 #define MALI_IOC_WAIT_FOR_NOTIFICATION      _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_WAIT_FOR_NOTIFICATION, _mali_uk_wait_for_notification_s *)
 #define MALI_IOC_GET_API_VERSION            _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_GET_API_VERSION, _mali_uk_get_api_version_s *)
 #define MALI_IOC_POST_NOTIFICATION          _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_POST_NOTIFICATION, _mali_uk_post_notification_s *)
 #define MALI_IOC_GET_USER_SETTING           _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_GET_USER_SETTING, _mali_uk_get_user_setting_s *)
 #define MALI_IOC_GET_USER_SETTINGS          _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_GET_USER_SETTINGS, _mali_uk_get_user_settings_s *)
-#define MALI_IOC_MEM_GET_BIG_BLOCK          _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_GET_BIG_BLOCK, void *)
-#define MALI_IOC_MEM_FREE_BIG_BLOCK         _IOW (MALI_IOC_MEMORY_BASE, _MALI_UK_FREE_BIG_BLOCK, void *)
-#define MALI_IOC_MEM_INIT                   _IOR (MALI_IOC_MEMORY_BASE, _MALI_UK_INIT_MEM, _mali_uk_init_mem_s *)
-#define MALI_IOC_MEM_TERM                   _IOW (MALI_IOC_MEMORY_BASE, _MALI_UK_TERM_MEM, _mali_uk_term_mem_s *)
+#define MALI_IOC_REQUEST_HIGH_PRIORITY      _IOW (MALI_IOC_CORE_BASE, _MALI_UK_REQUEST_HIGH_PRIORITY, _mali_uk_request_high_priority_s *)
+#define MALI_IOC_TIMELINE_GET_LATEST_POINT  _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_TIMELINE_GET_LATEST_POINT, _mali_uk_timeline_get_latest_point_s *)
+#define MALI_IOC_TIMELINE_WAIT              _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_TIMELINE_WAIT, _mali_uk_timeline_wait_s *)
+#define MALI_IOC_TIMELINE_CREATE_SYNC_FENCE _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_TIMELINE_CREATE_SYNC_FENCE, _mali_uk_timeline_create_sync_fence_s *)
+#define MALI_IOC_SOFT_JOB_START             _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_SOFT_JOB_START, _mali_uk_soft_job_start_s *)
+#define MALI_IOC_SOFT_JOB_SIGNAL            _IOWR(MALI_IOC_CORE_BASE, _MALI_UK_SOFT_JOB_SIGNAL, _mali_uk_soft_job_signal_s *)
+
 #define MALI_IOC_MEM_MAP_EXT                _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_MAP_EXT_MEM, _mali_uk_map_external_mem_s *)
 #define MALI_IOC_MEM_UNMAP_EXT              _IOW (MALI_IOC_MEMORY_BASE, _MALI_UK_UNMAP_EXT_MEM, _mali_uk_unmap_external_mem_s *)
-#define MALI_IOC_MEM_QUERY_MMU_PAGE_TABLE_DUMP_SIZE _IOR (MALI_IOC_MEMORY_BASE, _MALI_UK_QUERY_MMU_PAGE_TABLE_DUMP_SIZE, _mali_uk_query_mmu_page_table_dump_size_s *)
-#define MALI_IOC_MEM_DUMP_MMU_PAGE_TABLE    _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_DUMP_MMU_PAGE_TABLE, _mali_uk_dump_mmu_page_table_s *)
+#define MALI_IOC_MEM_ATTACH_DMA_BUF         _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_ATTACH_DMA_BUF, _mali_uk_attach_dma_buf_s *)
+#define MALI_IOC_MEM_RELEASE_DMA_BUF        _IOW(MALI_IOC_MEMORY_BASE, _MALI_UK_RELEASE_DMA_BUF, _mali_uk_release_dma_buf_s *)
+#define MALI_IOC_MEM_DMA_BUF_GET_SIZE       _IOR(MALI_IOC_MEMORY_BASE, _MALI_UK_DMA_BUF_GET_SIZE, _mali_uk_dma_buf_get_size_s *)
 #define MALI_IOC_MEM_ATTACH_UMP             _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_ATTACH_UMP_MEM, _mali_uk_attach_ump_mem_s *)
 #define MALI_IOC_MEM_RELEASE_UMP            _IOW(MALI_IOC_MEMORY_BASE, _MALI_UK_RELEASE_UMP_MEM, _mali_uk_release_ump_mem_s *)
+#define MALI_IOC_MEM_QUERY_MMU_PAGE_TABLE_DUMP_SIZE _IOR (MALI_IOC_MEMORY_BASE, _MALI_UK_QUERY_MMU_PAGE_TABLE_DUMP_SIZE, _mali_uk_query_mmu_page_table_dump_size_s *)
+#define MALI_IOC_MEM_DUMP_MMU_PAGE_TABLE    _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_DUMP_MMU_PAGE_TABLE, _mali_uk_dump_mmu_page_table_s *)
+#define MALI_IOC_MEM_WRITE_SAFE             _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_MEM_WRITE_SAFE, _mali_uk_mem_write_safe_s *)
+
 #define MALI_IOC_PP_START_JOB               _IOWR(MALI_IOC_PP_BASE, _MALI_UK_PP_START_JOB, _mali_uk_pp_start_job_s *)
-#define MALI_IOC_PP_NUMBER_OF_CORES_GET	    _IOR (MALI_IOC_PP_BASE, _MALI_UK_GET_PP_NUMBER_OF_CORES, _mali_uk_get_pp_number_of_cores_s *)
-#define MALI_IOC_PP_CORE_VERSION_GET	    _IOR (MALI_IOC_PP_BASE, _MALI_UK_GET_PP_CORE_VERSION, _mali_uk_get_pp_core_version_s * )
+#define MALI_IOC_PP_AND_GP_START_JOB        _IOWR(MALI_IOC_PP_BASE, _MALI_UK_PP_AND_GP_START_JOB, _mali_uk_pp_and_gp_start_job_s *)
+#define MALI_IOC_PP_NUMBER_OF_CORES_GET     _IOR (MALI_IOC_PP_BASE, _MALI_UK_GET_PP_NUMBER_OF_CORES, _mali_uk_get_pp_number_of_cores_s *)
+#define MALI_IOC_PP_CORE_VERSION_GET        _IOR (MALI_IOC_PP_BASE, _MALI_UK_GET_PP_CORE_VERSION, _mali_uk_get_pp_core_version_s * )
 #define MALI_IOC_PP_DISABLE_WB              _IOW (MALI_IOC_PP_BASE, _MALI_UK_PP_DISABLE_WB, _mali_uk_pp_disable_wb_s * )
+
 #define MALI_IOC_GP2_START_JOB              _IOWR(MALI_IOC_GP_BASE, _MALI_UK_GP_START_JOB, _mali_uk_gp_start_job_s *)
 #define MALI_IOC_GP2_NUMBER_OF_CORES_GET    _IOR (MALI_IOC_GP_BASE, _MALI_UK_GET_GP_NUMBER_OF_CORES, _mali_uk_get_gp_number_of_cores_s *)
-#define MALI_IOC_GP2_CORE_VERSION_GET	    _IOR (MALI_IOC_GP_BASE, _MALI_UK_GET_GP_CORE_VERSION, _mali_uk_get_gp_core_version_s *)
-#define MALI_IOC_GP2_SUSPEND_RESPONSE	    _IOW (MALI_IOC_GP_BASE, _MALI_UK_GP_SUSPEND_RESPONSE,_mali_uk_gp_suspend_response_s *)
+#define MALI_IOC_GP2_CORE_VERSION_GET       _IOR (MALI_IOC_GP_BASE, _MALI_UK_GET_GP_CORE_VERSION, _mali_uk_get_gp_core_version_s *)
+#define MALI_IOC_GP2_SUSPEND_RESPONSE       _IOW (MALI_IOC_GP_BASE, _MALI_UK_GP_SUSPEND_RESPONSE,_mali_uk_gp_suspend_response_s *)
+
 #define MALI_IOC_PROFILING_START            _IOWR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_START, _mali_uk_profiling_start_s *)
 #define MALI_IOC_PROFILING_ADD_EVENT        _IOWR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_ADD_EVENT, _mali_uk_profiling_add_event_s*)
 #define MALI_IOC_PROFILING_STOP             _IOWR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_STOP, _mali_uk_profiling_stop_s *)
@@ -71,8 +79,16 @@ extern "C"
 #define MALI_IOC_PROFILING_CLEAR            _IOWR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_CLEAR, _mali_uk_profiling_clear_s *)
 #define MALI_IOC_PROFILING_GET_CONFIG       _IOWR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_GET_CONFIG, _mali_uk_get_user_settings_s *)
 #define MALI_IOC_PROFILING_REPORT_SW_COUNTERS  _IOW (MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_REPORT_SW_COUNTERS, _mali_uk_sw_counters_report_s *)
+#define MALI_IOC_PROFILING_MEMORY_USAGE_GET _IOR(MALI_IOC_PROFILING_BASE, _MALI_UK_PROFILING_MEMORY_USAGE_GET, _mali_uk_profiling_memory_usage_get_s *)
+
 #define MALI_IOC_VSYNC_EVENT_REPORT         _IOW (MALI_IOC_VSYNC_BASE, _MALI_UK_VSYNC_EVENT_REPORT, _mali_uk_vsync_event_report_s *)
 
+/* Deprecated ioctls */
+#define MALI_IOC_MEM_GET_BIG_BLOCK          _IOWR(MALI_IOC_MEMORY_BASE, _MALI_UK_GET_BIG_BLOCK, void *)
+#define MALI_IOC_MEM_FREE_BIG_BLOCK         _IOW (MALI_IOC_MEMORY_BASE, _MALI_UK_FREE_BIG_BLOCK, void *)
+#define MALI_IOC_MEM_INIT                   _IOR (MALI_IOC_MEMORY_BASE, _MALI_UK_INIT_MEM, void *)
+#define MALI_IOC_MEM_TERM                   _IOW (MALI_IOC_MEMORY_BASE, _MALI_UK_TERM_MEM, void *)
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_profiling_events.h b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_profiling_events.h
old mode 100644
new mode 100755
index 3da99a3..ed3d46c
--- a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_profiling_events.h
+++ b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_profiling_events.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -22,8 +22,7 @@
 /**
  * Specifies what kind of event this is
  */
-typedef enum
-{
+typedef enum {
 	MALI_PROFILING_EVENT_TYPE_SINGLE  = 0 << 24,
 	MALI_PROFILING_EVENT_TYPE_START   = 1 << 24,
 	MALI_PROFILING_EVENT_TYPE_STOP    = 2 << 24,
@@ -35,8 +34,7 @@ typedef enum
 /**
  * Secifies the channel/source of the event
  */
-typedef enum
-{
+typedef enum {
 	MALI_PROFILING_EVENT_CHANNEL_SOFTWARE =  0 << 16,
 	MALI_PROFILING_EVENT_CHANNEL_GP0      =  1 << 16,
 	MALI_PROFILING_EVENT_CHANNEL_PP0      =  5 << 16,
@@ -57,53 +55,85 @@ typedef enum
 /**
  * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_SINGLE is used from software channel
  */
-typedef enum
-{
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_NONE             = 0,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_NEW_FRAME    = 1,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_FLUSH            = 2,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_SWAP_BUFFERS = 3,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_FB_EVENT         = 4,
-    MALI_PROFILING_EVENT_REASON_SINGLE_SW_ENTER_API_FUNC   = 10,
-    MALI_PROFILING_EVENT_REASON_SINGLE_SW_LEAVE_API_FUNC   = 11,
-   MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_TRY_LOCK    = 53,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_LOCK        = 54,
-	MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_UNLOCK      = 55,
+typedef enum {
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_NONE                  = 0,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_NEW_FRAME         = 1,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_FLUSH                 = 2,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_SWAP_BUFFERS      = 3,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_FB_EVENT              = 4,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_GP_ENQUEUE            = 5,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_PP_ENQUEUE            = 6,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_READBACK              = 7,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_WRITEBACK             = 8,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_ENTER_API_FUNC        = 10,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_LEAVE_API_FUNC        = 11,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_DISCARD_ATTACHMENTS   = 13,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_TRY_LOCK          = 53,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_LOCK              = 54,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_UMP_UNLOCK            = 55,
+	MALI_PROFILING_EVENT_REASON_SINGLE_LOCK_CONTENDED           = 56,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_MALI_FENCE_DUP    = 57,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_SET_PP_JOB_FENCE  = 58,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_WAIT_SYNC         = 59,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_CREATE_FENCE_SYNC = 60,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_CREATE_NATIVE_FENCE_SYNC = 61,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_FENCE_FLUSH       = 62,
+	MALI_PROFILING_EVENT_REASON_SINGLE_SW_EGL_FLUSH_SERVER_WAITS = 63,
 } cinstr_profiling_event_reason_single_sw_t;
 
 /**
  * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_START/STOP is used from software channel
+ * to inform whether the core is physical or virtual
  */
-typedef enum
-{
-	MALI_PROFILING_EVENT_REASON_START_STOP_SW_NONE      = 0,
-	MALI_PROFILING_EVENT_REASON_START_STOP_MALI         = 1,
+typedef enum {
+	MALI_PROFILING_EVENT_REASON_START_STOP_HW_PHYSICAL  = 0,
+	MALI_PROFILING_EVENT_REASON_START_STOP_HW_VIRTUAL   = 1,
+} cinstr_profiling_event_reason_start_stop_hw_t;
+
+/**
+ * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_START/STOP is used from software channel
+ */
+typedef enum {
+	/*MALI_PROFILING_EVENT_REASON_START_STOP_SW_NONE            = 0,*/
+	MALI_PROFILING_EVENT_REASON_START_STOP_SW_MALI            = 1,
+	MALI_PROFILING_EVENT_REASON_START_STOP_SW_CALLBACK_THREAD = 2,
+	MALI_PROFILING_EVENT_REASON_START_STOP_SW_WORKER_THREAD   = 3,
+	MALI_PROFILING_EVENT_REASON_START_STOP_SW_BOTTOM_HALF     = 4,
+	MALI_PROFILING_EVENT_REASON_START_STOP_SW_UPPER_HALF      = 5,
 } cinstr_profiling_event_reason_start_stop_sw_t;
 
 /**
  * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_SUSPEND/RESUME is used from software channel
  */
-typedef enum
-{
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_NONE                   =  0,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_PIPELINE_FULL          =  1,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC                  = 26,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_FB_IFRAME_WAIT         = 27,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_FB_IFRAME_SYNC         = 28,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VG_WAIT_FILTER_CLEANUP = 29,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VG_WAIT_TEXTURE        = 30,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_GLES_WAIT_MIPLEVEL     = 31,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_GLES_WAIT_READPIXELS   = 32,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_WAIT_SWAP_IMMEDIATE= 33,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_ICS_QUEUE_BUFFER       = 34,
-	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_ICS_DEQUEUE_BUFFER     = 35,
+typedef enum {
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_NONE                     =  0, /* used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_PIPELINE_FULL            =  1, /* NOT used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VSYNC                    = 26, /* used in some build configurations */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_FB_IFRAME_WAIT           = 27, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_FB_IFRAME_SYNC           = 28, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VG_WAIT_FILTER_CLEANUP   = 29, /* used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_VG_WAIT_TEXTURE          = 30, /* used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_GLES_WAIT_MIPLEVEL       = 31, /* used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_GLES_WAIT_READPIXELS     = 32, /* used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_WAIT_SWAP_IMMEDIATE  = 33, /* NOT used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_ICS_QUEUE_BUFFER         = 34, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_ICS_DEQUEUE_BUFFER       = 35, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_UMP_LOCK                 = 36, /* Not currently used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_X11_GLOBAL_LOCK          = 37, /* Not currently used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_X11_SWAP                 = 38, /* Not currently used */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_MALI_EGL_IMAGE_SYNC_WAIT = 39, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_GP_JOB_HANDLING          = 40, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_PP_JOB_HANDLING          = 41, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_MALI_FENCE_MERGE     = 42, /* USED */
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_MALI_FENCE_DUP       = 43,
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_FLUSH_SERVER_WAITS   = 44,
+	MALI_PROFILING_EVENT_REASON_SUSPEND_RESUME_SW_EGL_WAIT_SYNC            = 45, /* USED */
 } cinstr_profiling_event_reason_suspend_resume_sw_t;
 
 /**
  * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_SINGLE is used from a HW channel (GPx+PPx)
  */
-typedef enum
-{
+typedef enum {
 	MALI_PROFILING_EVENT_REASON_SINGLE_HW_NONE          = 0,
 	MALI_PROFILING_EVENT_REASON_SINGLE_HW_INTERRUPT     = 1,
 	MALI_PROFILING_EVENT_REASON_SINGLE_HW_FLUSH         = 2,
@@ -112,10 +142,33 @@ typedef enum
 /**
  * These events are applicable when the type MALI_PROFILING_EVENT_TYPE_SINGLE is used from the GPU channel
  */
-typedef enum
-{
+typedef enum {
 	MALI_PROFILING_EVENT_REASON_SINGLE_GPU_NONE              = 0,
 	MALI_PROFILING_EVENT_REASON_SINGLE_GPU_FREQ_VOLT_CHANGE  = 1,
+	MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L20_COUNTERS      = 2,
+	MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L21_COUNTERS      = 3,
+	MALI_PROFILING_EVENT_REASON_SINGLE_GPU_L22_COUNTERS      = 4,
 } cinstr_profiling_event_reason_single_gpu_t;
 
+/**
+ * These values are applicable for the 3rd data parameter when
+ * the type MALI_PROFILING_EVENT_TYPE_START is used from the software channel
+ * with the MALI_PROFILING_EVENT_REASON_START_STOP_BOTTOM_HALF reason.
+ */
+typedef enum {
+	MALI_PROFILING_EVENT_DATA_CORE_GP0             =  1,
+	MALI_PROFILING_EVENT_DATA_CORE_PP0             =  5,
+	MALI_PROFILING_EVENT_DATA_CORE_PP1             =  6,
+	MALI_PROFILING_EVENT_DATA_CORE_PP2             =  7,
+	MALI_PROFILING_EVENT_DATA_CORE_PP3             =  8,
+	MALI_PROFILING_EVENT_DATA_CORE_PP4             =  9,
+	MALI_PROFILING_EVENT_DATA_CORE_PP5             = 10,
+	MALI_PROFILING_EVENT_DATA_CORE_PP6             = 11,
+	MALI_PROFILING_EVENT_DATA_CORE_PP7             = 12,
+} cinstr_profiling_event_data_core_t;
+
+#define MALI_PROFILING_MAKE_EVENT_DATA_CORE_GP(num) (MALI_PROFILING_EVENT_DATA_CORE_GP0 + (num))
+#define MALI_PROFILING_MAKE_EVENT_DATA_CORE_PP(num) (MALI_PROFILING_EVENT_DATA_CORE_PP0 + (num))
+
+
 #endif /*_MALI_UTGARD_PROFILING_EVENTS_H_*/
diff --git a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_uk_types.h b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_uk_types.h
old mode 100644
new mode 100755
index 6fb604f..7f81827
--- a/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_uk_types.h
+++ b/drivers/gpu/mali/mali/include/linux/mali/mali_utgard_uk_types.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,10 +17,20 @@
 #define __MALI_UTGARD_UK_TYPES_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
+/* Iteration functions depend on these values being consecutive. */
+#define MALI_UK_TIMELINE_GP   0
+#define MALI_UK_TIMELINE_PP   1
+#define MALI_UK_TIMELINE_SOFT 2
+#define MALI_UK_TIMELINE_MAX  3
+
+typedef struct {
+	u32 points[MALI_UK_TIMELINE_MAX];
+	s32 sync_fd;
+} _mali_uk_fence_t;
+
 /**
  * @addtogroup uddapi Unified Device Driver (UDD) APIs
  *
@@ -40,14 +50,13 @@ extern "C"
  * for each U/K call.
  *
  * @see _mali_uk_functions */
-typedef enum
-{
-    _MALI_UK_CORE_SUBSYSTEM,      /**< Core Group of U/K calls */
-    _MALI_UK_MEMORY_SUBSYSTEM,    /**< Memory Group of U/K calls */
-    _MALI_UK_PP_SUBSYSTEM,        /**< Fragment Processor Group of U/K calls */
-    _MALI_UK_GP_SUBSYSTEM,        /**< Vertex Processor Group of U/K calls */
+typedef enum {
+	_MALI_UK_CORE_SUBSYSTEM,      /**< Core Group of U/K calls */
+	_MALI_UK_MEMORY_SUBSYSTEM,    /**< Memory Group of U/K calls */
+	_MALI_UK_PP_SUBSYSTEM,        /**< Fragment Processor Group of U/K calls */
+	_MALI_UK_GP_SUBSYSTEM,        /**< Vertex Processor Group of U/K calls */
 	_MALI_UK_PROFILING_SUBSYSTEM, /**< Profiling Group of U/K calls */
-    _MALI_UK_PMM_SUBSYSTEM,       /**< Power Management Module Group of U/K calls */
+	_MALI_UK_PMM_SUBSYSTEM,       /**< Power Management Module Group of U/K calls */
 	_MALI_UK_VSYNC_SUBSYSTEM,     /**< VSYNC Group of U/K calls */
 } _mali_uk_subsystem_t;
 
@@ -57,55 +66,63 @@ typedef enum
  * An ordered pair of numbers selected from
  * ( \ref _mali_uk_subsystem_t,\ref  _mali_uk_functions) will uniquely identify the
  * U/K call across all groups of functions, and all functions. */
-typedef enum
-{
+typedef enum {
 	/** Core functions */
 
-    _MALI_UK_OPEN                    = 0, /**< _mali_ukk_open() */
-    _MALI_UK_CLOSE,                       /**< _mali_ukk_close() */
-    _MALI_UK_GET_SYSTEM_INFO_SIZE,        /**< _mali_ukk_get_system_info_size() */
-    _MALI_UK_GET_SYSTEM_INFO,             /**< _mali_ukk_get_system_info() */
-    _MALI_UK_WAIT_FOR_NOTIFICATION,       /**< _mali_ukk_wait_for_notification() */
-    _MALI_UK_GET_API_VERSION,             /**< _mali_ukk_get_api_version() */
-    _MALI_UK_POST_NOTIFICATION,           /**< _mali_ukk_post_notification() */
-	_MALI_UK_GET_USER_SETTING,       /**< _mali_ukk_get_user_setting() *//**< [out] */
-	_MALI_UK_GET_USER_SETTINGS,       /**< _mali_ukk_get_user_settings() *//**< [out] */
+	_MALI_UK_OPEN                    = 0, /**< _mali_ukk_open() */
+	_MALI_UK_CLOSE,                       /**< _mali_ukk_close() */
+	_MALI_UK_WAIT_FOR_NOTIFICATION,       /**< _mali_ukk_wait_for_notification() */
+	_MALI_UK_GET_API_VERSION,             /**< _mali_ukk_get_api_version() */
+	_MALI_UK_POST_NOTIFICATION,           /**< _mali_ukk_post_notification() */
+	_MALI_UK_GET_USER_SETTING,            /**< _mali_ukk_get_user_setting() *//**< [out] */
+	_MALI_UK_GET_USER_SETTINGS,           /**< _mali_ukk_get_user_settings() *//**< [out] */
+	_MALI_UK_REQUEST_HIGH_PRIORITY,       /**< _mali_ukk_request_high_priority() */
+	_MALI_UK_TIMELINE_GET_LATEST_POINT,   /**< _mali_ukk_timeline_get_latest_point() */
+	_MALI_UK_TIMELINE_WAIT,               /**< _mali_ukk_timeline_wait() */
+	_MALI_UK_TIMELINE_CREATE_SYNC_FENCE,  /**< _mali_ukk_timeline_create_sync_fence() */
+	_MALI_UK_SOFT_JOB_START,              /**< _mali_ukk_soft_job_start() */
+	_MALI_UK_SOFT_JOB_SIGNAL,             /**< _mali_ukk_soft_job_signal() */
 
 	/** Memory functions */
 
-    _MALI_UK_INIT_MEM                = 0, /**< _mali_ukk_init_mem() */
-    _MALI_UK_TERM_MEM,                    /**< _mali_ukk_term_mem() */
-    _MALI_UK_GET_BIG_BLOCK,               /**< _mali_ukk_get_big_block() */
-    _MALI_UK_FREE_BIG_BLOCK,              /**< _mali_ukk_free_big_block() */
-    _MALI_UK_MAP_MEM,                     /**< _mali_ukk_mem_mmap() */
-    _MALI_UK_UNMAP_MEM,                   /**< _mali_ukk_mem_munmap() */
-    _MALI_UK_QUERY_MMU_PAGE_TABLE_DUMP_SIZE, /**< _mali_ukk_mem_get_mmu_page_table_dump_size() */
-    _MALI_UK_DUMP_MMU_PAGE_TABLE,         /**< _mali_ukk_mem_dump_mmu_page_table() */
-    _MALI_UK_ATTACH_UMP_MEM,             /**< _mali_ukk_attach_ump_mem() */
-    _MALI_UK_RELEASE_UMP_MEM,           /**< _mali_ukk_release_ump_mem() */
-    _MALI_UK_MAP_EXT_MEM,                 /**< _mali_uku_map_external_mem() */
-    _MALI_UK_UNMAP_EXT_MEM,               /**< _mali_uku_unmap_external_mem() */
-    _MALI_UK_VA_TO_MALI_PA,               /**< _mali_uku_va_to_mali_pa() */
-
-    /** Common functions for each core */
-
-    _MALI_UK_START_JOB           = 0,     /**< Start a Fragment/Vertex Processor Job on a core */
-    _MALI_UK_GET_NUMBER_OF_CORES,         /**< Get the number of Fragment/Vertex Processor cores */
-    _MALI_UK_GET_CORE_VERSION,            /**< Get the Fragment/Vertex Processor version compatible with all cores */
-
-    /** Fragment Processor Functions  */
-
-    _MALI_UK_PP_START_JOB            = _MALI_UK_START_JOB,            /**< _mali_ukk_pp_start_job() */
-    _MALI_UK_GET_PP_NUMBER_OF_CORES  = _MALI_UK_GET_NUMBER_OF_CORES,  /**< _mali_ukk_get_pp_number_of_cores() */
-    _MALI_UK_GET_PP_CORE_VERSION     = _MALI_UK_GET_CORE_VERSION,     /**< _mali_ukk_get_pp_core_version() */
-    _MALI_UK_PP_DISABLE_WB,                                           /**< _mali_ukk_pp_job_disable_wb() */
-
-    /** Vertex Processor Functions  */
-
-    _MALI_UK_GP_START_JOB            = _MALI_UK_START_JOB,            /**< _mali_ukk_gp_start_job() */
-    _MALI_UK_GET_GP_NUMBER_OF_CORES  = _MALI_UK_GET_NUMBER_OF_CORES,  /**< _mali_ukk_get_gp_number_of_cores() */
-    _MALI_UK_GET_GP_CORE_VERSION     = _MALI_UK_GET_CORE_VERSION,     /**< _mali_ukk_get_gp_core_version() */
-    _MALI_UK_GP_SUSPEND_RESPONSE,                                     /**< _mali_ukk_gp_suspend_response() */
+	_MALI_UK_INIT_MEM                = 0,    /**< _mali_ukk_init_mem() */
+	_MALI_UK_TERM_MEM,                       /**< _mali_ukk_term_mem() */
+	_MALI_UK_GET_BIG_BLOCK,                  /**< _mali_ukk_get_big_block() */
+	_MALI_UK_FREE_BIG_BLOCK,                 /**< _mali_ukk_free_big_block() */
+	_MALI_UK_MAP_MEM,                        /**< _mali_ukk_mem_mmap() */
+	_MALI_UK_UNMAP_MEM,                      /**< _mali_ukk_mem_munmap() */
+	_MALI_UK_QUERY_MMU_PAGE_TABLE_DUMP_SIZE, /**< _mali_ukk_mem_get_mmu_page_table_dump_size() */
+	_MALI_UK_DUMP_MMU_PAGE_TABLE,            /**< _mali_ukk_mem_dump_mmu_page_table() */
+	_MALI_UK_ATTACH_DMA_BUF,                 /**< _mali_ukk_attach_dma_buf() */
+	_MALI_UK_RELEASE_DMA_BUF,                /**< _mali_ukk_release_dma_buf() */
+	_MALI_UK_DMA_BUF_GET_SIZE,               /**< _mali_ukk_dma_buf_get_size() */
+	_MALI_UK_ATTACH_UMP_MEM,                 /**< _mali_ukk_attach_ump_mem() */
+	_MALI_UK_RELEASE_UMP_MEM,                /**< _mali_ukk_release_ump_mem() */
+	_MALI_UK_MAP_EXT_MEM,                    /**< _mali_uku_map_external_mem() */
+	_MALI_UK_UNMAP_EXT_MEM,                  /**< _mali_uku_unmap_external_mem() */
+	_MALI_UK_VA_TO_MALI_PA,                  /**< _mali_uku_va_to_mali_pa() */
+	_MALI_UK_MEM_WRITE_SAFE,                 /**< _mali_uku_mem_write_safe() */
+
+	/** Common functions for each core */
+
+	_MALI_UK_START_JOB           = 0,     /**< Start a Fragment/Vertex Processor Job on a core */
+	_MALI_UK_GET_NUMBER_OF_CORES,         /**< Get the number of Fragment/Vertex Processor cores */
+	_MALI_UK_GET_CORE_VERSION,            /**< Get the Fragment/Vertex Processor version compatible with all cores */
+
+	/** Fragment Processor Functions  */
+
+	_MALI_UK_PP_START_JOB            = _MALI_UK_START_JOB,            /**< _mali_ukk_pp_start_job() */
+	_MALI_UK_GET_PP_NUMBER_OF_CORES  = _MALI_UK_GET_NUMBER_OF_CORES,  /**< _mali_ukk_get_pp_number_of_cores() */
+	_MALI_UK_GET_PP_CORE_VERSION     = _MALI_UK_GET_CORE_VERSION,     /**< _mali_ukk_get_pp_core_version() */
+	_MALI_UK_PP_DISABLE_WB,                                           /**< _mali_ukk_pp_job_disable_wb() */
+	_MALI_UK_PP_AND_GP_START_JOB,                                     /**< _mali_ukk_pp_and_gp_start_job() */
+
+	/** Vertex Processor Functions  */
+
+	_MALI_UK_GP_START_JOB            = _MALI_UK_START_JOB,            /**< _mali_ukk_gp_start_job() */
+	_MALI_UK_GET_GP_NUMBER_OF_CORES  = _MALI_UK_GET_NUMBER_OF_CORES,  /**< _mali_ukk_get_gp_number_of_cores() */
+	_MALI_UK_GET_GP_CORE_VERSION     = _MALI_UK_GET_CORE_VERSION,     /**< _mali_ukk_get_gp_core_version() */
+	_MALI_UK_GP_SUSPEND_RESPONSE,                                     /**< _mali_ukk_gp_suspend_response() */
 
 	/** Profiling functions */
 
@@ -116,6 +133,7 @@ typedef enum
 	_MALI_UK_PROFILING_CLEAR,             /**< __mali_uku_profiling_clear() */
 	_MALI_UK_PROFILING_GET_CONFIG,        /**< __mali_uku_profiling_get_config() */
 	_MALI_UK_PROFILING_REPORT_SW_COUNTERS,/**< __mali_uku_profiling_report_sw_counters() */
+	_MALI_UK_PROFILING_MEMORY_USAGE_GET,  /**< __mali_uku_profiling_memory_usage_get() */
 
 	/** VSYNC reporting fuctions */
 	_MALI_UK_VSYNC_EVENT_REPORT      = 0, /**< _mali_ukk_vsync_event_report() */
@@ -126,9 +144,8 @@ typedef enum
  *
  * @see _mali_ukk_get_system_info_size()
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 size;                       /**< [out] size of buffer necessary to hold system information data, in bytes */
 } _mali_uk_get_system_info_size_s;
 
@@ -154,8 +171,7 @@ typedef u32 _mali_core_version;
  *
  * The 'raw' mode is reserved for future expansion.
  */
-typedef enum _mali_driver_mode
-{
+typedef enum _mali_driver_mode {
 	_MALI_DRIVER_MODE_RAW = 1,    /**< Reserved for future expansion */
 	_MALI_DRIVER_MODE_NORMAL = 2  /**< Normal mode of operation */
 } _mali_driver_mode;
@@ -163,8 +179,7 @@ typedef enum _mali_driver_mode
 /** @brief List of possible cores
  *
  * add new entries to the end of this enum */
-typedef enum _mali_core_type
-{
+typedef enum _mali_core_type {
 	_MALI_GP2 = 2,                /**< MaliGP2 Programmable Vertex Processor */
 	_MALI_200 = 5,                /**< Mali200 Programmable Fragment Processor */
 	_MALI_400_GP = 6,             /**< Mali400 Programmable Vertex Processor */
@@ -172,33 +187,6 @@ typedef enum _mali_core_type
 	/* insert new core here, do NOT alter the existing values */
 } _mali_core_type;
 
-/** @brief Information about each Mali Core
- *
- * Information is stored in a linked list, which is stored entirely in the
- * buffer pointed to by the system_info member of the
- * _mali_uk_get_system_info_s arguments provided to _mali_ukk_get_system_info()
- *
- * Both Fragment Processor (PP) and Vertex Processor (GP) cores are represented
- * by this struct.
- *
- * The type is reported by the type field, _mali_core_info::_mali_core_type.
- *
- * Each core is given a unique Sequence number identifying it, the core_nr
- * member.
- *
- * Flags are taken directly from the resource's flags, and are currently unused.
- *
- * Multiple mali_core_info structs are linked in a single linked list using the next field
- */
-typedef struct _mali_core_info
-{
-	_mali_core_type type;            /**< Type of core */
-	_mali_core_version version;      /**< Core Version, as reported by the Core's Version Register */
-	u32 reg_address;                 /**< Address of Registers */
-	u32 core_nr;                     /**< Sequence number */
-	u32 flags;                       /**< Flags. Currently Unused. */
-	struct _mali_core_info * next;   /**< Next core in Linked List */
-} _mali_core_info;
 
 /** @brief Capabilities of Memory Banks
  *
@@ -212,19 +200,25 @@ typedef struct _mali_core_info
  *
  * @see _mali_mem_info
  */
-typedef enum _mali_bus_usage
-{
-
-	_MALI_PP_READABLE   = (1<<0),  /** Readable by the Fragment Processor */
-	_MALI_PP_WRITEABLE  = (1<<1),  /** Writeable by the Fragment Processor */
-	_MALI_GP_READABLE   = (1<<2),  /** Readable by the Vertex Processor */
-	_MALI_GP_WRITEABLE  = (1<<3),  /** Writeable by the Vertex Processor */
-	_MALI_CPU_READABLE  = (1<<4),  /** Readable by the CPU */
-	_MALI_CPU_WRITEABLE = (1<<5),  /** Writeable by the CPU */
+typedef enum _mali_bus_usage {
+
+	_MALI_PP_READABLE   = (1 << 0), /** Readable by the Fragment Processor */
+	_MALI_PP_WRITEABLE  = (1 << 1), /** Writeable by the Fragment Processor */
+	_MALI_GP_READABLE   = (1 << 2), /** Readable by the Vertex Processor */
+	_MALI_GP_WRITEABLE  = (1 << 3), /** Writeable by the Vertex Processor */
+	_MALI_CPU_READABLE  = (1 << 4), /** Readable by the CPU */
+	_MALI_CPU_WRITEABLE = (1 << 5), /** Writeable by the CPU */
+	_MALI_GP_L2_ALLOC   = (1 << 6), /** GP allocate mali L2 cache lines*/
 	_MALI_MMU_READABLE  = _MALI_PP_READABLE | _MALI_GP_READABLE,   /** Readable by the MMU (including all cores behind it) */
 	_MALI_MMU_WRITEABLE = _MALI_PP_WRITEABLE | _MALI_GP_WRITEABLE, /** Writeable by the MMU (including all cores behind it) */
 } _mali_bus_usage;
 
+typedef enum mali_memory_cache_settings {
+	MALI_CACHE_STANDARD                     = 0,
+	MALI_CACHE_GP_READ_ALLOCATE     = 1,
+} mali_memory_cache_settings ;
+
+
 /** @brief Information about the Mali Memory system
  *
  * Information is stored in a linked list, which is stored entirely in the
@@ -235,11 +229,6 @@ typedef enum _mali_bus_usage
  * Each allocation can only come from one bank, and will not cross multiple
  * banks.
  *
- * Each bank is uniquely identified by its identifier member. On Mali-nonMMU
- * systems, to allocate from this bank, the value of identifier must be passed
- * as the type_id member of the  _mali_uk_get_big_block_s arguments to
- * _mali_ukk_get_big_block.
- *
  * On Mali-MMU systems, there is only one bank, which describes the maximum
  * possible address range that could be allocated (which may be much less than
  * the available physical memory)
@@ -255,60 +244,14 @@ typedef enum _mali_bus_usage
  * _MALI_PP_READABLE clear. However, it would be incorrect to use a framebuffer
  * where _MALI_PP_WRITEABLE is clear.
  */
-typedef struct _mali_mem_info
-{
+typedef struct _mali_mem_info {
 	u32 size;                     /**< Size of the memory bank in bytes */
 	_mali_bus_usage flags;        /**< Capabilitiy flags of the memory */
 	u32 maximum_order_supported;  /**< log2 supported size */
-	u32 identifier;               /**< Unique identifier, to be used in allocate calls */
-	struct _mali_mem_info * next; /**< Next List Link */
+	u32 identifier;               /* mali_memory_cache_settings cache_settings; */
+	struct _mali_mem_info *next;  /**< Next List Link */
 } _mali_mem_info;
 
-/** @brief Info about the whole Mali system.
- *
- * This Contains a linked list of the cores and memory banks available. Each
- * list pointer will remain inside the system_info buffer supplied in the
- * _mali_uk_get_system_info_s arguments to a _mali_ukk_get_system_info call.
- *
- * The has_mmu member must be inspected to ensure the correct group of
- * Memory function calls is obtained - that is, those for either Mali-MMU
- * or Mali-nonMMU. @see _mali_uk_memory
- */
-typedef struct _mali_system_info
-{
-	_mali_core_info * core_info;  /**< List of _mali_core_info structures */
-	_mali_mem_info * mem_info;    /**< List of _mali_mem_info structures */
-	u32 has_mmu;                  /**< Non-zero if Mali-MMU present. Zero otherwise. */
-	_mali_driver_mode drivermode; /**< Reserved. Must always be _MALI_DRIVER_MODE_NORMAL */
-} _mali_system_info;
-
-/** @brief Arguments to _mali_ukk_get_system_info()
- *
- * A buffer of the size returned by _mali_ukk_get_system_info_size() must be
- * allocated, and the pointer to this buffer must be written into the
- * system_info member. The buffer must be suitably aligned for storage of
- * the _mali_system_info structure - for example, one returned by
- * _mali_osk_malloc(), which will be suitably aligned for any structure.
- *
- * The ukk_private member must be set to zero by the user-side. Under an OS
- * implementation, the U/K interface must write in the user-side base address
- * into the ukk_private member, so that the common code in
- * _mali_ukk_get_system_info() can determine how to adjust the pointers such
- * that they are sensible from user space. Leaving ukk_private as NULL implies
- * that no pointer adjustment is necessary - which will be the case on a
- * bare-metal/RTOS system.
- *
- * @see _mali_system_info
- */
-typedef struct
-{
-    void *ctx;                              /**< [in,out] user-kernel context (trashed on output) */
-	u32 size;                               /**< [in] size of buffer provided to store system information data */
-	_mali_system_info * system_info;        /**< [in,out] pointer to buffer to store system information data. No initialisation of buffer required on input. */
-	u32 ukk_private;                        /**< [in] Kernel-side private word inserted by certain U/K interface implementations. Caller must set to Zero. */
-} _mali_uk_get_system_info_s;
-/** @} */ /* end group _mali_uk_getsysteminfo */
-
 /** @} */ /* end group _mali_uk_core */
 
 
@@ -335,15 +278,13 @@ typedef struct
  * - pass in the user-kernel context @c ctx that was returned from _mali_ukk_open()
  *
  */
-typedef enum _maligp_job_suspended_response_code
-{
+typedef enum _maligp_job_suspended_response_code {
 	_MALIGP_JOB_ABORT,                  /**< Abort the Vertex Processor job */
 	_MALIGP_JOB_RESUME_WITH_NEW_HEAP    /**< Resume the Vertex Processor job with a new heap */
 } _maligp_job_suspended_response_code;
 
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 cookie;                     /**< [in] cookie from the _mali_uk_gp_job_suspended_s notification */
 	_maligp_job_suspended_response_code code; /**< [in] abort or resume response code, see \ref _maligp_job_suspended_response_code */
 	u32 arguments[2];               /**< [in] 0 when aborting a job. When resuming a job, the Mali start and end address for a new heap to resume the job with */
@@ -355,26 +296,24 @@ typedef struct
  * @{ */
 
 /** @brief Status indicating the result of starting a Vertex or Fragment processor job */
-typedef enum
-{
-    _MALI_UK_START_JOB_STARTED,                         /**< Job started */
-    _MALI_UK_START_JOB_NOT_STARTED_DO_REQUEUE           /**< Job could not be started at this time. Try starting the job again */
+typedef enum {
+	_MALI_UK_START_JOB_STARTED,                         /**< Job started */
+	_MALI_UK_START_JOB_NOT_STARTED_DO_REQUEUE           /**< Job could not be started at this time. Try starting the job again */
 } _mali_uk_start_job_status;
 
 /** @brief Status indicating the result of the execution of a Vertex or Fragment processor job  */
 
-typedef enum
-{
-	_MALI_UK_JOB_STATUS_END_SUCCESS         = 1<<(16+0),
-	_MALI_UK_JOB_STATUS_END_OOM             = 1<<(16+1),
-	_MALI_UK_JOB_STATUS_END_ABORT           = 1<<(16+2),
-	_MALI_UK_JOB_STATUS_END_TIMEOUT_SW      = 1<<(16+3),
-	_MALI_UK_JOB_STATUS_END_HANG            = 1<<(16+4),
-	_MALI_UK_JOB_STATUS_END_SEG_FAULT       = 1<<(16+5),
-	_MALI_UK_JOB_STATUS_END_ILLEGAL_JOB     = 1<<(16+6),
-	_MALI_UK_JOB_STATUS_END_UNKNOWN_ERR     = 1<<(16+7),
-	_MALI_UK_JOB_STATUS_END_SHUTDOWN        = 1<<(16+8),
-	_MALI_UK_JOB_STATUS_END_SYSTEM_UNUSABLE = 1<<(16+9)
+typedef enum {
+	_MALI_UK_JOB_STATUS_END_SUCCESS         = 1 << (16 + 0),
+	_MALI_UK_JOB_STATUS_END_OOM             = 1 << (16 + 1),
+	_MALI_UK_JOB_STATUS_END_ABORT           = 1 << (16 + 2),
+	_MALI_UK_JOB_STATUS_END_TIMEOUT_SW      = 1 << (16 + 3),
+	_MALI_UK_JOB_STATUS_END_HANG            = 1 << (16 + 4),
+	_MALI_UK_JOB_STATUS_END_SEG_FAULT       = 1 << (16 + 5),
+	_MALI_UK_JOB_STATUS_END_ILLEGAL_JOB     = 1 << (16 + 6),
+	_MALI_UK_JOB_STATUS_END_UNKNOWN_ERR     = 1 << (16 + 7),
+	_MALI_UK_JOB_STATUS_END_SHUTDOWN        = 1 << (16 + 8),
+	_MALI_UK_JOB_STATUS_END_SYSTEM_UNUSABLE = 1 << (16 + 9)
 } _mali_uk_job_status;
 
 #define MALIGP2_NUM_REGS_FRAME (6)
@@ -432,42 +371,36 @@ typedef enum
  * you may be able to resolve this by providing more memory and resuming the job.
  *
  */
-typedef struct
-{
-    void *ctx;                          /**< [in,out] user-kernel context (trashed on output) */
-    u32 user_job_ptr;                   /**< [in] identifier for the job in user space, a @c mali_gp_job_info* */
-    u32 priority;                       /**< [in] job priority. A lower number means higher priority */
-    u32 frame_registers[MALIGP2_NUM_REGS_FRAME]; /**< [in] core specific registers associated with this job */
-    u32 perf_counter_flag;              /**< [in] bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
-    u32 perf_counter_src0;              /**< [in] source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
-    u32 perf_counter_src1;              /**< [in] source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
+typedef struct {
+	void *ctx;                          /**< [in,out] user-kernel context (trashed on output) */
+	u32 user_job_ptr;                   /**< [in] identifier for the job in user space, a @c mali_gp_job_info* */
+	u32 priority;                       /**< [in] job priority. A lower number means higher priority */
+	u32 frame_registers[MALIGP2_NUM_REGS_FRAME]; /**< [in] core specific registers associated with this job */
+	u32 perf_counter_flag;              /**< [in] bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
+	u32 perf_counter_src0;              /**< [in] source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
+	u32 perf_counter_src1;              /**< [in] source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
 	u32 frame_builder_id;               /**< [in] id of the originating frame builder */
 	u32 flush_id;                       /**< [in] flush id within the originating frame builder */
+	_mali_uk_fence_t fence;             /**< [in] fence this job must wait on */
+	u32 *timeline_point_ptr;            /**< [in,out] pointer to location where point on gp timeline for this job will be written */
 } _mali_uk_gp_start_job_s;
 
 #define _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE (1<<0) /**< Enable performance counter SRC0 for a job */
 #define _MALI_PERFORMANCE_COUNTER_FLAG_SRC1_ENABLE (1<<1) /**< Enable performance counter SRC1 for a job */
+#define _MALI_PERFORMANCE_COUNTER_FLAG_HEATMAP_ENABLE (1<<2) /**< Enable per tile (aka heatmap) generation with for a job (using the enabled counter sources) */
 
 /** @} */ /* end group _mali_uk_gpstartjob_s */
 
-typedef struct
-{
-    u32 user_job_ptr;               /**< [out] identifier for the job in user space */
-    _mali_uk_job_status status;     /**< [out] status of finished job */
-    u32 heap_current_addr;          /**< [out] value of the GP PLB PL heap start address register */
-    u32 perf_counter0;              /**< [out] value of perfomance counter 0 (see ARM DDI0415A) */
-    u32 perf_counter1;              /**< [out] value of perfomance counter 1 (see ARM DDI0415A) */
+typedef struct {
+	u32 user_job_ptr;               /**< [out] identifier for the job in user space */
+	_mali_uk_job_status status;     /**< [out] status of finished job */
+	u32 heap_current_addr;          /**< [out] value of the GP PLB PL heap start address register */
+	u32 perf_counter0;              /**< [out] value of performance counter 0 (see ARM DDI0415A) */
+	u32 perf_counter1;              /**< [out] value of performance counter 1 (see ARM DDI0415A) */
 } _mali_uk_gp_job_finished_s;
 
-typedef enum _maligp_job_suspended_reason
-{
-	_MALIGP_JOB_SUSPENDED_OUT_OF_MEMORY  /**< Polygon list builder unit (PLBU) has run out of memory */
-} _maligp_job_suspended_reason;
-
-typedef struct
-{
+typedef struct {
 	u32 user_job_ptr;                    /**< [out] identifier for the job in user space */
-	_maligp_job_suspended_reason reason; /**< [out] reason why the job stalled */
 	u32 cookie;                          /**< [out] identifier for the core in kernel space on which the job stalled */
 } _mali_uk_gp_job_suspended_s;
 
@@ -483,6 +416,12 @@ typedef struct
 
 #define _MALI_PP_MAX_WB_REGISTERS ((0x02C/4)+1)
 
+#define _MALI_DLBU_MAX_REGISTERS 4
+
+/** Flag for _mali_uk_pp_start_job_s */
+#define _MALI_PP_JOB_FLAG_NO_NOTIFICATION (1<<0)
+#define _MALI_PP_JOB_FLAG_IS_WINDOW_SURFACE (1<<1)
+
 /** @defgroup _mali_uk_ppstartjob_s Fragment Processor Start Job
  * @{ */
 
@@ -527,55 +466,98 @@ typedef struct
  * driver shutdown.
  *
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    u32 user_job_ptr;               /**< [in] identifier for the job in user space */
-    u32 priority;                   /**< [in] job priority. A lower number means higher priority */
-    u32 frame_registers[_MALI_PP_MAX_FRAME_REGISTERS];         /**< [in] core specific registers associated with first sub job, see ARM DDI0415A */
-    u32 frame_registers_addr_frame[_MALI_PP_MAX_SUB_JOBS - 1]; /**< [in] ADDR_FRAME registers for sub job 1-7 */
-    u32 frame_registers_addr_stack[_MALI_PP_MAX_SUB_JOBS - 1]; /**< [in] ADDR_STACK registers for sub job 1-7 */
-    u32 wb0_registers[_MALI_PP_MAX_WB_REGISTERS];
-    u32 wb1_registers[_MALI_PP_MAX_WB_REGISTERS];
-    u32 wb2_registers[_MALI_PP_MAX_WB_REGISTERS];
-	u32 num_cores;                      /**< [in] Number of cores to set up (valid range: 1-4) */
-    u32 perf_counter_flag;              /**< [in] bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
-    u32 perf_counter_src0;              /**< [in] source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
-    u32 perf_counter_src1;              /**< [in] source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 user_job_ptr;               /**< [in] identifier for the job in user space */
+	u32 priority;                   /**< [in] job priority. A lower number means higher priority */
+	u32 frame_registers[_MALI_PP_MAX_FRAME_REGISTERS];         /**< [in] core specific registers associated with first sub job, see ARM DDI0415A */
+	u32 frame_registers_addr_frame[_MALI_PP_MAX_SUB_JOBS - 1]; /**< [in] ADDR_FRAME registers for sub job 1-7 */
+	u32 frame_registers_addr_stack[_MALI_PP_MAX_SUB_JOBS - 1]; /**< [in] ADDR_STACK registers for sub job 1-7 */
+	u32 wb0_registers[_MALI_PP_MAX_WB_REGISTERS];
+	u32 wb1_registers[_MALI_PP_MAX_WB_REGISTERS];
+	u32 wb2_registers[_MALI_PP_MAX_WB_REGISTERS];
+	u32 dlbu_registers[_MALI_DLBU_MAX_REGISTERS]; /**< [in] Dynamic load balancing unit registers */
+	u32 num_cores;                      /**< [in] Number of cores to set up (valid range: 1-8(M450) or 4(M400)) */
+	u32 perf_counter_flag;              /**< [in] bitmask indicating which performance counters to enable, see \ref _MALI_PERFORMANCE_COUNTER_FLAG_SRC0_ENABLE and related macro definitions */
+	u32 perf_counter_src0;              /**< [in] source id for performance counter 0 (see ARM DDI0415A, Table 3-60) */
+	u32 perf_counter_src1;              /**< [in] source id for performance counter 1 (see ARM DDI0415A, Table 3-60) */
 	u32 frame_builder_id;               /**< [in] id of the originating frame builder */
 	u32 flush_id;                       /**< [in] flush id within the originating frame builder */
+	u32 flags;                          /**< [in] See _MALI_PP_JOB_FLAG_* for a list of avaiable flags */
+	u32 tilesx;                         /**< [in] number of tiles in the x direction (needed for heatmap generation */
+	u32 tilesy;                         /**< [in] number of tiles in y direction (needed for reading the heatmap memory) */
+	u32 heatmap_mem;                    /**< [in] memory address to store counter values per tile (aka heatmap) */
+	u32 num_memory_cookies;             /**< [in] number of memory cookies attached to job */
+	u32 *memory_cookies;                /**< [in] memory cookies attached to job  */
+	_mali_uk_fence_t fence;             /**< [in] fence this job must wait on */
+	u32 *timeline_point_ptr;            /**< [in,out] pointer to location where point on pp timeline for this job will be written */
 } _mali_uk_pp_start_job_s;
+
+typedef struct {
+	void *ctx;                          /**< [in,out] user-kernel context (trashed on output) */
+	_mali_uk_gp_start_job_s *gp_args;   /**< [in,out] GP uk arguments (see _mali_uk_gp_start_job_s) */
+	_mali_uk_pp_start_job_s *pp_args;   /**< [in,out] PP uk arguments (see _mali_uk_pp_start_job_s) */
+} _mali_uk_pp_and_gp_start_job_s;
+
 /** @} */ /* end group _mali_uk_ppstartjob_s */
 
-typedef struct
-{
-    u32 user_job_ptr;                          /**< [out] identifier for the job in user space */
-    _mali_uk_job_status status;                /**< [out] status of finished job */
-    u32 perf_counter0[_MALI_PP_MAX_SUB_JOBS];  /**< [out] value of perfomance counter 0 (see ARM DDI0415A), one for each sub job */
-    u32 perf_counter1[_MALI_PP_MAX_SUB_JOBS];  /**< [out] value of perfomance counter 1 (see ARM DDI0415A), one for each sub job */
+typedef struct {
+	u32 user_job_ptr;                          /**< [out] identifier for the job in user space */
+	_mali_uk_job_status status;                /**< [out] status of finished job */
+	u32 perf_counter0[_MALI_PP_MAX_SUB_JOBS];  /**< [out] value of perfomance counter 0 (see ARM DDI0415A), one for each sub job */
+	u32 perf_counter1[_MALI_PP_MAX_SUB_JOBS];  /**< [out] value of perfomance counter 1 (see ARM DDI0415A), one for each sub job */
+	u32 perf_counter_src0;
+	u32 perf_counter_src1;
 } _mali_uk_pp_job_finished_s;
 
+typedef struct {
+	u32 number_of_enabled_cores;               /**< [out] the new number of enabled cores */
+} _mali_uk_pp_num_cores_changed_s;
+
+
+
 /**
  * Flags to indicate write-back units
  */
-typedef enum
-{
+typedef enum {
 	_MALI_UK_PP_JOB_WB0 = 1,
 	_MALI_UK_PP_JOB_WB1 = 2,
 	_MALI_UK_PP_JOB_WB2 = 4,
 } _mali_uk_pp_job_wbx_flag;
 
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    u32 fb_id;                      /**< [in] Frame builder ID of job to disable WB units for */
-    u32 flush_id;                   /**< [in] Flush ID of job to disable WB units for */
-    _mali_uk_pp_job_wbx_flag wbx;   /**< [in] write-back units to disable */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 fb_id;                      /**< [in] Frame builder ID of job to disable WB units for */
+	u32 wb0_memory;
+	u32 wb1_memory;
+	u32 wb2_memory;
 } _mali_uk_pp_disable_wb_s;
 
 
 /** @} */ /* end group _mali_uk_pp */
 
+/** @defgroup _mali_uk_soft_job U/K Soft Job
+ * @{ */
+
+typedef struct {
+	void *ctx;                          /**< [in,out] user-kernel context (trashed on output) */
+	u32 type;                           /**< [in] type of soft job */
+	u32 user_job;                       /**< [in] identifier for the job in user space */
+	u32 *job_id_ptr;                    /**< [in,out] pointer to location where job id will be written */
+	_mali_uk_fence_t fence;             /**< [in] fence this job must wait on */
+	u32 point;                          /**< [out] point on soft timeline for this job */
+} _mali_uk_soft_job_start_s;
+
+typedef struct {
+	u32 user_job;                       /**< [out] identifier for the job in user space */
+} _mali_uk_soft_job_activated_s;
+
+typedef struct {
+	void *ctx;                          /**< [in,out] user-kernel context (trashed on output) */
+	u32 job_id;                         /**< [in] id for soft job */
+} _mali_uk_soft_job_signal_s;
+
+/** @} */ /* end group _mali_uk_soft_job */
 
 /** @addtogroup _mali_uk_core U/K Core
  * @{ */
@@ -593,22 +575,23 @@ typedef struct
  *
  * @see _mali_uk_wait_for_notification_s
  */
-typedef enum
-{
+typedef enum {
 	/** core notifications */
 
-	_MALI_NOTIFICATION_CORE_SHUTDOWN_IN_PROGRESS =  (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x20,
-	_MALI_NOTIFICATION_APPLICATION_QUIT =           (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x40,
-	_MALI_NOTIFICATION_SETTINGS_CHANGED =           (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x80,
+	_MALI_NOTIFICATION_CORE_SHUTDOWN_IN_PROGRESS = (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x20,
+	_MALI_NOTIFICATION_APPLICATION_QUIT = (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x40,
+	_MALI_NOTIFICATION_SETTINGS_CHANGED = (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x80,
+	_MALI_NOTIFICATION_SOFT_ACTIVATED = (_MALI_UK_CORE_SUBSYSTEM << 16) | 0x100,
 
 	/** Fragment Processor notifications */
 
-	_MALI_NOTIFICATION_PP_FINISHED =                (_MALI_UK_PP_SUBSYSTEM << 16) | 0x10,
+	_MALI_NOTIFICATION_PP_FINISHED = (_MALI_UK_PP_SUBSYSTEM << 16) | 0x10,
+	_MALI_NOTIFICATION_PP_NUM_CORE_CHANGE = (_MALI_UK_PP_SUBSYSTEM << 16) | 0x20,
 
 	/** Vertex Processor notifications */
 
-	_MALI_NOTIFICATION_GP_FINISHED =                (_MALI_UK_GP_SUBSYSTEM << 16) | 0x10,
-	_MALI_NOTIFICATION_GP_STALLED =                 (_MALI_UK_GP_SUBSYSTEM << 16) | 0x20,
+	_MALI_NOTIFICATION_GP_FINISHED = (_MALI_UK_GP_SUBSYSTEM << 16) | 0x10,
+	_MALI_NOTIFICATION_GP_STALLED = (_MALI_UK_GP_SUBSYSTEM << 16) | 0x20,
 
 } _mali_uk_notification_type;
 
@@ -623,8 +606,7 @@ typedef enum
  *
  *
  */
-typedef enum
-{
+typedef enum {
 	_MALI_UK_USER_SETTING_SW_EVENTS_ENABLE = 0,
 	_MALI_UK_USER_SETTING_COLORBUFFER_CAPTURE_ENABLED,
 	_MALI_UK_USER_SETTING_DEPTHBUFFER_CAPTURE_ENABLED,
@@ -642,24 +624,23 @@ typedef enum
 /* See mali_user_settings_db.c */
 extern const char *_mali_uk_user_setting_descriptions[];
 #define _MALI_UK_USER_SETTING_DESCRIPTIONS \
-{                                           \
-	"sw_events_enable",                 \
-	"colorbuffer_capture_enable",       \
-	"depthbuffer_capture_enable",       \
-	"stencilbuffer_capture_enable",     \
-	"per_tile_counters_enable",         \
-	"buffer_capture_compositor",        \
-	"buffer_capture_window",            \
-	"buffer_capture_other",             \
-	"buffer_capture_n_frames",          \
-	"buffer_capture_resize_factor",     \
-	"sw_counters_enable",               \
-};
+	{                                           \
+		"sw_events_enable",                 \
+		"colorbuffer_capture_enable",       \
+		"depthbuffer_capture_enable",       \
+		"stencilbuffer_capture_enable",     \
+		"per_tile_counters_enable",         \
+		"buffer_capture_compositor",        \
+		"buffer_capture_window",            \
+		"buffer_capture_other",             \
+		"buffer_capture_n_frames",          \
+		"buffer_capture_resize_factor",     \
+		"sw_counters_enable",               \
+	};
 
 /** @brief struct to hold the value to a particular setting as seen in the kernel space
  */
-typedef struct
-{
+typedef struct {
 	_mali_uk_user_setting_t setting;
 	u32 value;
 } _mali_uk_settings_changed_s;
@@ -707,16 +688,15 @@ typedef struct
  *     - The reason member of gp_job_suspended is set to _MALIGP_JOB_SUSPENDED_OUT_OF_MEMORY
  * when the polygon list builder unit has run out of memory.
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
 	_mali_uk_notification_type type; /**< [out] Type of notification available */
-	union
-	{
+	union {
 		_mali_uk_gp_job_suspended_s gp_job_suspended;/**< [out] Notification data for _MALI_NOTIFICATION_GP_STALLED notification type */
 		_mali_uk_gp_job_finished_s  gp_job_finished; /**< [out] Notification data for _MALI_NOTIFICATION_GP_FINISHED notification type */
 		_mali_uk_pp_job_finished_s  pp_job_finished; /**< [out] Notification data for _MALI_NOTIFICATION_PP_FINISHED notification type */
 		_mali_uk_settings_changed_s setting_changed;/**< [out] Notification data for _MALI_NOTIFICAATION_SETTINGS_CHANGED notification type */
+		_mali_uk_soft_job_activated_s soft_job_activated; /**< [out] Notification data for _MALI_NOTIFICATION_SOFT_ACTIVATED notification type */
 	} data;
 } _mali_uk_wait_for_notification_s;
 
@@ -725,9 +705,8 @@ typedef struct
  * Posts the specified notification to the notification queue for this application.
  * This is used to send a quit message to the callback thread.
  */
-typedef struct
-{
-    void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
 	_mali_uk_notification_type type; /**< [in] Type of notification to post */
 } _mali_uk_post_notification_s;
 
@@ -761,7 +740,7 @@ typedef struct
  * The 16bit integer is stored twice in a 32bit integer
  * For example, for version 1 the value would be 0x00010001
  */
-#define _MALI_API_VERSION 14
+#define _MALI_API_VERSION 401
 #define _MALI_UK_API_VERSION _MAKE_VERSION_ID(_MALI_API_VERSION)
 
 /**
@@ -785,9 +764,8 @@ typedef u32 _mali_uk_api_version;
  * interface is compatible with the kernel-side interface, since future versions
  * of the interface may be backwards compatible.
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	_mali_uk_api_version version;   /**< [in,out] API version of user-side interface. */
 	int compatible;                 /**< [out] @c 1 when @version is compatible, @c 0 otherwise */
 } _mali_uk_get_api_version_s;
@@ -803,45 +781,35 @@ typedef struct
  * All settings are given reference to the context pointed to by the ctx pointer.
  *
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
 	u32 settings[_MALI_UK_USER_SETTING_MAX]; /**< [out] The values for all settings */
 } _mali_uk_get_user_settings_s;
 
 /** @brief struct to hold the value of a particular setting from the user space within a given context
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
 	_mali_uk_user_setting_t setting; /**< [in] setting to get */
 	u32 value;                       /**< [out] value of setting */
 } _mali_uk_get_user_setting_s;
 
+/** @brief Arguments for _mali_ukk_request_high_priority() */
+typedef struct {
+	void *ctx;                       /**< [in,out] user-kernel context (trashed on output) */
+} _mali_uk_request_high_priority_s;
+
 /** @} */ /* end group _mali_uk_core */
 
 
 /** @defgroup _mali_uk_memory U/K Memory
  * @{ */
 
-/** @brief Arguments for _mali_ukk_init_mem(). */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-	u32 mali_address_base;          /**< [out] start of MALI address space */
-	u32 memory_size;                /**< [out] total MALI address space available */
-} _mali_uk_init_mem_s;
-
-/** @brief Arguments for _mali_ukk_term_mem(). */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-} _mali_uk_term_mem_s;
-
-/** @note Mali-MMU only */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+/** Flag for _mali_uk_map_external_mem_s, _mali_uk_attach_ump_mem_s and _mali_uk_attach_dma_buf_s */
+#define _MALI_MAP_EXTERNAL_MAP_GUARD_PAGE (1<<0)
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 phys_addr;                  /**< [in] physical address */
 	u32 size;                       /**< [in] size */
 	u32 mali_address;               /**< [in] mali address to map the physical memory to */
@@ -850,20 +818,36 @@ typedef struct
 	u32 cookie;                     /**< [out] identifier for mapped memory object in kernel space  */
 } _mali_uk_map_external_mem_s;
 
-/** Flag for _mali_uk_map_external_mem_s and _mali_uk_attach_ump_mem_s */
-#define _MALI_MAP_EXTERNAL_MAP_GUARD_PAGE (1<<0)
-
-/** @note Mali-MMU only */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 cookie;                     /**< [out] identifier for mapped memory object in kernel space  */
 } _mali_uk_unmap_external_mem_s;
 
+/** @note This is identical to _mali_uk_map_external_mem_s above, however phys_addr is replaced by memory descriptor */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 mem_fd;                     /**< [in] Memory descriptor */
+	u32 size;                       /**< [in] size */
+	u32 mali_address;               /**< [in] mali address to map the physical memory to */
+	u32 rights;                     /**< [in] rights necessary for accessing memory */
+	u32 flags;                      /**< [in] flags, see \ref _MALI_MAP_EXTERNAL_MAP_GUARD_PAGE */
+	u32 cookie;                     /**< [out] identifier for mapped memory object in kernel space  */
+} _mali_uk_attach_dma_buf_s;
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 mem_fd;                     /**< [in] Memory descriptor */
+	u32 size;                       /**< [out] size */
+} _mali_uk_dma_buf_get_size_s;
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 cookie;                     /**< [in] identifier for mapped memory object in kernel space  */
+} _mali_uk_release_dma_buf_s;
+
 /** @note This is identical to _mali_uk_map_external_mem_s above, however phys_addr is replaced by secure_id */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 secure_id;                  /**< [in] secure id */
 	u32 size;                       /**< [in] size */
 	u32 mali_address;               /**< [in] mali address to map the physical memory to */
@@ -872,10 +856,8 @@ typedef struct
 	u32 cookie;                     /**< [out] identifier for mapped memory object in kernel space  */
 } _mali_uk_attach_ump_mem_s;
 
-/** @note Mali-MMU only; will be supported in future version */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 cookie;                     /**< [in] identifier for mapped memory object in kernel space  */
 } _mali_uk_release_ump_mem_s;
 
@@ -900,27 +882,33 @@ typedef struct
  * va is updated to be page aligned, and size is updated to be a non-zero
  * multiple of the system's pagesize.
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	void *va;                       /**< [in,out] Virtual address of the start of the range */
 	u32 pa;                         /**< [out] Physical base address of the range */
 	u32 size;                       /**< [in,out] Size of the range, in bytes. */
 } _mali_uk_va_to_mali_pa_s;
 
-
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+/**
+ * @brief Arguments for _mali_uk[uk]_mem_write_safe()
+ */
+typedef struct {
+	void *ctx;        /**< [in,out] user-kernel context (trashed on output) */
+	const void *src;  /**< [in]     Pointer to source data */
+	void *dest;       /**< [in]     Destination Mali buffer */
+	u32 size;         /**< [in,out] Number of bytes to write/copy on input, number of bytes actually written/copied on output */
+} _mali_uk_mem_write_safe_s;
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 size;                       /**< [out] size of MMU page table information (registers + page tables) */
 } _mali_uk_query_mmu_page_table_dump_size_s;
 
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 size;                       /**< [in] size of buffer to receive mmu page table information */
-    void *buffer;                   /**< [in,out] buffer to receive mmu page table information */
-    u32 register_writes_size;       /**< [out] size of MMU register dump */
+	void *buffer;                   /**< [in,out] buffer to receive mmu page table information */
+	u32 register_writes_size;       /**< [out] size of MMU register dump */
 	u32 *register_writes;           /**< [out] pointer within buffer where MMU register dump is stored */
 	u32 page_table_dump_size;       /**< [out] size of MMU page table dump */
 	u32 *page_table_dump;           /**< [out] pointer within buffer where MMU page table dump is stored */
@@ -938,10 +926,10 @@ typedef struct
  * - Upon successful return from _mali_ukk_get_pp_number_of_cores(), @c number_of_cores
  * will contain the number of Fragment Processor cores in the system.
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    u32 number_of_cores;            /**< [out] number of Fragment Processor cores in the system */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 number_of_total_cores;      /**< [out] Total number of Fragment Processor cores in the system */
+	u32 number_of_enabled_cores;    /**< [out] Number of enabled Fragment Processor cores */
 } _mali_uk_get_pp_number_of_cores_s;
 
 /** @brief Arguments for _mali_ukk_get_pp_core_version()
@@ -950,10 +938,9 @@ typedef struct
  * - Upon successful return from _mali_ukk_get_pp_core_version(), @c version contains
  * the version that all Fragment Processor cores are compatible with.
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    _mali_core_version version;     /**< [out] version returned from core, see \ref _mali_core_version  */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	_mali_core_version version;     /**< [out] version returned from core, see \ref _mali_core_version  */
 } _mali_uk_get_pp_core_version_s;
 
 /** @} */ /* end group _mali_uk_pp */
@@ -968,10 +955,9 @@ typedef struct
  * - Upon successful return from _mali_ukk_get_gp_number_of_cores(), @c number_of_cores
  * will contain the number of Vertex Processor cores in the system.
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    u32 number_of_cores;            /**< [out] number of Vertex Processor cores in the system */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 number_of_cores;            /**< [out] number of Vertex Processor cores in the system */
 } _mali_uk_get_gp_number_of_cores_s;
 
 /** @brief Arguments for _mali_ukk_get_gp_core_version()
@@ -980,33 +966,28 @@ typedef struct
  * - Upon successful return from _mali_ukk_get_gp_core_version(), @c version contains
  * the version that all Vertex Processor cores are compatible with.
  */
-typedef struct
-{
-    void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-    _mali_core_version version;     /**< [out] version returned from core, see \ref _mali_core_version */
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	_mali_core_version version;     /**< [out] version returned from core, see \ref _mali_core_version */
 } _mali_uk_get_gp_core_version_s;
 
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 limit;                      /**< [in,out] The desired limit for number of events to record on input, actual limit on output */
 } _mali_uk_profiling_start_s;
 
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 event_id;                   /**< [in] event id to register (see  enum mali_profiling_events for values) */
 	u32 data[5];                    /**< [in] event specific data */
 } _mali_uk_profiling_add_event_s;
 
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 count;                      /**< [out] The number of events sampled */
 } _mali_uk_profiling_stop_s;
 
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	u32 index;                      /**< [in] which index to get (starting at zero) */
 	u64 timestamp;                  /**< [out] timestamp of event */
@@ -1014,11 +995,15 @@ typedef struct
 	u32 data[5];                    /**< [out] event specific data */
 } _mali_uk_profiling_get_event_s;
 
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 } _mali_uk_profiling_clear_s;
 
+typedef struct {
+	void *ctx;                     /**< [in,out] user-kernel context (trashed on output) */
+	u32 memory_usage;              /**< [out] total memory usage */
+} _mali_uk_profiling_memory_usage_get_s;
+
 /** @} */ /* end group _mali_uk_gp */
 
 
@@ -1051,8 +1036,7 @@ typedef struct
  * The uku_private member is currently reserved for use by the user-side
  * implementation of the U/K interface. Its value must be zero.
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	void *mapping;                  /**< [out] Returns user-space virtual address for the mapping */
 	u32 size;                       /**< [in] Size of the requested mapping */
@@ -1060,6 +1044,7 @@ typedef struct
 	u32 cookie;                     /**< [out] Returns a cookie for use in munmap calls */
 	void *uku_private;              /**< [in] User-side Private word used by U/K interface */
 	void *ukk_private;              /**< [in] Kernel-side Private word used by U/K interface */
+	mali_memory_cache_settings cache_settings; /**< [in] Option to set special cache flags, tuning L2 efficency */
 } _mali_uk_mem_mmap_s;
 
 /** @brief Arguments to _mali_ukk_mem_munmap()
@@ -1072,8 +1057,7 @@ typedef struct
  * An error will be returned if an attempt is made to unmap only part of the
  * originally obtained range, or to unmap more than was originally obtained.
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	void *mapping;                  /**< [in] The mapping returned from mmap call */
 	u32 size;                       /**< [in] The size passed to mmap call */
@@ -1089,8 +1073,7 @@ typedef struct
  * These events are reported when DDK starts to wait for vsync and when the
  * vsync has occured and the DDK can continue on the next frame.
  */
-typedef enum _mali_uk_vsync_event
-{
+typedef enum _mali_uk_vsync_event {
 	_MALI_UK_VSYNC_EVENT_BEGIN_WAIT = 0,
 	_MALI_UK_VSYNC_EVENT_END_WAIT
 } _mali_uk_vsync_event;
@@ -1098,8 +1081,7 @@ typedef enum _mali_uk_vsync_event
 /** @brief Arguments to _mali_ukk_vsync_event()
  *
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
 	_mali_uk_vsync_event event;     /**< [in] VSYNCH event type */
 } _mali_uk_vsync_event_report_s;
@@ -1113,15 +1095,38 @@ typedef struct
  *
  * Values recorded for each of the software counters during a single renderpass.
  */
-typedef struct
-{
+typedef struct {
 	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
-	u32* counters;                  /**< [in] The array of counter values */
+	u32 *counters;                  /**< [in] The array of counter values */
 	u32  num_counters;              /**< [in] The number of elements in counters array */
 } _mali_uk_sw_counters_report_s;
 
 /** @} */ /* end group _mali_uk_sw_counters_report */
 
+/** @defgroup _mali_uk_timeline U/K Mali Timeline
+ * @{ */
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	u32 timeline;                   /**< [in] timeline id */
+	u32 point;                      /**< [out] latest point on timeline */
+} _mali_uk_timeline_get_latest_point_s;
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	_mali_uk_fence_t fence;         /**< [in] fence */
+	u32 timeout;                    /**< [in] timeout (0 for no wait, -1 for blocking) */
+	u32 status;                     /**< [out] status of fence (1 if signaled, 0 if timeout) */
+} _mali_uk_timeline_wait_s;
+
+typedef struct {
+	void *ctx;                      /**< [in,out] user-kernel context (trashed on output) */
+	_mali_uk_fence_t fence;         /**< [in] mali fence to create linux sync fence from */
+	s32 sync_fd;                    /**< [out] file descriptor for new linux sync fence */
+} _mali_uk_timeline_create_sync_fence_s;
+
+/** @} */ /* end group _mali_uk_timeline */
+
 /** @} */ /* end group u_k_api */
 
 /** @} */ /* end group uddapi */
diff --git a/drivers/gpu/mali/mali/linux/license/gpl/mali_kernel_license.h b/drivers/gpu/mali/mali/linux/license/gpl/mali_kernel_license.h
old mode 100644
new mode 100755
index cf2c950..9442bd3
--- a/drivers/gpu/mali/mali/linux/license/gpl/mali_kernel_license.h
+++ b/drivers/gpu/mali/mali/linux/license/gpl/mali_kernel_license.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,8 +17,7 @@
 #define __MALI_KERNEL_LICENSE_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 #define MALI_KERNEL_LINUX_LICENSE     "GPL"
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_linux.c b/drivers/gpu/mali/mali/linux/mali_kernel_linux.c
old mode 100644
new mode 100755
index 8ef98bc..5a96994
--- a/drivers/gpu/mali/mali/linux/mali_kernel_linux.c
+++ b/drivers/gpu/mali/mali/linux/mali_kernel_linux.c
@@ -1,9 +1,9 @@
 /**
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,6 +17,12 @@
 #include <linux/cdev.h>     /* character device definitions */
 #include <linux/mm.h>       /* memory manager definitions */
 #include <linux/mali/mali_utgard_ioctl.h>
+#include <linux/version.h>
+#include <linux/device.h>
+#include "mali_kernel_license.h"
+#include <linux/platform_device.h>
+#include <linux/miscdevice.h>
+#include <linux/mali/mali_utgard.h>
 #include "mali_kernel_common.h"
 #include "mali_session.h"
 #include "mali_kernel_core.h"
@@ -24,22 +30,25 @@
 #include "mali_kernel_linux.h"
 #include "mali_ukk.h"
 #include "mali_ukk_wrappers.h"
-#include "mali_kernel_pm.h"
 #include "mali_kernel_sysfs.h"
-#include "mali_platform.h"
+#include "mali_pm.h"
 #include "mali_kernel_license.h"
+#include "mali_memory.h"
+#include "mali_memory_dma_buf.h"
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+#include "mali_profiling_internal.h"
+#endif
 
 /* Streamline support for the Mali driver */
-#if defined(CONFIG_TRACEPOINTS) && MALI_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_TRACEPOINTS) && defined(CONFIG_MALI400_PROFILING)
 /* Ask Linux to create the tracepoints */
 #define CREATE_TRACE_POINTS
 #include "mali_linux_trace.h"
-#endif /* CONFIG_TRACEPOINTS */
-
-static _mali_osk_errcode_t initialize_kernel_device(void);
-static int initialize_sysfs(void);
-static void terminate_kernel_device(void);
 
+EXPORT_TRACEPOINT_SYMBOL_GPL(mali_timeline_event);
+EXPORT_TRACEPOINT_SYMBOL_GPL(mali_hw_counter);
+EXPORT_TRACEPOINT_SYMBOL_GPL(mali_sw_counters);
+#endif /* CONFIG_TRACEPOINTS */
 
 /* from the __malidrv_build_info.c file that is generated during build */
 extern const char *__malidrv_build_info(void);
@@ -49,11 +58,7 @@ int mali_debug_level = 2;
 module_param(mali_debug_level, int, S_IRUSR | S_IWUSR | S_IWGRP | S_IRGRP | S_IROTH); /* rw-rw-r-- */
 MODULE_PARM_DESC(mali_debug_level, "Higher number, more dmesg output");
 
-/* By default the module uses any available major, but it's possible to set it at load time to a specific number */
-int mali_major = 0;
-module_param(mali_major, int, S_IRUGO); /* r--r--r-- */
-MODULE_PARM_DESC(mali_major, "Device major number");
-
+extern int mali_max_job_runtime;
 module_param(mali_max_job_runtime, int, S_IRUSR | S_IWUSR | S_IWGRP | S_IRGRP | S_IROTH);
 MODULE_PARM_DESC(mali_max_job_runtime, "Maximum allowed job runtime in msecs.\nJobs will be killed after this no matter what");
 
@@ -61,12 +66,52 @@ extern int mali_l2_max_reads;
 module_param(mali_l2_max_reads, int, S_IRUSR | S_IRGRP | S_IROTH);
 MODULE_PARM_DESC(mali_l2_max_reads, "Maximum reads for Mali L2 cache");
 
-#if MALI_TIMELINE_PROFILING_ENABLED
+extern unsigned int mali_dedicated_mem_start;
+module_param(mali_dedicated_mem_start, uint, S_IRUSR | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_dedicated_mem_start, "Physical start address of dedicated Mali GPU memory.");
+
+extern unsigned int mali_dedicated_mem_size;
+module_param(mali_dedicated_mem_size, uint, S_IRUSR | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_dedicated_mem_size, "Size of dedicated Mali GPU memory.");
+
+extern unsigned int mali_shared_mem_size;
+module_param(mali_shared_mem_size, uint, S_IRUSR | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_shared_mem_size, "Size of shared Mali GPU memory.");
+
+#if defined(CONFIG_MALI400_PROFILING)
 extern int mali_boot_profiling;
 module_param(mali_boot_profiling, int, S_IRUSR | S_IRGRP | S_IROTH);
 MODULE_PARM_DESC(mali_boot_profiling, "Start profiling as a part of Mali driver initialization");
 #endif
 
+extern int mali_max_pp_cores_group_1;
+module_param(mali_max_pp_cores_group_1, int, S_IRUSR | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_max_pp_cores_group_1, "Limit the number of PP cores to use from first PP group.");
+
+extern int mali_max_pp_cores_group_2;
+module_param(mali_max_pp_cores_group_2, int, S_IRUSR | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_max_pp_cores_group_2, "Limit the number of PP cores to use from second PP group (Mali-450 only).");
+
+#if defined(CONFIG_MALI400_POWER_PERFORMANCE_POLICY)
+/** the max fps the same as display vsync default 60, can set by module insert parameter */
+extern int mali_max_system_fps;
+module_param(mali_max_system_fps, int, S_IRUSR | S_IWUSR | S_IWGRP | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_max_system_fps, "Max system fps the same as display VSYNC.");
+
+/** a lower limit on their desired FPS default 58, can set by module insert parameter*/
+extern int mali_desired_fps;
+module_param(mali_desired_fps, int, S_IRUSR | S_IWUSR | S_IWGRP | S_IRGRP | S_IROTH);
+MODULE_PARM_DESC(mali_desired_fps, "A bit lower than max_system_fps which user desired fps");
+#endif
+
+#if MALI_ENABLE_CPU_CYCLES
+#include <linux/cpumask.h>
+#include <linux/timer.h>
+#include <asm/smp.h>
+static struct timer_list mali_init_cpu_clock_timers[8];
+static u32 mali_cpu_clock_last_value[8] = {0,};
+#endif
+
 /* Export symbols from common code: mali_user_settings.c */
 #include "mali_user_settings_db.h"
 EXPORT_SYMBOL(mali_set_user_setting);
@@ -74,9 +119,14 @@ EXPORT_SYMBOL(mali_get_user_setting);
 
 static char mali_dev_name[] = "mali"; /* should be const, but the functions we call requires non-cost */
 
-/* the mali device */
-static struct mali_dev device;
+/* This driver only supports one Mali device, and this variable stores this single platform device */
+struct platform_device *mali_platform_device = NULL;
+
+/* This driver only supports one Mali device, and this variable stores the exposed misc device (/dev/mali) */
+static struct miscdevice mali_miscdevice = { 0, };
 
+static int mali_miscdevice_register(struct platform_device *pdev);
+static void mali_miscdevice_unregister(void);
 
 static int mali_open(struct inode *inode, struct file *filp);
 static int mali_release(struct inode *inode, struct file *filp);
@@ -86,11 +136,69 @@ static long mali_ioctl(struct file *filp, unsigned int cmd, unsigned long arg);
 static int mali_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg);
 #endif
 
-static int mali_mmap(struct file * filp, struct vm_area_struct * vma);
+static int mali_probe(struct platform_device *pdev);
+static int mali_remove(struct platform_device *pdev);
 
-/* Linux char file operations provided by the Mali module */
-struct file_operations mali_fops =
-{
+static int mali_driver_suspend_scheduler(struct device *dev);
+static int mali_driver_resume_scheduler(struct device *dev);
+
+#ifdef CONFIG_PM_RUNTIME
+static int mali_driver_runtime_suspend(struct device *dev);
+static int mali_driver_runtime_resume(struct device *dev);
+static int mali_driver_runtime_idle(struct device *dev);
+#endif
+
+#if defined(MALI_FAKE_PLATFORM_DEVICE)
+extern int mali_platform_device_register(void);
+extern int mali_platform_device_unregister(void);
+#endif
+
+/* Linux power management operations provided by the Mali device driver */
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 29))
+struct pm_ext_ops mali_dev_ext_pm_ops = {
+	.base =
+	{
+		.suspend = mali_driver_suspend_scheduler,
+		.resume = mali_driver_resume_scheduler,
+		.freeze = mali_driver_suspend_scheduler,
+		.thaw =   mali_driver_resume_scheduler,
+	},
+};
+#else
+static const struct dev_pm_ops mali_dev_pm_ops = {
+#ifdef CONFIG_PM_RUNTIME
+	.runtime_suspend = mali_driver_runtime_suspend,
+	.runtime_resume = mali_driver_runtime_resume,
+	.runtime_idle = mali_driver_runtime_idle,
+#endif
+	.suspend = mali_driver_suspend_scheduler,
+	.resume = mali_driver_resume_scheduler,
+	.freeze = mali_driver_suspend_scheduler,
+	.thaw = mali_driver_resume_scheduler,
+	.poweroff = mali_driver_suspend_scheduler,
+};
+#endif
+
+/* The Mali device driver struct */
+static struct platform_driver mali_platform_driver = {
+	.probe  = mali_probe,
+	.remove = mali_remove,
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 29))
+	.pm = &mali_dev_ext_pm_ops,
+#endif
+	.driver =
+	{
+		.name   = MALI_GPU_NAME_UTGARD,
+		.owner  = THIS_MODULE,
+		.bus = &platform_bus_type,
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 29))
+		.pm = &mali_dev_pm_ops,
+#endif
+	},
+};
+
+/* Linux misc device operations (/dev/mali) */
+struct file_operations mali_fops = {
 	.owner = THIS_MODULE,
 	.open = mali_open,
 	.release = mali_release,
@@ -103,214 +211,365 @@ struct file_operations mali_fops =
 };
 
 
-int mali_driver_init(void)
+#if MALI_ENABLE_CPU_CYCLES
+void mali_init_cpu_time_counters(int reset, int enable_divide_by_64)
 {
-	int ret = 0;
+	/* The CPU assembly reference used is: ARM Architecture Reference Manual ARMv7-AR C.b */
+	u32 write_value;
 
-	MALI_DEBUG_PRINT(2, ("\n"));
-	MALI_DEBUG_PRINT(2, ("Inserting Mali v%d device driver. \n",_MALI_API_VERSION));
-	MALI_DEBUG_PRINT(2, ("Compiled: %s, time: %s.\n", __DATE__, __TIME__));
-	MALI_DEBUG_PRINT(2, ("Driver revision: %s\n", SVN_REV_STRING));
+	/* See B4.1.116 PMCNTENSET, Performance Monitors Count Enable Set register, VMSA */
+	/* setting p15 c9 c12 1 to 0x8000000f==CPU_CYCLE_ENABLE |EVENT_3_ENABLE|EVENT_2_ENABLE|EVENT_1_ENABLE|EVENT_0_ENABLE */
+	asm volatile("mcr p15, 0, %0, c9, c12, 1" :: "r"(0x8000000f));
 
-	ret = _mali_dev_platform_register();
-	if (0 != ret) goto platform_register_failed;
-	ret = map_errcode(initialize_kernel_device());
-	if (0 != ret) goto initialize_kernel_device_failed;
 
-	ret = map_errcode(mali_platform_init());
-	if (0 != ret) goto platform_init_failed;
+	/* See B4.1.117 PMCR, Performance Monitors Control Register. Writing to p15, c9, c12, 0 */
+	write_value = 1 << 0; /* Bit 0 set. Enable counters */
+	if (reset) {
+		write_value |= 1 << 1; /* Reset event counters */
+		write_value |= 1 << 2; /* Reset cycle counter  */
+	}
+	if (enable_divide_by_64) {
+		write_value |= 1 << 3; /* Enable the Clock divider by 64 */
+	}
+	write_value |= 1 << 4; /* Export enable. Not needed */
+	asm volatile("MCR p15, 0, %0, c9, c12, 0\t\n" :: "r"(write_value));
 
-	mali_osk_low_level_mem_init();
+	/* PMOVSR Overflow Flag Status Register - Clear Clock and Event overflows */
+	asm volatile("MCR p15, 0, %0, c9, c12, 3\t\n" :: "r"(0x8000000f));
 
-	ret = map_errcode(mali_initialize_subsystems());
-	if (0 != ret) goto initialize_subsystems_failed;
 
-	ret = initialize_sysfs();
-	if (0 != ret) goto initialize_sysfs_failed;
+	/* See B4.1.124 PMUSERENR - setting p15 c9 c14 to 1" */
+	/* User mode access to the Performance Monitors enabled. */
+	/* Lets User space read cpu clock cycles */
+	asm volatile("mcr p15, 0, %0, c9, c14, 0" :: "r"(1));
+}
 
-	MALI_PRINT(("Mali device driver loaded\n"));
+/** A timer function that configures the cycle clock counter on current CPU.
+ * The function \a mali_init_cpu_time_counters_on_all_cpus sets up this
+ * function to trigger on all Cpus during module load.
+ */
+static void mali_init_cpu_clock_timer_func(unsigned long data)
+{
+	int reset_counters, enable_divide_clock_counter_by_64;
+	int current_cpu = raw_smp_processor_id();
+	unsigned int sample0;
+	unsigned int sample1;
 
-	return 0; /* Success */
+	MALI_IGNORE(data);
 
-	/* Error handling */
-initialize_sysfs_failed:
-	mali_terminate_subsystems();
-initialize_subsystems_failed:
-	mali_osk_low_level_mem_term();
-	mali_platform_deinit();
-platform_init_failed:
-	terminate_kernel_device();
-initialize_kernel_device_failed:
-	_mali_dev_platform_unregister();
-platform_register_failed:
-	return ret;
+	reset_counters = 1;
+	enable_divide_clock_counter_by_64 = 0;
+	mali_init_cpu_time_counters(reset_counters, enable_divide_clock_counter_by_64);
+
+	sample0 = mali_get_cpu_cyclecount();
+	sample1 = mali_get_cpu_cyclecount();
+
+	MALI_DEBUG_PRINT(3, ("Init Cpu %d cycle counter- First two samples: %08x %08x \n", current_cpu, sample0, sample1));
 }
 
-void mali_driver_exit(void)
+/** A timer functions for storing current time on all cpus.
+ * Used for checking if the clocks have similar values or if they are drifting.
+ */
+static void mali_print_cpu_clock_timer_func(unsigned long data)
 {
-	MALI_DEBUG_PRINT(2, ("\n"));
-	MALI_DEBUG_PRINT(2, ("Unloading Mali v%d device driver.\n",_MALI_API_VERSION));
-
-	/* No need to terminate sysfs, this will be done automatically along with device termination */
+	int current_cpu = raw_smp_processor_id();
+	unsigned int sample0;
 
-	mali_terminate_subsystems();
+	MALI_IGNORE(data);
+	sample0 = mali_get_cpu_cyclecount();
+	if (current_cpu < 8) {
+		mali_cpu_clock_last_value[current_cpu] = sample0;
+	}
+}
 
-	mali_osk_low_level_mem_term();
+/** Init the performance registers on all CPUs to count clock cycles.
+ * For init \a print_only should be 0.
+ * If \a print_only is 1, it will intead print the current clock value of all CPUs.
+ */
+void mali_init_cpu_time_counters_on_all_cpus(int print_only)
+{
+	int i = 0;
+	int cpu_number;
+	int jiffies_trigger;
+	int jiffies_wait;
+
+	jiffies_wait = 2;
+	jiffies_trigger = jiffies + jiffies_wait;
+
+	for (i = 0 ; i < 8 ; i++) {
+		init_timer(&mali_init_cpu_clock_timers[i]);
+		if (print_only) mali_init_cpu_clock_timers[i].function = mali_print_cpu_clock_timer_func;
+		else            mali_init_cpu_clock_timers[i].function = mali_init_cpu_clock_timer_func;
+		mali_init_cpu_clock_timers[i].expires = jiffies_trigger ;
+	}
+	cpu_number = cpumask_first(cpu_online_mask);
+	for (i = 0 ; i < 8 ; i++) {
+		int next_cpu;
+		add_timer_on(&mali_init_cpu_clock_timers[i], cpu_number);
+		next_cpu = cpumask_next(cpu_number, cpu_online_mask);
+		if (next_cpu >= nr_cpu_ids) break;
+		cpu_number = next_cpu;
+	}
 
-	mali_platform_deinit();
+	while (jiffies_wait) jiffies_wait = schedule_timeout_uninterruptible(jiffies_wait);
 
-	terminate_kernel_device();
-	_mali_dev_platform_unregister();
+	for (i = 0 ; i < 8 ; i++) {
+		del_timer_sync(&mali_init_cpu_clock_timers[i]);
+	}
 
-#if MALI_LICENSE_IS_GPL
-	/* @@@@ clean up the work queues! This should not be terminated here, since it isn't inited in the function above! */
-	flush_workqueue(mali_wq);
-	destroy_workqueue(mali_wq);
-	mali_wq = NULL;
+	if (print_only) {
+		if ((0 == mali_cpu_clock_last_value[2]) && (0 == mali_cpu_clock_last_value[3])) {
+			/* Diff can be printed if we want to check if the clocks are in sync
+			int diff = mali_cpu_clock_last_value[0] - mali_cpu_clock_last_value[1];*/
+			MALI_DEBUG_PRINT(2, ("CPU cycle counters readout all: %08x %08x\n", mali_cpu_clock_last_value[0], mali_cpu_clock_last_value[1]));
+		} else {
+			MALI_DEBUG_PRINT(2, ("CPU cycle counters readout all: %08x %08x %08x %08x\n", mali_cpu_clock_last_value[0], mali_cpu_clock_last_value[1], mali_cpu_clock_last_value[2], mali_cpu_clock_last_value[3]));
+		}
+	}
+}
 #endif
 
-	MALI_PRINT(("Mali device driver unloaded\n"));
-}
 
-static int initialize_kernel_device(void)
+int mali_module_init(void)
 {
-	int err;
-	dev_t dev = 0;
-	if (0 == mali_major)
-	{
-		/* auto select a major */
-		err = alloc_chrdev_region(&dev, 0/*first minor*/, 1/*count*/, mali_dev_name);
-		mali_major = MAJOR(dev);
+	int err = 0;
+
+	MALI_DEBUG_PRINT(2, ("Inserting Mali v%d device driver. \n", _MALI_API_VERSION));
+	MALI_DEBUG_PRINT(2, ("Compiled: %s, time: %s.\n", __DATE__, __TIME__));
+	MALI_DEBUG_PRINT(2, ("Driver revision: %s\n", SVN_REV_STRING));
+
+#if MALI_ENABLE_CPU_CYCLES
+	mali_init_cpu_time_counters_on_all_cpus(0);
+	MALI_DEBUG_PRINT(2, ("CPU cycle counter setup complete\n"));
+	/* Printing the current cpu counters */
+	mali_init_cpu_time_counters_on_all_cpus(1);
+#endif
+
+	/* Initialize module wide settings */
+#if defined(MALI_FAKE_PLATFORM_DEVICE)
+	MALI_DEBUG_PRINT(2, ("mali_module_init() registering device\n"));
+	err = mali_platform_device_register();
+	if (0 != err) {
+		return err;
 	}
-	else
-	{
-		/* use load time defined major number */
-		dev = MKDEV(mali_major, 0);
-		err = register_chrdev_region(dev, 1/*count*/, mali_dev_name);
+#endif
+
+	MALI_DEBUG_PRINT(2, ("mali_module_init() registering driver\n"));
+
+	err = platform_driver_register(&mali_platform_driver);
+
+	if (0 != err) {
+		MALI_DEBUG_PRINT(2, ("mali_module_init() Failed to register driver (%d)\n", err));
+#if defined(MALI_FAKE_PLATFORM_DEVICE)
+		mali_platform_device_unregister();
+#endif
+		mali_platform_device = NULL;
+		return err;
 	}
 
-	if (err)
-	{
-			goto init_chrdev_err;
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+	err = _mali_internal_profiling_init(mali_boot_profiling ? MALI_TRUE : MALI_FALSE);
+	if (0 != err) {
+		/* No biggie if we wheren't able to initialize the profiling */
+		MALI_PRINT_ERROR(("Failed to initialize profiling, feature will be unavailable\n"));
 	}
+#endif
 
-	memset(&device, 0, sizeof(device));
+	MALI_PRINT(("Mali device driver loaded\n"));
 
-	/* initialize our char dev data */
-	cdev_init(&device.cdev, &mali_fops);
-	device.cdev.owner = THIS_MODULE;
-	device.cdev.ops = &mali_fops;
+	return 0; /* Success */
+}
 
-	/* register char dev with the kernel */
-	err = cdev_add(&device.cdev, dev, 1/*count*/);
-	if (err)
-	{
-			goto init_cdev_err;
+void mali_module_exit(void)
+{
+	MALI_DEBUG_PRINT(2, ("Unloading Mali v%d device driver.\n", _MALI_API_VERSION));
+
+	MALI_DEBUG_PRINT(2, ("mali_module_exit() unregistering driver\n"));
+
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+	_mali_internal_profiling_term();
+#endif
+
+	platform_driver_unregister(&mali_platform_driver);
+
+#if defined(MALI_FAKE_PLATFORM_DEVICE)
+	MALI_DEBUG_PRINT(2, ("mali_module_exit() unregistering device\n"));
+	mali_platform_device_unregister();
+#endif
+
+	MALI_PRINT(("Mali device driver unloaded\n"));
+}
+
+static int mali_probe(struct platform_device *pdev)
+{
+	int err;
+
+	MALI_DEBUG_PRINT(2, ("mali_probe(): Called for platform device %s\n", pdev->name));
+
+	if (NULL != mali_platform_device) {
+		/* Already connected to a device, return error */
+		MALI_PRINT_ERROR(("mali_probe(): The Mali driver is already connected with a Mali device."));
+		return -EEXIST;
 	}
 
-	/* Success! */
-	return 0;
+	mali_platform_device = pdev;
+
+	if (_MALI_OSK_ERR_OK == _mali_osk_wq_init()) {
+		/* Initialize the Mali GPU HW specified by pdev */
+		if (_MALI_OSK_ERR_OK == mali_initialize_subsystems()) {
+			/* Register a misc device (so we are accessible from user space) */
+			err = mali_miscdevice_register(pdev);
+			if (0 == err) {
+				/* Setup sysfs entries */
+				err = mali_sysfs_register(mali_dev_name);
+				if (0 == err) {
+					MALI_DEBUG_PRINT(2, ("mali_probe(): Successfully initialized driver for platform device %s\n", pdev->name));
+					return 0;
+				} else {
+					MALI_PRINT_ERROR(("mali_probe(): failed to register sysfs entries"));
+				}
+				mali_miscdevice_unregister();
+			} else {
+				MALI_PRINT_ERROR(("mali_probe(): failed to register Mali misc device."));
+			}
+			mali_terminate_subsystems();
+		} else {
+			MALI_PRINT_ERROR(("mali_probe(): Failed to initialize Mali device driver."));
+		}
+		_mali_osk_wq_term();
+	}
 
-init_cdev_err:
-	unregister_chrdev_region(dev, 1/*count*/);
-init_chrdev_err:
-	return err;
+	mali_platform_device = NULL;
+	return -EFAULT;
 }
 
-static int initialize_sysfs(void)
+static int mali_remove(struct platform_device *pdev)
 {
-	dev_t dev = MKDEV(mali_major, 0);
-	return mali_sysfs_register(&device, dev, mali_dev_name);
+	MALI_DEBUG_PRINT(2, ("mali_remove() called for platform device %s\n", pdev->name));
+	mali_sysfs_unregister();
+	mali_miscdevice_unregister();
+	mali_terminate_subsystems();
+	_mali_osk_wq_term();
+	mali_platform_device = NULL;
+	return 0;
 }
 
-static void terminate_kernel_device(void)
+static int mali_miscdevice_register(struct platform_device *pdev)
 {
-	dev_t dev = MKDEV(mali_major, 0);
+	int err;
 
-	mali_sysfs_unregister(&device, dev, mali_dev_name);
+	mali_miscdevice.minor = MISC_DYNAMIC_MINOR;
+	mali_miscdevice.name = mali_dev_name;
+	mali_miscdevice.fops = &mali_fops;
+	mali_miscdevice.parent = get_device(&pdev->dev);
 
-	/* unregister char device */
-	cdev_del(&device.cdev);
-	/* free major */
-	unregister_chrdev_region(dev, 1/*count*/);
-	return;
+	err = misc_register(&mali_miscdevice);
+	if (0 != err) {
+		MALI_PRINT_ERROR(("Failed to register misc device, misc_register() returned %d\n", err));
+	}
+
+	return err;
 }
 
-/** @note munmap handler is done by vma close handler */
-static int mali_mmap(struct file * filp, struct vm_area_struct * vma)
+static void mali_miscdevice_unregister(void)
 {
-	struct mali_session_data * session_data;
-	_mali_uk_mem_mmap_s args = {0, };
+	misc_deregister(&mali_miscdevice);
+}
 
-    session_data = (struct mali_session_data *)filp->private_data;
-	if (NULL == session_data)
-	{
-		MALI_PRINT_ERROR(("mmap called without any session data available\n"));
-		return -EFAULT;
-	}
+static int mali_driver_suspend_scheduler(struct device *dev)
+{
+	mali_pm_os_suspend();
+	return 0;
+}
 
-	MALI_DEBUG_PRINT(4, ("MMap() handler: start=0x%08X, phys=0x%08X, size=0x%08X\n", (unsigned int)vma->vm_start, (unsigned int)(vma->vm_pgoff << PAGE_SHIFT), (unsigned int)(vma->vm_end - vma->vm_start)) );
+static int mali_driver_resume_scheduler(struct device *dev)
+{
+	mali_pm_os_resume();
+	return 0;
+}
 
-	/* Re-pack the arguments that mmap() packed for us */
-	args.ctx = session_data;
-	args.phys_addr = vma->vm_pgoff << PAGE_SHIFT;
-	args.size = vma->vm_end - vma->vm_start;
-	args.ukk_private = vma;
+#ifdef CONFIG_PM_RUNTIME
+static int mali_driver_runtime_suspend(struct device *dev)
+{
+	mali_pm_runtime_suspend();
+	return 0;
+}
 
-	/* Call the common mmap handler */
-	MALI_CHECK(_MALI_OSK_ERR_OK ==_mali_ukk_mem_mmap( &args ), -EFAULT);
+static int mali_driver_runtime_resume(struct device *dev)
+{
+	mali_pm_runtime_resume();
+	return 0;
+}
 
-    return 0;
+static int mali_driver_runtime_idle(struct device *dev)
+{
+	/* Nothing to do */
+	return 0;
 }
+#endif
 
 static int mali_open(struct inode *inode, struct file *filp)
 {
-	struct mali_session_data * session_data;
-    _mali_osk_errcode_t err;
+	struct mali_session_data *session_data;
+	_mali_osk_errcode_t err;
 
 	/* input validation */
-	if (0 != MINOR(inode->i_rdev)) return -ENODEV;
+	if (mali_miscdevice.minor != iminor(inode)) {
+		MALI_PRINT_ERROR(("mali_open() Minor does not match\n"));
+		return -ENODEV;
+	}
 
 	/* allocated struct to track this session */
-    err = _mali_ukk_open((void **)&session_data);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	err = _mali_ukk_open((void **)&session_data);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
 	/* initialize file pointer */
 	filp->f_pos = 0;
 
 	/* link in our session data */
-	filp->private_data = (void*)session_data;
+	filp->private_data = (void *)session_data;
 
 	return 0;
 }
 
 static int mali_release(struct inode *inode, struct file *filp)
 {
-    _mali_osk_errcode_t err;
+	_mali_osk_errcode_t err;
 
-    /* input validation */
-	if (0 != MINOR(inode->i_rdev)) return -ENODEV;
+	/* input validation */
+	if (mali_miscdevice.minor != iminor(inode)) {
+		MALI_PRINT_ERROR(("mali_release() Minor does not match\n"));
+		return -ENODEV;
+	}
 
-    err = _mali_ukk_close((void **)&filp->private_data);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	err = _mali_ukk_close((void **)&filp->private_data);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
 	return 0;
 }
 
-int map_errcode( _mali_osk_errcode_t err )
+int map_errcode(_mali_osk_errcode_t err)
 {
-    switch(err)
-    {
-        case _MALI_OSK_ERR_OK : return 0;
-        case _MALI_OSK_ERR_FAULT: return -EFAULT;
-        case _MALI_OSK_ERR_INVALID_FUNC: return -ENOTTY;
-        case _MALI_OSK_ERR_INVALID_ARGS: return -EINVAL;
-        case _MALI_OSK_ERR_NOMEM: return -ENOMEM;
-        case _MALI_OSK_ERR_TIMEOUT: return -ETIMEDOUT;
-        case _MALI_OSK_ERR_RESTARTSYSCALL: return -ERESTARTSYS;
-        case _MALI_OSK_ERR_ITEM_NOT_FOUND: return -ENOENT;
-        default: return -EFAULT;
-    }
+	switch (err) {
+	case _MALI_OSK_ERR_OK :
+		return 0;
+	case _MALI_OSK_ERR_FAULT:
+		return -EFAULT;
+	case _MALI_OSK_ERR_INVALID_FUNC:
+		return -ENOTTY;
+	case _MALI_OSK_ERR_INVALID_ARGS:
+		return -EINVAL;
+	case _MALI_OSK_ERR_NOMEM:
+		return -ENOMEM;
+	case _MALI_OSK_ERR_TIMEOUT:
+		return -ETIMEDOUT;
+	case _MALI_OSK_ERR_RESTARTSYSCALL:
+		return -ERESTARTSYS;
+	case _MALI_OSK_ERR_ITEM_NOT_FOUND:
+		return -ENOENT;
+	default:
+		return -EFAULT;
+	}
 }
 
 #ifdef HAVE_UNLOCKED_IOCTL
@@ -330,185 +589,227 @@ static int mali_ioctl(struct inode *inode, struct file *filp, unsigned int cmd,
 	MALI_DEBUG_PRINT(7, ("Ioctl received 0x%08X 0x%08lX\n", cmd, arg));
 
 	session_data = (struct mali_session_data *)filp->private_data;
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MALI_DEBUG_PRINT(7, ("filp->private_data was NULL\n"));
 		return -ENOTTY;
 	}
 
-	if (NULL == (void *)arg)
-	{
+	if (NULL == (void *)arg) {
 		MALI_DEBUG_PRINT(7, ("arg was NULL\n"));
 		return -ENOTTY;
 	}
 
-	switch(cmd)
-	{
-		case MALI_IOC_GET_SYSTEM_INFO_SIZE:
-			err = get_system_info_size_wrapper(session_data, (_mali_uk_get_system_info_size_s __user *)arg);
-			break;
+	switch (cmd) {
+	case MALI_IOC_WAIT_FOR_NOTIFICATION:
+		err = wait_for_notification_wrapper(session_data, (_mali_uk_wait_for_notification_s __user *)arg);
+		break;
+
+	case MALI_IOC_GET_API_VERSION:
+		err = get_api_version_wrapper(session_data, (_mali_uk_get_api_version_s __user *)arg);
+		break;
 
-		case MALI_IOC_GET_SYSTEM_INFO:
-			err = get_system_info_wrapper(session_data, (_mali_uk_get_system_info_s __user *)arg);
-			break;
+	case MALI_IOC_POST_NOTIFICATION:
+		err = post_notification_wrapper(session_data, (_mali_uk_post_notification_s __user *)arg);
+		break;
 
-		case MALI_IOC_WAIT_FOR_NOTIFICATION:
-			err = wait_for_notification_wrapper(session_data, (_mali_uk_wait_for_notification_s __user *)arg);
-			break;
+	case MALI_IOC_GET_USER_SETTINGS:
+		err = get_user_settings_wrapper(session_data, (_mali_uk_get_user_settings_s __user *)arg);
+		break;
 
-		case MALI_IOC_GET_API_VERSION:
-			err = get_api_version_wrapper(session_data, (_mali_uk_get_api_version_s __user *)arg);
-			break;
+	case MALI_IOC_REQUEST_HIGH_PRIORITY:
+		err = request_high_priority_wrapper(session_data, (_mali_uk_request_high_priority_s __user *)arg);
+		break;
 
-		case MALI_IOC_POST_NOTIFICATION:
-			err = post_notification_wrapper(session_data, (_mali_uk_post_notification_s __user *)arg);
-			break;
+#if defined(CONFIG_MALI400_PROFILING)
+	case MALI_IOC_PROFILING_START:
+		err = profiling_start_wrapper(session_data, (_mali_uk_profiling_start_s __user *)arg);
+		break;
 
-		case MALI_IOC_GET_USER_SETTINGS:
-			err = get_user_settings_wrapper(session_data, (_mali_uk_get_user_settings_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_ADD_EVENT:
+		err = profiling_add_event_wrapper(session_data, (_mali_uk_profiling_add_event_s __user *)arg);
+		break;
 
-#if MALI_TIMELINE_PROFILING_ENABLED
-		case MALI_IOC_PROFILING_START:
-			err = profiling_start_wrapper(session_data, (_mali_uk_profiling_start_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_STOP:
+		err = profiling_stop_wrapper(session_data, (_mali_uk_profiling_stop_s __user *)arg);
+		break;
 
-		case MALI_IOC_PROFILING_ADD_EVENT:
-			err = profiling_add_event_wrapper(session_data, (_mali_uk_profiling_add_event_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_GET_EVENT:
+		err = profiling_get_event_wrapper(session_data, (_mali_uk_profiling_get_event_s __user *)arg);
+		break;
 
-		case MALI_IOC_PROFILING_STOP:
-			err = profiling_stop_wrapper(session_data, (_mali_uk_profiling_stop_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_CLEAR:
+		err = profiling_clear_wrapper(session_data, (_mali_uk_profiling_clear_s __user *)arg);
+		break;
 
-		case MALI_IOC_PROFILING_GET_EVENT:
-			err = profiling_get_event_wrapper(session_data, (_mali_uk_profiling_get_event_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_GET_CONFIG:
+		/* Deprecated: still compatible with get_user_settings */
+		err = get_user_settings_wrapper(session_data, (_mali_uk_get_user_settings_s __user *)arg);
+		break;
 
-		case MALI_IOC_PROFILING_CLEAR:
-			err = profiling_clear_wrapper(session_data, (_mali_uk_profiling_clear_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_REPORT_SW_COUNTERS:
+		err = profiling_report_sw_counters_wrapper(session_data, (_mali_uk_sw_counters_report_s __user *)arg);
+		break;
 
-		case MALI_IOC_PROFILING_GET_CONFIG:
-			/* Deprecated: still compatible with get_user_settings */
-			err = get_user_settings_wrapper(session_data, (_mali_uk_get_user_settings_s __user *)arg);
-			break;
 
-		case MALI_IOC_PROFILING_REPORT_SW_COUNTERS:
-			err = profiling_report_sw_counters_wrapper(session_data, (_mali_uk_sw_counters_report_s __user *)arg);
-			break;
+	case MALI_IOC_PROFILING_MEMORY_USAGE_GET:
+		err = profiling_memory_usage_get_wrapper(session_data, (_mali_uk_profiling_memory_usage_get_s __user *)arg);
+		break;
 
 #else
 
-		case MALI_IOC_PROFILING_START:              /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_ADD_EVENT:          /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_STOP:               /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_GET_EVENT:          /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_CLEAR:              /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_GET_CONFIG:         /* FALL-THROUGH */
-		case MALI_IOC_PROFILING_REPORT_SW_COUNTERS: /* FALL-THROUGH */
-			MALI_DEBUG_PRINT(2, ("Profiling not supported\n"));
-			err = -ENOTTY;
-			break;
+	case MALI_IOC_PROFILING_START:              /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_ADD_EVENT:          /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_STOP:               /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_GET_EVENT:          /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_CLEAR:              /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_GET_CONFIG:         /* FALL-THROUGH */
+	case MALI_IOC_PROFILING_REPORT_SW_COUNTERS: /* FALL-THROUGH */
+		MALI_DEBUG_PRINT(2, ("Profiling not supported\n"));
+		err = -ENOTTY;
+		break;
 
 #endif
 
-		case MALI_IOC_MEM_INIT:
-			err = mem_init_wrapper(session_data, (_mali_uk_init_mem_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_WRITE_SAFE:
+		err = mem_write_safe_wrapper(session_data, (_mali_uk_mem_write_safe_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_TERM:
-			err = mem_term_wrapper(session_data, (_mali_uk_term_mem_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_MAP_EXT:
+		err = mem_map_ext_wrapper(session_data, (_mali_uk_map_external_mem_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_MAP_EXT:
-			err = mem_map_ext_wrapper(session_data, (_mali_uk_map_external_mem_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_UNMAP_EXT:
+		err = mem_unmap_ext_wrapper(session_data, (_mali_uk_unmap_external_mem_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_UNMAP_EXT:
-			err = mem_unmap_ext_wrapper(session_data, (_mali_uk_unmap_external_mem_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_QUERY_MMU_PAGE_TABLE_DUMP_SIZE:
+		err = mem_query_mmu_page_table_dump_size_wrapper(session_data, (_mali_uk_query_mmu_page_table_dump_size_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_QUERY_MMU_PAGE_TABLE_DUMP_SIZE:
-			err = mem_query_mmu_page_table_dump_size_wrapper(session_data, (_mali_uk_query_mmu_page_table_dump_size_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_DUMP_MMU_PAGE_TABLE:
+		err = mem_dump_mmu_page_table_wrapper(session_data, (_mali_uk_dump_mmu_page_table_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_DUMP_MMU_PAGE_TABLE:
-			err = mem_dump_mmu_page_table_wrapper(session_data, (_mali_uk_dump_mmu_page_table_s __user *)arg);
-			break;
+#if defined(CONFIG_MALI400_UMP)
 
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
+	case MALI_IOC_MEM_ATTACH_UMP:
+		err = mem_attach_ump_wrapper(session_data, (_mali_uk_attach_ump_mem_s __user *)arg);
+		break;
 
-		case MALI_IOC_MEM_ATTACH_UMP:
-			err = mem_attach_ump_wrapper(session_data, (_mali_uk_attach_ump_mem_s __user *)arg);
-			break;
-
-		case MALI_IOC_MEM_RELEASE_UMP:
-			err = mem_release_ump_wrapper(session_data, (_mali_uk_release_ump_mem_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_RELEASE_UMP:
+		err = mem_release_ump_wrapper(session_data, (_mali_uk_release_ump_mem_s __user *)arg);
+		break;
 
 #else
 
-		case MALI_IOC_MEM_ATTACH_UMP:
-		case MALI_IOC_MEM_RELEASE_UMP: /* FALL-THROUGH */
-			MALI_DEBUG_PRINT(2, ("UMP not supported\n"));
-			err = -ENOTTY;
-			break;
+	case MALI_IOC_MEM_ATTACH_UMP:
+	case MALI_IOC_MEM_RELEASE_UMP: /* FALL-THROUGH */
+		MALI_DEBUG_PRINT(2, ("UMP not supported\n"));
+		err = -ENOTTY;
+		break;
 #endif
 
-		case MALI_IOC_PP_START_JOB:
-			err = pp_start_job_wrapper(session_data, (_mali_uk_pp_start_job_s __user *)arg);
-			break;
-
-		case MALI_IOC_PP_NUMBER_OF_CORES_GET:
-			err = pp_get_number_of_cores_wrapper(session_data, (_mali_uk_get_pp_number_of_cores_s __user *)arg);
-			break;
-
-		case MALI_IOC_PP_CORE_VERSION_GET:
-			err = pp_get_core_version_wrapper(session_data, (_mali_uk_get_pp_core_version_s __user *)arg);
-			break;
-
-		case MALI_IOC_PP_DISABLE_WB:
-			err = pp_disable_wb_wrapper(session_data, (_mali_uk_pp_disable_wb_s __user *)arg);
-			break;
-
-		case MALI_IOC_GP2_START_JOB:
-			err = gp_start_job_wrapper(session_data, (_mali_uk_gp_start_job_s __user *)arg);
-			break;
+#ifdef CONFIG_DMA_SHARED_BUFFER
+	case MALI_IOC_MEM_ATTACH_DMA_BUF:
+		err = mali_attach_dma_buf(session_data, (_mali_uk_attach_dma_buf_s __user *)arg);
+		break;
 
-		case MALI_IOC_GP2_NUMBER_OF_CORES_GET:
-			err = gp_get_number_of_cores_wrapper(session_data, (_mali_uk_get_gp_number_of_cores_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_RELEASE_DMA_BUF:
+		err = mali_release_dma_buf(session_data, (_mali_uk_release_dma_buf_s __user *)arg);
+		break;
 
-		case MALI_IOC_GP2_CORE_VERSION_GET:
-			err = gp_get_core_version_wrapper(session_data, (_mali_uk_get_gp_core_version_s __user *)arg);
-			break;
-
-		case MALI_IOC_GP2_SUSPEND_RESPONSE:
-			err = gp_suspend_response_wrapper(session_data, (_mali_uk_gp_suspend_response_s __user *)arg);
-			break;
-
-		case MALI_IOC_VSYNC_EVENT_REPORT:
-			err = vsync_event_report_wrapper(session_data, (_mali_uk_vsync_event_report_s __user *)arg);
-			break;
+	case MALI_IOC_MEM_DMA_BUF_GET_SIZE:
+		err = mali_dma_buf_get_size(session_data, (_mali_uk_dma_buf_get_size_s __user *)arg);
+		break;
+#else
 
-		case MALI_IOC_MEM_GET_BIG_BLOCK: /* Fallthrough */
-		case MALI_IOC_MEM_FREE_BIG_BLOCK:
-			MALI_PRINT_ERROR(("Non-MMU mode is no longer supported.\n"));
-			err = -ENOTTY;
-			break;
+	case MALI_IOC_MEM_ATTACH_DMA_BUF:   /* FALL-THROUGH */
+	case MALI_IOC_MEM_RELEASE_DMA_BUF:  /* FALL-THROUGH */
+	case MALI_IOC_MEM_DMA_BUF_GET_SIZE: /* FALL-THROUGH */
+		MALI_DEBUG_PRINT(2, ("DMA-BUF not supported\n"));
+		err = -ENOTTY;
+		break;
+#endif
 
-		default:
-			MALI_DEBUG_PRINT(2, ("No handler for ioctl 0x%08X 0x%08lX\n", cmd, arg));
-			err = -ENOTTY;
+	case MALI_IOC_PP_START_JOB:
+		err = pp_start_job_wrapper(session_data, (_mali_uk_pp_start_job_s __user *)arg);
+		break;
+
+	case MALI_IOC_PP_AND_GP_START_JOB:
+		err = pp_and_gp_start_job_wrapper(session_data, (_mali_uk_pp_and_gp_start_job_s __user *)arg);
+		break;
+
+	case MALI_IOC_PP_NUMBER_OF_CORES_GET:
+		err = pp_get_number_of_cores_wrapper(session_data, (_mali_uk_get_pp_number_of_cores_s __user *)arg);
+		break;
+
+	case MALI_IOC_PP_CORE_VERSION_GET:
+		err = pp_get_core_version_wrapper(session_data, (_mali_uk_get_pp_core_version_s __user *)arg);
+		break;
+
+	case MALI_IOC_PP_DISABLE_WB:
+		err = pp_disable_wb_wrapper(session_data, (_mali_uk_pp_disable_wb_s __user *)arg);
+		break;
+
+	case MALI_IOC_GP2_START_JOB:
+		err = gp_start_job_wrapper(session_data, (_mali_uk_gp_start_job_s __user *)arg);
+		break;
+
+	case MALI_IOC_GP2_NUMBER_OF_CORES_GET:
+		err = gp_get_number_of_cores_wrapper(session_data, (_mali_uk_get_gp_number_of_cores_s __user *)arg);
+		break;
+
+	case MALI_IOC_GP2_CORE_VERSION_GET:
+		err = gp_get_core_version_wrapper(session_data, (_mali_uk_get_gp_core_version_s __user *)arg);
+		break;
+
+	case MALI_IOC_GP2_SUSPEND_RESPONSE:
+		err = gp_suspend_response_wrapper(session_data, (_mali_uk_gp_suspend_response_s __user *)arg);
+		break;
+
+	case MALI_IOC_VSYNC_EVENT_REPORT:
+		err = vsync_event_report_wrapper(session_data, (_mali_uk_vsync_event_report_s __user *)arg);
+		break;
+
+	case MALI_IOC_TIMELINE_GET_LATEST_POINT:
+		err = timeline_get_latest_point_wrapper(session_data, (_mali_uk_timeline_get_latest_point_s __user *)arg);
+		break;
+	case MALI_IOC_TIMELINE_WAIT:
+		err = timeline_wait_wrapper(session_data, (_mali_uk_timeline_wait_s __user *)arg);
+		break;
+	case MALI_IOC_TIMELINE_CREATE_SYNC_FENCE:
+		err = timeline_create_sync_fence_wrapper(session_data, (_mali_uk_timeline_create_sync_fence_s __user *)arg);
+		break;
+	case MALI_IOC_SOFT_JOB_START:
+		err = soft_job_start_wrapper(session_data, (_mali_uk_soft_job_start_s __user *)arg);
+		break;
+	case MALI_IOC_SOFT_JOB_SIGNAL:
+		err = soft_job_signal_wrapper(session_data, (_mali_uk_soft_job_signal_s __user *)arg);
+		break;
+
+	case MALI_IOC_MEM_INIT: /* Fallthrough */
+	case MALI_IOC_MEM_TERM: /* Fallthrough */
+		MALI_DEBUG_PRINT(2, ("Deprecated ioctls called\n"));
+		err = -ENOTTY;
+		break;
+
+	case MALI_IOC_MEM_GET_BIG_BLOCK: /* Fallthrough */
+	case MALI_IOC_MEM_FREE_BIG_BLOCK:
+		MALI_PRINT_ERROR(("Non-MMU mode is no longer supported.\n"));
+		err = -ENOTTY;
+		break;
+
+	default:
+		MALI_DEBUG_PRINT(2, ("No handler for ioctl 0x%08X 0x%08lX\n", cmd, arg));
+		err = -ENOTTY;
 	};
 
 	return err;
 }
 
 
-module_init(mali_driver_init);
-module_exit(mali_driver_exit);
+module_init(mali_module_init);
+module_exit(mali_module_exit);
 
 MODULE_LICENSE(MALI_KERNEL_LINUX_LICENSE);
 MODULE_AUTHOR("ARM Ltd.");
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_linux.h b/drivers/gpu/mali/mali/linux/mali_kernel_linux.h
old mode 100644
new mode 100755
index 454b3d3..ee7444b
--- a/drivers/gpu/mali/mali/linux/mali_kernel_linux.h
+++ b/drivers/gpu/mali/mali/linux/mali_kernel_linux.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,29 +12,14 @@
 #define __MALI_KERNEL_LINUX_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 #include <linux/cdev.h>     /* character device definitions */
 #include "mali_kernel_license.h"
-#include "mali_osk.h"
+#include "mali_osk_types.h"
 
-struct mali_dev
-{
-	struct cdev cdev;
-#if MALI_LICENSE_IS_GPL
-	struct class *  mali_class;
-#endif
-};
-
-#if MALI_LICENSE_IS_GPL
-/* Defined in mali_osk_irq.h */
-extern struct workqueue_struct * mali_wq;
-#endif
-
-void mali_osk_low_level_mem_init(void);
-void mali_osk_low_level_mem_term(void);
+extern struct platform_device *mali_platform_device;
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_pm.c b/drivers/gpu/mali/mali/linux/mali_kernel_pm.c
deleted file mode 100644
index ce9ed7d..0000000
--- a/drivers/gpu/mali/mali/linux/mali_kernel_pm.c
+++ /dev/null
@@ -1,267 +0,0 @@
-/**
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-/**
- * @file mali_kernel_pm.c
- * Linux Power Management integration
- */
-
-#include <linux/module.h>
-
-#include <linux/sched.h>
-#include <linux/platform_device.h>
-#include <linux/version.h>
-#include <asm/current.h>
-#include <linux/suspend.h>
-#include <linux/module.h>
-#ifdef CONFIG_PM_RUNTIME
-#include <linux/pm_runtime.h>
-#endif
-#include "mali_osk.h"
-#include "mali_uk_types.h"
-#include "mali_kernel_common.h"
-#include "mali_kernel_license.h"
-#include "mali_linux_pm.h"
-#include "mali_pm.h"
-#include "mali_platform.h"
-
-#if ! MALI_LICENSE_IS_GPL
-#undef CONFIG_PM_RUNTIME
-#endif
-
-static int mali_probe(struct platform_device *pdev);
-static int mali_remove(struct platform_device *pdev);
-
-#ifdef CONFIG_PM_RUNTIME
-static int mali_runtime_suspend(struct device *dev);
-static int mali_runtime_resume(struct device *dev);
-#endif
-
-#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,29))
-static int mali_os_suspend(struct platform_device *pdev, pm_message_t state);
-static int mali_os_resume(struct platform_device *pdev);
-#else
-static int mali_os_suspend(struct device *dev);
-static int mali_os_resume(struct device *dev);
-#endif
-
-
-#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29))
-static const struct dev_pm_ops mali_dev_pm_ops =
-{
-#ifdef CONFIG_PM_RUNTIME
-	.runtime_suspend = mali_runtime_suspend,
-	.runtime_resume = mali_runtime_resume,
-	.runtime_idle = NULL,
-#else
-	.suspend = mali_os_suspend,
-	.resume = mali_os_resume,
-#endif
-
-	.freeze = mali_os_suspend,
-	.poweroff = mali_os_suspend,
-	.thaw = mali_os_resume,
-	.restore = mali_os_resume,
-};
-#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,29))
-struct pm_ext_ops mali_ext_pm_operations =
-{
-	.base =
-	{
-		.freeze = mali_os_suspend,
-		.thaw =   mali_os_resume,
-		.poweroff = mali_os_suspend,
-		.restore = mali_os_resume,
-	},
-};
-#endif
-
-
-static struct platform_driver mali_plat_driver =
-{
-	.probe  = mali_probe,
-	.remove = mali_remove,
-#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,29))
-	.suspend = mali_os_suspend,
-	.resume  = mali_os_resume,
-	.pm = &mali_ext_pm_operations,
-#endif
-
-	.driver =
-	{
-		.name   = "mali_dev",
-		.owner  = THIS_MODULE,
-#if MALI_LICENSE_IS_GPL
-		.bus = &platform_bus_type,
-#endif
-#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,29))
-		.pm = &mali_dev_pm_ops,
-#endif
-	},
-};
-
-#ifdef CONFIG_PM_RUNTIME
-static int mali_pwr_suspend_notifier(struct notifier_block *nb,unsigned long event,void* dummy);
-
-static struct notifier_block mali_pwr_notif_block =
-{
-	.notifier_call = mali_pwr_suspend_notifier
-};
-#endif
-
-/** This function is called when platform device is unregistered. This function
- * is necessary when the platform device is unregistered.
- */
-static void _mali_release_pm(struct device *device)
-{
-}
-struct platform_device mali_gpu_device =
-{
-	.name = "mali_dev",
-	.id = 0,
-	.dev.release = _mali_release_pm
-};
-
-/** This function is called when the device is probed */
-static int mali_probe(struct platform_device *pdev)
-{
-	return 0;
-}
-
-static int mali_remove(struct platform_device *pdev)
-{
-#ifdef CONFIG_PM_RUNTIME
-	pm_runtime_disable(&pdev->dev);
-#endif
-	return 0;
-}
-
-#ifdef CONFIG_PM_RUNTIME
-static int mali_pwr_suspend_notifier(struct notifier_block *nb,unsigned long event,void* dummy)
-{
-	switch (event)
-	{
-		case PM_SUSPEND_PREPARE:
-			MALI_DEBUG_PRINT(2, ("mali_pwr_suspend_notifier(PM_SUSPEND_PREPARE) called\n"));
-			mali_pm_os_suspend();
-			break;
-		case PM_POST_SUSPEND:
-			MALI_DEBUG_PRINT(2, ("mali_pwr_suspend_notifier(PM_SUSPEND_PREPARE) called\n"));
-			mali_pm_os_resume();
-			break;
-		default:
-			break;
-	}
-	return 0;
-}
-#endif
-
-
-#ifdef CONFIG_PM_RUNTIME
-
-static int mali_runtime_suspend(struct device *dev)
-{
-	MALI_DEBUG_PRINT(3, ("mali_runtime_suspend() called\n"));
-	mali_pm_runtime_suspend();
-	return 0; /* all ok */
-}
-
-static int mali_runtime_resume(struct device *dev)
-{
-	MALI_DEBUG_PRINT(3, ("mali_runtime_resume() called\n"));
-	mali_pm_runtime_resume();
-	return 0; /* all ok */
-}
-
-#endif
-
-#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,29))
-
-static int mali_os_suspend(struct platform_device *pdev, pm_message_t state)
-{
-	MALI_DEBUG_PRINT(3, ("mali_os_suspend(old) called\n"));
-	mali_pm_os_suspend();
-	return 0; /* all ok */
-}
-
-static int mali_os_resume(struct platform_device *pdev)
-{
-	MALI_DEBUG_PRINT(3, ("mali_os_resume(old) called\n"));
-	mali_pm_os_resume();
-	return 0; /* all ok */
-}
-
-#else
-
-static int mali_os_suspend(struct device *dev)
-{
-	MALI_DEBUG_PRINT(3, ("mali_os_suspend(new) called\n"));
-	mali_pm_os_suspend();
-	return 0; /* all ok */
-}
-
-static int mali_os_resume(struct device *dev)
-{
-	MALI_DEBUG_PRINT(3, ("mali_os_resume(new) called\n"));
-	mali_pm_os_resume();
-	return 0; /* all ok */
-}
-
-#endif
-
-/** This function is called when Mali GPU device is initialized
- */
-int _mali_dev_platform_register(void)
-{
-	int err;
-
-#ifdef CONFIG_PM_RUNTIME
-	set_mali_parent_power_domain((void *)&mali_gpu_device);
-#endif
-
-#ifdef CONFIG_PM_RUNTIME
-	err = register_pm_notifier(&mali_pwr_notif_block);
-	if (err)
-	{
-		return err;
-	}
-#endif
-
-#if MALI_LICENSE_IS_GPL
-	err = platform_device_register(&mali_gpu_device);
-	if (!err)
-	{
-		err = platform_driver_register(&mali_plat_driver);
-		if (err)
-		{
-#ifdef CONFIG_PM_RUNTIME
-			unregister_pm_notifier(&mali_pwr_notif_block);
-#endif
-			platform_device_unregister(&mali_gpu_device);
-		}
-	}
-#endif
-
-	return err;
-}
-
-/** This function is called when Mali GPU device is unloaded
- */
-void _mali_dev_platform_unregister(void)
-{
-#ifdef CONFIG_PM_RUNTIME
-	unregister_pm_notifier(&mali_pwr_notif_block);
-#endif
-
-#if MALI_LICENSE_IS_GPL
-	platform_driver_unregister(&mali_plat_driver);
-	platform_device_unregister(&mali_gpu_device);
-#endif
-}
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_pm.h b/drivers/gpu/mali/mali/linux/mali_kernel_pm.h
deleted file mode 100644
index 89efa1c..0000000
--- a/drivers/gpu/mali/mali/linux/mali_kernel_pm.h
+++ /dev/null
@@ -1,17 +0,0 @@
-/*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_KERNEL_PM_H__
-#define __MALI_KERNEL_PM_H__
-
-int _mali_dev_platform_register(void);
-void _mali_dev_platform_unregister(void);
-
-#endif /* __MALI_KERNEL_PM_H__ */
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.c b/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.c
old mode 100644
new mode 100755
index b5216d3..10d970f
--- a/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.c
+++ b/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.c
@@ -1,9 +1,9 @@
 /**
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,11 +17,9 @@
 #include <linux/kernel.h>
 #include <linux/fs.h>
 #include <linux/device.h>
-#include <linux/version.h>
 #include <linux/module.h>
 #include "mali_kernel_license.h"
 #include "mali_kernel_common.h"
-#include "mali_kernel_linux.h"
 #include "mali_ukk.h"
 
 #if MALI_LICENSE_IS_GPL
@@ -30,13 +28,16 @@
 #include <linux/debugfs.h>
 #include <asm/uaccess.h>
 #include <linux/module.h>
+#include <linux/mali/mali_utgard.h>
 #include "mali_kernel_sysfs.h"
-#if MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
 #include <linux/slab.h>
 #include "mali_osk_profiling.h"
 #endif
+
+#include <linux/mali/mali_utgard.h>
 #include "mali_pm.h"
-#include "mali_cluster.h"
+#include "mali_pmu.h"
 #include "mali_group.h"
 #include "mali_gp.h"
 #include "mali_pp.h"
@@ -44,30 +45,39 @@
 #include "mali_hw_core.h"
 #include "mali_kernel_core.h"
 #include "mali_user_settings_db.h"
-#include "mali_device_pause_resume.h"
+#include "mali_profiling_internal.h"
+#include "mali_gp_job.h"
+#include "mali_pp_job.h"
+#include "mali_pp_scheduler.h"
+
+#define PRIVATE_DATA_COUNTER_MAKE_GP(src) (src)
+#define PRIVATE_DATA_COUNTER_MAKE_PP(src) ((1 << 24) | src)
+#define PRIVATE_DATA_COUNTER_MAKE_PP_SUB_JOB(src, sub_job) ((1 << 24) | (1 << 16) | (sub_job << 8) | src)
+#define PRIVATE_DATA_COUNTER_IS_PP(a) ((((a) >> 24) & 0xFF) ? MALI_TRUE : MALI_FALSE)
+#define PRIVATE_DATA_COUNTER_GET_SRC(a) (a & 0xFF)
+#define PRIVATE_DATA_COUNTER_IS_SUB_JOB(a) ((((a) >> 16) & 0xFF) ? MALI_TRUE : MALI_FALSE)
+#define PRIVATE_DATA_COUNTER_GET_SUB_JOB(a) (((a) >> 8) & 0xFF)
 
 #define POWER_BUFFER_SIZE 3
 
 static struct dentry *mali_debugfs_dir = NULL;
 
-typedef enum
-{
-        _MALI_DEVICE_SUSPEND,
-        _MALI_DEVICE_RESUME,
-        _MALI_DEVICE_DVFS_PAUSE,
-        _MALI_DEVICE_DVFS_RESUME,
-        _MALI_MAX_EVENTS
+typedef enum {
+	_MALI_DEVICE_SUSPEND,
+	_MALI_DEVICE_RESUME,
+	_MALI_DEVICE_DVFS_PAUSE,
+	_MALI_DEVICE_DVFS_RESUME,
+	_MALI_MAX_EVENTS
 } _mali_device_debug_power_events;
 
-static const char* const mali_power_events[_MALI_MAX_EVENTS] = {
-        [_MALI_DEVICE_SUSPEND] = "suspend",
-        [_MALI_DEVICE_RESUME] = "resume",
-        [_MALI_DEVICE_DVFS_PAUSE] = "dvfs_pause",
-        [_MALI_DEVICE_DVFS_RESUME] = "dvfs_resume",
+static const char *const mali_power_events[_MALI_MAX_EVENTS] = {
+	[_MALI_DEVICE_SUSPEND] = "suspend",
+	[_MALI_DEVICE_RESUME] = "resume",
+	[_MALI_DEVICE_DVFS_PAUSE] = "dvfs_pause",
+	[_MALI_DEVICE_DVFS_RESUME] = "dvfs_resume",
 };
 
-static u32 virtual_power_status_register=0;
-static char pwr_buf[POWER_BUFFER_SIZE];
+static mali_bool power_always_on_enabled = MALI_FALSE;
 
 static int open_copy_private_data(struct inode *inode, struct file *filp)
 {
@@ -75,419 +85,199 @@ static int open_copy_private_data(struct inode *inode, struct file *filp)
 	return 0;
 }
 
-static ssize_t gp_gpx_counter_srcx_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *gpos, u32 src_id)
+static ssize_t group_enabled_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
 {
-	char buf[64];
 	int r;
-	u32 val;
-	struct mali_gp_core *gp_core = (struct mali_gp_core *)filp->private_data;
-
-	if (0 == src_id)
-	{
-		val = mali_gp_core_get_counter_src0(gp_core);
-	}
-	else
-	{
-		val = mali_gp_core_get_counter_src1(gp_core);
-	}
-
-	if (MALI_HW_CORE_NO_COUNTER == val)
-	{
-		r = sprintf(buf, "-1\n");
-	}
-	else
-	{
-		r = sprintf(buf, "%u\n", val);
-	}
-	return simple_read_from_buffer(ubuf, cnt, gpos, buf, r);
-}
-
-static ssize_t gp_gpx_counter_srcx_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos, u32 src_id)
-{
-	struct mali_gp_core *gp_core = (struct mali_gp_core *)filp->private_data;
-	char buf[64];
-	long val;
-	int ret;
-
-	if (cnt >= sizeof(buf))
-	{
-		return -EINVAL;
-	}
-
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
-		return -EFAULT;
-	}
-
-	buf[cnt] = 0;
-
-	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
-		return ret;
-	}
+	char buffer[64];
+	struct mali_group *group;
 
-	if (val < 0)
-	{
-		/* any negative input will disable counter */
-		val = MALI_HW_CORE_NO_COUNTER;
-	}
+	group = (struct mali_group *)filp->private_data;
+	MALI_DEBUG_ASSERT_POINTER(group);
 
-	if (0 == src_id)
-	{
-		if (MALI_TRUE != mali_gp_core_set_counter_src0(gp_core, (u32)val))
-		{
-			return 0;
-		}
-	}
-	else
-	{
-		if (MALI_TRUE != mali_gp_core_set_counter_src1(gp_core, (u32)val))
-		{
-			return 0;
-		}
-	}
+	r = snprintf(buffer, 64, "%u\n", mali_group_is_enabled(group) ? 1 : 0);
 
-	*gpos += cnt;
-	return cnt;
+	return simple_read_from_buffer(buf, count, offp, buffer, r);
 }
 
-static ssize_t gp_all_counter_srcx_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos, u32 src_id)
+static ssize_t group_enabled_write(struct file *filp, const char __user *buf, size_t count, loff_t *offp)
 {
-	char buf[64];
-	long val;
-	int ret;
-	u32 ci;
-	struct mali_cluster *cluster;
+	int r;
+	char buffer[64];
+	unsigned long val;
+	struct mali_group *group;
 
-	if (cnt >= sizeof(buf))
-	{
-		return -EINVAL;
-	}
+	group = (struct mali_group *)filp->private_data;
+	MALI_DEBUG_ASSERT_POINTER(group);
 
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
-		return -EFAULT;
+	if (count >= sizeof(buffer)) {
+		return -ENOMEM;
 	}
 
-	buf[cnt] = 0;
-
-	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
-		return ret;
+	if (copy_from_user(&buffer[0], buf, count)) {
+		return -EFAULT;
 	}
+	buffer[count] = '\0';
 
-	if (val < 0)
-	{
-		/* any negative input will disable counter */
-		val = MALI_HW_CORE_NO_COUNTER;
+	r = strict_strtoul(&buffer[0], 10, &val);
+	if (0 != r) {
+		return -EINVAL;
 	}
 
-	ci = 0;
-	cluster = mali_cluster_get_global_cluster(ci);
-	while (NULL != cluster)
-	{
-		u32 gi = 0;
-		struct mali_group *group = mali_cluster_get_group(cluster, gi);
-		while (NULL != group)
-		{
-			struct mali_gp_core *gp_core = mali_group_get_gp_core(group);
-			if (NULL != gp_core)
-			{
-				if (0 == src_id)
-				{
-					if (MALI_TRUE != mali_gp_core_set_counter_src0(gp_core, (u32)val))
-					{
-						return 0;
-					}
-				}
-				else
-				{
-					if (MALI_TRUE != mali_gp_core_set_counter_src1(gp_core, (u32)val))
-					{
-						return 0;
-					}
-				}
-			}
-
-			/* try next group */
-			gi++;
-			group = mali_cluster_get_group(cluster, gi);
-		}
-
-		/* try next cluster */
-		ci++;
-		cluster = mali_cluster_get_global_cluster(ci);
+	switch (val) {
+	case 1:
+		mali_group_enable(group);
+		break;
+	case 0:
+		mali_group_disable(group);
+		break;
+	default:
+		return -EINVAL;
+		break;
 	}
 
-	*gpos += cnt;
-	return cnt;
-}
-
-static ssize_t gp_gpx_counter_src0_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *gpos)
-{
-	return gp_gpx_counter_srcx_read(filp, ubuf, cnt, gpos, 0);
+	*offp += count;
+	return count;
 }
 
-static ssize_t gp_gpx_counter_src1_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *gpos)
-{
-	return gp_gpx_counter_srcx_read(filp, ubuf, cnt, gpos, 1);
-}
+static const struct file_operations group_enabled_fops = {
+	.owner = THIS_MODULE,
+	.open  = open_copy_private_data,
+	.read = group_enabled_read,
+	.write = group_enabled_write,
+};
 
-static ssize_t gp_gpx_counter_src0_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos)
+static ssize_t hw_core_base_addr_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
 {
-	return gp_gpx_counter_srcx_write(filp, ubuf, cnt, gpos, 0);
-}
+	int r;
+	char buffer[64];
+	struct mali_hw_core *hw_core;
 
-static ssize_t gp_gpx_counter_src1_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos)
-{
-	return gp_gpx_counter_srcx_write(filp, ubuf, cnt, gpos, 1);
-}
+	hw_core = (struct mali_hw_core *)filp->private_data;
+	MALI_DEBUG_ASSERT_POINTER(hw_core);
 
-static ssize_t gp_all_counter_src0_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos)
-{
-	return gp_all_counter_srcx_write(filp, ubuf, cnt, gpos, 0);
-}
+	r = snprintf(buffer, 64, "0x%08X\n", hw_core->phys_addr);
 
-static ssize_t gp_all_counter_src1_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *gpos)
-{
-	return gp_all_counter_srcx_write(filp, ubuf, cnt, gpos, 1);
+	return simple_read_from_buffer(buf, count, offp, buffer, r);
 }
 
-static const struct file_operations gp_gpx_counter_src0_fops = {
-	.owner = THIS_MODULE,
-	.open  = open_copy_private_data,
-	.read  = gp_gpx_counter_src0_read,
-	.write = gp_gpx_counter_src0_write,
-};
-
-static const struct file_operations gp_gpx_counter_src1_fops = {
+static const struct file_operations hw_core_base_addr_fops = {
 	.owner = THIS_MODULE,
 	.open  = open_copy_private_data,
-	.read  = gp_gpx_counter_src1_read,
-	.write = gp_gpx_counter_src1_write,
+	.read = hw_core_base_addr_read,
 };
 
-static const struct file_operations gp_all_counter_src0_fops = {
-	.owner = THIS_MODULE,
-	.write = gp_all_counter_src0_write,
-};
-
-static const struct file_operations gp_all_counter_src1_fops = {
-	.owner = THIS_MODULE,
-	.write = gp_all_counter_src1_write,
-};
-
-static ssize_t pp_ppx_counter_srcx_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos, u32 src_id)
+static ssize_t profiling_counter_src_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
 {
+	u32 is_pp = PRIVATE_DATA_COUNTER_IS_PP((u32)filp->private_data);
+	u32 src_id = PRIVATE_DATA_COUNTER_GET_SRC((u32)filp->private_data);
+	mali_bool is_sub_job = PRIVATE_DATA_COUNTER_IS_SUB_JOB((u32)filp->private_data);
+	u32 sub_job = PRIVATE_DATA_COUNTER_GET_SUB_JOB((u32)filp->private_data);
 	char buf[64];
 	int r;
 	u32 val;
-	struct mali_pp_core *pp_core = (struct mali_pp_core *)filp->private_data;
-
-	if (0 == src_id)
-	{
-		val = mali_pp_core_get_counter_src0(pp_core);
-	}
-	else
-	{
-		val = mali_pp_core_get_counter_src1(pp_core);
-	}
-
-	if (MALI_HW_CORE_NO_COUNTER == val)
-	{
-		r = sprintf(buf, "-1\n");
-	}
-	else
-	{
-		r = sprintf(buf, "%u\n", val);
-	}
-	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
-}
-
-static ssize_t pp_ppx_counter_srcx_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos, u32 src_id)
-{
-	struct mali_pp_core *pp_core = (struct mali_pp_core *)filp->private_data;
-	char buf[64];
-	long val;
-	int ret;
-
-	if (cnt >= sizeof(buf))
-	{
-		return -EINVAL;
-	}
-
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
-		return -EFAULT;
-	}
-
-	buf[cnt] = 0;
 
-	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
-		return ret;
-	}
-
-	if (val < 0)
-	{
-		/* any negative input will disable counter */
-		val = MALI_HW_CORE_NO_COUNTER;
-	}
-
-	if (0 == src_id)
-	{
-		if (MALI_TRUE != mali_pp_core_set_counter_src0(pp_core, (u32)val))
-		{
-			return 0;
+	if (MALI_TRUE == is_pp) {
+		/* PP counter */
+		if (MALI_TRUE == is_sub_job) {
+			/* Get counter for a particular sub job */
+			if (0 == src_id) {
+				val = mali_pp_job_get_pp_counter_sub_job_src0(sub_job);
+			} else {
+				val = mali_pp_job_get_pp_counter_sub_job_src1(sub_job);
+			}
+		} else {
+			/* Get default counter for all PP sub jobs */
+			if (0 == src_id) {
+				val = mali_pp_job_get_pp_counter_global_src0();
+			} else {
+				val = mali_pp_job_get_pp_counter_global_src1();
+			}
 		}
-	}
-	else
-	{
-		if (MALI_TRUE != mali_pp_core_set_counter_src1(pp_core, (u32)val))
-		{
-			return 0;
+	} else {
+		/* GP counter */
+		if (0 == src_id) {
+			val = mali_gp_job_get_gp_counter_src0();
+		} else {
+			val = mali_gp_job_get_gp_counter_src1();
 		}
 	}
 
-	*ppos += cnt;
-	return cnt;
+	if (MALI_HW_CORE_NO_COUNTER == val) {
+		r = snprintf(buf, 64, "-1\n");
+	} else {
+		r = snprintf(buf, 64, "%u\n", val);
+	}
+
+	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
 }
 
-static ssize_t pp_all_counter_srcx_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos, u32 src_id)
+static ssize_t profiling_counter_src_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
 {
+	u32 is_pp = PRIVATE_DATA_COUNTER_IS_PP((u32)filp->private_data);
+	u32 src_id = PRIVATE_DATA_COUNTER_GET_SRC((u32)filp->private_data);
+	mali_bool is_sub_job = PRIVATE_DATA_COUNTER_IS_SUB_JOB((u32)filp->private_data);
+	u32 sub_job = PRIVATE_DATA_COUNTER_GET_SUB_JOB((u32)filp->private_data);
 	char buf[64];
 	long val;
 	int ret;
-	u32 ci;
-	struct mali_cluster *cluster;
 
-	if (cnt >= sizeof(buf))
-	{
+	if (cnt >= sizeof(buf)) {
 		return -EINVAL;
 	}
 
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
+	if (copy_from_user(&buf, ubuf, cnt)) {
 		return -EFAULT;
 	}
 
 	buf[cnt] = 0;
 
 	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
+	if (ret < 0) {
 		return ret;
 	}
 
-	if (val < 0)
-	{
+	if (val < 0) {
 		/* any negative input will disable counter */
 		val = MALI_HW_CORE_NO_COUNTER;
 	}
 
-	ci = 0;
-	cluster = mali_cluster_get_global_cluster(ci);
-	while (NULL != cluster)
-	{
-		u32 gi = 0;
-		struct mali_group *group = mali_cluster_get_group(cluster, gi);
-		while (NULL != group)
-		{
-			struct mali_pp_core *pp_core = mali_group_get_pp_core(group);
-			if (NULL != pp_core)
-			{
-				if (0 == src_id)
-				{
-					if (MALI_TRUE != mali_pp_core_set_counter_src0(pp_core, (u32)val))
-					{
-						return 0;
-					}
-				}
-				else
-				{
-					if (MALI_TRUE != mali_pp_core_set_counter_src1(pp_core, (u32)val))
-					{
-						return 0;
-					}
-				}
+	if (MALI_TRUE == is_pp) {
+		/* PP counter */
+		if (MALI_TRUE == is_sub_job) {
+			/* Set counter for a particular sub job */
+			if (0 == src_id) {
+				mali_pp_job_set_pp_counter_sub_job_src0(sub_job, (u32)val);
+			} else {
+				mali_pp_job_set_pp_counter_sub_job_src1(sub_job, (u32)val);
+			}
+		} else {
+			/* Set default counter for all PP sub jobs */
+			if (0 == src_id) {
+				mali_pp_job_set_pp_counter_global_src0((u32)val);
+			} else {
+				mali_pp_job_set_pp_counter_global_src1((u32)val);
 			}
-
-			/* try next group */
-			gi++;
-			group = mali_cluster_get_group(cluster, gi);
 		}
-
-		/* try next cluster */
-		ci++;
-		cluster = mali_cluster_get_global_cluster(ci);
+	} else {
+		/* GP counter */
+		if (0 == src_id) {
+			mali_gp_job_set_gp_counter_src0((u32)val);
+		} else {
+			mali_gp_job_set_gp_counter_src1((u32)val);
+		}
 	}
 
 	*ppos += cnt;
 	return cnt;
 }
 
-static ssize_t pp_ppx_counter_src0_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_ppx_counter_srcx_read(filp, ubuf, cnt, ppos, 0);
-}
-
-static ssize_t pp_ppx_counter_src1_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_ppx_counter_srcx_read(filp, ubuf, cnt, ppos, 1);
-}
-
-static ssize_t pp_ppx_counter_src0_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_ppx_counter_srcx_write(filp, ubuf, cnt, ppos, 0);
-}
-
-static ssize_t pp_ppx_counter_src1_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_ppx_counter_srcx_write(filp, ubuf, cnt, ppos, 1);
-}
-
-static ssize_t pp_all_counter_src0_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_all_counter_srcx_write(filp, ubuf, cnt, ppos, 0);
-}
-
-static ssize_t pp_all_counter_src1_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
-{
-	return pp_all_counter_srcx_write(filp, ubuf, cnt, ppos, 1);
-}
-
-static const struct file_operations pp_ppx_counter_src0_fops = {
+static const struct file_operations profiling_counter_src_fops = {
 	.owner = THIS_MODULE,
 	.open  = open_copy_private_data,
-	.read  = pp_ppx_counter_src0_read,
-	.write = pp_ppx_counter_src0_write,
-};
-
-static const struct file_operations pp_ppx_counter_src1_fops = {
-	.owner = THIS_MODULE,
-	.open  = open_copy_private_data,
-	.read  = pp_ppx_counter_src1_read,
-	.write = pp_ppx_counter_src1_write,
-};
-
-static const struct file_operations pp_all_counter_src0_fops = {
-	.owner = THIS_MODULE,
-	.write = pp_all_counter_src0_write,
-};
-
-static const struct file_operations pp_all_counter_src1_fops = {
-	.owner = THIS_MODULE,
-	.write = pp_all_counter_src1_write,
+	.read  = profiling_counter_src_read,
+	.write = profiling_counter_src_write,
 };
 
-
-
-
-
-
 static ssize_t l2_l2x_counter_srcx_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos, u32 src_id)
 {
 	char buf[64];
@@ -495,22 +285,16 @@ static ssize_t l2_l2x_counter_srcx_read(struct file *filp, char __user *ubuf, si
 	u32 val;
 	struct mali_l2_cache_core *l2_core = (struct mali_l2_cache_core *)filp->private_data;
 
-	if (0 == src_id)
-	{
+	if (0 == src_id) {
 		val = mali_l2_cache_core_get_counter_src0(l2_core);
-	}
-	else
-	{
+	} else {
 		val = mali_l2_cache_core_get_counter_src1(l2_core);
 	}
 
-	if (MALI_HW_CORE_NO_COUNTER == val)
-	{
-		r = sprintf(buf, "-1\n");
-	}
-	else
-	{
-		r = sprintf(buf, "%u\n", val);
+	if (MALI_HW_CORE_NO_COUNTER == val) {
+		r = snprintf(buf, 64, "-1\n");
+	} else {
+		r = snprintf(buf, 64, "%u\n", val);
 	}
 	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
 }
@@ -522,43 +306,30 @@ static ssize_t l2_l2x_counter_srcx_write(struct file *filp, const char __user *u
 	long val;
 	int ret;
 
-	if (cnt >= sizeof(buf))
-	{
+	if (cnt >= sizeof(buf)) {
 		return -EINVAL;
 	}
 
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
+	if (copy_from_user(&buf, ubuf, cnt)) {
 		return -EFAULT;
 	}
 
 	buf[cnt] = 0;
 
 	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
+	if (ret < 0) {
 		return ret;
 	}
 
-	if (val < 0)
-	{
+	if (val < 0) {
 		/* any negative input will disable counter */
 		val = MALI_HW_CORE_NO_COUNTER;
 	}
 
-	if (0 == src_id)
-	{
-		if (MALI_TRUE != mali_l2_cache_core_set_counter_src0(l2_core, (u32)val))
-		{
-			return 0;
-		}
-	}
-	else
-	{
-		if (MALI_TRUE != mali_l2_cache_core_set_counter_src1(l2_core, (u32)val))
-		{
-			return 0;
-		}
+	if (0 == src_id) {
+		mali_l2_cache_core_set_counter_src0(l2_core, (u32)val);
+	} else {
+		mali_l2_cache_core_set_counter_src1(l2_core, (u32)val);
 	}
 
 	*ppos += cnt;
@@ -573,47 +344,33 @@ static ssize_t l2_all_counter_srcx_write(struct file *filp, const char __user *u
 	u32 l2_id;
 	struct mali_l2_cache_core *l2_cache;
 
-	if (cnt >= sizeof(buf))
-	{
+	if (cnt >= sizeof(buf)) {
 		return -EINVAL;
 	}
 
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
+	if (copy_from_user(&buf, ubuf, cnt)) {
 		return -EFAULT;
 	}
 
 	buf[cnt] = 0;
 
 	ret = strict_strtol(buf, 10, &val);
-	if (ret < 0)
-	{
+	if (ret < 0) {
 		return ret;
 	}
 
-	if (val < 0)
-	{
+	if (val < 0) {
 		/* any negative input will disable counter */
 		val = MALI_HW_CORE_NO_COUNTER;
 	}
 
 	l2_id = 0;
 	l2_cache = mali_l2_cache_core_get_glob_l2_core(l2_id);
-	while (NULL != l2_cache)
-	{
-		if (0 == src_id)
-		{
-			if (MALI_TRUE != mali_l2_cache_core_set_counter_src0(l2_cache, (u32)val))
-			{
-				return 0;
-			}
-		}
-		else
-		{
-			if (MALI_TRUE != mali_l2_cache_core_set_counter_src1(l2_cache, (u32)val))
-			{
-				return 0;
-			}
+	while (NULL != l2_cache) {
+		if (0 == src_id) {
+			mali_l2_cache_core_set_counter_src0(l2_cache, (u32)val);
+		} else {
+			mali_l2_cache_core_set_counter_src1(l2_cache, (u32)val);
 		}
 
 		/* try next L2 */
@@ -679,71 +436,80 @@ static const struct file_operations l2_all_counter_src1_fops = {
 	.write = l2_all_counter_src1_write,
 };
 
-static ssize_t power_events_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
+static ssize_t power_always_on_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
 {
+	unsigned long val;
+	int ret;
+	char buf[32];
 
-	memset(pwr_buf,0,POWER_BUFFER_SIZE);
-	virtual_power_status_register = 0;
-	if (!strncmp(ubuf,mali_power_events[_MALI_DEVICE_SUSPEND],strlen(mali_power_events[_MALI_DEVICE_SUSPEND])))
-	{
-		mali_pm_os_suspend();
-		/* @@@@ assuming currently suspend is successful later on to tune as per previous*/
-		virtual_power_status_register =1;
-
+	cnt = min(cnt, sizeof(buf) - 1);
+	if (copy_from_user(buf, ubuf, cnt)) {
+		return -EFAULT;
 	}
-	else if (!strncmp(ubuf,mali_power_events[_MALI_DEVICE_RESUME],strlen(mali_power_events[_MALI_DEVICE_RESUME])))
-	{
-		mali_pm_os_resume();
+	buf[cnt] = '\0';
 
-		/* @@@@ assuming currently resume is successful later on to tune as per previous */
-		virtual_power_status_register = 1;
-	}
-	else if (!strncmp(ubuf,mali_power_events[_MALI_DEVICE_DVFS_PAUSE],strlen(mali_power_events[_MALI_DEVICE_DVFS_PAUSE])))
-	{
-		mali_bool power_on;
-		mali_dev_pause(&power_on);
-		if (!power_on)
-		{
-			virtual_power_status_register = 2;
-			mali_dev_resume();
-		}
-		else
-		{
-			/*  @@@@ assuming currently resume is successful later on to tune as per previous */
-			virtual_power_status_register =1;
-		}
+	ret = strict_strtoul(buf, 10, &val);
+	if (0 != ret) {
+		return ret;
 	}
-	else if (!strncmp(ubuf,mali_power_events[_MALI_DEVICE_DVFS_RESUME],strlen(mali_power_events[_MALI_DEVICE_DVFS_RESUME])))
-	{
-		mali_dev_resume();
-		/*  @@@@ assuming currently resume is successful later on to tune as per previous */
-		virtual_power_status_register = 1;
 
+	/* Update setting (not exactly thread safe) */
+	if (1 == val && MALI_FALSE == power_always_on_enabled) {
+		power_always_on_enabled = MALI_TRUE;
+		_mali_osk_pm_dev_ref_add();
+	} else if (0 == val && MALI_TRUE == power_always_on_enabled) {
+		power_always_on_enabled = MALI_FALSE;
+		_mali_osk_pm_dev_ref_dec();
 	}
+
 	*ppos += cnt;
-	sprintf(pwr_buf, "%d",virtual_power_status_register);
 	return cnt;
 }
 
-static ssize_t power_events_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
+static ssize_t power_always_on_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
+{
+	if (MALI_TRUE == power_always_on_enabled) {
+		return simple_read_from_buffer(ubuf, cnt, ppos, "1\n", 2);
+	} else {
+		return simple_read_from_buffer(ubuf, cnt, ppos, "0\n", 2);
+	}
+}
+
+static const struct file_operations power_always_on_fops = {
+	.owner = THIS_MODULE,
+	.read  = power_always_on_read,
+	.write = power_always_on_write,
+};
+
+static ssize_t power_power_events_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
 {
-	return simple_read_from_buffer(ubuf, cnt, ppos, pwr_buf, POWER_BUFFER_SIZE);
+
+	if (!strncmp(ubuf, mali_power_events[_MALI_DEVICE_SUSPEND], strlen(mali_power_events[_MALI_DEVICE_SUSPEND]))) {
+		mali_pm_os_suspend();
+
+	} else if (!strncmp(ubuf, mali_power_events[_MALI_DEVICE_RESUME], strlen(mali_power_events[_MALI_DEVICE_RESUME]))) {
+		mali_pm_os_resume();
+	} else if (!strncmp(ubuf, mali_power_events[_MALI_DEVICE_DVFS_PAUSE], strlen(mali_power_events[_MALI_DEVICE_DVFS_PAUSE]))) {
+		mali_dev_pause();
+	} else if (!strncmp(ubuf, mali_power_events[_MALI_DEVICE_DVFS_RESUME], strlen(mali_power_events[_MALI_DEVICE_DVFS_RESUME]))) {
+		mali_dev_resume();
+	}
+	*ppos += cnt;
+	return cnt;
 }
 
-static loff_t power_events_seek(struct file *file, loff_t offset, int orig)
+static loff_t power_power_events_seek(struct file *file, loff_t offset, int orig)
 {
 	file->f_pos = offset;
-        return 0;
+	return 0;
 }
 
-static const struct file_operations power_events_fops = {
+static const struct file_operations power_power_events_fops = {
 	.owner = THIS_MODULE,
-	.read  = power_events_read,
-	.write = power_events_write,
-	.llseek = power_events_seek,
+	.write = power_power_events_write,
+	.llseek = power_power_events_seek,
 };
 
-
 #if MALI_STATE_TRACKING
 static int mali_seq_internal_state_show(struct seq_file *seq_file, void *v)
 {
@@ -753,14 +519,13 @@ static int mali_seq_internal_state_show(struct seq_file *seq_file, void *v)
 
 	size = seq_get_buf(seq_file, &buf);
 
-	if(!size)
-	{
-			return -ENOMEM;
+	if (!size) {
+		return -ENOMEM;
 	}
 
 	/* Create the internal state dump. */
-	len  = snprintf(buf+len, size-len, "Mali device driver %s\n", SVN_REV_STRING);
-	len += snprintf(buf+len, size-len, "License: %s\n\n", MALI_KERNEL_LINUX_LICENSE);
+	len  = snprintf(buf + len, size - len, "Mali device driver %s\n", SVN_REV_STRING);
+	len += snprintf(buf + len, size - len, "License: %s\n\n", MALI_KERNEL_LINUX_LICENSE);
 
 	len += _mali_kernel_core_dump_state(buf + len, size - len);
 
@@ -783,14 +548,13 @@ static const struct file_operations mali_seq_internal_state_fops = {
 };
 #endif /* MALI_STATE_TRACKING */
 
-
-#if MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
 static ssize_t profiling_record_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
 {
 	char buf[64];
 	int r;
 
-	r = sprintf(buf, "%u\n", _mali_osk_profiling_is_recording() ? 1 : 0);
+	r = snprintf(buf, 64, "%u\n", _mali_internal_profiling_is_recording() ? 1 : 0);
 	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
 }
 
@@ -800,60 +564,49 @@ static ssize_t profiling_record_write(struct file *filp, const char __user *ubuf
 	unsigned long val;
 	int ret;
 
-	if (cnt >= sizeof(buf))
-	{
+	if (cnt >= sizeof(buf)) {
 		return -EINVAL;
 	}
 
-	if (copy_from_user(&buf, ubuf, cnt))
-	{
+	if (copy_from_user(&buf, ubuf, cnt)) {
 		return -EFAULT;
 	}
 
 	buf[cnt] = 0;
 
 	ret = strict_strtoul(buf, 10, &val);
-	if (ret < 0)
-	{
+	if (ret < 0) {
 		return ret;
 	}
 
-	if (val != 0)
-	{
+	if (val != 0) {
 		u32 limit = MALI_PROFILING_MAX_BUFFER_ENTRIES; /* This can be made configurable at a later stage if we need to */
 
 		/* check if we are already recording */
-		if (MALI_TRUE == _mali_osk_profiling_is_recording())
-		{
+		if (MALI_TRUE == _mali_internal_profiling_is_recording()) {
 			MALI_DEBUG_PRINT(3, ("Recording of profiling events already in progress\n"));
 			return -EFAULT;
 		}
 
 		/* check if we need to clear out an old recording first */
-		if (MALI_TRUE == _mali_osk_profiling_have_recording())
-		{
-			if (_MALI_OSK_ERR_OK != _mali_osk_profiling_clear())
-			{
+		if (MALI_TRUE == _mali_internal_profiling_have_recording()) {
+			if (_MALI_OSK_ERR_OK != _mali_internal_profiling_clear()) {
 				MALI_DEBUG_PRINT(3, ("Failed to clear existing recording of profiling events\n"));
 				return -EFAULT;
 			}
 		}
 
 		/* start recording profiling data */
-		if (_MALI_OSK_ERR_OK != _mali_osk_profiling_start(&limit))
-		{
+		if (_MALI_OSK_ERR_OK != _mali_internal_profiling_start(&limit)) {
 			MALI_DEBUG_PRINT(3, ("Failed to start recording of profiling events\n"));
 			return -EFAULT;
 		}
 
 		MALI_DEBUG_PRINT(3, ("Profiling recording started (max %u events)\n", limit));
-	}
-	else
-	{
+	} else {
 		/* stop recording profiling data */
 		u32 count = 0;
-		if (_MALI_OSK_ERR_OK != _mali_osk_profiling_stop(&count))
-		{
+		if (_MALI_OSK_ERR_OK != _mali_internal_profiling_stop(&count)) {
 			MALI_DEBUG_PRINT(2, ("Failed to stop recording of profiling events\n"));
 			return -EFAULT;
 		}
@@ -876,14 +629,12 @@ static void *profiling_events_start(struct seq_file *s, loff_t *pos)
 	loff_t *spos;
 
 	/* check if we have data avaiable */
-	if (MALI_TRUE != _mali_osk_profiling_have_recording())
-	{
+	if (MALI_TRUE != _mali_internal_profiling_have_recording()) {
 		return NULL;
 	}
 
 	spos = kmalloc(sizeof(loff_t), GFP_KERNEL);
-	if (NULL == spos)
-	{
+	if (NULL == spos) {
 		return NULL;
 	}
 
@@ -896,14 +647,12 @@ static void *profiling_events_next(struct seq_file *s, void *v, loff_t *pos)
 	loff_t *spos = v;
 
 	/* check if we have data avaiable */
-	if (MALI_TRUE != _mali_osk_profiling_have_recording())
-	{
+	if (MALI_TRUE != _mali_internal_profiling_have_recording()) {
 		return NULL;
 	}
 
 	/* check if the next entry actually is avaiable */
-	if (_mali_osk_profiling_get_count() <= (u32)(*spos + 1))
-	{
+	if (_mali_internal_profiling_get_count() <= (u32)(*spos + 1)) {
 		return NULL;
 	}
 
@@ -924,11 +673,10 @@ static int profiling_events_show(struct seq_file *seq_file, void *v)
 	u32 event_id;
 	u32 data[5];
 
-	index = (u32)*spos;
+	index = (u32) * spos;
 
 	/* Retrieve all events */
-	if (_MALI_OSK_ERR_OK == _mali_osk_profiling_get_event(index, &timestamp, &event_id, data))
-	{
+	if (_MALI_OSK_ERR_OK == _mali_internal_profiling_get_event(index, &timestamp, &event_id, data)) {
 		seq_printf(seq_file, "%llu %u %u %u %u %u %u\n", timestamp, event_id, data[0], data[1], data[2], data[3], data[4]);
 		return 0;
 	}
@@ -936,6 +684,117 @@ static int profiling_events_show(struct seq_file *seq_file, void *v)
 	return 0;
 }
 
+static int profiling_events_show_human_readable(struct seq_file *seq_file, void *v)
+{
+#define MALI_EVENT_ID_IS_HW(event_id) (((event_id & 0x00FF0000) >= MALI_PROFILING_EVENT_CHANNEL_GP0) && ((event_id & 0x00FF0000) <= MALI_PROFILING_EVENT_CHANNEL_PP7))
+
+	static u64 start_time = 0;
+	loff_t *spos = v;
+	u32 index;
+	u64 timestamp;
+	u32 event_id;
+	u32 data[5];
+
+	index = (u32) * spos;
+
+	/* Retrieve all events */
+	if (_MALI_OSK_ERR_OK == _mali_internal_profiling_get_event(index, &timestamp, &event_id, data)) {
+		seq_printf(seq_file, "%llu %u %u %u %u %u %u # ", timestamp, event_id, data[0], data[1], data[2], data[3], data[4]);
+
+		if (0 == index) {
+			start_time = timestamp;
+		}
+
+		seq_printf(seq_file, "[%06u] ", index);
+
+		switch (event_id & 0x0F000000) {
+		case MALI_PROFILING_EVENT_TYPE_SINGLE:
+			seq_printf(seq_file, "SINGLE | ");
+			break;
+		case MALI_PROFILING_EVENT_TYPE_START:
+			seq_printf(seq_file, "START | ");
+			break;
+		case MALI_PROFILING_EVENT_TYPE_STOP:
+			seq_printf(seq_file, "STOP | ");
+			break;
+		case MALI_PROFILING_EVENT_TYPE_SUSPEND:
+			seq_printf(seq_file, "SUSPEND | ");
+			break;
+		case MALI_PROFILING_EVENT_TYPE_RESUME:
+			seq_printf(seq_file, "RESUME | ");
+			break;
+		default:
+			seq_printf(seq_file, "0x%01X | ", (event_id & 0x0F000000) >> 24);
+			break;
+		}
+
+		switch (event_id & 0x00FF0000) {
+		case MALI_PROFILING_EVENT_CHANNEL_SOFTWARE:
+			seq_printf(seq_file, "SW | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_GP0:
+			seq_printf(seq_file, "GP0 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP0:
+			seq_printf(seq_file, "PP0 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP1:
+			seq_printf(seq_file, "PP1 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP2:
+			seq_printf(seq_file, "PP2 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP3:
+			seq_printf(seq_file, "PP3 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP4:
+			seq_printf(seq_file, "PP4 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP5:
+			seq_printf(seq_file, "PP5 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP6:
+			seq_printf(seq_file, "PP6 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_PP7:
+			seq_printf(seq_file, "PP7 | ");
+			break;
+		case MALI_PROFILING_EVENT_CHANNEL_GPU:
+			seq_printf(seq_file, "GPU | ");
+			break;
+		default:
+			seq_printf(seq_file, "0x%02X | ", (event_id & 0x00FF0000) >> 16);
+			break;
+		}
+
+		if (MALI_EVENT_ID_IS_HW(event_id)) {
+			if (((event_id & 0x0F000000) == MALI_PROFILING_EVENT_TYPE_START) || ((event_id & 0x0F000000) == MALI_PROFILING_EVENT_TYPE_STOP)) {
+				switch (event_id & 0x0000FFFF) {
+				case MALI_PROFILING_EVENT_REASON_START_STOP_HW_PHYSICAL:
+					seq_printf(seq_file, "PHYSICAL | ");
+					break;
+				case MALI_PROFILING_EVENT_REASON_START_STOP_HW_VIRTUAL:
+					seq_printf(seq_file, "VIRTUAL | ");
+					break;
+				default:
+					seq_printf(seq_file, "0x%04X | ", event_id & 0x0000FFFF);
+					break;
+				}
+			} else {
+				seq_printf(seq_file, "0x%04X | ", event_id & 0x0000FFFF);
+			}
+		} else {
+			seq_printf(seq_file, "0x%04X | ", event_id & 0x0000FFFF);
+		}
+
+		seq_printf(seq_file, "T0 + 0x%016llX\n", timestamp - start_time);
+
+		return 0;
+	}
+
+	return 0;
+}
+
 static const struct seq_operations profiling_events_seq_ops = {
 	.start = profiling_events_start,
 	.next  = profiling_events_next,
@@ -955,6 +814,27 @@ static const struct file_operations profiling_events_fops = {
 	.llseek = seq_lseek,
 	.release = seq_release,
 };
+
+static const struct seq_operations profiling_events_human_readable_seq_ops = {
+	.start = profiling_events_start,
+	.next  = profiling_events_next,
+	.stop  = profiling_events_stop,
+	.show  = profiling_events_show_human_readable
+};
+
+static int profiling_events_human_readable_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &profiling_events_human_readable_seq_ops);
+}
+
+static const struct file_operations profiling_events_human_readable_fops = {
+	.owner = THIS_MODULE,
+	.open = profiling_events_human_readable_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release,
+};
+
 #endif
 
 static ssize_t memory_used_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
@@ -972,6 +852,51 @@ static const struct file_operations memory_usage_fops = {
 	.read = memory_used_read,
 };
 
+static ssize_t utilization_gp_pp_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
+{
+	char buf[64];
+	size_t r;
+	u32 uval = _mali_ukk_utilization_gp_pp();
+
+	r = snprintf(buf, 64, "%u\n", uval);
+	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
+}
+
+static ssize_t utilization_gp_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
+{
+	char buf[64];
+	size_t r;
+	u32 uval = _mali_ukk_utilization_gp();
+
+	r = snprintf(buf, 64, "%u\n", uval);
+	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
+}
+
+static ssize_t utilization_pp_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
+{
+	char buf[64];
+	size_t r;
+	u32 uval = _mali_ukk_utilization_pp();
+
+	r = snprintf(buf, 64, "%u\n", uval);
+	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
+}
+
+
+static const struct file_operations utilization_gp_pp_fops = {
+	.owner = THIS_MODULE,
+	.read = utilization_gp_pp_read,
+};
+
+static const struct file_operations utilization_gp_fops = {
+	.owner = THIS_MODULE,
+	.read = utilization_gp_read,
+};
+
+static const struct file_operations utilization_pp_fops = {
+	.owner = THIS_MODULE,
+	.read = utilization_pp_read,
+};
 
 static ssize_t user_settings_write(struct file *filp, const char __user *ubuf, size_t cnt, loff_t *ppos)
 {
@@ -981,15 +906,13 @@ static ssize_t user_settings_write(struct file *filp, const char __user *ubuf, s
 	char buf[32];
 
 	cnt = min(cnt, sizeof(buf) - 1);
-	if (copy_from_user(buf, ubuf, cnt))
-	{
+	if (copy_from_user(buf, ubuf, cnt)) {
 		return -EFAULT;
 	}
 	buf[cnt] = '\0';
 
 	ret = strict_strtoul(buf, 10, &val);
-	if (0 != ret)
-	{
+	if (0 != ret) {
 		return ret;
 	}
 
@@ -1026,180 +949,338 @@ static int mali_sysfs_user_settings_register(void)
 {
 	struct dentry *mali_user_settings_dir = debugfs_create_dir("userspace_settings", mali_debugfs_dir);
 
-	if (mali_user_settings_dir != NULL)
-	{
+	if (mali_user_settings_dir != NULL) {
 		int i;
-		for (i = 0; i < _MALI_UK_USER_SETTING_MAX; i++)
-		{
-			debugfs_create_file(_mali_uk_user_setting_descriptions[i], 0600, mali_user_settings_dir, (void*)i, &user_settings_fops);
+		for (i = 0; i < _MALI_UK_USER_SETTING_MAX; i++) {
+			debugfs_create_file(_mali_uk_user_setting_descriptions[i], 0600, mali_user_settings_dir, (void *)i, &user_settings_fops);
 		}
 	}
 
 	return 0;
 }
 
-int mali_sysfs_register(struct mali_dev *device, dev_t dev, const char *mali_dev_name)
+static ssize_t pmu_power_down_write(struct file *filp, const char __user *buf, size_t count, loff_t *offp)
+{
+	int ret;
+	char buffer[32];
+	unsigned long val;
+	struct mali_pmu_core *pmu;
+	_mali_osk_errcode_t err;
+
+	if (count >= sizeof(buffer)) {
+		return -ENOMEM;
+	}
+
+	if (copy_from_user(&buffer[0], buf, count)) {
+		return -EFAULT;
+	}
+	buffer[count] = '\0';
+
+	ret = strict_strtoul(&buffer[0], 10, &val);
+	if (0 != ret) {
+		return -EINVAL;
+	}
+
+	pmu = mali_pmu_get_global_pmu_core();
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+
+	err = mali_pmu_power_down(pmu, val);
+	if (_MALI_OSK_ERR_OK != err) {
+		return -EINVAL;
+	}
+
+	*offp += count;
+	return count;
+}
+
+static ssize_t pmu_power_up_write(struct file *filp, const char __user *buf, size_t count, loff_t *offp)
+{
+	int ret;
+	char buffer[32];
+	unsigned long val;
+	struct mali_pmu_core *pmu;
+	_mali_osk_errcode_t err;
+
+	if (count >= sizeof(buffer)) {
+		return -ENOMEM;
+	}
+
+	if (copy_from_user(&buffer[0], buf, count)) {
+		return -EFAULT;
+	}
+	buffer[count] = '\0';
+
+	ret = strict_strtoul(&buffer[0], 10, &val);
+	if (0 != ret) {
+		return -EINVAL;
+	}
+
+	pmu = mali_pmu_get_global_pmu_core();
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+
+	err = mali_pmu_power_up(pmu, val);
+	if (_MALI_OSK_ERR_OK != err) {
+		return -EINVAL;
+	}
+
+	*offp += count;
+	return count;
+}
+
+static const struct file_operations pmu_power_down_fops = {
+	.owner = THIS_MODULE,
+	.write = pmu_power_down_write,
+};
+
+static const struct file_operations pmu_power_up_fops = {
+	.owner = THIS_MODULE,
+	.write = pmu_power_up_write,
+};
+
+static ssize_t pp_num_cores_enabled_write(struct file *filp, const char __user *buf, size_t count, loff_t *offp)
+{
+	int ret;
+	char buffer[32];
+	unsigned long val;
+
+	if (count >= sizeof(buffer)) {
+		return -ENOMEM;
+	}
+
+	if (copy_from_user(&buffer[0], buf, count)) {
+		return -EFAULT;
+	}
+	buffer[count] = '\0';
+
+	ret = strict_strtoul(&buffer[0], 10, &val);
+	if (0 != ret) {
+		return -EINVAL;
+	}
+
+	ret = mali_pp_scheduler_set_perf_level(val, MALI_TRUE); /* override even if core scaling is disabled */
+	if (ret) {
+		return ret;
+	}
+
+	*offp += count;
+	return count;
+}
+
+static ssize_t pp_num_cores_enabled_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
+{
+	int r;
+	char buffer[64];
+
+	r = snprintf(buffer, 64, "%u\n", mali_pp_scheduler_get_num_cores_enabled());
+
+	return simple_read_from_buffer(buf, count, offp, buffer, r);
+}
+
+static const struct file_operations pp_num_cores_enabled_fops = {
+	.owner = THIS_MODULE,
+	.write = pp_num_cores_enabled_write,
+	.read = pp_num_cores_enabled_read,
+	.llseek = default_llseek,
+};
+
+static ssize_t pp_num_cores_total_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
+{
+	int r;
+	char buffer[64];
+
+	r = snprintf(buffer, 64, "%u\n", mali_pp_scheduler_get_num_cores_total());
+
+	return simple_read_from_buffer(buf, count, offp, buffer, r);
+}
+
+static const struct file_operations pp_num_cores_total_fops = {
+	.owner = THIS_MODULE,
+	.read = pp_num_cores_total_read,
+};
+
+static ssize_t pp_core_scaling_enabled_write(struct file *filp, const char __user *buf, size_t count, loff_t *offp)
 {
-	int err = 0;
-	struct device * mdev;
-
-	device->mali_class = class_create(THIS_MODULE, mali_dev_name);
-	if (IS_ERR(device->mali_class))
-	{
-		err = PTR_ERR(device->mali_class);
-		goto init_class_err;
+	int ret;
+	char buffer[32];
+	unsigned long val;
+
+	if (count >= sizeof(buffer)) {
+		return -ENOMEM;
+	}
+
+	if (copy_from_user(&buffer[0], buf, count)) {
+		return -EFAULT;
 	}
-	mdev = device_create(device->mali_class, NULL, dev, NULL, mali_dev_name);
-	if (IS_ERR(mdev))
-	{
-		err = PTR_ERR(mdev);
-		goto init_mdev_err;
+	buffer[count] = '\0';
+
+	ret = strict_strtoul(&buffer[0], 10, &val);
+	if (0 != ret) {
+		return -EINVAL;
 	}
 
+	switch (val) {
+	case 1:
+		mali_pp_scheduler_core_scaling_enable();
+		break;
+	case 0:
+		mali_pp_scheduler_core_scaling_disable();
+		break;
+	default:
+		return -EINVAL;
+		break;
+	}
+
+	*offp += count;
+	return count;
+}
+
+static ssize_t pp_core_scaling_enabled_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
+{
+	return simple_read_from_buffer(buf, count, offp, mali_pp_scheduler_core_scaling_is_enabled() ? "1\n" : "0\n", 2);
+}
+static const struct file_operations pp_core_scaling_enabled_fops = {
+	.owner = THIS_MODULE,
+	.write = pp_core_scaling_enabled_write,
+	.read = pp_core_scaling_enabled_read,
+	.llseek = default_llseek,
+};
+
+static ssize_t version_read(struct file *filp, char __user *buf, size_t count, loff_t *offp)
+{
+	int r = 0;
+	char buffer[64];
+
+	switch (mali_kernel_core_get_product_id()) {
+	case _MALI_PRODUCT_ID_MALI200:
+		r = snprintf(buffer, 64, "Mali-200\n");
+		break;
+	case _MALI_PRODUCT_ID_MALI300:
+		r = snprintf(buffer, 64, "Mali-300\n");
+		break;
+	case _MALI_PRODUCT_ID_MALI400:
+		r = snprintf(buffer, 64, "Mali-400 MP\n");
+		break;
+	case _MALI_PRODUCT_ID_MALI450:
+		r = snprintf(buffer, 64, "Mali-450 MP\n");
+		break;
+	case _MALI_PRODUCT_ID_UNKNOWN:
+		return -EINVAL;
+		break;
+	};
+
+	return simple_read_from_buffer(buf, count, offp, buffer, r);
+}
+
+static const struct file_operations version_fops = {
+	.owner = THIS_MODULE,
+	.read = version_read,
+};
+
+int mali_sysfs_register(const char *mali_dev_name)
+{
 	mali_debugfs_dir = debugfs_create_dir(mali_dev_name, NULL);
-	if(ERR_PTR(-ENODEV) == mali_debugfs_dir)
-	{
+	if (ERR_PTR(-ENODEV) == mali_debugfs_dir) {
 		/* Debugfs not supported. */
 		mali_debugfs_dir = NULL;
-	}
-	else
-	{
-		if(NULL != mali_debugfs_dir)
-		{
+	} else {
+		if (NULL != mali_debugfs_dir) {
 			/* Debugfs directory created successfully; create files now */
+			struct dentry *mali_pmu_dir;
 			struct dentry *mali_power_dir;
 			struct dentry *mali_gp_dir;
 			struct dentry *mali_pp_dir;
 			struct dentry *mali_l2_dir;
-#if MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
 			struct dentry *mali_profiling_dir;
-#endif
+
+			debugfs_create_file("version", 0400, mali_debugfs_dir, NULL, &version_fops);
+
+			mali_pmu_dir = debugfs_create_dir("pmu", mali_debugfs_dir);
+			if (NULL != mali_pmu_dir) {
+				debugfs_create_file("power_down", 0200, mali_pmu_dir, NULL, &pmu_power_down_fops);
+				debugfs_create_file("power_up", 0200, mali_pmu_dir, NULL, &pmu_power_up_fops);
+			}
 
 			mali_power_dir = debugfs_create_dir("power", mali_debugfs_dir);
-			if (mali_power_dir != NULL)
-			{
-				debugfs_create_file("power_events", 0400, mali_power_dir, NULL, &power_events_fops);
+			if (mali_power_dir != NULL) {
+				debugfs_create_file("always_on", 0600, mali_power_dir, NULL, &power_always_on_fops);
+				debugfs_create_file("power_events", 0200, mali_power_dir, NULL, &power_power_events_fops);
 			}
 
 			mali_gp_dir = debugfs_create_dir("gp", mali_debugfs_dir);
-			if (mali_gp_dir != NULL)
-			{
-				struct dentry *mali_gp_all_dir;
-				u32 ci;
-				struct mali_cluster *cluster;
-
-				mali_gp_all_dir = debugfs_create_dir("all", mali_gp_dir);
-				if (mali_gp_all_dir != NULL)
-				{
-					debugfs_create_file("counter_src0", 0400, mali_gp_all_dir, NULL, &gp_all_counter_src0_fops);
-					debugfs_create_file("counter_src1", 0400, mali_gp_all_dir, NULL, &gp_all_counter_src1_fops);
-				}
-
-				ci = 0;
-				cluster = mali_cluster_get_global_cluster(ci);
-				while (NULL != cluster)
-				{
-					u32 gi = 0;
-					struct mali_group *group = mali_cluster_get_group(cluster, gi);
-					while (NULL != group)
-					{
-						struct mali_gp_core *gp_core = mali_group_get_gp_core(group);
-						if (NULL != gp_core)
-						{
-							struct dentry *mali_gp_gpx_dir;
-							mali_gp_gpx_dir = debugfs_create_dir("gp0", mali_gp_dir);
-							if (NULL != mali_gp_gpx_dir)
-							{
-								debugfs_create_file("counter_src0", 0600, mali_gp_gpx_dir, gp_core, &gp_gpx_counter_src0_fops);
-								debugfs_create_file("counter_src1", 0600, mali_gp_gpx_dir, gp_core, &gp_gpx_counter_src1_fops);
-							}
-							break; /* no need to look for any other GP cores */
+			if (mali_gp_dir != NULL) {
+				u32 num_groups;
+				int i;
+
+				num_groups = mali_group_get_glob_num_groups();
+				for (i = 0; i < num_groups; i++) {
+					struct mali_group *group = mali_group_get_glob_group(i);
+
+					struct mali_gp_core *gp_core = mali_group_get_gp_core(group);
+					if (NULL != gp_core) {
+						struct dentry *mali_gp_gpx_dir;
+						mali_gp_gpx_dir = debugfs_create_dir("gp0", mali_gp_dir);
+						if (NULL != mali_gp_gpx_dir) {
+							debugfs_create_file("base_addr", 0400, mali_gp_gpx_dir, &gp_core->hw_core, &hw_core_base_addr_fops);
+							debugfs_create_file("enabled", 0600, mali_gp_gpx_dir, group, &group_enabled_fops);
 						}
-
-						/* try next group */
-						gi++;
-						group = mali_cluster_get_group(cluster, gi);
+						break; /* no need to look for any other GP cores */
 					}
 
-					/* try next cluster */
-					ci++;
-					cluster = mali_cluster_get_global_cluster(ci);
 				}
 			}
 
 			mali_pp_dir = debugfs_create_dir("pp", mali_debugfs_dir);
-			if (mali_pp_dir != NULL)
-			{
-				struct dentry *mali_pp_all_dir;
-				u32 ci;
-				struct mali_cluster *cluster;
-
-				mali_pp_all_dir = debugfs_create_dir("all", mali_pp_dir);
-				if (mali_pp_all_dir != NULL)
-				{
-					debugfs_create_file("counter_src0", 0400, mali_pp_all_dir, NULL, &pp_all_counter_src0_fops);
-					debugfs_create_file("counter_src1", 0400, mali_pp_all_dir, NULL, &pp_all_counter_src1_fops);
-				}
-
-				ci = 0;
-				cluster = mali_cluster_get_global_cluster(ci);
-				while (NULL != cluster)
-				{
-					u32 gi = 0;
-					struct mali_group *group = mali_cluster_get_group(cluster, gi);
-					while (NULL != group)
-					{
-						struct mali_pp_core *pp_core = mali_group_get_pp_core(group);
-						if (NULL != pp_core)
-						{
-							char buf[16];
-							struct dentry *mali_pp_ppx_dir;
-							_mali_osk_snprintf(buf, sizeof(buf), "pp%u", mali_pp_core_get_id(pp_core));
-							mali_pp_ppx_dir = debugfs_create_dir(buf, mali_pp_dir);
-							if (NULL != mali_pp_ppx_dir)
-							{
-								debugfs_create_file("counter_src0", 0600, mali_pp_ppx_dir, pp_core, &pp_ppx_counter_src0_fops);
-								debugfs_create_file("counter_src1", 0600, mali_pp_ppx_dir, pp_core, &pp_ppx_counter_src1_fops);
+			if (mali_pp_dir != NULL) {
+				u32 num_groups;
+				int i;
+
+				debugfs_create_file("num_cores_total", 0400, mali_pp_dir, NULL, &pp_num_cores_total_fops);
+				debugfs_create_file("num_cores_enabled", 0600, mali_pp_dir, NULL, &pp_num_cores_enabled_fops);
+				debugfs_create_file("core_scaling_enabled", 0600, mali_pp_dir, NULL, &pp_core_scaling_enabled_fops);
+
+				num_groups = mali_group_get_glob_num_groups();
+				for (i = 0; i < num_groups; i++) {
+					struct mali_group *group = mali_group_get_glob_group(i);
+
+					struct mali_pp_core *pp_core = mali_group_get_pp_core(group);
+					if (NULL != pp_core) {
+						char buf[16];
+						struct dentry *mali_pp_ppx_dir;
+						_mali_osk_snprintf(buf, sizeof(buf), "pp%u", mali_pp_core_get_id(pp_core));
+						mali_pp_ppx_dir = debugfs_create_dir(buf, mali_pp_dir);
+						if (NULL != mali_pp_ppx_dir) {
+							debugfs_create_file("base_addr", 0400, mali_pp_ppx_dir, &pp_core->hw_core, &hw_core_base_addr_fops);
+							if (!mali_group_is_virtual(group)) {
+								debugfs_create_file("enabled", 0600, mali_pp_ppx_dir, group, &group_enabled_fops);
 							}
 						}
-
-						/* try next group */
-						gi++;
-						group = mali_cluster_get_group(cluster, gi);
 					}
-
-					/* try next cluster */
-					ci++;
-					cluster = mali_cluster_get_global_cluster(ci);
 				}
 			}
 
 			mali_l2_dir = debugfs_create_dir("l2", mali_debugfs_dir);
-			if (mali_l2_dir != NULL)
-			{
+			if (mali_l2_dir != NULL) {
 				struct dentry *mali_l2_all_dir;
 				u32 l2_id;
 				struct mali_l2_cache_core *l2_cache;
 
 				mali_l2_all_dir = debugfs_create_dir("all", mali_l2_dir);
-				if (mali_l2_all_dir != NULL)
-				{
-					debugfs_create_file("counter_src0", 0400, mali_l2_all_dir, NULL, &l2_all_counter_src0_fops);
-					debugfs_create_file("counter_src1", 0400, mali_l2_all_dir, NULL, &l2_all_counter_src1_fops);
+				if (mali_l2_all_dir != NULL) {
+					debugfs_create_file("counter_src0", 0200, mali_l2_all_dir, NULL, &l2_all_counter_src0_fops);
+					debugfs_create_file("counter_src1", 0200, mali_l2_all_dir, NULL, &l2_all_counter_src1_fops);
 				}
 
 				l2_id = 0;
 				l2_cache = mali_l2_cache_core_get_glob_l2_core(l2_id);
-				while (NULL != l2_cache)
-				{
+				while (NULL != l2_cache) {
 					char buf[16];
 					struct dentry *mali_l2_l2x_dir;
 					_mali_osk_snprintf(buf, sizeof(buf), "l2%u", l2_id);
 					mali_l2_l2x_dir = debugfs_create_dir(buf, mali_l2_dir);
-					if (NULL != mali_l2_l2x_dir)
-					{
+					if (NULL != mali_l2_l2x_dir) {
 						debugfs_create_file("counter_src0", 0600, mali_l2_l2x_dir, l2_cache, &l2_l2x_counter_src0_fops);
 						debugfs_create_file("counter_src1", 0600, mali_l2_l2x_dir, l2_cache, &l2_l2x_counter_src1_fops);
+						debugfs_create_file("base_addr", 0400, mali_l2_l2x_dir, &l2_cache->hw_core, &hw_core_base_addr_fops);
 					}
 
 					/* try next L2 */
@@ -1210,30 +1291,70 @@ int mali_sysfs_register(struct mali_dev *device, dev_t dev, const char *mali_dev
 
 			debugfs_create_file("memory_usage", 0400, mali_debugfs_dir, NULL, &memory_usage_fops);
 
-#if MALI_INTERNAL_TIMELINE_PROFILING_ENABLED
+			debugfs_create_file("utilization_gp_pp", 0400, mali_debugfs_dir, NULL, &utilization_gp_pp_fops);
+			debugfs_create_file("utilization_gp", 0400, mali_debugfs_dir, NULL, &utilization_gp_fops);
+			debugfs_create_file("utilization_pp", 0400, mali_debugfs_dir, NULL, &utilization_pp_fops);
+
 			mali_profiling_dir = debugfs_create_dir("profiling", mali_debugfs_dir);
-			if (mali_profiling_dir != NULL)
-			{
-				struct dentry *mali_profiling_proc_dir = debugfs_create_dir("proc", mali_profiling_dir);
-				if (mali_profiling_proc_dir != NULL)
-				{
+			if (mali_profiling_dir != NULL) {
+				u32 max_sub_jobs;
+				int i;
+				struct dentry *mali_profiling_gp_dir;
+				struct dentry *mali_profiling_pp_dir;
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+				struct dentry *mali_profiling_proc_dir;
+#endif
+				/*
+				 * Create directory where we can set GP HW counters.
+				 */
+				mali_profiling_gp_dir = debugfs_create_dir("gp", mali_profiling_dir);
+				if (mali_profiling_gp_dir != NULL) {
+					debugfs_create_file("counter_src0", 0600, mali_profiling_gp_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_GP(0), &profiling_counter_src_fops);
+					debugfs_create_file("counter_src1", 0600, mali_profiling_gp_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_GP(1), &profiling_counter_src_fops);
+				}
+
+				/*
+				 * Create directory where we can set PP HW counters.
+				 * Possible override with specific HW counters for a particular sub job
+				 * (Disable core scaling before using the override!)
+				 */
+				mali_profiling_pp_dir = debugfs_create_dir("pp", mali_profiling_dir);
+				if (mali_profiling_pp_dir != NULL) {
+					debugfs_create_file("counter_src0", 0600, mali_profiling_pp_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_PP(0), &profiling_counter_src_fops);
+					debugfs_create_file("counter_src1", 0600, mali_profiling_pp_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_PP(1), &profiling_counter_src_fops);
+				}
+
+				max_sub_jobs = mali_pp_scheduler_get_num_cores_total();
+				for (i = 0; i < max_sub_jobs; i++) {
+					char buf[16];
+					struct dentry *mali_profiling_pp_x_dir;
+					_mali_osk_snprintf(buf, sizeof(buf), "%u", i);
+					mali_profiling_pp_x_dir = debugfs_create_dir(buf, mali_profiling_pp_dir);
+					if (NULL != mali_profiling_pp_x_dir) {
+						debugfs_create_file("counter_src0", 0600, mali_profiling_pp_x_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_PP_SUB_JOB(0, i), &profiling_counter_src_fops);
+						debugfs_create_file("counter_src1", 0600, mali_profiling_pp_x_dir, (void *)PRIVATE_DATA_COUNTER_MAKE_PP_SUB_JOB(1, i), &profiling_counter_src_fops);
+					}
+				}
+
+#if defined(CONFIG_MALI400_INTERNAL_PROFILING)
+				mali_profiling_proc_dir = debugfs_create_dir("proc", mali_profiling_dir);
+				if (mali_profiling_proc_dir != NULL) {
 					struct dentry *mali_profiling_proc_default_dir = debugfs_create_dir("default", mali_profiling_proc_dir);
-					if (mali_profiling_proc_default_dir != NULL)
-					{
-						debugfs_create_file("enable", 0600, mali_profiling_proc_default_dir, (void*)_MALI_UK_USER_SETTING_SW_EVENTS_ENABLE, &user_settings_fops);
+					if (mali_profiling_proc_default_dir != NULL) {
+						debugfs_create_file("enable", 0600, mali_profiling_proc_default_dir, (void *)_MALI_UK_USER_SETTING_SW_EVENTS_ENABLE, &user_settings_fops);
 					}
 				}
 				debugfs_create_file("record", 0600, mali_profiling_dir, NULL, &profiling_record_fops);
 				debugfs_create_file("events", 0400, mali_profiling_dir, NULL, &profiling_events_fops);
-			}
+				debugfs_create_file("events_human_readable", 0400, mali_profiling_dir, NULL, &profiling_events_human_readable_fops);
 #endif
+			}
 
 #if MALI_STATE_TRACKING
 			debugfs_create_file("state_dump", 0400, mali_debugfs_dir, NULL, &mali_seq_internal_state_fops);
 #endif
 
-			if (mali_sysfs_user_settings_register())
-			{
+			if (mali_sysfs_user_settings_register()) {
 				/* Failed to create the debugfs entries for the user settings DB. */
 				MALI_DEBUG_PRINT(2, ("Failed to create user setting debugfs files. Ignoring...\n"));
 			}
@@ -1242,28 +1363,17 @@ int mali_sysfs_register(struct mali_dev *device, dev_t dev, const char *mali_dev
 
 	/* Success! */
 	return 0;
-
-	/* Error handling */
-init_mdev_err:
-	class_destroy(device->mali_class);
-init_class_err:
-
-	return err;
 }
 
-int mali_sysfs_unregister(struct mali_dev *device, dev_t dev, const char *mali_dev_name)
+int mali_sysfs_unregister(void)
 {
-	if(NULL != mali_debugfs_dir)
-	{
+	if (NULL != mali_debugfs_dir) {
 		debugfs_remove_recursive(mali_debugfs_dir);
 	}
-	device_destroy(device->mali_class, dev);
-	class_destroy(device->mali_class);
-
 	return 0;
 }
 
-#else
+#else /* MALI_LICENSE_IS_GPL */
 
 /* Dummy implementations for non-GPL */
 
@@ -1272,10 +1382,9 @@ int mali_sysfs_register(struct mali_dev *device, dev_t dev, const char *mali_dev
 	return 0;
 }
 
-int mali_sysfs_unregister(struct mali_dev *device, dev_t dev, const char *mali_dev_name)
+int mali_sysfs_unregister(void)
 {
 	return 0;
 }
 
-
-#endif
+#endif /* MALI_LICENSE_IS_GPL */
diff --git a/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.h b/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.h
old mode 100644
new mode 100755
index 5eed5f0..2e9c9a5
--- a/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.h
+++ b/drivers/gpu/mali/mali/linux/mali_kernel_sysfs.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,16 +12,15 @@
 #define __MALI_KERNEL_SYSFS_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
-#define MALI_PROC_DIR "driver/mali"
-
-int mali_sysfs_register(struct mali_dev *mali_class, dev_t dev, const char *mali_dev_name);
+#include <linux/device.h>
 
-int mali_sysfs_unregister(struct mali_dev *mali_class, dev_t dev, const char *mali_dev_name);
+#define MALI_PROC_DIR "driver/mali"
 
+int mali_sysfs_register(const char *mali_dev_name);
+int mali_sysfs_unregister(void);
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_linux_pm.h b/drivers/gpu/mali/mali/linux/mali_linux_pm.h
deleted file mode 100644
index bd18216..0000000
--- a/drivers/gpu/mali/mali/linux/mali_linux_pm.h
+++ /dev/null
@@ -1,50 +0,0 @@
-
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#ifndef __MALI_LINUX_PM_H__
-#define __MALI_LINUX_PM_H__
-
-#ifdef CONFIG_PM
-/* Number of power states supported for making power up and down */
-typedef enum
-{
-	_MALI_DEVICE_SUSPEND,                         /* Suspend */
-	_MALI_DEVICE_RESUME,                          /* Resume */
-	_MALI_DEVICE_MAX_POWER_STATES,                /* Maximum power states */
-} _mali_device_power_states;
-
-/* Number of DVFS events */
-typedef enum
-{
-	_MALI_DVFS_PAUSE_EVENT = _MALI_DEVICE_MAX_POWER_STATES,     /* DVFS Pause event */
-	_MALI_DVFS_RESUME_EVENT,                                        /* DVFS Resume event */
-	_MALI_MAX_DEBUG_OPERATIONS,
-} _mali_device_dvfs_events;
-
-extern _mali_device_power_states mali_device_state;
-extern _mali_device_power_states mali_dvfs_device_state;
-extern  _mali_osk_lock_t *lock;
-extern short is_wake_up_needed;
-extern int timeout_fired;
-extern struct platform_device mali_gpu_device;
-
-/* dvfs pm thread */
-extern struct task_struct *dvfs_pm_thread;
-
-/* Power management thread */
-extern struct task_struct *pm_thread;
-
-int mali_device_suspend(u32 event_id, struct task_struct **pwr_mgmt_thread);
-int mali_device_resume(u32 event_id, struct task_struct **pwr_mgmt_thread);
-int mali_get_ospmm_thread_state(void);
-
-#endif /* CONFIG_PM */
-#endif /* __MALI_LINUX_PM_H___ */
diff --git a/drivers/gpu/mali/mali/linux/mali_linux_pm_testsuite.h b/drivers/gpu/mali/mali/linux/mali_linux_pm_testsuite.h
deleted file mode 100644
index 5879bb7..0000000
--- a/drivers/gpu/mali/mali/linux/mali_linux_pm_testsuite.h
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-#ifndef __MALI_LINUX_PM_TESTSUITE_H__
-#define __MALI_LINUX_PM_TESTSUITE_H__
-
-#if MALI_POWER_MGMT_TEST_SUITE && defined(CONFIG_PM)
-
-typedef enum
-{
-        _MALI_DEVICE_PMM_TIMEOUT_EVENT,
-        _MALI_DEVICE_PMM_JOB_SCHEDULING_EVENTS,
-	_MALI_DEVICE_PMM_REGISTERED_CORES,
-        _MALI_DEVICE_MAX_PMM_EVENTS
-
-} _mali_device_pmm_recording_events;
-
-extern unsigned int mali_timeout_event_recording_on;
-extern unsigned int mali_job_scheduling_events_recording_on;
-extern unsigned int pwr_mgmt_status_reg;
-extern unsigned int is_mali_pmm_testsuite_enabled;
-extern unsigned int is_mali_pmu_present;
-
-#endif /* MALI_POWER_MGMT_TEST_SUITE && defined(CONFIG_PM) */
-
-#endif /* __MALI_LINUX_PM_TESTSUITE_H__ */
diff --git a/drivers/gpu/mali/mali/linux/mali_linux_trace.h b/drivers/gpu/mali/mali/linux/mali_linux_trace.h
old mode 100644
new mode 100755
index c07c579..c418613
--- a/drivers/gpu/mali/mali/linux/mali_linux_trace.h
+++ b/drivers/gpu/mali/mali/linux/mali_linux_trace.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -38,31 +38,31 @@
  */
 TRACE_EVENT(mali_timeline_event,
 
-    TP_PROTO(unsigned int event_id, unsigned int d0, unsigned int d1,
-        unsigned int d2, unsigned int d3, unsigned int d4),
+	    TP_PROTO(unsigned int event_id, unsigned int d0, unsigned int d1,
+		     unsigned int d2, unsigned int d3, unsigned int d4),
 
-    TP_ARGS(event_id, d0, d1, d2, d3, d4),
+	    TP_ARGS(event_id, d0, d1, d2, d3, d4),
 
-    TP_STRUCT__entry(
-        __field(unsigned int, event_id)
-        __field(unsigned int, d0)
-        __field(unsigned int, d1)
-        __field(unsigned int, d2)
-        __field(unsigned int, d3)
-        __field(unsigned int, d4)
-    ),
+	    TP_STRUCT__entry(
+		    __field(unsigned int, event_id)
+		    __field(unsigned int, d0)
+		    __field(unsigned int, d1)
+		    __field(unsigned int, d2)
+		    __field(unsigned int, d3)
+		    __field(unsigned int, d4)
+	    ),
 
-    TP_fast_assign(
-        __entry->event_id = event_id;
-        __entry->d0 = d0;
-        __entry->d1 = d1;
-        __entry->d2 = d2;
-        __entry->d3 = d3;
-        __entry->d4 = d4;
-    ),
+	    TP_fast_assign(
+		    __entry->event_id = event_id;
+		    __entry->d0 = d0;
+		    __entry->d1 = d1;
+		    __entry->d2 = d2;
+		    __entry->d3 = d3;
+		    __entry->d4 = d4;
+	    ),
 
-    TP_printk("event=%d", __entry->event_id)
-);
+	    TP_printk("event=%d", __entry->event_id)
+	   );
 
 /**
  * Define a tracepoint used to regsiter the value of a hardware counter.
@@ -75,21 +75,21 @@ TRACE_EVENT(mali_timeline_event,
  */
 TRACE_EVENT(mali_hw_counter,
 
-    TP_PROTO(unsigned int counter_id, unsigned int value),
+	    TP_PROTO(unsigned int counter_id, unsigned int value),
 
-    TP_ARGS(counter_id, value),
+	    TP_ARGS(counter_id, value),
 
-    TP_STRUCT__entry(
-        __field(unsigned int, counter_id)
-        __field(unsigned int, value)
-    ),
+	    TP_STRUCT__entry(
+		    __field(unsigned int, counter_id)
+		    __field(unsigned int, value)
+	    ),
 
-    TP_fast_assign(
-        __entry->counter_id = counter_id;
-    ),
+	    TP_fast_assign(
+		    __entry->counter_id = counter_id;
+	    ),
 
-    TP_printk("event %d = %d", __entry->counter_id, __entry->value)
-);
+	    TP_printk("event %d = %d", __entry->counter_id, __entry->value)
+	   );
 
 /**
  * Define a tracepoint used to send a bundle of software counters.
@@ -98,28 +98,65 @@ TRACE_EVENT(mali_hw_counter,
  */
 TRACE_EVENT(mali_sw_counters,
 
-    TP_PROTO(pid_t pid, pid_t tid, void * surface_id, unsigned int * counters),
+	    TP_PROTO(pid_t pid, pid_t tid, void *surface_id, unsigned int *counters),
+
+	    TP_ARGS(pid, tid, surface_id, counters),
 
-    TP_ARGS(pid, tid, surface_id, counters),
+	    TP_STRUCT__entry(
+		    __field(pid_t, pid)
+		    __field(pid_t, tid)
+		    __field(void *, surface_id)
+		    __field(unsigned int *, counters)
+	    ),
 
-    TP_STRUCT__entry(
-            __field(pid_t, pid)
-            __field(pid_t, tid)
-            __field(void *, surface_id)
-            __field(unsigned int *, counters)
-    ),
+	    TP_fast_assign(
+		    __entry->pid = pid;
+		    __entry->tid = tid;
+		    __entry->surface_id = surface_id;
+		    __entry->counters = counters;
+	    ),
 
-    TP_fast_assign(
-            __entry->pid = pid;
-			__entry->tid = tid;
-			__entry->surface_id = surface_id;
-			__entry->counters = counters;
-    ),
+	    TP_printk("counters were %s", __entry->counters == NULL ? "NULL" : "not NULL")
+	   );
+
+/**
+ * Define a tracepoint used to gather core activity for systrace
+ * @param pid The process id for which the core activity originates from
+ * @param active If the core is active (1) or not (0)
+ * @param core_type The type of core active, either GP (1) or PP (0)
+ * @param core_id The core id that is active for the core_type
+ * @param frame_builder_id The frame builder id associated with this core activity
+ * @param flush_id The flush id associated with this core activity
+ */
+TRACE_EVENT(mali_core_active,
 
-    TP_printk("counters were %s", __entry->counters == NULL? "NULL" : "not NULL")
-);
+	    TP_PROTO(pid_t pid, unsigned int active, unsigned int core_type, unsigned int core_id, unsigned int frame_builder_id, unsigned int flush_id),
+
+	    TP_ARGS(pid, active, core_type, core_id, frame_builder_id, flush_id),
+
+	    TP_STRUCT__entry(
+		    __field(pid_t, pid)
+		    __field(unsigned int, active)
+		    __field(unsigned int, core_type)
+		    __field(unsigned int, core_id)
+		    __field(unsigned int, frame_builder_id)
+		    __field(unsigned int, flush_id)
+	    ),
+
+	    TP_fast_assign(
+		    __entry->pid = pid;
+		    __entry->active = active;
+		    __entry->core_type = core_type;
+		    __entry->core_id = core_id;
+		    __entry->frame_builder_id = frame_builder_id;
+		    __entry->flush_id = flush_id;
+	    ),
+
+	    TP_printk("%s|%d|%s%i:%x|%d", __entry->active ? "S" : "F", __entry->pid, __entry->core_type ? "GP" : "PP", __entry->core_id, __entry->flush_id, __entry->frame_builder_id)
+	   );
 
 #endif /* MALI_LINUX_TRACE_H */
 
 /* This part must exist outside the header guard. */
 #include <trace/define_trace.h>
+
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_atomics.c b/drivers/gpu/mali/mali/linux/mali_osk_atomics.c
old mode 100644
new mode 100755
index 846fd3b..2f4154f
--- a/drivers/gpu/mali/mali/linux/mali_osk_atomics.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_atomics.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,39 +17,44 @@
 #include <asm/atomic.h>
 #include "mali_kernel_common.h"
 
-void _mali_osk_atomic_dec( _mali_osk_atomic_t *atom )
+void _mali_osk_atomic_dec(_mali_osk_atomic_t *atom)
 {
-    atomic_dec((atomic_t *)&atom->u.val);
+	atomic_dec((atomic_t *)&atom->u.val);
 }
 
-u32 _mali_osk_atomic_dec_return( _mali_osk_atomic_t *atom )
+u32 _mali_osk_atomic_dec_return(_mali_osk_atomic_t *atom)
 {
-    return atomic_dec_return((atomic_t *)&atom->u.val);
+	return atomic_dec_return((atomic_t *)&atom->u.val);
 }
 
-void _mali_osk_atomic_inc( _mali_osk_atomic_t *atom )
+void _mali_osk_atomic_inc(_mali_osk_atomic_t *atom)
 {
-    atomic_inc((atomic_t *)&atom->u.val);
+	atomic_inc((atomic_t *)&atom->u.val);
 }
 
-u32 _mali_osk_atomic_inc_return( _mali_osk_atomic_t *atom )
+u32 _mali_osk_atomic_inc_return(_mali_osk_atomic_t *atom)
 {
-    return atomic_inc_return((atomic_t *)&atom->u.val);
+	return atomic_inc_return((atomic_t *)&atom->u.val);
 }
 
-_mali_osk_errcode_t _mali_osk_atomic_init( _mali_osk_atomic_t *atom, u32 val )
+_mali_osk_errcode_t _mali_osk_atomic_init(_mali_osk_atomic_t *atom, u32 val)
 {
-    MALI_CHECK_NON_NULL(atom, _MALI_OSK_ERR_INVALID_ARGS);
-    atomic_set((atomic_t *)&atom->u.val, val);
-    return _MALI_OSK_ERR_OK;
+	MALI_CHECK_NON_NULL(atom, _MALI_OSK_ERR_INVALID_ARGS);
+	atomic_set((atomic_t *)&atom->u.val, val);
+	return _MALI_OSK_ERR_OK;
 }
 
-u32 _mali_osk_atomic_read( _mali_osk_atomic_t *atom )
+u32 _mali_osk_atomic_read(_mali_osk_atomic_t *atom)
 {
-    return atomic_read((atomic_t *)&atom->u.val);
+	return atomic_read((atomic_t *)&atom->u.val);
 }
 
-void _mali_osk_atomic_term( _mali_osk_atomic_t *atom )
+void _mali_osk_atomic_term(_mali_osk_atomic_t *atom)
 {
-    MALI_IGNORE(atom);
+	MALI_IGNORE(atom);
+}
+
+u32 _mali_osk_atomic_xchg(_mali_osk_atomic_t *atom, u32 val)
+{
+	return atomic_xchg((atomic_t *)&atom->u.val, val);
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.c b/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.c
deleted file mode 100644
index 739e77b..0000000
--- a/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.c
+++ /dev/null
@@ -1,86 +0,0 @@
-/*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-#include <linux/slab.h>
-#include <linux/pagemap.h>
-#include <linux/mm.h>
-#include <linux/mman.h>
-#include <linux/sched.h>
-#include <asm/page.h>
-#include <asm/pgtable.h>
-#include <asm/atomic.h>
-
-#include "mali_osk.h"
-#include "mali_ukk.h"
-#include "mali_kernel_common.h"
-
-/**
- * @file mali_osk_specific.c
- * Implementation of per-OS Kernel level specifics
- */
-
-_mali_osk_errcode_t _mali_osk_specific_indirect_mmap( _mali_uk_mem_mmap_s *args )
-{
-	/* args->ctx ignored here; args->ukk_private required instead */
-	/* we need to lock the mmap semaphore before calling the do_mmap function */
-    down_write(&current->mm->mmap_sem);
-
-    args->mapping = (void __user *)do_mmap(
-											(struct file *)args->ukk_private,
-											0, /* start mapping from any address after NULL */
-											args->size,
-											PROT_READ | PROT_WRITE,
-											MAP_SHARED,
-											args->phys_addr
-										   );
-
-	/* and unlock it after the call */
-	up_write(&current->mm->mmap_sem);
-
-	/* No cookie required here */
-	args->cookie = 0;
-	/* uku_private meaningless, so zero */
-	args->uku_private = NULL;
-
-	if ( (NULL == args->mapping) || IS_ERR((void *)args->mapping) )
-	{
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	/* Success */
-	return _MALI_OSK_ERR_OK;
-}
-
-
-_mali_osk_errcode_t _mali_osk_specific_indirect_munmap( _mali_uk_mem_munmap_s *args )
-{
-	/* args->ctx and args->cookie ignored here */
-
-	if ((NULL != current) && (NULL != current->mm))
-	{
-		/* remove mapping of mali memory from the process' view */
-		/* lock mmap semaphore before call */
-		/* lock mmap_sem before calling do_munmap */
-		down_write(&current->mm->mmap_sem);
-		do_munmap(
-					current->mm,
-					(unsigned long)args->mapping,
-					args->size
-				);
-		/* and unlock after call */
-		up_write(&current->mm->mmap_sem);
-		MALI_DEBUG_PRINT(5, ("unmapped\n"));
-	}
-	else
-	{
-		MALI_DEBUG_PRINT(2, ("Freeing of a big block while no user process attached, assuming crash cleanup in progress\n"));
-	}
-
-	return _MALI_OSK_ERR_OK; /* always succeeds */
-}
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.h b/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.h
deleted file mode 100644
index 1c3a6fd..0000000
--- a/drivers/gpu/mali/mali/linux/mali_osk_indir_mmap.h
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-/**
- * @file mali_osk_specific.h
- * Defines per-OS Kernel level specifics, such as unusual workarounds for
- * certain OSs.
- */
-
-#ifndef __MALI_OSK_INDIR_MMAP_H__
-#define __MALI_OSK_INDIR_MMAP_H__
-
-#include "mali_uk_types.h"
-
-#ifdef __cplusplus
-extern "C"
-{
-#endif
-
-/**
- * Linux specific means for calling _mali_ukk_mem_mmap/munmap
- *
- * The presence of _MALI_OSK_SPECIFIC_INDIRECT_MMAP indicates that
- * _mali_osk_specific_indirect_mmap and _mali_osk_specific_indirect_munmap
- * should be used instead of _mali_ukk_mem_mmap/_mali_ukk_mem_munmap.
- *
- * The arguments are the same as _mali_ukk_mem_mmap/_mali_ukk_mem_munmap.
- *
- * In ALL operating system other than Linux, it is expected that common code
- * should be able to call _mali_ukk_mem_mmap/_mali_ukk_mem_munmap directly.
- * Such systems should NOT define _MALI_OSK_SPECIFIC_INDIRECT_MMAP.
- */
-_mali_osk_errcode_t _mali_osk_specific_indirect_mmap( _mali_uk_mem_mmap_s *args );
-_mali_osk_errcode_t _mali_osk_specific_indirect_munmap( _mali_uk_mem_munmap_s *args );
-
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* __MALI_OSK_INDIR_MMAP_H__ */
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_irq.c b/drivers/gpu/mali/mali/linux/mali_osk_irq.c
old mode 100644
new mode 100755
index 2290307..8d24222
--- a/drivers/gpu/mali/mali/linux/mali_osk_irq.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_irq.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,208 +13,166 @@
  * Implementation of the OS abstraction layer for the kernel device driver
  */
 
-#include <linux/slab.h>	/* For memory allocation */
-#include <linux/workqueue.h>
-#include <linux/version.h>
+#include <linux/slab.h> /* For memory allocation */
+#include <linux/interrupt.h>
+#include <linux/wait.h>
+#include <linux/sched.h>
 
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
-#include "mali_kernel_license.h"
-#include "mali_kernel_linux.h"
-#include "linux/interrupt.h"
 
-typedef struct _mali_osk_irq_t_struct
-{
+typedef struct _mali_osk_irq_t_struct {
 	u32 irqnum;
 	void *data;
 	_mali_osk_irq_uhandler_t uhandler;
-	_mali_osk_irq_bhandler_t bhandler;
-	struct work_struct work_queue_irq_handle; /* Workqueue for the bottom half of the IRQ-handling. This job is activated when this core gets an IRQ.*/
 } mali_osk_irq_object_t;
 
-#if MALI_LICENSE_IS_GPL
-static struct workqueue_struct *pmm_wq = NULL;
-struct workqueue_struct *mali_wq = NULL;
-#endif
-
-typedef void (*workqueue_func_t)(void *);
 typedef irqreturn_t (*irq_handler_func_t)(int, void *, struct pt_regs *);
-static irqreturn_t irq_handler_upper_half (int port_name, void* dev_id ); /* , struct pt_regs *regs*/
+static irqreturn_t irq_handler_upper_half(int port_name, void *dev_id);   /* , struct pt_regs *regs*/
 
-#if defined(INIT_DELAYED_WORK)
-static void irq_handler_bottom_half ( struct work_struct *work );
-#else
-static void irq_handler_bottom_half ( void *  input );
-#endif
+#if defined(DEBUG)
 
-/**
- * Linux kernel version has marked SA_SHIRQ as deprecated, IRQF_SHARED should be used.
- * This is to handle older kernels which haven't done this swap.
- */
-#ifndef IRQF_SHARED
-#define IRQF_SHARED SA_SHIRQ
-#endif /* IRQF_SHARED */
+struct test_interrupt_data {
+	_mali_osk_irq_ack_t ack_func;
+	void *probe_data;
+	mali_bool interrupt_received;
+	wait_queue_head_t wq;
+};
+
+static irqreturn_t test_interrupt_upper_half(int port_name, void *dev_id)
+{
+	irqreturn_t ret = IRQ_NONE;
+	struct test_interrupt_data *data = (struct test_interrupt_data *)dev_id;
+
+	if (_MALI_OSK_ERR_OK == data->ack_func(data->probe_data)) {
+		data->interrupt_received = MALI_TRUE;
+		wake_up(&data->wq);
+		ret = IRQ_HANDLED;
+	}
+
+	return ret;
+}
+
+static _mali_osk_errcode_t test_interrupt(u32 irqnum,
+		_mali_osk_irq_trigger_t trigger_func,
+		_mali_osk_irq_ack_t ack_func,
+		void *probe_data,
+		const char *description)
+{
+	unsigned long irq_flags = 0;
+	struct test_interrupt_data data = {
+		.ack_func = ack_func,
+		.probe_data = probe_data,
+		.interrupt_received = MALI_FALSE,
+	};
+
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	irq_flags |= IRQF_SHARED;
+#endif /* defined(CONFIG_MALI_SHARED_INTERRUPTS) */
+
+	if (0 != request_irq(irqnum, test_interrupt_upper_half, irq_flags, description, &data)) {
+		MALI_DEBUG_PRINT(2, ("Unable to install test IRQ handler for core '%s'\n", description));
+		return _MALI_OSK_ERR_FAULT;
+	}
+
+	init_waitqueue_head(&data.wq);
+
+	trigger_func(probe_data);
+	wait_event_timeout(data.wq, data.interrupt_received, 100);
+
+	free_irq(irqnum, &data);
+
+	if (data.interrupt_received) {
+		MALI_DEBUG_PRINT(3, ("%s: Interrupt test OK\n", description));
+		return _MALI_OSK_ERR_OK;
+	} else {
+		MALI_PRINT_ERROR(("%s: Failed interrupt test on %u\n", description, irqnum));
+		return _MALI_OSK_ERR_FAULT;
+	}
+}
 
-_mali_osk_irq_t *_mali_osk_irq_init( u32 irqnum, _mali_osk_irq_uhandler_t uhandler,	_mali_osk_irq_bhandler_t bhandler, _mali_osk_irq_trigger_t trigger_func, _mali_osk_irq_ack_t ack_func, void *data, const char *description )
+#endif /* defined(DEBUG) */
+
+_mali_osk_irq_t *_mali_osk_irq_init(u32 irqnum, _mali_osk_irq_uhandler_t uhandler, void *int_data, _mali_osk_irq_trigger_t trigger_func, _mali_osk_irq_ack_t ack_func, void *probe_data, const char *description)
 {
 	mali_osk_irq_object_t *irq_object;
+	unsigned long irq_flags = 0;
+
+#if defined(CONFIG_MALI_SHARED_INTERRUPTS)
+	irq_flags |= IRQF_SHARED;
+#endif /* defined(CONFIG_MALI_SHARED_INTERRUPTS) */
 
 	irq_object = kmalloc(sizeof(mali_osk_irq_object_t), GFP_KERNEL);
-	if (NULL == irq_object) return NULL;
-
-#if MALI_LICENSE_IS_GPL
-	if (NULL == mali_wq)
-	{
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,36)
-		mali_wq = alloc_workqueue("mali", WQ_UNBOUND, 0);
-#else
-		mali_wq = create_workqueue("mali");
-#endif
-		if(NULL == mali_wq)
-		{
-			MALI_PRINT_ERROR(("Unable to create Mali workqueue\n"));
-			kfree(irq_object);
-			return NULL;
-		}
+	if (NULL == irq_object) {
+		return NULL;
 	}
-#endif
 
-	/* workqueue API changed in 2.6.20, support both versions: */
-#if defined(INIT_DELAYED_WORK)
-	/* New syntax: INIT_WORK( struct work_struct *work, void (*function)(struct work_struct *)) */
-	INIT_WORK( &irq_object->work_queue_irq_handle, irq_handler_bottom_half);
-#else
-	/* Old syntax: INIT_WORK( struct work_struct *work, void (*function)(void *), void *data) */
-	INIT_WORK( &irq_object->work_queue_irq_handle, irq_handler_bottom_half, irq_object);
-#endif /* defined(INIT_DELAYED_WORK) */
-
-	if (-1 == irqnum)
-	{
+	if (-1 == irqnum) {
 		/* Probe for IRQ */
-		if ( (NULL != trigger_func) && (NULL != ack_func) )
-		{
+		if ((NULL != trigger_func) && (NULL != ack_func)) {
 			unsigned long probe_count = 3;
 			_mali_osk_errcode_t err;
 			int irq;
 
 			MALI_DEBUG_PRINT(2, ("Probing for irq\n"));
 
-			do
-			{
+			do {
 				unsigned long mask;
 
 				mask = probe_irq_on();
-				trigger_func(data);
+				trigger_func(probe_data);
 
 				_mali_osk_time_ubusydelay(5);
 
 				irq = probe_irq_off(mask);
-				err = ack_func(data);
-			}
-			while (irq < 0 && (err == _MALI_OSK_ERR_OK) && probe_count--);
+				err = ack_func(probe_data);
+			} while (irq < 0 && (err == _MALI_OSK_ERR_OK) && probe_count--);
 
 			if (irq < 0 || (_MALI_OSK_ERR_OK != err)) irqnum = -1;
 			else irqnum = irq;
-		}
-		else irqnum = -1; /* no probe functions, fault */
+		} else irqnum = -1; /* no probe functions, fault */
 
-		if (-1 != irqnum)
-		{
+		if (-1 != irqnum) {
 			/* found an irq */
 			MALI_DEBUG_PRINT(2, ("Found irq %d\n", irqnum));
-		}
-		else
-		{
+		} else {
 			MALI_DEBUG_PRINT(2, ("Probe for irq failed\n"));
 		}
 	}
 
 	irq_object->irqnum = irqnum;
 	irq_object->uhandler = uhandler;
-	irq_object->bhandler = bhandler;
-	irq_object->data = data;
-
-	/* Is this a real IRQ handler we need? */
-	if (irqnum != _MALI_OSK_IRQ_NUMBER_FAKE && irqnum != _MALI_OSK_IRQ_NUMBER_PMM)
-	{
-		if (-1 == irqnum)
-		{
-			MALI_DEBUG_PRINT(2, ("No IRQ for core '%s' found during probe\n", description));
-			kfree(irq_object);
-			return NULL;
-		}
+	irq_object->data = int_data;
 
-		if (0 != request_irq(irqnum, irq_handler_upper_half, IRQF_SHARED, description, irq_object))
-		{
-			MALI_DEBUG_PRINT(2, ("Unable to install IRQ handler for core '%s'\n", description));
-			kfree(irq_object);
-			return NULL;
-		}
+	if (-1 == irqnum) {
+		MALI_DEBUG_PRINT(2, ("No IRQ for core '%s' found during probe\n", description));
+		kfree(irq_object);
+		return NULL;
 	}
 
-#if MALI_LICENSE_IS_GPL
-	if ( _MALI_OSK_IRQ_NUMBER_PMM == irqnum )
-	{
-		pmm_wq = create_singlethread_workqueue("mali-pmm-wq");
+#if defined(DEBUG)
+	/* Verify that the configured interrupt settings are working */
+	if (_MALI_OSK_ERR_OK != test_interrupt(irqnum, trigger_func, ack_func, probe_data, description)) {
+		MALI_DEBUG_PRINT(2, ("Test of IRQ handler for core '%s' failed\n", description));
+		kfree(irq_object);
+		return NULL;
 	}
 #endif
 
-	return irq_object;
-}
-
-void _mali_osk_irq_schedulework( _mali_osk_irq_t *irq )
-{
-	mali_osk_irq_object_t *irq_object = (mali_osk_irq_object_t *)irq;
-#if MALI_LICENSE_IS_GPL
-	if ( irq_object->irqnum == _MALI_OSK_IRQ_NUMBER_PMM )
-	{
-		queue_work( pmm_wq,&irq_object->work_queue_irq_handle );
+	if (0 != request_irq(irqnum, irq_handler_upper_half, irq_flags, description, irq_object)) {
+		MALI_DEBUG_PRINT(2, ("Unable to install IRQ handler for core '%s'\n", description));
+		kfree(irq_object);
+		return NULL;
 	}
-	else
-	{
-		queue_work(mali_wq, &irq_object->work_queue_irq_handle);
-	}
-#else
-	schedule_work(&irq_object->work_queue_irq_handle);
-#endif
-}
 
-void _mali_osk_flush_workqueue( _mali_osk_irq_t *irq )
-{
-#if MALI_LICENSE_IS_GPL
-	if (NULL != irq)
-	{
-		mali_osk_irq_object_t *irq_object = (mali_osk_irq_object_t *)irq;
-		if(irq_object->irqnum == _MALI_OSK_IRQ_NUMBER_PMM )
-		{
-			flush_workqueue(pmm_wq);
-		}
-		else
-		{
-			flush_workqueue(mali_wq);
-		}
-	}
-	else
-	{
-		flush_workqueue(mali_wq);
-	}
-#endif
+	return irq_object;
 }
 
-void _mali_osk_irq_term( _mali_osk_irq_t *irq )
+void _mali_osk_irq_term(_mali_osk_irq_t *irq)
 {
 	mali_osk_irq_object_t *irq_object = (mali_osk_irq_object_t *)irq;
-
-#if MALI_LICENSE_IS_GPL
-	if(irq_object->irqnum == _MALI_OSK_IRQ_NUMBER_PMM )
-	{
-		flush_workqueue(pmm_wq);
-		destroy_workqueue(pmm_wq);
-	}
-#endif
 	free_irq(irq_object->irqnum, irq_object);
 	kfree(irq_object);
-	flush_scheduled_work();
 }
 
 
@@ -229,37 +187,14 @@ void _mali_osk_irq_term( _mali_osk_irq_t *irq )
  * Then we schedule the mali_core_irq_handler_bottom_half to run as high priority
  * work queue job.
  */
-static irqreturn_t irq_handler_upper_half (int port_name, void* dev_id ) /* , struct pt_regs *regs*/
+static irqreturn_t irq_handler_upper_half(int port_name, void *dev_id)   /* , struct pt_regs *regs*/
 {
+	irqreturn_t ret = IRQ_NONE;
 	mali_osk_irq_object_t *irq_object = (mali_osk_irq_object_t *)dev_id;
 
-	if (irq_object->uhandler(irq_object->data) == _MALI_OSK_ERR_OK)
-	{
-		return IRQ_HANDLED;
-	}
-	return IRQ_NONE;
-}
-
-/* Is executed when an interrupt occur on one core */
-/* workqueue API changed in 2.6.20, support both versions: */
-#if defined(INIT_DELAYED_WORK)
-static void irq_handler_bottom_half ( struct work_struct *work )
-#else
-static void irq_handler_bottom_half ( void *  input )
-#endif
-{
-	mali_osk_irq_object_t *irq_object;
-
-#if defined(INIT_DELAYED_WORK)
-	irq_object = _MALI_OSK_CONTAINER_OF(work, mali_osk_irq_object_t, work_queue_irq_handle);
-#else
-	if ( NULL == input )
-	{
-		MALI_PRINT_ERROR(("IRQ: Null pointer! Illegal!"));
-		return; /* Error */
+	if (_MALI_OSK_ERR_OK == irq_object->uhandler(irq_object->data)) {
+		ret = IRQ_HANDLED;
 	}
-	irq_object = (mali_osk_irq_object_t *) input;
-#endif
 
-	irq_object->bhandler(irq_object->data);
+	return ret;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_locks.c b/drivers/gpu/mali/mali/linux/mali_osk_locks.c
old mode 100644
new mode 100755
index c3c8d09..c37613c
--- a/drivers/gpu/mali/mali/linux/mali_osk_locks.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_locks.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,324 +13,269 @@
  * Implemenation of the OS abstraction layer for the kernel device driver
  */
 
-/* needed to detect kernel version specific code */
-#include <linux/version.h>
-
-#include <linux/spinlock.h>
-#include <linux/rwsem.h>
-
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-#include <linux/semaphore.h>
-#else /* pre 2.6.26 the file was in the arch specific location */
-#include <asm/semaphore.h>
-#endif
-
-#include <linux/slab.h>
-#include "mali_osk.h"
+#include "mali_osk_locks.h"
 #include "mali_kernel_common.h"
+#include "mali_osk.h"
 
-/* These are all the locks we implement: */
-typedef enum
-{
-	_MALI_OSK_INTERNAL_LOCKTYPE_SPIN,            /* Mutex, implicitly non-interruptable, use spin_lock/spin_unlock */
-	_MALI_OSK_INTERNAL_LOCKTYPE_SPIN_IRQ,        /* Mutex, IRQ version of spinlock, use spin_lock_irqsave/spin_unlock_irqrestore */
-	_MALI_OSK_INTERNAL_LOCKTYPE_MUTEX,           /* Interruptable, use up()/down_interruptable() */
-	_MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT,    /* Non-Interruptable, use up()/down() */
-	_MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT_RW, /* Non-interruptable, Reader/Writer, use {up,down}{read,write}() */
-
-	/* Linux supports, but we do not support:
-	 * Non-Interruptable Reader/Writer spinlock mutexes - RW optimization will be switched off
-	 */
 
-	/* Linux does not support:
-	 * One-locks, of any sort - no optimization for this fact will be made.
-	 */
+#ifdef DEBUG
+#ifdef LOCK_ORDER_CHECKING
+static DEFINE_SPINLOCK(lock_tracking_lock);
+static mali_bool add_lock_to_log_and_check(struct _mali_osk_lock_debug_s *lock, uint32_t tid);
+static void remove_lock_from_log(struct _mali_osk_lock_debug_s *lock, uint32_t tid);
+static const char *const lock_order_to_string(_mali_osk_lock_order_t order);
+#endif /* LOCK_ORDER_CHECKING */
+
+void _mali_osk_locks_debug_init(struct _mali_osk_lock_debug_s *checker, _mali_osk_lock_flags_t flags, _mali_osk_lock_order_t order)
+{
+	checker->orig_flags = flags;
+	checker->owner = 0;
 
-} _mali_osk_internal_locktype;
+#ifdef LOCK_ORDER_CHECKING
+	checker->order = order;
+	checker->next = NULL;
+#endif
+}
 
-struct _mali_osk_lock_t_struct
-{
-    _mali_osk_internal_locktype type;
-	unsigned long flags;
-    union
-    {
-        spinlock_t spinlock;
-        struct semaphore sema;
-        struct rw_semaphore rw_sema;
-    } obj;
-	MALI_DEBUG_CODE(
-				  /** original flags for debug checking */
-				  _mali_osk_lock_flags_t orig_flags;
-
-				  /* id of the thread currently holding this lock, 0 if no
-				   * threads hold it. */
-				  u32 owner;
-				  /* number of owners this lock currently has (can be > 1 if
-				   * taken in R/O mode. */
-				  u32 nOwners;
-				  /* what mode the lock was taken in */
-				  _mali_osk_lock_mode_t mode;
-	); /* MALI_DEBUG_CODE */
-};
-
-_mali_osk_lock_t *_mali_osk_lock_init( _mali_osk_lock_flags_t flags, u32 initial, u32 order )
+void _mali_osk_locks_debug_add(struct _mali_osk_lock_debug_s *checker)
 {
-    _mali_osk_lock_t *lock = NULL;
-
-	/* Validate parameters: */
-	/* Flags acceptable */
-	MALI_DEBUG_ASSERT( 0 == ( flags & ~(_MALI_OSK_LOCKFLAG_SPINLOCK
-                                      | _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ
-                                      | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE
-                                      | _MALI_OSK_LOCKFLAG_READERWRITER
-                                      | _MALI_OSK_LOCKFLAG_ORDERED
-                                      | _MALI_OSK_LOCKFLAG_ONELOCK )) );
-	/* Spinlocks are always non-interruptable */
-	MALI_DEBUG_ASSERT( (((flags & _MALI_OSK_LOCKFLAG_SPINLOCK) || (flags & _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ)) && (flags & _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE))
-					 || !(flags & _MALI_OSK_LOCKFLAG_SPINLOCK));
-	/* Parameter initial SBZ - for future expansion */
-	MALI_DEBUG_ASSERT( 0 == initial );
-
-	lock = kmalloc(sizeof(_mali_osk_lock_t), GFP_KERNEL);
-
-	if ( NULL == lock )
-	{
-		return lock;
-	}
-
-	/* Determine type of mutex: */
-    /* defaults to interruptable mutex if no flags are specified */
+	checker->owner = _mali_osk_get_tid();
 
-	if ( (flags & _MALI_OSK_LOCKFLAG_SPINLOCK) )
-	{
-		/* Non-interruptable Spinlocks override all others */
-		lock->type = _MALI_OSK_INTERNAL_LOCKTYPE_SPIN;
-		spin_lock_init( &lock->obj.spinlock );
-	}
-	else if ( (flags & _MALI_OSK_LOCKFLAG_SPINLOCK_IRQ ) )
-	{
-		lock->type = _MALI_OSK_INTERNAL_LOCKTYPE_SPIN_IRQ;
-		lock->flags = 0;
-		spin_lock_init( &lock->obj.spinlock );
-	}
-	else if ( (flags & _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE)
-			  && (flags & _MALI_OSK_LOCKFLAG_READERWRITER) )
-	{
-		lock->type = _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT_RW;
-		init_rwsem( &lock->obj.rw_sema );
-	}
-	else
-	{
-		/* Usual mutex types */
-		if ( (flags & _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE) )
-		{
-			lock->type = _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT;
-		}
-		else
-		{
-			lock->type = _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX;
+#ifdef LOCK_ORDER_CHECKING
+	if (!(checker->orig_flags & _MALI_OSK_LOCKFLAG_UNORDERED)) {
+		if (!add_lock_to_log_and_check(checker, _mali_osk_get_tid())) {
+			printk(KERN_ERR "%d: ERROR lock %p taken while holding a lock of a higher order.\n",
+			       _mali_osk_get_tid(), checker);
+			dump_stack();
 		}
+	}
+#endif
+}
+
+void _mali_osk_locks_debug_remove(struct _mali_osk_lock_debug_s *checker)
+{
 
-		/* Initially unlocked */
-		sema_init( &lock->obj.sema, 1 );
+#ifdef LOCK_ORDER_CHECKING
+	if (!(checker->orig_flags & _MALI_OSK_LOCKFLAG_UNORDERED)) {
+		remove_lock_from_log(checker, _mali_osk_get_tid());
 	}
+#endif
+	checker->owner = 0;
+}
 
-#ifdef DEBUG
-	/* Debug tracking of flags */
-	lock->orig_flags = flags;
 
-	/* Debug tracking of lock owner */
-	lock->owner = 0;
-	lock->nOwners = 0;
-#endif /* DEBUG */
+#ifdef LOCK_ORDER_CHECKING
+/* Lock order checking
+ * -------------------
+ *
+ * To assure that lock ordering scheme defined by _mali_osk_lock_order_t is strictly adhered to, the
+ * following function will, together with a linked list and some extra members in _mali_osk_lock_debug_s,
+ * make sure that a lock that is taken has a higher order than the current highest-order lock a
+ * thread holds.
+ *
+ * This is done in the following manner:
+ * - A linked list keeps track of locks held by a thread.
+ * - A `next' pointer is added to each lock. This is used to chain the locks together.
+ * - When taking a lock, the `add_lock_to_log_and_check' makes sure that taking
+ *   the given lock is legal. It will follow the linked list  to find the last
+ *   lock taken by this thread. If the last lock's order was lower than the
+ *   lock that is to be taken, it appends the new lock to the list and returns
+ *   true, if not, it return false. This return value is assert()'ed on in
+ *   _mali_osk_lock_wait().
+ */
 
-    return lock;
-}
+static struct _mali_osk_lock_debug_s *lock_lookup_list;
 
-#ifdef DEBUG
-u32 _mali_osk_lock_get_owner( _mali_osk_lock_t *lock )
+static void dump_lock_tracking_list(void)
 {
-	return lock->owner;
-}
+	struct _mali_osk_lock_debug_s *l;
+	u32 n = 1;
 
-u32 _mali_osk_lock_get_number_owners( _mali_osk_lock_t *lock )
-{
-	return lock->nOwners;
+	/* print list for debugging purposes */
+	l = lock_lookup_list;
+
+	while (NULL != l) {
+		printk(" [lock: %p, tid_owner: %d, order: %d] ->", l, l->owner, l->order);
+		l = l->next;
+		MALI_DEBUG_ASSERT(n++ < 100);
+	}
+	printk(" NULL\n");
 }
 
-u32 _mali_osk_lock_get_mode( _mali_osk_lock_t *lock )
+static int tracking_list_length(void)
 {
-	return lock->mode;
+	struct _mali_osk_lock_debug_s *l;
+	u32 n = 0;
+	l = lock_lookup_list;
+
+	while (NULL != l) {
+		l = l->next;
+		n++;
+		MALI_DEBUG_ASSERT(n < 100);
+	}
+	return n;
 }
-#endif /* DEBUG */
 
-_mali_osk_errcode_t _mali_osk_lock_wait( _mali_osk_lock_t *lock, _mali_osk_lock_mode_t mode)
+static mali_bool add_lock_to_log_and_check(struct _mali_osk_lock_debug_s *lock, uint32_t tid)
 {
-    _mali_osk_errcode_t err = _MALI_OSK_ERR_OK;
-
-	/* Parameter validation */
-	MALI_DEBUG_ASSERT_POINTER( lock );
-
-	MALI_DEBUG_ASSERT( _MALI_OSK_LOCKMODE_RW == mode
-					 || _MALI_OSK_LOCKMODE_RO == mode );
-
-	/* Only allow RO locks when the initial object was a Reader/Writer lock
-	 * Since information is lost on the internal locktype, we use the original
-	 * information, which is only stored when built for DEBUG */
-	MALI_DEBUG_ASSERT( _MALI_OSK_LOCKMODE_RW == mode
-					 || (_MALI_OSK_LOCKMODE_RO == mode && (_MALI_OSK_LOCKFLAG_READERWRITER & lock->orig_flags)) );
-
-	switch ( lock->type )
-	{
-	case _MALI_OSK_INTERNAL_LOCKTYPE_SPIN:
-		spin_lock(&lock->obj.spinlock);
-		break;
-	case _MALI_OSK_INTERNAL_LOCKTYPE_SPIN_IRQ:
-		spin_lock_irqsave(&lock->obj.spinlock, lock->flags);
-		break;
+	mali_bool ret = MALI_FALSE;
+	_mali_osk_lock_order_t highest_order_for_tid = _MALI_OSK_LOCK_ORDER_FIRST;
+	struct _mali_osk_lock_debug_s *highest_order_lock = (struct _mali_osk_lock_debug_s *)0xbeefbabe;
+	struct _mali_osk_lock_debug_s *l;
+	unsigned long local_lock_flag;
+	u32 len;
+
+	spin_lock_irqsave(&lock_tracking_lock, local_lock_flag);
+	len = tracking_list_length();
+
+	l  = lock_lookup_list;
+	if (NULL == l) { /* This is the first lock taken by this thread -- record and return true */
+		lock_lookup_list = lock;
+		spin_unlock_irqrestore(&lock_tracking_lock, local_lock_flag);
+		return MALI_TRUE;
+	} else {
+		/* Traverse the locks taken and find the lock of the highest order.
+		 * Since several threads may hold locks, each lock's owner must be
+		 * checked so that locks not owned by this thread can be ignored. */
+		for (;;) {
+			MALI_DEBUG_ASSERT_POINTER(l);
+			if (tid == l->owner && l->order >= highest_order_for_tid) {
+				highest_order_for_tid = l->order;
+				highest_order_lock = l;
+			}
 
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX:
-		if ( down_interruptible(&lock->obj.sema) )
-		{
-			MALI_PRINT_ERROR(("Can not lock mutex\n"));
-			err = _MALI_OSK_ERR_RESTARTSYSCALL;
+			if (NULL != l->next) {
+				l = l->next;
+			} else {
+				break;
+			}
 		}
-		break;
 
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT:
-		down(&lock->obj.sema);
-		break;
+		l->next = lock;
+		l->next = NULL;
+	}
 
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT_RW:
-		if (mode == _MALI_OSK_LOCKMODE_RO)
-        {
-            down_read(&lock->obj.rw_sema);
-        }
-        else
-        {
-            down_write(&lock->obj.rw_sema);
-        }
-		break;
+	/* We have now found the highest order lock currently held by this thread and can see if it is
+	 * legal to take the requested lock. */
+	ret = highest_order_for_tid < lock->order;
 
-	default:
-		/* Reaching here indicates a programming error, so you will not get here
-		 * on non-DEBUG builds */
-		MALI_DEBUG_PRINT_ERROR( ("Invalid internal lock type: %.8X", lock->type ) );
-		break;
+	if (!ret) {
+		printk(KERN_ERR "Took lock of order %d (%s) while holding lock of order %d (%s)\n",
+		       lock->order, lock_order_to_string(lock->order),
+		       highest_order_for_tid, lock_order_to_string(highest_order_for_tid));
+		dump_lock_tracking_list();
 	}
 
-#ifdef DEBUG
-	/* This thread is now the owner of this lock */
-	if (_MALI_OSK_ERR_OK == err)
-	{
-		if (mode == _MALI_OSK_LOCKMODE_RW)
-		{
-			/*MALI_DEBUG_ASSERT(0 == lock->owner);*/
-			if (0 != lock->owner)
-			{
-				printk(KERN_ERR "%d: ERROR: Lock %p already has owner %d\n", _mali_osk_get_tid(), lock, lock->owner);
-				dump_stack();
-			}
-			lock->owner = _mali_osk_get_tid();
-			lock->mode = mode;
-			++lock->nOwners;
-		}
-		else /* mode == _MALI_OSK_LOCKMODE_RO */
-		{
-			lock->owner |= _mali_osk_get_tid();
-			lock->mode = mode;
-			++lock->nOwners;
-		}
+	if (len + 1 != tracking_list_length()) {
+		printk(KERN_ERR "************ lock: %p\n", lock);
+		printk(KERN_ERR "************ before: %d *** after: %d ****\n", len, tracking_list_length());
+		dump_lock_tracking_list();
+		MALI_DEBUG_ASSERT_POINTER(NULL);
 	}
-#endif
 
-    return err;
+	spin_unlock_irqrestore(&lock_tracking_lock, local_lock_flag);
+	return ret;
 }
 
-void _mali_osk_lock_signal( _mali_osk_lock_t *lock, _mali_osk_lock_mode_t mode )
+static void remove_lock_from_log(struct _mali_osk_lock_debug_s *lock, uint32_t tid)
 {
-	/* Parameter validation */
-	MALI_DEBUG_ASSERT_POINTER( lock );
+	struct _mali_osk_lock_debug_s *curr;
+	struct _mali_osk_lock_debug_s *prev = NULL;
+	unsigned long local_lock_flag;
+	u32 len;
+	u32 n = 0;
+
+	spin_lock_irqsave(&lock_tracking_lock, local_lock_flag);
+	len = tracking_list_length();
+	curr = lock_lookup_list;
+
+	if (NULL == curr) {
+		printk(KERN_ERR "Error: Lock tracking list was empty on call to remove_lock_from_log\n");
+		dump_lock_tracking_list();
+	}
 
-	MALI_DEBUG_ASSERT( _MALI_OSK_LOCKMODE_RW == mode
-					 || _MALI_OSK_LOCKMODE_RO == mode );
+	MALI_DEBUG_ASSERT_POINTER(curr);
 
-	/* Only allow RO locks when the initial object was a Reader/Writer lock
-	 * Since information is lost on the internal locktype, we use the original
-	 * information, which is only stored when built for DEBUG */
-	MALI_DEBUG_ASSERT( _MALI_OSK_LOCKMODE_RW == mode
-					 || (_MALI_OSK_LOCKMODE_RO == mode && (_MALI_OSK_LOCKFLAG_READERWRITER & lock->orig_flags)) );
 
-#ifdef DEBUG
-	/* make sure the thread releasing the lock actually was the owner */
-	if (mode == _MALI_OSK_LOCKMODE_RW)
-	{
-		/*MALI_DEBUG_ASSERT(_mali_osk_get_tid() == lock->owner);*/
-		if (_mali_osk_get_tid() != lock->owner)
-		{
-			printk(KERN_ERR "%d: ERROR: Lock %p owner was %d\n", _mali_osk_get_tid(), lock, lock->owner);
-			dump_stack();
-		}
-		/* This lock now has no owner */
-		lock->owner = 0;
-		--lock->nOwners;
+	while (lock != curr) {
+		prev = curr;
+
+		MALI_DEBUG_ASSERT_POINTER(curr);
+		curr = curr->next;
+		MALI_DEBUG_ASSERT(n++ < 100);
 	}
-	else /* mode == _MALI_OSK_LOCKMODE_RO */
-	{
-		if ((_mali_osk_get_tid() & lock->owner) != _mali_osk_get_tid())
-		{
-			printk(KERN_ERR "%d: ERROR: Not an owner of %p lock.\n", _mali_osk_get_tid(), lock);
-			dump_stack();
-		}
 
-		/* if this is the last thread holding this lock in R/O mode, set owner
-		 * back to 0 */
-		if (0 == --lock->nOwners)
-		{
-			lock->owner = 0;
-		}
+	if (NULL == prev) {
+		lock_lookup_list = curr->next;
+	} else {
+		MALI_DEBUG_ASSERT_POINTER(curr);
+		MALI_DEBUG_ASSERT_POINTER(prev);
+		prev->next = curr->next;
 	}
-#endif /* DEBUG */
 
-	switch ( lock->type )
-	{
-	case _MALI_OSK_INTERNAL_LOCKTYPE_SPIN:
-		spin_unlock(&lock->obj.spinlock);
+	lock->next = NULL;
+
+	if (len - 1 != tracking_list_length()) {
+		printk(KERN_ERR "************ lock: %p\n", lock);
+		printk(KERN_ERR "************ before: %d *** after: %d ****\n", len, tracking_list_length());
+		dump_lock_tracking_list();
+		MALI_DEBUG_ASSERT_POINTER(NULL);
+	}
+
+	spin_unlock_irqrestore(&lock_tracking_lock, local_lock_flag);
+}
+
+static const char *const lock_order_to_string(_mali_osk_lock_order_t order)
+{
+	switch (order) {
+	case _MALI_OSK_LOCK_ORDER_SESSIONS:
+		return "_MALI_OSK_LOCK_ORDER_SESSIONS";
 		break;
-	case _MALI_OSK_INTERNAL_LOCKTYPE_SPIN_IRQ:
-		spin_unlock_irqrestore(&lock->obj.spinlock, lock->flags);
+	case _MALI_OSK_LOCK_ORDER_MEM_SESSION:
+		return "_MALI_OSK_LOCK_ORDER_MEM_SESSION";
 		break;
-
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX:
-		/* FALLTHROUGH */
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT:
-		up(&lock->obj.sema);
+	case _MALI_OSK_LOCK_ORDER_MEM_INFO:
+		return "_MALI_OSK_LOCK_ORDER_MEM_INFO";
 		break;
-
-	case _MALI_OSK_INTERNAL_LOCKTYPE_MUTEX_NONINT_RW:
-		if (mode == _MALI_OSK_LOCKMODE_RO)
-        {
-            up_read(&lock->obj.rw_sema);
-        }
-        else
-        {
-            up_write(&lock->obj.rw_sema);
-        }
+	case _MALI_OSK_LOCK_ORDER_MEM_PT_CACHE:
+		return "_MALI_OSK_LOCK_ORDER_MEM_PT_CACHE";
 		break;
-
-	default:
-		/* Reaching here indicates a programming error, so you will not get here
-		 * on non-DEBUG builds */
-		MALI_DEBUG_PRINT_ERROR( ("Invalid internal lock type: %.8X", lock->type ) );
+	case _MALI_OSK_LOCK_ORDER_DESCRIPTOR_MAP:
+		return "_MALI_OSK_LOCK_ORDER_DESCRIPTOR_MAP";
+		break;
+	case _MALI_OSK_LOCK_ORDER_GROUP_VIRTUAL:
+		return "_MALI_OSK_LOCK_ORDER_GROUP_VIRTUAL";
+		break;
+	case _MALI_OSK_LOCK_ORDER_GROUP:
+		return "_MALI_OSK_LOCK_ORDER_GROUP";
+		break;
+	case _MALI_OSK_LOCK_ORDER_SCHEDULER:
+		return "_MALI_OSK_LOCK_ORDER_SCHEDULER";
+		break;
+	case _MALI_OSK_LOCK_ORDER_PM_CORE_STATE:
+		return "_MALI_OSK_LOCK_ORDER_PM_CORE_STATE";
 		break;
+	case _MALI_OSK_LOCK_ORDER_L2_COMMAND:
+		return "_MALI_OSK_LOCK_ORDER_L2_COMMAND";
+		break;
+	case _MALI_OSK_LOCK_ORDER_PROFILING:
+		return "_MALI_OSK_LOCK_ORDER_PROFILING";
+		break;
+	case _MALI_OSK_LOCK_ORDER_L2_COUNTER:
+		return "_MALI_OSK_LOCK_ORDER_L2_COUNTER";
+		break;
+	case _MALI_OSK_LOCK_ORDER_UTILIZATION:
+		return "_MALI_OSK_LOCK_ORDER_UTILIZATION";
+		break;
+	case _MALI_OSK_LOCK_ORDER_PM_EXECUTE:
+		return "_MALI_OSK_LOCK_ORDER_PM_EXECUTE";
+		break;
+	case _MALI_OSK_LOCK_ORDER_SESSION_PENDING_JOBS:
+		return "_MALI_OSK_LOCK_ORDER_SESSION_PENDING_JOBS";
+		break;
+	default:
+		return "";
 	}
 }
-
-void _mali_osk_lock_term( _mali_osk_lock_t *lock )
-{
-	/* Parameter validation  */
-	MALI_DEBUG_ASSERT_POINTER( lock );
-
-	/* Linux requires no explicit termination of spinlocks, semaphores, or rw_semaphores */
-    kfree(lock);
-}
+#endif /* LOCK_ORDER_CHECKING */
+#endif /* DEBUG */
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_low_level_mem.c b/drivers/gpu/mali/mali/linux/mali_osk_low_level_mem.c
old mode 100644
new mode 100755
index eaf6653..e83b4cc
--- a/drivers/gpu/mali/mali/linux/mali_osk_low_level_mem.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_low_level_mem.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -13,578 +13,125 @@
  * Implementation of the OS abstraction layer for the kernel device driver
  */
 
-/* needed to detect kernel version specific code */
-#include <linux/version.h>
-
 #include <asm/io.h>
 #include <linux/ioport.h>
 #include <linux/slab.h>
-#include <linux/mm.h>
-#include <linux/dma-mapping.h>
 
-#include "mali_osk.h"
-#include "mali_ukk.h" /* required to hook in _mali_ukk_mem_mmap handling */
 #include "mali_kernel_common.h"
-#include "mali_kernel_linux.h"
-
-static void mali_kernel_memory_vma_open(struct vm_area_struct * vma);
-static void mali_kernel_memory_vma_close(struct vm_area_struct * vma);
-
-
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-static int mali_kernel_memory_cpu_page_fault_handler(struct vm_area_struct *vma, struct vm_fault *vmf);
-#else
-static unsigned long mali_kernel_memory_cpu_page_fault_handler(struct vm_area_struct * vma, unsigned long address);
-#endif
-
-
-typedef struct mali_vma_usage_tracker
-{
-	int references;
-	u32 cookie;
-} mali_vma_usage_tracker;
-
-
-/* Linked list structure to hold details of all OS allocations in a particular
- * mapping
- */
-struct AllocationList
-{
-	struct AllocationList *next;
-	u32 offset;
-	u32 physaddr;
-};
-
-typedef struct AllocationList AllocationList;
-
-/* Private structure to store details of a mapping region returned
- * from _mali_osk_mem_mapregion_init
- */
-struct MappingInfo
-{
-	struct vm_area_struct *vma;
-	struct AllocationList *list;
-};
-
-typedef struct MappingInfo MappingInfo;
-
-
-static u32 _kernel_page_allocate(void);
-static void _kernel_page_release(u32 physical_address);
-static AllocationList * _allocation_list_item_get(void);
-static void _allocation_list_item_release(AllocationList * item);
-
-
-/* Variable declarations */
-static DEFINE_SPINLOCK(allocation_list_spinlock);
-static AllocationList * pre_allocated_memory = (AllocationList*) NULL ;
-static int pre_allocated_memory_size_current  = 0;
-#ifdef MALI_OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB
-	static int pre_allocated_memory_size_max      = MALI_OS_MEMORY_KERNEL_BUFFER_SIZE_IN_MB * 1024 * 1024;
-#else
-	static int pre_allocated_memory_size_max      = 6 * 1024 * 1024; /* 6 MiB */
-#endif
-
-static struct vm_operations_struct mali_kernel_vm_ops =
-{
-	.open = mali_kernel_memory_vma_open,
-	.close = mali_kernel_memory_vma_close,
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-	.fault = mali_kernel_memory_cpu_page_fault_handler
-#else
-	.nopfn = mali_kernel_memory_cpu_page_fault_handler
-#endif
-};
-
-
-void mali_osk_low_level_mem_init(void)
-{
-	pre_allocated_memory = (AllocationList*) NULL ;
-}
-
-void mali_osk_low_level_mem_term(void)
-{
-	while ( NULL != pre_allocated_memory )
-	{
-		AllocationList *item;
-		item = pre_allocated_memory;
-		pre_allocated_memory = item->next;
-		_kernel_page_release(item->physaddr);
-		_mali_osk_free( item );
-	}
-	pre_allocated_memory_size_current  = 0;
-}
-
-static u32 _kernel_page_allocate(void)
-{
-	struct page *new_page;
-	u32 linux_phys_addr;
-
-	new_page = alloc_page(GFP_HIGHUSER | __GFP_ZERO | __GFP_REPEAT | __GFP_NOWARN | __GFP_COLD);
-
-	if ( NULL == new_page )
-	{
-		return 0;
-	}
-
-	/* Ensure page is flushed from CPU caches. */
-	linux_phys_addr = dma_map_page(NULL, new_page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
-
-	return linux_phys_addr;
-}
-
-static void _kernel_page_release(u32 physical_address)
-{
-	struct page *unmap_page;
-
-	#if 1
-	dma_unmap_page(NULL, physical_address, PAGE_SIZE, DMA_BIDIRECTIONAL);
-	#endif
-
-	unmap_page = pfn_to_page( physical_address >> PAGE_SHIFT );
-	MALI_DEBUG_ASSERT_POINTER( unmap_page );
-	__free_page( unmap_page );
-}
-
-static AllocationList * _allocation_list_item_get(void)
-{
-	AllocationList *item = NULL;
-	unsigned long flags;
-
-	spin_lock_irqsave(&allocation_list_spinlock,flags);
-	if ( pre_allocated_memory )
-	{
-		item = pre_allocated_memory;
-		pre_allocated_memory = pre_allocated_memory->next;
-		pre_allocated_memory_size_current -= PAGE_SIZE;
-
-		spin_unlock_irqrestore(&allocation_list_spinlock,flags);
-		return item;
-	}
-	spin_unlock_irqrestore(&allocation_list_spinlock,flags);
-
-	item = _mali_osk_malloc( sizeof(AllocationList) );
-	if ( NULL == item)
-	{
-		return NULL;
-	}
-
-	item->physaddr = _kernel_page_allocate();
-	if ( 0 == item->physaddr )
-	{
-		/* Non-fatal error condition, out of memory. Upper levels will handle this. */
-		_mali_osk_free( item );
-		return NULL;
-	}
-	return item;
-}
-
-static void _allocation_list_item_release(AllocationList * item)
-{
-	unsigned long flags;
-	spin_lock_irqsave(&allocation_list_spinlock,flags);
-	if ( pre_allocated_memory_size_current < pre_allocated_memory_size_max)
-	{
-		item->next = pre_allocated_memory;
-		pre_allocated_memory = item;
-		pre_allocated_memory_size_current += PAGE_SIZE;
-		spin_unlock_irqrestore(&allocation_list_spinlock,flags);
-		return;
-	}
-	spin_unlock_irqrestore(&allocation_list_spinlock,flags);
-
-	_kernel_page_release(item->physaddr);
-	_mali_osk_free( item );
-}
-
-
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-static int mali_kernel_memory_cpu_page_fault_handler(struct vm_area_struct *vma, struct vm_fault *vmf)
-#else
-static unsigned long mali_kernel_memory_cpu_page_fault_handler(struct vm_area_struct * vma, unsigned long address)
-#endif
-{
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-	void __user * address;
-	address = vmf->virtual_address;
-#endif
-	/*
-	 * We always fail the call since all memory is pre-faulted when assigned to the process.
-	 * Only the Mali cores can use page faults to extend buffers.
-	*/
-
-	MALI_DEBUG_PRINT(1, ("Page-fault in Mali memory region caused by the CPU.\n"));
-	MALI_DEBUG_PRINT(1, ("Tried to access %p (process local virtual address) which is not currently mapped to any Mali memory.\n", (void*)address));
-
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-	return VM_FAULT_SIGBUS;
-#else
-	return NOPFN_SIGBUS;
-#endif
-}
-
-static void mali_kernel_memory_vma_open(struct vm_area_struct * vma)
-{
-	mali_vma_usage_tracker * vma_usage_tracker;
-	MALI_DEBUG_PRINT(4, ("Open called on vma %p\n", vma));
-
-	vma_usage_tracker = (mali_vma_usage_tracker*)vma->vm_private_data;
-	vma_usage_tracker->references++;
-
-	return;
-}
-
-static void mali_kernel_memory_vma_close(struct vm_area_struct * vma)
-{
-	_mali_uk_mem_munmap_s args = {0, };
-	mali_memory_allocation * descriptor;
-	mali_vma_usage_tracker * vma_usage_tracker;
-	MALI_DEBUG_PRINT(3, ("Close called on vma %p\n", vma));
-
-	vma_usage_tracker = (mali_vma_usage_tracker*)vma->vm_private_data;
-
-	BUG_ON(!vma_usage_tracker);
-	BUG_ON(0 == vma_usage_tracker->references);
-
-	vma_usage_tracker->references--;
-
-	if (0 != vma_usage_tracker->references)
-	{
-		MALI_DEBUG_PRINT(3, ("Ignoring this close, %d references still exists\n", vma_usage_tracker->references));
-		return;
-	}
-
-	/** @note args->context unused, initialized to 0.
-	 * Instead, we use the memory_session from the cookie */
-
-	descriptor = (mali_memory_allocation *)vma_usage_tracker->cookie;
-
-	args.cookie = (u32)descriptor;
-	args.mapping = descriptor->mapping;
-	args.size = descriptor->size;
-
-	_mali_ukk_mem_munmap( &args );
-
-	/* vma_usage_tracker is free()d by _mali_osk_mem_mapregion_term().
-	 * In the case of the memory engine, it is called as the release function that has been registered with the engine*/
-}
-
+#include "mali_osk.h"
+#include "mali_ukk.h"
 
-void _mali_osk_mem_barrier( void )
+void _mali_osk_mem_barrier(void)
 {
 	mb();
 }
 
-void _mali_osk_write_mem_barrier( void )
+void _mali_osk_write_mem_barrier(void)
 {
 	wmb();
 }
 
-mali_io_address _mali_osk_mem_mapioregion( u32 phys, u32 size, const char *description )
+mali_io_address _mali_osk_mem_mapioregion(u32 phys, u32 size, const char *description)
 {
 	return (mali_io_address)ioremap_nocache(phys, size);
 }
 
-void _mali_osk_mem_unmapioregion( u32 phys, u32 size, mali_io_address virt )
+void _mali_osk_mem_unmapioregion(u32 phys, u32 size, mali_io_address virt)
 {
-	iounmap((void*)virt);
+	iounmap((void *)virt);
 }
 
-mali_io_address _mali_osk_mem_allocioregion( u32 *phys, u32 size )
-{
-	void * virt;
- 	MALI_DEBUG_ASSERT_POINTER( phys );
- 	MALI_DEBUG_ASSERT( 0 == (size & ~_MALI_OSK_CPU_PAGE_MASK) );
- 	MALI_DEBUG_ASSERT( 0 != size );
-
-	/* dma_alloc_* uses a limited region of address space. On most arch/marchs
-	 * 2 to 14 MiB is available. This should be enough for the page tables, which
-	 * currently is the only user of this function. */
-	virt = dma_alloc_coherent(NULL, size, phys, GFP_KERNEL | GFP_DMA );
-
-	MALI_DEBUG_PRINT(3, ("Page table virt: 0x%x = dma_alloc_coherent(size:%d, phys:0x%x, )\n", virt, size, phys));
-
- 	if ( NULL == virt )
- 	{
-		MALI_DEBUG_PRINT(5, ("allocioregion: Failed to allocate Pagetable memory, size=0x%.8X\n", size ));
- 		return 0;
- 	}
-
-	MALI_DEBUG_ASSERT( 0 == (*phys & ~_MALI_OSK_CPU_PAGE_MASK) );
-
- 	return (mali_io_address)virt;
-}
-
-void _mali_osk_mem_freeioregion( u32 phys, u32 size, mali_io_address virt )
-{
- 	MALI_DEBUG_ASSERT_POINTER( (void*)virt );
- 	MALI_DEBUG_ASSERT( 0 != size );
- 	MALI_DEBUG_ASSERT( 0 == (phys & ( (1 << PAGE_SHIFT) - 1 )) );
-
-	dma_free_coherent(NULL, size, virt, phys);
-}
-
-_mali_osk_errcode_t inline _mali_osk_mem_reqregion( u32 phys, u32 size, const char *description )
+_mali_osk_errcode_t inline _mali_osk_mem_reqregion(u32 phys, u32 size, const char *description)
 {
+#if MALI_LICENSE_IS_GPL
+	return _MALI_OSK_ERR_OK; /* GPL driver gets the mem region for the resources registered automatically */
+#else
 	return ((NULL == request_mem_region(phys, size, description)) ? _MALI_OSK_ERR_NOMEM : _MALI_OSK_ERR_OK);
+#endif
 }
 
-void inline _mali_osk_mem_unreqregion( u32 phys, u32 size )
+void inline _mali_osk_mem_unreqregion(u32 phys, u32 size)
 {
+#if !MALI_LICENSE_IS_GPL
 	release_mem_region(phys, size);
+#endif
 }
 
-void inline _mali_osk_mem_iowrite32_relaxed( volatile mali_io_address addr, u32 offset, u32 val )
+void inline _mali_osk_mem_iowrite32_relaxed(volatile mali_io_address addr, u32 offset, u32 val)
 {
-	__raw_writel(cpu_to_le32(val),((u8*)addr) + offset);
+	__raw_writel(cpu_to_le32(val), ((u8 *)addr) + offset);
 }
 
-u32 inline _mali_osk_mem_ioread32( volatile mali_io_address addr, u32 offset )
+u32 inline _mali_osk_mem_ioread32(volatile mali_io_address addr, u32 offset)
 {
-	return ioread32(((u8*)addr) + offset);
+	return ioread32(((u8 *)addr) + offset);
 }
 
-void inline _mali_osk_mem_iowrite32( volatile mali_io_address addr, u32 offset, u32 val )
+void inline _mali_osk_mem_iowrite32(volatile mali_io_address addr, u32 offset, u32 val)
 {
-	iowrite32(val, ((u8*)addr) + offset);
+	iowrite32(val, ((u8 *)addr) + offset);
 }
 
-void _mali_osk_cache_flushall( void )
+void _mali_osk_cache_flushall(void)
 {
 	/** @note Cached memory is not currently supported in this implementation */
 }
 
-void _mali_osk_cache_ensure_uncached_range_flushed( void *uncached_mapping, u32 offset, u32 size )
+void _mali_osk_cache_ensure_uncached_range_flushed(void *uncached_mapping, u32 offset, u32 size)
 {
 	_mali_osk_write_mem_barrier();
 }
 
-_mali_osk_errcode_t _mali_osk_mem_mapregion_init( mali_memory_allocation * descriptor )
-{
-	struct vm_area_struct *vma;
-	mali_vma_usage_tracker * vma_usage_tracker;
-	MappingInfo *mappingInfo;
-
-	if (NULL == descriptor) return _MALI_OSK_ERR_FAULT;
-
-	MALI_DEBUG_ASSERT( 0 != (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE) );
-
-	vma = (struct vm_area_struct*)descriptor->process_addr_mapping_info;
-
-	if (NULL == vma ) return _MALI_OSK_ERR_FAULT;
-
-	/* Re-write the process_addr_mapping_info */
-	mappingInfo = _mali_osk_calloc( 1, sizeof(MappingInfo) );
-
-	if ( NULL == mappingInfo ) return _MALI_OSK_ERR_FAULT;
-
-	vma_usage_tracker = _mali_osk_calloc( 1, sizeof(mali_vma_usage_tracker) );
-
-	if (NULL == vma_usage_tracker)
-	{
-		MALI_DEBUG_PRINT(2, ("Failed to allocate memory to track memory usage\n"));
-		_mali_osk_free( mappingInfo );
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	mappingInfo->vma = vma;
-	descriptor->process_addr_mapping_info = mappingInfo;
-
-	/* Do the va range allocation - in this case, it was done earlier, so we copy in that information */
-	descriptor->mapping = (void __user*)vma->vm_start;
-	/* list member is already NULL */
-
-	/*
-	  set some bits which indicate that:
-	  The memory is IO memory, meaning that no paging is to be performed and the memory should not be included in crash dumps
-	  The memory is reserved, meaning that it's present and can never be paged out (see also previous entry)
-	*/
-	vma->vm_flags |= VM_IO;
-	vma->vm_flags |= VM_RESERVED;
-	vma->vm_flags |= VM_DONTCOPY;
-
-	vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
-	vma->vm_ops = &mali_kernel_vm_ops; /* Operations used on any memory system */
-
-	vma_usage_tracker->references = 1; /* set initial reference count to be 1 as vma_open won't be called for the first mmap call */
-	vma_usage_tracker->cookie = (u32)descriptor; /* cookie for munmap */
-
-	vma->vm_private_data = vma_usage_tracker;
-
-	return _MALI_OSK_ERR_OK;
-}
-
-void _mali_osk_mem_mapregion_term( mali_memory_allocation * descriptor )
-{
-	struct vm_area_struct* vma;
-	mali_vma_usage_tracker * vma_usage_tracker;
-	MappingInfo *mappingInfo;
-
-	if (NULL == descriptor) return;
-
-	MALI_DEBUG_ASSERT( 0 != (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE) );
-
-	mappingInfo = (MappingInfo *)descriptor->process_addr_mapping_info;
-
-	MALI_DEBUG_ASSERT_POINTER( mappingInfo );
-
-	/* Linux does the right thing as part of munmap to remove the mapping
-	 * All that remains is that we remove the vma_usage_tracker setup in init() */
-	vma = mappingInfo->vma;
-
-	MALI_DEBUG_ASSERT_POINTER( vma );
-
-	/* ASSERT that there are no allocations on the list. Unmap should've been
-	 * called on all OS allocations. */
-	MALI_DEBUG_ASSERT( NULL == mappingInfo->list );
-
-	vma_usage_tracker = vma->vm_private_data;
-
-	/* We only get called if mem_mapregion_init succeeded */
-	_mali_osk_free(vma_usage_tracker);
-
-	_mali_osk_free( mappingInfo );
-	return;
-}
-
-_mali_osk_errcode_t _mali_osk_mem_mapregion_map( mali_memory_allocation * descriptor, u32 offset, u32 *phys_addr, u32 size )
+u32 _mali_osk_mem_write_safe(void *dest, const void *src, u32 size)
 {
-	struct vm_area_struct *vma;
-	MappingInfo *mappingInfo;
-
-	if (NULL == descriptor) return _MALI_OSK_ERR_FAULT;
-
-	MALI_DEBUG_ASSERT_POINTER( phys_addr );
-
-	MALI_DEBUG_ASSERT( 0 != (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE) );
-
-	MALI_DEBUG_ASSERT( 0 == (size & ~_MALI_OSK_CPU_PAGE_MASK) );
+#define MALI_MEM_SAFE_COPY_BLOCK_SIZE 4096
+	u32 retval = 0;
+	void *temp_buf;
 
-	MALI_DEBUG_ASSERT( 0 == (offset & ~_MALI_OSK_CPU_PAGE_MASK));
+	temp_buf = kmalloc(MALI_MEM_SAFE_COPY_BLOCK_SIZE, GFP_KERNEL);
+	if (NULL != temp_buf) {
+		u32 bytes_left_to_copy = size;
+		u32 i;
+		for (i = 0; i < size; i += MALI_MEM_SAFE_COPY_BLOCK_SIZE) {
+			u32 size_to_copy;
+			u32 size_copied;
+			u32 bytes_left;
 
-	if (NULL == descriptor->mapping) return _MALI_OSK_ERR_INVALID_ARGS;
-
-	if (size > (descriptor->size - offset))
-	{
-		MALI_DEBUG_PRINT(1,("_mali_osk_mem_mapregion_map: virtual memory area not large enough to map physical 0x%x size %x into area 0x%x at offset 0x%xr\n",
-		                    *phys_addr, size, descriptor->mapping, offset));
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	mappingInfo = (MappingInfo *)descriptor->process_addr_mapping_info;
-
-	MALI_DEBUG_ASSERT_POINTER( mappingInfo );
-
-	vma = mappingInfo->vma;
-
-	if (NULL == vma ) return _MALI_OSK_ERR_FAULT;
-
-	MALI_DEBUG_PRINT(7, ("Process map: mapping 0x%08X to process address 0x%08lX length 0x%08X\n", *phys_addr, (long unsigned int)(descriptor->mapping + offset), size));
+			if (bytes_left_to_copy > MALI_MEM_SAFE_COPY_BLOCK_SIZE) {
+				size_to_copy = MALI_MEM_SAFE_COPY_BLOCK_SIZE;
+			} else {
+				size_to_copy = bytes_left_to_copy;
+			}
 
-	if ( MALI_MEMORY_ALLOCATION_OS_ALLOCATED_PHYSADDR_MAGIC == *phys_addr )
-	{
-		_mali_osk_errcode_t ret;
-		AllocationList *alloc_item;
-		u32 linux_phys_frame_num;
+			bytes_left = copy_from_user(temp_buf, ((char *)src) + i, size_to_copy);
+			size_copied = size_to_copy - bytes_left;
 
-		alloc_item = _allocation_list_item_get();
-		if (NULL == alloc_item)
-		{
-			MALI_DEBUG_PRINT(1, ("Failed to allocate list item\n"));
-			return _MALI_OSK_ERR_NOMEM;
-		}
+			bytes_left = copy_to_user(((char *)dest) + i, temp_buf, size_copied);
+			size_copied -= bytes_left;
 
-		linux_phys_frame_num = alloc_item->physaddr >> PAGE_SHIFT;
+			bytes_left_to_copy -= size_copied;
+			retval += size_copied;
 
-		ret = ( remap_pfn_range( vma, ((u32)descriptor->mapping) + offset, linux_phys_frame_num, size, vma->vm_page_prot) ) ? _MALI_OSK_ERR_FAULT : _MALI_OSK_ERR_OK;
-
-		if ( ret != _MALI_OSK_ERR_OK)
-		{
-			_allocation_list_item_release(alloc_item);
-			return ret;
+			if (size_copied != size_to_copy) {
+				break; /* Early out, we was not able to copy this entire block */
+			}
 		}
 
-		/* Put our alloc_item into the list of allocations on success */
-		alloc_item->next = mappingInfo->list;
-		alloc_item->offset = offset;
-
-		/*alloc_item->physaddr = linux_phys_addr;*/
-		mappingInfo->list = alloc_item;
-
-		/* Write out new physical address on success */
-		*phys_addr = alloc_item->physaddr;
-
-		return ret;
+		kfree(temp_buf);
 	}
 
-	/* Otherwise, Use the supplied physical address */
-
-	/* ASSERT that supplied phys_addr is page aligned */
-	MALI_DEBUG_ASSERT( 0 == ((*phys_addr) & ~_MALI_OSK_CPU_PAGE_MASK) );
-
-	return ( remap_pfn_range( vma, ((u32)descriptor->mapping) + offset, *phys_addr >> PAGE_SHIFT, size, vma->vm_page_prot) ) ? _MALI_OSK_ERR_FAULT : _MALI_OSK_ERR_OK;
-
+	return retval;
 }
 
-void _mali_osk_mem_mapregion_unmap( mali_memory_allocation * descriptor, u32 offset, u32 size, _mali_osk_mem_mapregion_flags_t flags )
+_mali_osk_errcode_t _mali_ukk_mem_write_safe(_mali_uk_mem_write_safe_s *args)
 {
-	MappingInfo *mappingInfo;
-
-   if (NULL == descriptor) return;
-
-	MALI_DEBUG_ASSERT( 0 != (descriptor->flags & MALI_MEMORY_ALLOCATION_FLAG_MAP_INTO_USERSPACE) );
-
-	MALI_DEBUG_ASSERT( 0 == (size & ~_MALI_OSK_CPU_PAGE_MASK) );
-
-	MALI_DEBUG_ASSERT( 0 == (offset & ~_MALI_OSK_CPU_PAGE_MASK) );
-
-	if (NULL == descriptor->mapping) return;
+	MALI_DEBUG_ASSERT_POINTER(args);
 
-	if (size > (descriptor->size - offset))
-	{
-		MALI_DEBUG_PRINT(1,("_mali_osk_mem_mapregion_unmap: virtual memory area not large enough to unmap size %x from area 0x%x at offset 0x%x\n",
-							size, descriptor->mapping, offset));
-		return;
+	if (NULL == args->ctx) {
+		return _MALI_OSK_ERR_INVALID_ARGS;
 	}
-	mappingInfo = (MappingInfo *)descriptor->process_addr_mapping_info;
 
-	MALI_DEBUG_ASSERT_POINTER( mappingInfo );
-
-	if ( 0 != (flags & _MALI_OSK_MEM_MAPREGION_FLAG_OS_ALLOCATED_PHYSADDR) )
-	{
-		/* This physical RAM was allocated in _mali_osk_mem_mapregion_map and
-		 * so needs to be unmapped
-		 */
-		while (size)
-		{
-			/* First find the allocation in the list of allocations */
-			AllocationList *alloc = mappingInfo->list;
-			AllocationList **prev = &(mappingInfo->list);
-			while (NULL != alloc && alloc->offset != offset)
-			{
-				prev = &(alloc->next);
-				alloc = alloc->next;
-			}
-			if (alloc == NULL) {
-				MALI_DEBUG_PRINT(1, ("Unmapping memory that isn't mapped\n"));
-				size -= _MALI_OSK_CPU_PAGE_SIZE;
-				offset += _MALI_OSK_CPU_PAGE_SIZE;
-				continue;
-			}
-
-			_kernel_page_release(alloc->physaddr);
-
-			/* Remove the allocation from the list */
-			*prev = alloc->next;
-			_mali_osk_free( alloc );
-
-			/* Move onto the next allocation */
-			size -= _MALI_OSK_CPU_PAGE_SIZE;
-			offset += _MALI_OSK_CPU_PAGE_SIZE;
-		}
-	}
-
-	/* Linux does the right thing as part of munmap to remove the mapping */
-
-	return;
+	/* Return number of bytes actually copied */
+	args->size = _mali_osk_mem_write_safe(args->dest, args->src, args->size);
+	return _MALI_OSK_ERR_OK;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_mali.c b/drivers/gpu/mali/mali/linux/mali_osk_mali.c
old mode 100644
new mode 100755
index 442dd2c..659b64a
--- a/drivers/gpu/mali/mali/linux/mali_osk_mali.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_mali.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,20 +14,105 @@
  */
 #include <linux/kernel.h>
 #include <asm/uaccess.h>
+#include <linux/platform_device.h>
+#include <linux/mali/mali_utgard.h>
 
+#include "mali_osk_mali.h"
 #include "mali_kernel_common.h" /* MALI_xxx macros */
 #include "mali_osk.h"           /* kernel side OS functions */
-#include "mali_uk_types.h"
-#include "config.h"        /* contains the configuration of the arch we are compiling for */
+#include "mali_kernel_linux.h"
 
-_mali_osk_errcode_t _mali_osk_resources_init( _mali_osk_resource_t **arch_config, u32 *num_resources )
+_mali_osk_errcode_t _mali_osk_resource_find(u32 addr, _mali_osk_resource_t *res)
 {
-    *num_resources = sizeof(arch_configuration) / sizeof(arch_configuration[0]);
-    *arch_config = arch_configuration;
-    return _MALI_OSK_ERR_OK;
+	int i;
+
+	if (NULL == mali_platform_device) {
+		/* Not connected to a device */
+		return _MALI_OSK_ERR_ITEM_NOT_FOUND;
+	}
+
+	for (i = 0; i < mali_platform_device->num_resources; i++) {
+		if (IORESOURCE_MEM == resource_type(&(mali_platform_device->resource[i])) &&
+		    mali_platform_device->resource[i].start == addr) {
+			if (NULL != res) {
+				res->base = addr;
+				res->description = mali_platform_device->resource[i].name;
+
+				/* Any (optional) IRQ resource belonging to this resource will follow */
+				if ((i + 1) < mali_platform_device->num_resources &&
+				    IORESOURCE_IRQ == resource_type(&(mali_platform_device->resource[i + 1]))) {
+					res->irq = mali_platform_device->resource[i + 1].start;
+				} else {
+					res->irq = -1;
+				}
+			}
+			return _MALI_OSK_ERR_OK;
+		}
+	}
+
+	return _MALI_OSK_ERR_ITEM_NOT_FOUND;
 }
 
-void _mali_osk_resources_term( _mali_osk_resource_t **arch_config, u32 num_resources )
+u32 _mali_osk_resource_base_address(void)
 {
-    /* Nothing to do */
+	u32 lowest_addr = 0xFFFFFFFF;
+	u32 ret = 0;
+
+	if (NULL != mali_platform_device) {
+		int i;
+		for (i = 0; i < mali_platform_device->num_resources; i++) {
+			if (mali_platform_device->resource[i].flags & IORESOURCE_MEM &&
+			    mali_platform_device->resource[i].start < lowest_addr) {
+				lowest_addr = mali_platform_device->resource[i].start;
+				ret = lowest_addr;
+			}
+		}
+	}
+
+	return ret;
+}
+
+_mali_osk_errcode_t _mali_osk_device_data_get(_mali_osk_device_data *data)
+{
+	MALI_DEBUG_ASSERT_POINTER(data);
+
+	if (NULL != mali_platform_device) {
+		struct mali_gpu_device_data *os_data = NULL;
+
+		os_data = (struct mali_gpu_device_data *)mali_platform_device->dev.platform_data;
+		if (NULL != os_data) {
+			/* Copy data from OS dependant struct to Mali neutral struct (identical!) */
+			BUILD_BUG_ON(sizeof(*os_data) != sizeof(*data));
+			_mali_osk_memcpy(data, os_data, sizeof(*os_data));
+
+			return _MALI_OSK_ERR_OK;
+		}
+	}
+
+	return _MALI_OSK_ERR_ITEM_NOT_FOUND;
+}
+
+mali_bool _mali_osk_shared_interrupts(void)
+{
+	u32 irqs[128];
+	u32 i, j, irq, num_irqs_found = 0;
+
+	MALI_DEBUG_ASSERT_POINTER(mali_platform_device);
+	MALI_DEBUG_ASSERT(128 >= mali_platform_device->num_resources);
+
+	for (i = 0; i < mali_platform_device->num_resources; i++) {
+		if (IORESOURCE_IRQ & mali_platform_device->resource[i].flags) {
+			irq = mali_platform_device->resource[i].start;
+
+			for (j = 0; j < num_irqs_found; ++j) {
+				if (irq == irqs[j]) {
+					return MALI_TRUE;
+				}
+			}
+
+			irqs[num_irqs_found++] = irq;
+		}
+	}
+
+	return MALI_FALSE;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_math.c b/drivers/gpu/mali/mali/linux/mali_osk_math.c
old mode 100644
new mode 100755
index b81fa83..02741b0
--- a/drivers/gpu/mali/mali/linux/mali_osk_math.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_math.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,7 +16,12 @@
 #include "mali_osk.h"
 #include <linux/bitops.h>
 
-u32 inline _mali_osk_clz( u32 input )
+u32 _mali_osk_clz(u32 input)
 {
-	return 32-fls(input);
+	return 32 - fls(input);
+}
+
+u32 _mali_osk_fls(u32 input)
+{
+	return fls(input);
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_memory.c b/drivers/gpu/mali/mali/linux/mali_osk_memory.c
old mode 100644
new mode 100755
index e83e676..27dea0e
--- a/drivers/gpu/mali/mali/linux/mali_osk_memory.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_memory.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,42 +17,42 @@
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 
-void inline *_mali_osk_calloc( u32 n, u32 size )
+void inline *_mali_osk_calloc(u32 n, u32 size)
 {
-    return kcalloc(n, size, GFP_KERNEL);
+	return kcalloc(n, size, GFP_KERNEL);
 }
 
-void inline *_mali_osk_malloc( u32 size )
+void inline *_mali_osk_malloc(u32 size)
 {
-    return kmalloc(size, GFP_KERNEL);
+	return kmalloc(size, GFP_KERNEL);
 }
 
-void inline _mali_osk_free( void *ptr )
+void inline _mali_osk_free(void *ptr)
 {
-    kfree(ptr);
+	kfree(ptr);
 }
 
-void inline *_mali_osk_valloc( u32 size )
+void inline *_mali_osk_valloc(u32 size)
 {
-    return vmalloc(size);
+	return vmalloc(size);
 }
 
-void inline _mali_osk_vfree( void *ptr )
+void inline _mali_osk_vfree(void *ptr)
 {
-    vfree(ptr);
+	vfree(ptr);
 }
 
-void inline *_mali_osk_memcpy( void *dst, const void *src, u32	len )
+void inline *_mali_osk_memcpy(void *dst, const void *src, u32  len)
 {
-    return memcpy(dst, src, len);
+	return memcpy(dst, src, len);
 }
 
-void inline *_mali_osk_memset( void *s, u32 c, u32 n )
+void inline *_mali_osk_memset(void *s, u32 c, u32 n)
 {
-    return memset(s, c, n);
+	return memset(s, c, n);
 }
 
-mali_bool _mali_osk_mem_check_allocated( u32 max_allocated )
+mali_bool _mali_osk_mem_check_allocated(u32 max_allocated)
 {
 	/* No need to prevent an out-of-memory dialogue appearing on Linux,
 	 * so we always return MALI_TRUE.
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_misc.c b/drivers/gpu/mali/mali/linux/mali_osk_misc.c
old mode 100644
new mode 100755
index e31aee8..6e104ad
--- a/drivers/gpu/mali/mali/linux/mali_osk_misc.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_misc.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -19,15 +19,17 @@
 #include <linux/module.h>
 #include "mali_osk.h"
 
-void _mali_osk_dbgmsg( const char *fmt, ... )
+#if !defined(CONFIG_MALI_QUIET)
+void _mali_osk_dbgmsg(const char *fmt, ...)
 {
-    va_list args;
-    va_start(args, fmt);
-    vprintk(fmt, args);
+	va_list args;
+	va_start(args, fmt);
+	vprintk(fmt, args);
 	va_end(args);
 }
+#endif /* !defined(CONFIG_MALI_QUIET) */
 
-u32 _mali_osk_snprintf( char *buf, u32 size, const char *fmt, ... )
+u32 _mali_osk_snprintf(char *buf, u32 size, const char *fmt, ...)
 {
 	int res;
 	va_list args;
@@ -60,5 +62,13 @@ u32 _mali_osk_get_pid(void)
 u32 _mali_osk_get_tid(void)
 {
 	/* pid is actually identifying the thread on Linux */
-	return (u32)current->pid;
+	u32 tid = current->pid;
+
+	/* If the pid is 0 the core was idle.  Instead of returning 0 we return a special number
+	 * identifying which core we are on. */
+	if (0 == tid) {
+		tid = -(1 + raw_smp_processor_id());
+	}
+
+	return tid;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_notification.c b/drivers/gpu/mali/mali/linux/mali_osk_notification.c
old mode 100644
new mode 100755
index 951cba8..8a1e786
--- a/drivers/gpu/mali/mali/linux/mali_osk_notification.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_notification.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,16 +16,9 @@
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
 
-/* needed to detect kernel version specific code */
-#include <linux/version.h>
-
 #include <linux/sched.h>
 #include <linux/slab.h>
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-#include <linux/semaphore.h>
-#else /* pre 2.6.26 the file was in the arch specific location */
-#include <asm/semaphore.h>
-#endif
+#include <linux/spinlock.h>
 
 /**
  * Declaration of the notification queue object type
@@ -33,55 +26,49 @@
  * It also contains a wait queue of exclusive waiters blocked in the ioctl
  * When a new notification is posted a single thread is resumed.
  */
-struct _mali_osk_notification_queue_t_struct
-{
-	struct semaphore mutex; /**< Mutex protecting the list */
+struct _mali_osk_notification_queue_t_struct {
+	spinlock_t mutex; /**< Mutex protecting the list */
 	wait_queue_head_t receive_queue; /**< Threads waiting for new entries to the queue */
 	struct list_head head; /**< List of notifications waiting to be picked up */
 };
 
-typedef struct _mali_osk_notification_wrapper_t_struct
-{
-    struct list_head list;           /**< Internal linked list variable */
-    _mali_osk_notification_t data;   /**< Notification data */
+typedef struct _mali_osk_notification_wrapper_t_struct {
+	struct list_head list;           /**< Internal linked list variable */
+	_mali_osk_notification_t data;   /**< Notification data */
 } _mali_osk_notification_wrapper_t;
 
-_mali_osk_notification_queue_t *_mali_osk_notification_queue_init( void )
+_mali_osk_notification_queue_t *_mali_osk_notification_queue_init(void)
 {
-	_mali_osk_notification_queue_t *	result;
+	_mali_osk_notification_queue_t         *result;
 
 	result = (_mali_osk_notification_queue_t *)kmalloc(sizeof(_mali_osk_notification_queue_t), GFP_KERNEL);
 	if (NULL == result) return NULL;
 
-	sema_init(&result->mutex, 1);
+	spin_lock_init(&result->mutex);
 	init_waitqueue_head(&result->receive_queue);
 	INIT_LIST_HEAD(&result->head);
 
 	return result;
 }
 
-_mali_osk_notification_t *_mali_osk_notification_create( u32 type, u32 size )
+_mali_osk_notification_t *_mali_osk_notification_create(u32 type, u32 size)
 {
 	/* OPT Recycling of notification objects */
-    _mali_osk_notification_wrapper_t *notification;
+	_mali_osk_notification_wrapper_t *notification;
 
-	notification = (_mali_osk_notification_wrapper_t *)kmalloc( sizeof(_mali_osk_notification_wrapper_t) + size,
-	                                                            GFP_KERNEL | __GFP_HIGH | __GFP_REPEAT);
-    if (NULL == notification)
-    {
+	notification = (_mali_osk_notification_wrapper_t *)kmalloc(sizeof(_mali_osk_notification_wrapper_t) + size,
+			GFP_KERNEL | __GFP_HIGH | __GFP_REPEAT);
+	if (NULL == notification) {
 		MALI_DEBUG_PRINT(1, ("Failed to create a notification object\n"));
 		return NULL;
-    }
+	}
 
 	/* Init the list */
 	INIT_LIST_HEAD(&notification->list);
 
-	if (0 != size)
-	{
-		notification->data.result_buffer = ((u8*)notification) + sizeof(_mali_osk_notification_wrapper_t);
-	}
-	else
-	{
+	if (0 != size) {
+		notification->data.result_buffer = ((u8 *)notification) + sizeof(_mali_osk_notification_wrapper_t);
+	} else {
 		notification->data.result_buffer = NULL;
 	}
 
@@ -90,99 +77,105 @@ _mali_osk_notification_t *_mali_osk_notification_create( u32 type, u32 size )
 	notification->data.result_buffer_size = size;
 
 	/* all ok */
-    return &(notification->data);
+	return &(notification->data);
 }
 
-void _mali_osk_notification_delete( _mali_osk_notification_t *object )
+void _mali_osk_notification_delete(_mali_osk_notification_t *object)
 {
 	_mali_osk_notification_wrapper_t *notification;
-	MALI_DEBUG_ASSERT_POINTER( object );
+	MALI_DEBUG_ASSERT_POINTER(object);
 
-    notification = container_of( object, _mali_osk_notification_wrapper_t, data );
+	notification = container_of(object, _mali_osk_notification_wrapper_t, data);
 
 	/* Free the container */
 	kfree(notification);
 }
 
-void _mali_osk_notification_queue_term( _mali_osk_notification_queue_t *queue )
+void _mali_osk_notification_queue_term(_mali_osk_notification_queue_t *queue)
 {
-	MALI_DEBUG_ASSERT_POINTER( queue );
+	_mali_osk_notification_t *result;
+	MALI_DEBUG_ASSERT_POINTER(queue);
+
+	while (_MALI_OSK_ERR_OK == _mali_osk_notification_queue_dequeue(queue, &result)) {
+		_mali_osk_notification_delete(result);
+	}
 
 	/* not much to do, just free the memory */
 	kfree(queue);
 }
-
-void _mali_osk_notification_queue_send( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t *object )
+void _mali_osk_notification_queue_send(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t *object)
 {
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	unsigned long irq_flags;
+#endif
+
 	_mali_osk_notification_wrapper_t *notification;
-	MALI_DEBUG_ASSERT_POINTER( queue );
-	MALI_DEBUG_ASSERT_POINTER( object );
+	MALI_DEBUG_ASSERT_POINTER(queue);
+	MALI_DEBUG_ASSERT_POINTER(object);
 
-    notification = container_of( object, _mali_osk_notification_wrapper_t, data );
+	notification = container_of(object, _mali_osk_notification_wrapper_t, data);
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	spin_lock_irqsave(&queue->mutex, irq_flags);
+#else
+	spin_lock(&queue->mutex);
+#endif
 
-	/* lock queue access */
-	down(&queue->mutex);
-	/* add to list */
 	list_add_tail(&notification->list, &queue->head);
-	/* unlock the queue */
-	up(&queue->mutex);
+
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	spin_unlock_irqrestore(&queue->mutex, irq_flags);
+#else
+	spin_unlock(&queue->mutex);
+#endif
 
 	/* and wake up one possible exclusive waiter */
 	wake_up(&queue->receive_queue);
 }
 
-static int _mali_notification_queue_is_empty( _mali_osk_notification_queue_t *queue )
-{
-	int ret;
-
-	down(&queue->mutex);
-	ret = list_empty(&queue->head);
-	up(&queue->mutex);
-	return ret;
-}
-
-#if MALI_STATE_TRACKING
-mali_bool _mali_osk_notification_queue_is_empty( _mali_osk_notification_queue_t *queue )
+_mali_osk_errcode_t _mali_osk_notification_queue_dequeue(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result)
 {
-	return _mali_notification_queue_is_empty(queue) ? MALI_TRUE : MALI_FALSE;
-}
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	unsigned long irq_flags;
 #endif
 
-_mali_osk_errcode_t _mali_osk_notification_queue_dequeue( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result )
-{
 	_mali_osk_errcode_t ret = _MALI_OSK_ERR_ITEM_NOT_FOUND;
 	_mali_osk_notification_wrapper_t *wrapper_object;
 
-	down(&queue->mutex);
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	spin_lock_irqsave(&queue->mutex, irq_flags);
+#else
+	spin_lock(&queue->mutex);
+#endif
 
-	if (!list_empty(&queue->head))
-	{
+	if (!list_empty(&queue->head)) {
 		wrapper_object = list_entry(queue->head.next, _mali_osk_notification_wrapper_t, list);
 		*result = &(wrapper_object->data);
 		list_del_init(&wrapper_object->list);
 		ret = _MALI_OSK_ERR_OK;
 	}
 
-	up(&queue->mutex);
+#if defined(MALI_UPPER_HALF_SCHEDULING)
+	spin_unlock_irqrestore(&queue->mutex, irq_flags);
+#else
+	spin_unlock(&queue->mutex);
+#endif
 
 	return ret;
 }
 
-_mali_osk_errcode_t _mali_osk_notification_queue_receive( _mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result )
+_mali_osk_errcode_t _mali_osk_notification_queue_receive(_mali_osk_notification_queue_t *queue, _mali_osk_notification_t **result)
 {
-    /* check input */
-	MALI_DEBUG_ASSERT_POINTER( queue );
-	MALI_DEBUG_ASSERT_POINTER( result );
+	/* check input */
+	MALI_DEBUG_ASSERT_POINTER(queue);
+	MALI_DEBUG_ASSERT_POINTER(result);
 
-    /* default result */
+	/* default result */
 	*result = NULL;
 
-	while (_MALI_OSK_ERR_OK != _mali_osk_notification_queue_dequeue(queue, result))
-	{
-		if (wait_event_interruptible(queue->receive_queue, !_mali_notification_queue_is_empty(queue)))
-		{
-			return _MALI_OSK_ERR_RESTARTSYSCALL;
-		}
+	if (wait_event_interruptible(queue->receive_queue,
+				     _MALI_OSK_ERR_OK == _mali_osk_notification_queue_dequeue(queue, result))) {
+		return _MALI_OSK_ERR_RESTARTSYSCALL;
 	}
 
 	return _MALI_OSK_ERR_OK; /* all ok */
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_pm.c b/drivers/gpu/mali/mali/linux/mali_osk_pm.c
old mode 100644
new mode 100755
index 088adad..a65cde1
--- a/drivers/gpu/mali/mali/linux/mali_osk_pm.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_pm.c
@@ -1,9 +1,9 @@
 /**
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -19,65 +19,91 @@
 #include <linux/pm_runtime.h>
 #endif /* CONFIG_PM_RUNTIME */
 #include <linux/platform_device.h>
-#include "mali_platform.h"
+#include <linux/version.h>
 #include "mali_osk.h"
-#include "mali_uk_types.h"
 #include "mali_kernel_common.h"
-#include "mali_kernel_license.h"
-#include "mali_linux_pm.h"
-#include "mali_kernel_license.h"
+#include "mali_kernel_linux.h"
 
-#if ! MALI_LICENSE_IS_GPL
-#undef CONFIG_PM_RUNTIME
-#endif
+static _mali_osk_atomic_t mali_pm_ref_count;
+
+void _mali_osk_pm_dev_enable(void)
+{
+	_mali_osk_atomic_init(&mali_pm_ref_count, 0);
+}
+
+void _mali_osk_pm_dev_disable(void)
+{
+	_mali_osk_atomic_term(&mali_pm_ref_count);
+}
 
-extern struct platform_device mali_gpu_device;
+/* Can NOT run in atomic context */
+_mali_osk_errcode_t _mali_osk_pm_dev_ref_add(void)
+{
+#ifdef CONFIG_PM_RUNTIME
+	int err;
+	MALI_DEBUG_ASSERT_POINTER(mali_platform_device);
+	err = pm_runtime_get_sync(&(mali_platform_device->dev));
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 37))
+	pm_runtime_mark_last_busy(&(mali_platform_device->dev));
+#endif
+	if (0 > err) {
+		MALI_PRINT_ERROR(("Mali OSK PM: pm_runtime_get_sync() returned error code %d\n", err));
+		return _MALI_OSK_ERR_FAULT;
+	}
+	_mali_osk_atomic_inc(&mali_pm_ref_count);
+	MALI_DEBUG_PRINT(4, ("Mali OSK PM: Power ref taken (%u)\n", _mali_osk_atomic_read(&mali_pm_ref_count)));
+#endif
+	return _MALI_OSK_ERR_OK;
+}
 
+/* Can run in atomic context */
+void _mali_osk_pm_dev_ref_dec(void)
+{
 #ifdef CONFIG_PM_RUNTIME
-static mali_bool have_runtime_reference = MALI_FALSE;
+	MALI_DEBUG_ASSERT_POINTER(mali_platform_device);
+	_mali_osk_atomic_dec(&mali_pm_ref_count);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 37))
+	pm_runtime_mark_last_busy(&(mali_platform_device->dev));
+	pm_runtime_put_autosuspend(&(mali_platform_device->dev));
+#else
+	pm_runtime_put(&(mali_platform_device->dev));
+#endif
+	MALI_DEBUG_PRINT(4, ("Mali OSK PM: Power ref released (%u)\n", _mali_osk_atomic_read(&mali_pm_ref_count)));
 #endif
+}
 
-void _mali_osk_pm_dev_enable(void)
+/* Can run in atomic context */
+mali_bool _mali_osk_pm_dev_ref_add_no_power_on(void)
 {
 #ifdef CONFIG_PM_RUNTIME
-	pm_runtime_enable(&(mali_gpu_device.dev));
+	u32 ref;
+	MALI_DEBUG_ASSERT_POINTER(mali_platform_device);
+	pm_runtime_get_noresume(&(mali_platform_device->dev));
+	ref = _mali_osk_atomic_read(&mali_pm_ref_count);
+	MALI_DEBUG_PRINT(4, ("Mali OSK PM: No-power ref taken (%u)\n", _mali_osk_atomic_read(&mali_pm_ref_count)));
+	return ref > 0 ? MALI_TRUE : MALI_FALSE;
+#else
+	return MALI_TRUE;
 #endif
 }
 
-/* NB: Function is not thread safe */
-_mali_osk_errcode_t _mali_osk_pm_dev_idle(void)
+/* Can run in atomic context */
+void _mali_osk_pm_dev_ref_dec_no_power_on(void)
 {
 #ifdef CONFIG_PM_RUNTIME
-	if (MALI_TRUE == have_runtime_reference)
-	{
-		int err;
-		err = pm_runtime_put_sync(&(mali_gpu_device.dev));
-		if (0 > err)
-		{
-			MALI_PRINT_ERROR(("OSK PM: pm_runtime_put_sync() returned error code %d\n", err));
-			return _MALI_OSK_ERR_FAULT;
-		}
-		have_runtime_reference = MALI_FALSE;
-	}
+	MALI_DEBUG_ASSERT_POINTER(mali_platform_device);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 37))
+	pm_runtime_put_autosuspend(&(mali_platform_device->dev));
+#else
+	pm_runtime_put(&(mali_platform_device->dev));
+#endif
+	MALI_DEBUG_PRINT(4, ("Mali OSK PM: No-power ref released (%u)\n", _mali_osk_atomic_read(&mali_pm_ref_count)));
 #endif
-	return _MALI_OSK_ERR_OK;
 }
 
-/* NB: Function is not thread safe */
-_mali_osk_errcode_t _mali_osk_pm_dev_activate(void)
+void _mali_osk_pm_dev_barrier(void)
 {
 #ifdef CONFIG_PM_RUNTIME
-	if (MALI_TRUE != have_runtime_reference)
-	{
-		int err;
-		err = pm_runtime_get_sync(&(mali_gpu_device.dev));
-		if (0 > err)
-		{
-			MALI_PRINT_ERROR(("OSK PM: pm_runtime_get_sync() returned error code %d\n", err));
-			return _MALI_OSK_ERR_FAULT;
-		}
-		have_runtime_reference = MALI_TRUE;
-	}
+	pm_runtime_barrier(&(mali_platform_device->dev));
 #endif
-	return _MALI_OSK_ERR_OK;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_profiling_gator.c b/drivers/gpu/mali/mali/linux/mali_osk_profiling_gator.c
deleted file mode 100644
index b2e1149..0000000
--- a/drivers/gpu/mali/mali/linux/mali_osk_profiling_gator.c
+++ /dev/null
@@ -1,261 +0,0 @@
-/*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include <linux/module.h>
-
-#include "mali_kernel_common.h"
-#include "mali_osk.h"
-#include "mali_ukk.h"
-#include "mali_uk_types.h"
-#include "mali_osk_profiling.h"
-#include "mali_linux_trace.h"
-#include "mali_gp.h"
-#include "mali_pp.h"
-#include "mali_l2_cache.h"
-#include "mali_user_settings_db.h"
-
-_mali_osk_errcode_t _mali_osk_profiling_init(mali_bool auto_start)
-{
-	if (MALI_TRUE == auto_start)
-	{
-		mali_set_user_setting(_MALI_UK_USER_SETTING_SW_EVENTS_ENABLE, MALI_TRUE);
-	}
-
-	return _MALI_OSK_ERR_OK;
-}
-
-void _mali_osk_profiling_term(void)
-{
-	/* Nothing to do */
-}
-
-_mali_osk_errcode_t _mali_osk_profiling_start(u32 * limit)
-{
-	/* Nothing to do */
-	return _MALI_OSK_ERR_OK;
-}
-
-_mali_osk_errcode_t _mali_osk_profiling_stop(u32 *count)
-{
-	/* Nothing to do */
-	return _MALI_OSK_ERR_OK;
-}
-
-u32 _mali_osk_profiling_get_count(void)
-{
-	return 0;
-}
-
-_mali_osk_errcode_t _mali_osk_profiling_get_event(u32 index, u64* timestamp, u32* event_id, u32 data[5])
-{
-	/* Nothing to do */
-	return _MALI_OSK_ERR_OK;
-}
-
-_mali_osk_errcode_t _mali_osk_profiling_clear(void)
-{
-	/* Nothing to do */
-	return _MALI_OSK_ERR_OK;
-}
-
-mali_bool _mali_osk_profiling_is_recording(void)
-{
-	return MALI_FALSE;
-}
-
-mali_bool _mali_osk_profiling_have_recording(void)
-{
-	return MALI_FALSE;
-}
-
-void _mali_osk_profiling_report_sw_counters(u32 *counters)
-{
-	trace_mali_sw_counters(_mali_osk_get_pid(), _mali_osk_get_tid(), NULL, counters);
-}
-
-
-_mali_osk_errcode_t _mali_ukk_profiling_start(_mali_uk_profiling_start_s *args)
-{
-	return _mali_osk_profiling_start(&args->limit);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_add_event(_mali_uk_profiling_add_event_s *args)
-{
-	/* Always add process and thread identificator in the first two data elements for events from user space */
-	_mali_osk_profiling_add_event(args->event_id, _mali_osk_get_pid(), _mali_osk_get_tid(), args->data[2], args->data[3], args->data[4]);
-
-	return _MALI_OSK_ERR_OK;
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_stop(_mali_uk_profiling_stop_s *args)
-{
-	return _mali_osk_profiling_stop(&args->count);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_get_event(_mali_uk_profiling_get_event_s *args)
-{
-	return _mali_osk_profiling_get_event(args->index, &args->timestamp, &args->event_id, args->data);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_clear(_mali_uk_profiling_clear_s *args)
-{
-	return _mali_osk_profiling_clear();
-}
-
-_mali_osk_errcode_t _mali_ukk_sw_counters_report(_mali_uk_sw_counters_report_s *args)
-{
-	_mali_osk_profiling_report_sw_counters(args->counters);
-	return _MALI_OSK_ERR_OK;
-}
-
-/**
- * Called by gator.ko to set HW counters
- *
- * @param counter_id The counter ID.
- * @param event_id Event ID that the counter should count (HW counter value from TRM).
- *
- * @return 1 on success, 0 on failure.
- */
-int _mali_profiling_set_event(u32 counter_id, s32 event_id)
-{
-
-	if (counter_id == COUNTER_VP_C0)
-	{
-		struct mali_gp_core* gp_core = mali_gp_get_global_gp_core();
-		if (NULL != gp_core)
-		{
-			if (MALI_TRUE == mali_gp_core_set_counter_src0(gp_core, event_id))
-			{
-				return 1;
-			}
-		}
-	}
-	else if (counter_id == COUNTER_VP_C1)
-	{
-		struct mali_gp_core* gp_core = mali_gp_get_global_gp_core();
-		if (NULL != gp_core)
-		{
-			if (MALI_TRUE == mali_gp_core_set_counter_src1(gp_core, event_id))
-			{
-				return 1;
-			}
-		}
-	}
-	else if (counter_id >= COUNTER_FP0_C0 && counter_id <= COUNTER_FP3_C1)
-	{
-		u32 core_id = (counter_id - COUNTER_FP0_C0) >> 1;
-		struct mali_pp_core* pp_core = mali_pp_get_global_pp_core(core_id);
-		if (NULL != pp_core)
-		{
-			u32 counter_src = (counter_id - COUNTER_FP0_C0) & 1;
-			if (0 == counter_src)
-			{
-				if (MALI_TRUE == mali_pp_core_set_counter_src0(pp_core, event_id))
-				{
-					return 1;
-				}
-			}
-			else
-			{
-				if (MALI_TRUE == mali_pp_core_set_counter_src1(pp_core, event_id))
-				{
-					return 1;
-				}
-			}
-		}
-	}
-	else if (counter_id >= COUNTER_L2_C0 && counter_id <= COUNTER_L2_C1)
-	{
-		u32 core_id = (counter_id - COUNTER_L2_C0) >> 1;
-		struct mali_l2_cache_core* l2_cache_core = mali_l2_cache_core_get_glob_l2_core(core_id);
-		if (NULL != l2_cache_core)
-		{
-			u32 counter_src = (counter_id - COUNTER_L2_C0) & 1;
-			if (0 == counter_src)
-			{
-				if (MALI_TRUE == mali_l2_cache_core_set_counter_src0(l2_cache_core, event_id))
-				{
-					return 1;
-				}
-			}
-			else
-			{
-				if (MALI_TRUE == mali_l2_cache_core_set_counter_src1(l2_cache_core, event_id))
-				{
-					return 1;
-				}
-			}
-		}
-	}
-
-	return 0;
-}
-
-/**
- * Called by gator.ko to retrieve the L2 cache counter values for the first L2 cache.
- * The L2 cache counters are unique in that they are polled by gator, rather than being
- * transmitted via the tracepoint mechanism.
- *
- * @param src0 First L2 cache counter ID.
- * @param val0 First L2 cache counter value.
- * @param src1 Second L2 cache counter ID.
- * @param val1 Second L2 cache counter value.
- */
-void _mali_profiling_get_counters(u32 *src0, u32 *val0, u32 *src1, u32 *val1)
-{
-	 struct mali_l2_cache_core *l2_cache = mali_l2_cache_core_get_glob_l2_core(0);
-	 if (NULL != l2_cache)
-	 {
-		if (MALI_TRUE == mali_l2_cache_lock_power_state(l2_cache))
-		{
-			/* It is now safe to access the L2 cache core in order to retrieve the counters */
-			mali_l2_cache_core_get_counter_values(l2_cache, src0, val0, src1, val1);
-		}
-		mali_l2_cache_unlock_power_state(l2_cache);
-	 }
-}
-
-/*
- * List of possible actions to be controlled by Streamline.
- * The following numbers are used by gator to control the frame buffer dumping and s/w counter reporting.
- * We cannot use the enums in mali_uk_types.h because they are unknown inside gator.
- */
-#define FBDUMP_CONTROL_ENABLE (1)
-#define FBDUMP_CONTROL_RATE (2)
-#define SW_COUNTER_ENABLE (3)
-#define FBDUMP_CONTROL_RESIZE_FACTOR (4)
-
-/**
- * Called by gator to control the production of profiling information at runtime.
- */
-void _mali_profiling_control(u32 action, u32 value)
-{
-	switch(action)
-	{
-	case FBDUMP_CONTROL_ENABLE:
-		mali_set_user_setting(_MALI_UK_USER_SETTING_COLORBUFFER_CAPTURE_ENABLED, (value == 0 ? MALI_FALSE : MALI_TRUE));
-		break;
-	case FBDUMP_CONTROL_RATE:
-		mali_set_user_setting(_MALI_UK_USER_SETTING_BUFFER_CAPTURE_N_FRAMES, value);
-		break;
-	case SW_COUNTER_ENABLE:
-		mali_set_user_setting(_MALI_UK_USER_SETTING_SW_COUNTER_ENABLED, value);
-		break;
-	case FBDUMP_CONTROL_RESIZE_FACTOR:
-		mali_set_user_setting(_MALI_UK_USER_SETTING_BUFFER_CAPTURE_RESIZE_FACTOR, value);
-		break;
-	default:
-		break;	/* Ignore unimplemented actions */
-	}
-}
-
-EXPORT_SYMBOL(_mali_profiling_set_event);
-EXPORT_SYMBOL(_mali_profiling_get_counters);
-EXPORT_SYMBOL(_mali_profiling_control);
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_profiling_internal.c b/drivers/gpu/mali/mali/linux/mali_osk_profiling_internal.c
deleted file mode 100644
index 86d6c05..0000000
--- a/drivers/gpu/mali/mali/linux/mali_osk_profiling_internal.c
+++ /dev/null
@@ -1,307 +0,0 @@
-/*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
- * This program is free software and is provided to you under the terms of the GNU General Public License version 2
- * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
- * A copy of the licence is included with the program, and can also be obtained from Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
- */
-
-#include "mali_kernel_common.h"
-#include "mali_osk.h"
-#include "mali_osk_mali.h"
-#include "mali_ukk.h"
-#include "mali_timestamp.h"
-#include "mali_osk_profiling.h"
-#include "mali_user_settings_db.h"
-
-typedef struct mali_profiling_entry
-{
-	u64 timestamp;
-	u32 event_id;
-	u32 data[5];
-} mali_profiling_entry;
-
-
-typedef enum mali_profiling_state
-{
-	MALI_PROFILING_STATE_UNINITIALIZED,
-	MALI_PROFILING_STATE_IDLE,
-	MALI_PROFILING_STATE_RUNNING,
-	MALI_PROFILING_STATE_RETURN,
-} mali_profiling_state;
-
-
-static _mali_osk_lock_t *lock = NULL;
-static mali_profiling_state prof_state = MALI_PROFILING_STATE_UNINITIALIZED;
-static mali_profiling_entry* profile_entries = NULL;
-static u32 profile_entry_count = 0;
-static _mali_osk_atomic_t profile_insert_index;
-static _mali_osk_atomic_t profile_entries_written;
-
-_mali_osk_errcode_t _mali_osk_profiling_init(mali_bool auto_start)
-{
-	profile_entries = NULL;
-	profile_entry_count = 0;
-	_mali_osk_atomic_init(&profile_insert_index, 0);
-	_mali_osk_atomic_init(&profile_entries_written, 0);
-
-	lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_ORDERED | _MALI_OSK_LOCKFLAG_SPINLOCK | _MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, _MALI_OSK_LOCK_ORDER_PROFILING);
-	if (NULL == lock)
-	{
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	prof_state = MALI_PROFILING_STATE_IDLE;
-
-	if (MALI_TRUE == auto_start)
-	{
-		u32 limit = MALI_PROFILING_MAX_BUFFER_ENTRIES; /* Use maximum buffer size */
-
-		mali_set_user_setting(_MALI_UK_USER_SETTING_SW_EVENTS_ENABLE, MALI_TRUE);
-		if (_MALI_OSK_ERR_OK != _mali_osk_profiling_start(&limit))
-		{
-			return _MALI_OSK_ERR_FAULT;
-		}
-	}
-
-	return _MALI_OSK_ERR_OK;
-}
-
-void _mali_osk_profiling_term(void)
-{
-	prof_state = MALI_PROFILING_STATE_UNINITIALIZED;
-
-	/* wait for all elements to be completely inserted into array */
-	while (_mali_osk_atomic_read(&profile_insert_index) != _mali_osk_atomic_read(&profile_entries_written))
-	{
-		/* do nothing */;
-	}
-
-	if (NULL != profile_entries)
-	{
-		_mali_osk_vfree(profile_entries);
-		profile_entries = NULL;
-	}
-
-	if (NULL != lock)
-	{
-		_mali_osk_lock_term(lock);
-		lock = NULL;
-	}
-}
-
-inline _mali_osk_errcode_t _mali_osk_profiling_start(u32 * limit)
-{
-	_mali_osk_errcode_t ret;
-
-	mali_profiling_entry *new_profile_entries = _mali_osk_valloc(*limit * sizeof(mali_profiling_entry));
-
-	if(NULL == new_profile_entries)
-	{
-		return _MALI_OSK_ERR_NOMEM;
-	}
-
-	_mali_osk_lock_wait(lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (prof_state != MALI_PROFILING_STATE_IDLE)
-	{
-		_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-		_mali_osk_vfree(new_profile_entries);
-		return _MALI_OSK_ERR_INVALID_ARGS; /* invalid to call this function in this state */
-	}
-
-	if (*limit > MALI_PROFILING_MAX_BUFFER_ENTRIES)
-	{
-		*limit = MALI_PROFILING_MAX_BUFFER_ENTRIES;
-	}
-
-	profile_entries = new_profile_entries;
-	profile_entry_count = *limit;
-
-	ret = _mali_timestamp_reset();
-
-	if (ret == _MALI_OSK_ERR_OK)
-	{
-		prof_state = MALI_PROFILING_STATE_RUNNING;
-	}
-	else
-	{
-		_mali_osk_vfree(profile_entries);
-		profile_entries = NULL;
-	}
-
-	_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-	return ret;
-}
-
-inline void _mali_osk_profiling_add_event(u32 event_id, u32 data0, u32 data1, u32 data2, u32 data3, u32 data4)
-{
-	u32 cur_index = _mali_osk_atomic_inc_return(&profile_insert_index) - 1;
-
-	if (prof_state != MALI_PROFILING_STATE_RUNNING || cur_index >= profile_entry_count)
-	{
-		/*
-		 * Not in recording mode, or buffer is full
-		 * Decrement index again, and early out
-		 */
-		_mali_osk_atomic_dec(&profile_insert_index);
-		return;
-	}
-
-	profile_entries[cur_index].timestamp = _mali_timestamp_get();
-	profile_entries[cur_index].event_id = event_id;
-	profile_entries[cur_index].data[0] = data0;
-	profile_entries[cur_index].data[1] = data1;
-	profile_entries[cur_index].data[2] = data2;
-	profile_entries[cur_index].data[3] = data3;
-	profile_entries[cur_index].data[4] = data4;
-
-	_mali_osk_atomic_inc(&profile_entries_written);
-}
-
-inline void _mali_osk_profiling_report_hw_counter(u32 counter_id, u32 value)
-{
-    /* Not implemented */
-}
-
-void _mali_osk_profiling_report_sw_counters(u32 *counters)
-{
-	/* Not implemented */
-}
-
-inline _mali_osk_errcode_t _mali_osk_profiling_stop(u32 * count)
-{
-	_mali_osk_lock_wait(lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (prof_state != MALI_PROFILING_STATE_RUNNING)
-	{
-		_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-		return _MALI_OSK_ERR_INVALID_ARGS; /* invalid to call this function in this state */
-	}
-
-	/* go into return state (user to retreive events), no more events will be added after this */
-	prof_state = MALI_PROFILING_STATE_RETURN;
-
-	_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-
-	/* wait for all elements to be completely inserted into array */
-	while (_mali_osk_atomic_read(&profile_insert_index) != _mali_osk_atomic_read(&profile_entries_written))
-	{
-		/* do nothing */;
-	}
-
-	*count = _mali_osk_atomic_read(&profile_insert_index);
-
-	return _MALI_OSK_ERR_OK;
-}
-
-inline u32 _mali_osk_profiling_get_count(void)
-{
-	u32 retval = 0;
-
-	_mali_osk_lock_wait(lock, _MALI_OSK_LOCKMODE_RW);
-	if (prof_state == MALI_PROFILING_STATE_RETURN)
-	{
-		retval = _mali_osk_atomic_read(&profile_entries_written);
-	}
-	_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-
-	return retval;
-}
-
-inline _mali_osk_errcode_t _mali_osk_profiling_get_event(u32 index, u64* timestamp, u32* event_id, u32 data[5])
-{
-	_mali_osk_lock_wait(lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (prof_state != MALI_PROFILING_STATE_RETURN)
-	{
-		_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-		return _MALI_OSK_ERR_INVALID_ARGS; /* invalid to call this function in this state */
-	}
-
-	if (index >= _mali_osk_atomic_read(&profile_entries_written))
-	{
-		_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-		return _MALI_OSK_ERR_FAULT;
-	}
-
-	*timestamp = profile_entries[index].timestamp;
-	*event_id = profile_entries[index].event_id;
-	data[0] = profile_entries[index].data[0];
-	data[1] = profile_entries[index].data[1];
-	data[2] = profile_entries[index].data[2];
-	data[3] = profile_entries[index].data[3];
-	data[4] = profile_entries[index].data[4];
-
-	_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-	return _MALI_OSK_ERR_OK;
-}
-
-inline _mali_osk_errcode_t _mali_osk_profiling_clear(void)
-{
-	_mali_osk_lock_wait(lock, _MALI_OSK_LOCKMODE_RW);
-
-	if (prof_state != MALI_PROFILING_STATE_RETURN)
-	{
-		_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-		return _MALI_OSK_ERR_INVALID_ARGS; /* invalid to call this function in this state */
-	}
-
-	prof_state = MALI_PROFILING_STATE_IDLE;
-	profile_entry_count = 0;
-	_mali_osk_atomic_init(&profile_insert_index, 0);
-	_mali_osk_atomic_init(&profile_entries_written, 0);
-	if (NULL != profile_entries)
-	{
-		_mali_osk_vfree(profile_entries);
-		profile_entries = NULL;
-	}
-
-	_mali_osk_lock_signal(lock, _MALI_OSK_LOCKMODE_RW);
-	return _MALI_OSK_ERR_OK;
-}
-
-mali_bool _mali_osk_profiling_is_recording(void)
-{
-	return prof_state == MALI_PROFILING_STATE_RUNNING ? MALI_TRUE : MALI_FALSE;
-}
-
-mali_bool _mali_osk_profiling_have_recording(void)
-{
-	return prof_state == MALI_PROFILING_STATE_RETURN ? MALI_TRUE : MALI_FALSE;
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_start(_mali_uk_profiling_start_s *args)
-{
-	return _mali_osk_profiling_start(&args->limit);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_add_event(_mali_uk_profiling_add_event_s *args)
-{
-	/* Always add process and thread identificator in the first two data elements for events from user space */
-	_mali_osk_profiling_add_event(args->event_id, _mali_osk_get_pid(), _mali_osk_get_tid(), args->data[2], args->data[3], args->data[4]);
-	return _MALI_OSK_ERR_OK;
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_stop(_mali_uk_profiling_stop_s *args)
-{
-	return _mali_osk_profiling_stop(&args->count);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_get_event(_mali_uk_profiling_get_event_s *args)
-{
-	return _mali_osk_profiling_get_event(args->index, &args->timestamp, &args->event_id, args->data);
-}
-
-_mali_osk_errcode_t _mali_ukk_profiling_clear(_mali_uk_profiling_clear_s *args)
-{
-	return _mali_osk_profiling_clear();
-}
-
-_mali_osk_errcode_t _mali_ukk_sw_counters_report(_mali_uk_sw_counters_report_s *args)
-{
-	_mali_osk_profiling_report_sw_counters(args->counters);
-	return _MALI_OSK_ERR_OK;
-}
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_specific.h b/drivers/gpu/mali/mali/linux/mali_osk_specific.h
old mode 100644
new mode 100755
index 425b18b..ac054be
--- a/drivers/gpu/mali/mali/linux/mali_osk_specific.h
+++ b/drivers/gpu/mali/mali/linux/mali_osk_specific.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,114 +17,76 @@
 #ifndef __MALI_OSK_SPECIFIC_H__
 #define __MALI_OSK_SPECIFIC_H__
 
-#ifdef __cplusplus
-extern "C"
-{
-#endif
+#include <asm/uaccess.h>
+#include <linux/platform_device.h>
+#include <linux/dmapool.h>
+#include <linux/gfp.h>
+#include <linux/hardirq.h>
+
+#include "mali_osk_types.h"
+#include "mali_kernel_linux.h"
 
 #define MALI_STATIC_INLINE static inline
 #define MALI_NON_STATIC_INLINE inline
 
-#ifdef __cplusplus
+typedef struct dma_pool *mali_dma_pool;
+
+
+MALI_STATIC_INLINE mali_dma_pool mali_dma_pool_create(u32 size, u32 alignment, u32 boundary)
+{
+	return dma_pool_create("mali-dma", &mali_platform_device->dev, size, alignment, boundary);
+}
+
+MALI_STATIC_INLINE void mali_dma_pool_destroy(mali_dma_pool pool)
+{
+	dma_pool_destroy(pool);
+}
+
+MALI_STATIC_INLINE mali_io_address mali_dma_pool_alloc(mali_dma_pool pool, u32 *phys_addr)
+{
+	return dma_pool_alloc(pool, GFP_KERNEL, phys_addr);
+}
+
+MALI_STATIC_INLINE void mali_dma_pool_free(mali_dma_pool pool, void *virt_addr, u32 phys_addr)
+{
+	dma_pool_free(pool, virt_addr, phys_addr);
 }
+
+
+#if MALI_ENABLE_CPU_CYCLES
+/* Reads out the clock cycle performance counter of the current cpu.
+   It is useful for cost-free (2 cycle) measuring of the time spent
+   in a code path. Sample before and after, the diff number of cycles.
+   When the CPU is idle it will not increase this clock counter.
+   It means that the counter is accurate if only spin-locks are used,
+   but mutexes may lead to too low values since the cpu might "idle"
+   waiting for the mutex to become available.
+   The clock source is configured on the CPU during mali module load,
+   but will not give useful output after a CPU has been power cycled.
+   It is therefore important to configure the system to not turn of
+   the cpu cores when using this functionallity.*/
+static inline unsigned int mali_get_cpu_cyclecount(void)
+{
+	unsigned int value;
+	/* Reading the CCNT Register - CPU clock counter */
+	asm volatile("MRC p15, 0, %0, c9, c13, 0\t\n": "=r"(value));
+	return value;
+}
+
+void mali_init_cpu_time_counters(int reset, int enable_divide_by_64);
 #endif
 
-/** The list of events supported by the Mali DDK. */
-typedef enum
+
+MALI_STATIC_INLINE u32 _mali_osk_copy_from_user(void *to, void *from, u32 n)
+{
+	return (u32)copy_from_user(to, from, (unsigned long)n);
+}
+
+MALI_STATIC_INLINE mali_bool _mali_osk_in_atomic(void)
 {
-    /* Vertex processor activity */
-    ACTIVITY_VP = 0,
-
-    /* Fragment processor activity */
-    ACTIVITY_FP0,
-    ACTIVITY_FP1,
-    ACTIVITY_FP2,
-    ACTIVITY_FP3,
-
-    /* L2 cache counters */
-    COUNTER_L2_C0,
-    COUNTER_L2_C1,
-
-    /* Vertex processor counters */
-    COUNTER_VP_C0,
-    COUNTER_VP_C1,
-
-    /* Fragment processor counters */
-    COUNTER_FP0_C0,
-    COUNTER_FP0_C1,
-    COUNTER_FP1_C0,
-    COUNTER_FP1_C1,
-    COUNTER_FP2_C0,
-    COUNTER_FP2_C1,
-    COUNTER_FP3_C0,
-    COUNTER_FP3_C1,
-
-    /*
-     * If more hardware counters are added, the _mali_osk_hw_counter_table
-     * below should also be updated.
-     */
-
-    /* EGL software counters */
-    COUNTER_EGL_BLIT_TIME,
-
-    /* GLES software counters */
-    COUNTER_GLES_DRAW_ELEMENTS_CALLS,
-    COUNTER_GLES_DRAW_ELEMENTS_NUM_INDICES,
-    COUNTER_GLES_DRAW_ELEMENTS_NUM_TRANSFORMED,
-    COUNTER_GLES_DRAW_ARRAYS_CALLS,
-    COUNTER_GLES_DRAW_ARRAYS_NUM_TRANSFORMED,
-    COUNTER_GLES_DRAW_POINTS,
-    COUNTER_GLES_DRAW_LINES,
-    COUNTER_GLES_DRAW_LINE_LOOP,
-    COUNTER_GLES_DRAW_LINE_STRIP,
-    COUNTER_GLES_DRAW_TRIANGLES,
-    COUNTER_GLES_DRAW_TRIANGLE_STRIP,
-    COUNTER_GLES_DRAW_TRIANGLE_FAN,
-    COUNTER_GLES_NON_VBO_DATA_COPY_TIME,
-    COUNTER_GLES_UNIFORM_BYTES_COPIED_TO_MALI,
-    COUNTER_GLES_UPLOAD_TEXTURE_TIME,
-    COUNTER_GLES_UPLOAD_VBO_TIME,
-    COUNTER_GLES_NUM_FLUSHES,
-    COUNTER_GLES_NUM_VSHADERS_GENERATED,
-    COUNTER_GLES_NUM_FSHADERS_GENERATED,
-    COUNTER_GLES_VSHADER_GEN_TIME,
-    COUNTER_GLES_FSHADER_GEN_TIME,
-    COUNTER_GLES_INPUT_TRIANGLES,
-    COUNTER_GLES_VXCACHE_HIT,
-    COUNTER_GLES_VXCACHE_MISS,
-    COUNTER_GLES_VXCACHE_COLLISION,
-    COUNTER_GLES_CULLED_TRIANGLES,
-    COUNTER_GLES_CULLED_LINES,
-    COUNTER_GLES_BACKFACE_TRIANGLES,
-    COUNTER_GLES_GBCLIP_TRIANGLES,
-    COUNTER_GLES_GBCLIP_LINES,
-    COUNTER_GLES_TRIANGLES_DRAWN,
-    COUNTER_GLES_DRAWCALL_TIME,
-    COUNTER_GLES_TRIANGLES_COUNT,
-    COUNTER_GLES_INDEPENDENT_TRIANGLES_COUNT,
-    COUNTER_GLES_STRIP_TRIANGLES_COUNT,
-    COUNTER_GLES_FAN_TRIANGLES_COUNT,
-    COUNTER_GLES_LINES_COUNT,
-    COUNTER_GLES_INDEPENDENT_LINES_COUNT,
-    COUNTER_GLES_STRIP_LINES_COUNT,
-    COUNTER_GLES_LOOP_LINES_COUNT,
-
-    /* Framebuffer capture pseudo-counter */
-    COUNTER_FILMSTRIP,
-
-    NUMBER_OF_EVENTS
-} _mali_osk_counter_id;
-
-#define FIRST_ACTIVITY_EVENT    ACTIVITY_VP
-#define LAST_ACTIVITY_EVENT     ACTIVITY_FP3
-
-#define FIRST_HW_COUNTER        COUNTER_L2_C0
-#define LAST_HW_COUNTER         COUNTER_FP3_C1
-
-#define FIRST_SW_COUNTER        COUNTER_EGL_BLIT_TIME
-#define LAST_SW_COUNTER         COUNTER_GLES_LOOP_LINES_COUNT
-
-#define FIRST_SPECIAL_COUNTER   COUNTER_FILMSTRIP
-#define LAST_SPECIAL_COUNTER    COUNTER_FILMSTRIP
+	return in_atomic();
+}
+
+#define _mali_osk_put_user(x, ptr) put_user(x, ptr)
 
 #endif /* __MALI_OSK_SPECIFIC_H__ */
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_time.c b/drivers/gpu/mali/mali/linux/mali_osk_time.c
old mode 100644
new mode 100755
index eded165..e7989ed
--- a/drivers/gpu/mali/mali/linux/mali_osk_time.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_time.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,32 +18,32 @@
 #include <linux/time.h>
 #include <asm/delay.h>
 
-int	_mali_osk_time_after( u32 ticka, u32 tickb )
+int     _mali_osk_time_after(u32 ticka, u32 tickb)
 {
-    return time_after((unsigned long)ticka, (unsigned long)tickb);
+	return time_after((unsigned long)ticka, (unsigned long)tickb);
 }
 
-u32	_mali_osk_time_mstoticks( u32 ms )
+u32     _mali_osk_time_mstoticks(u32 ms)
 {
-    return msecs_to_jiffies(ms);
+	return msecs_to_jiffies(ms);
 }
 
-u32	_mali_osk_time_tickstoms( u32 ticks )
+u32     _mali_osk_time_tickstoms(u32 ticks)
 {
-    return jiffies_to_msecs(ticks);
+	return jiffies_to_msecs(ticks);
 }
 
-u32	_mali_osk_time_tickcount( void )
+u32     _mali_osk_time_tickcount(void)
 {
-    return jiffies;
+	return jiffies;
 }
 
-void _mali_osk_time_ubusydelay( u32 usecs )
+void _mali_osk_time_ubusydelay(u32 usecs)
 {
-    udelay(usecs);
+	udelay(usecs);
 }
 
-u64 _mali_osk_time_get_ns( void )
+u64 _mali_osk_time_get_ns(void)
 {
 	struct timespec tsval;
 	getnstimeofday(&tsval);
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_timers.c b/drivers/gpu/mali/mali/linux/mali_osk_timers.c
old mode 100644
new mode 100755
index 981bcfc..4b3799b
--- a/drivers/gpu/mali/mali/linux/mali_osk_timers.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_timers.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,48 +18,59 @@
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
 
-struct _mali_osk_timer_t_struct
-{
-    struct timer_list timer;
+struct _mali_osk_timer_t_struct {
+	struct timer_list timer;
 };
 
 typedef void (*timer_timeout_function_t)(unsigned long);
 
 _mali_osk_timer_t *_mali_osk_timer_init(void)
 {
-    _mali_osk_timer_t *t = (_mali_osk_timer_t*)kmalloc(sizeof(_mali_osk_timer_t), GFP_KERNEL);
-    if (NULL != t) init_timer(&t->timer);
-    return t;
+	_mali_osk_timer_t *t = (_mali_osk_timer_t *)kmalloc(sizeof(_mali_osk_timer_t), GFP_KERNEL);
+	if (NULL != t) init_timer(&t->timer);
+	return t;
 }
 
-void _mali_osk_timer_add( _mali_osk_timer_t *tim, u32 ticks_to_expire )
+void _mali_osk_timer_add(_mali_osk_timer_t *tim, u32 ticks_to_expire)
 {
 	MALI_DEBUG_ASSERT_POINTER(tim);
-    tim->timer.expires = _mali_osk_time_tickcount() + ticks_to_expire;
-    add_timer(&(tim->timer));
+	tim->timer.expires = jiffies + ticks_to_expire;
+	add_timer(&(tim->timer));
 }
 
-void _mali_osk_timer_mod( _mali_osk_timer_t *tim, u32 expiry_tick)
+void _mali_osk_timer_mod(_mali_osk_timer_t *tim, u32 ticks_to_expire)
 {
-    MALI_DEBUG_ASSERT_POINTER(tim);
-    mod_timer(&(tim->timer), expiry_tick);
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	mod_timer(&(tim->timer), jiffies + ticks_to_expire);
 }
 
-void _mali_osk_timer_del( _mali_osk_timer_t *tim )
+void _mali_osk_timer_del(_mali_osk_timer_t *tim)
 {
-    MALI_DEBUG_ASSERT_POINTER(tim);
-    del_timer_sync(&(tim->timer));
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	del_timer_sync(&(tim->timer));
 }
 
-void _mali_osk_timer_setcallback( _mali_osk_timer_t *tim, _mali_osk_timer_callback_t callback, void *data )
+void _mali_osk_timer_del_async(_mali_osk_timer_t *tim)
 {
-    MALI_DEBUG_ASSERT_POINTER(tim);
-    tim->timer.data = (unsigned long)data;
-    tim->timer.function = (timer_timeout_function_t)callback;
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	del_timer(&(tim->timer));
 }
 
-void _mali_osk_timer_term( _mali_osk_timer_t *tim )
+mali_bool _mali_osk_timer_pending(_mali_osk_timer_t *tim)
 {
-    MALI_DEBUG_ASSERT_POINTER(tim);
-    kfree(tim);
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	return 1 == timer_pending(&(tim->timer));
+}
+
+void _mali_osk_timer_setcallback(_mali_osk_timer_t *tim, _mali_osk_timer_callback_t callback, void *data)
+{
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	tim->timer.data = (unsigned long)data;
+	tim->timer.function = (timer_timeout_function_t)callback;
+}
+
+void _mali_osk_timer_term(_mali_osk_timer_t *tim)
+{
+	MALI_DEBUG_ASSERT_POINTER(tim);
+	kfree(tim);
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_osk_wait_queue.c b/drivers/gpu/mali/mali/linux/mali_osk_wait_queue.c
old mode 100644
new mode 100755
index f992f81..d14b7d5
--- a/drivers/gpu/mali/mali/linux/mali_osk_wait_queue.c
+++ b/drivers/gpu/mali/mali/linux/mali_osk_wait_queue.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,54 +20,59 @@
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
 
-struct _mali_osk_wait_queue_t_struct
-{
-    wait_queue_head_t wait_queue;
+struct _mali_osk_wait_queue_t_struct {
+	wait_queue_head_t wait_queue;
 };
 
-_mali_osk_wait_queue_t* _mali_osk_wait_queue_init( void )
+_mali_osk_wait_queue_t *_mali_osk_wait_queue_init(void)
 {
-    _mali_osk_wait_queue_t* ret = NULL;
+	_mali_osk_wait_queue_t *ret = NULL;
+
+	ret = kmalloc(sizeof(_mali_osk_wait_queue_t), GFP_KERNEL);
 
-    ret = kmalloc(sizeof(_mali_osk_wait_queue_t), GFP_KERNEL);
+	if (NULL == ret) {
+		return ret;
+	}
 
-    if (NULL == ret)
-    {
-        return ret;
-    }
+	init_waitqueue_head(&ret->wait_queue);
+	MALI_DEBUG_ASSERT(!waitqueue_active(&ret->wait_queue));
 
-    init_waitqueue_head(&ret->wait_queue);
-    MALI_DEBUG_ASSERT(!waitqueue_active(&ret->wait_queue));
+	return ret;
+}
 
-    return ret;
+void _mali_osk_wait_queue_wait_event(_mali_osk_wait_queue_t *queue, mali_bool(*condition)(void *), void *data)
+{
+	MALI_DEBUG_ASSERT_POINTER(queue);
+	MALI_DEBUG_PRINT(6, ("Adding to wait queue %p\n", queue));
+	wait_event(queue->wait_queue, condition(data));
 }
 
-void _mali_osk_wait_queue_wait_event( _mali_osk_wait_queue_t *queue, mali_bool (*condition)(void) )
+void _mali_osk_wait_queue_wait_event_timeout(_mali_osk_wait_queue_t *queue, mali_bool(*condition)(void *), void *data, u32 timeout)
 {
-    MALI_DEBUG_ASSERT_POINTER( queue );
-    MALI_DEBUG_PRINT(6, ("Adding to wait queue %p\n", queue));
-    wait_event(queue->wait_queue, condition());
+	MALI_DEBUG_ASSERT_POINTER(queue);
+	MALI_DEBUG_PRINT(6, ("Adding to wait queue %p\n", queue));
+	wait_event_timeout(queue->wait_queue, condition(data), _mali_osk_time_mstoticks(timeout));
 }
 
-void _mali_osk_wait_queue_wake_up( _mali_osk_wait_queue_t *queue )
+void _mali_osk_wait_queue_wake_up(_mali_osk_wait_queue_t *queue)
 {
-    MALI_DEBUG_ASSERT_POINTER( queue );
+	MALI_DEBUG_ASSERT_POINTER(queue);
 
-    /* if queue is empty, don't attempt to wake up its elements */
-    if (!waitqueue_active(&queue->wait_queue)) return;
+	/* if queue is empty, don't attempt to wake up its elements */
+	if (!waitqueue_active(&queue->wait_queue)) return;
 
-    MALI_DEBUG_PRINT(6, ("Waking up elements in wait queue %p ....\n", queue));
+	MALI_DEBUG_PRINT(6, ("Waking up elements in wait queue %p ....\n", queue));
 
-    wake_up_all(&queue->wait_queue);
+	wake_up_all(&queue->wait_queue);
 
-    MALI_DEBUG_PRINT(6, ("... elements in wait queue %p woken up\n", queue));
+	MALI_DEBUG_PRINT(6, ("... elements in wait queue %p woken up\n", queue));
 }
 
-void _mali_osk_wait_queue_term( _mali_osk_wait_queue_t *queue )
+void _mali_osk_wait_queue_term(_mali_osk_wait_queue_t *queue)
 {
 	/* Parameter validation  */
-	MALI_DEBUG_ASSERT_POINTER( queue );
+	MALI_DEBUG_ASSERT_POINTER(queue);
 
 	/* Linux requires no explicit termination of wait queues */
-    kfree(queue);
+	kfree(queue);
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_pmu_power_up_down.c b/drivers/gpu/mali/mali/linux/mali_pmu_power_up_down.c
old mode 100644
new mode 100755
index 5e79a1e..77ac70e
--- a/drivers/gpu/mali/mali/linux/mali_pmu_power_up_down.c
+++ b/drivers/gpu/mali/mali/linux/mali_pmu_power_up_down.c
@@ -1,9 +1,9 @@
 /**
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,6 +18,7 @@
 #include "mali_osk.h"
 #include "mali_kernel_common.h"
 #include "mali_pmu.h"
+#include "mali_pp_scheduler.h"
 #include "linux/mali/mali_utgard.h"
 
 /* Mali PMU power up/down APIs */
@@ -28,13 +29,12 @@ int mali_pmu_powerup(void)
 
 	MALI_DEBUG_PRINT(5, ("Mali PMU: Power up\n"));
 
-	if (NULL == pmu)
-	{
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	if (NULL == pmu) {
 		return -ENXIO;
 	}
 
-	if (_MALI_OSK_ERR_OK != mali_pmu_powerup_all(pmu))
-	{
+	if (_MALI_OSK_ERR_OK != mali_pmu_power_up_all(pmu)) {
 		return -EFAULT;
 	}
 
@@ -49,13 +49,12 @@ int mali_pmu_powerdown(void)
 
 	MALI_DEBUG_PRINT(5, ("Mali PMU: Power down\n"));
 
-	if (NULL == pmu)
-	{
+	MALI_DEBUG_ASSERT_POINTER(pmu);
+	if (NULL == pmu) {
 		return -ENXIO;
 	}
 
-	if (_MALI_OSK_ERR_OK != mali_pmu_powerdown_all(pmu))
-	{
+	if (_MALI_OSK_ERR_OK != mali_pmu_power_down_all(pmu)) {
 		return -EFAULT;
 	}
 
@@ -63,3 +62,10 @@ int mali_pmu_powerdown(void)
 }
 
 EXPORT_SYMBOL(mali_pmu_powerdown);
+
+int mali_perf_set_num_pp_cores(unsigned int num_cores)
+{
+	return mali_pp_scheduler_set_perf_level(num_cores, MALI_FALSE);
+}
+
+EXPORT_SYMBOL(mali_perf_set_num_pp_cores);
diff --git a/drivers/gpu/mali/mali/linux/mali_profiling_events.h b/drivers/gpu/mali/mali/linux/mali_profiling_events.h
old mode 100644
new mode 100755
index 8785614..e41323c
--- a/drivers/gpu/mali/mali/linux/mali_profiling_events.h
+++ b/drivers/gpu/mali/mali/linux/mali_profiling_events.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012, 2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/mali/linux/mali_uk_types.h b/drivers/gpu/mali/mali/linux/mali_uk_types.h
old mode 100644
new mode 100755
index 8c2bd25..c7e2ef5
--- a/drivers/gpu/mali/mali/linux/mali_uk_types.h
+++ b/drivers/gpu/mali/mali/linux/mali_uk_types.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2012, 2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_core.c b/drivers/gpu/mali/mali/linux/mali_ukk_core.c
old mode 100644
new mode 100755
index c4919ae..112cea2
--- a/drivers/gpu/mali/mali/linux/mali_ukk_core.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_core.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,102 +20,41 @@
 int get_api_version_wrapper(struct mali_session_data *session_data, _mali_uk_get_api_version_s __user *uargs)
 {
 	_mali_uk_get_api_version_s kargs;
-    _mali_osk_errcode_t err;
-
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-
-    if (0 != get_user(kargs.version, &uargs->version)) return -EFAULT;
-
-    kargs.ctx = session_data;
-    err = _mali_ukk_get_api_version(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
-
-    if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
-    if (0 != put_user(kargs.compatible, &uargs->compatible)) return -EFAULT;
-
-    return 0;
-}
-
-int get_system_info_size_wrapper(struct mali_session_data *session_data, _mali_uk_get_system_info_size_s __user *uargs)
-{
-	_mali_uk_get_system_info_size_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_get_system_info_size(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	if (0 != get_user(kargs.version, &uargs->version)) return -EFAULT;
 
-    if (0 != put_user(kargs.size, &uargs->size)) return -EFAULT;
+	kargs.ctx = session_data;
+	err = _mali_ukk_get_api_version(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-    return 0;
-}
+	if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
+	if (0 != put_user(kargs.compatible, &uargs->compatible)) return -EFAULT;
 
-int get_system_info_wrapper(struct mali_session_data *session_data, _mali_uk_get_system_info_s __user *uargs)
-{
-	_mali_uk_get_system_info_s kargs;
-    _mali_osk_errcode_t err;
-    _mali_system_info *system_info_user;
-    _mali_system_info *system_info_kernel;
-
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-
-    if (0 != get_user(kargs.system_info, &uargs->system_info)) return -EFAULT;
-    if (0 != get_user(kargs.size, &uargs->size)) return -EFAULT;
-
-    /* A temporary kernel buffer for the system_info datastructure is passed through the system_info
-     * member. The ukk_private member will point to the user space destination of this buffer so
-     * that _mali_ukk_get_system_info() can correct the pointers in the system_info correctly
-     * for user space.
-     */
-    system_info_kernel = kmalloc(kargs.size, GFP_KERNEL);
-    if (NULL == system_info_kernel) return -EFAULT;
-
-    system_info_user = kargs.system_info;
-    kargs.system_info = system_info_kernel;
-    kargs.ukk_private = (u32)system_info_user;
-    kargs.ctx = session_data;
-
-    err = _mali_ukk_get_system_info(&kargs);
-    if (_MALI_OSK_ERR_OK != err)
-    {
-        kfree(system_info_kernel);
-        return map_errcode(err);
-    }
-
-    if (0 != copy_to_user(system_info_user, system_info_kernel, kargs.size))
-    {
-        kfree(system_info_kernel);
-        return -EFAULT;
-    }
-
-    kfree(system_info_kernel);
-    return 0;
+	return 0;
 }
 
 int wait_for_notification_wrapper(struct mali_session_data *session_data, _mali_uk_wait_for_notification_s __user *uargs)
 {
-    _mali_uk_wait_for_notification_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_wait_for_notification_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_wait_for_notification(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
+	err = _mali_ukk_wait_for_notification(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-	if(_MALI_NOTIFICATION_CORE_SHUTDOWN_IN_PROGRESS != kargs.type)
-	{
+	if (_MALI_NOTIFICATION_CORE_SHUTDOWN_IN_PROGRESS != kargs.type) {
 		kargs.ctx = NULL; /* prevent kernel address to be returned to user space */
 		if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_wait_for_notification_s))) return -EFAULT;
-	}
-	else
-	{
+	} else {
 		if (0 != put_user(kargs.type, &uargs->type)) return -EFAULT;
 	}
 
-    return 0;
+	return 0;
 }
 
 int post_notification_wrapper(struct mali_session_data *session_data, _mali_uk_post_notification_s __user *uargs)
@@ -127,14 +66,12 @@ int post_notification_wrapper(struct mali_session_data *session_data, _mali_uk_p
 
 	kargs.ctx = session_data;
 
-	if (0 != get_user(kargs.type, &uargs->type))
-	{
+	if (0 != get_user(kargs.type, &uargs->type)) {
 		return -EFAULT;
 	}
 
 	err = _mali_ukk_post_notification(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
@@ -150,8 +87,7 @@ int get_user_settings_wrapper(struct mali_session_data *session_data, _mali_uk_g
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_get_user_settings(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
@@ -160,3 +96,18 @@ int get_user_settings_wrapper(struct mali_session_data *session_data, _mali_uk_g
 
 	return 0;
 }
+
+int request_high_priority_wrapper(struct mali_session_data *session_data, _mali_uk_request_high_priority_s __user *uargs)
+{
+	_mali_uk_request_high_priority_s kargs;
+	_mali_osk_errcode_t err;
+
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+
+	kargs.ctx = session_data;
+	err = _mali_ukk_request_high_priority(&kargs);
+
+	kargs.ctx = NULL;
+
+	return map_errcode(err);
+}
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_gp.c b/drivers/gpu/mali/mali/linux/mali_ukk_gp.c
old mode 100644
new mode 100755
index 5cd5b33..573cabd
--- a/drivers/gpu/mali/mali/linux/mali_ukk_gp.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_gp.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,96 +18,74 @@
 
 int gp_start_job_wrapper(struct mali_session_data *session_data, _mali_uk_gp_start_job_s __user *uargs)
 {
-    _mali_uk_gp_start_job_s kargs;
-    _mali_osk_errcode_t err;
-
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
-
-	if (!access_ok(VERIFY_WRITE, uargs, sizeof(_mali_uk_gp_start_job_s)))
-	{
-		return -EFAULT;
-	}
-
-    if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_gp_start_job_s))) return -EFAULT;
-
-    kargs.ctx = session_data;
-    err = _mali_ukk_gp_start_job(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
-
-    kargs.ctx = NULL; /* prevent kernel address to be returned to user space */
-
-    if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_gp_start_job_s)))
-	{
-		/*
-		 * If this happens, then user space will not know that the job was actually started,
-		 * and if we return a queued job, then user space will still think that one is still queued.
-		 * This will typically lead to a deadlock in user space.
-		 * This could however only happen if user space deliberately passes a user buffer which
-		 * passes the access_ok(VERIFY_WRITE) check, but isn't fully writable at the time of copy_to_user().
-		 * The official Mali driver will never attempt to do that, and kernel space should not be affected.
-		 * That is why we do not bother to do a complex rollback in this very very very rare case.
-		 */
-		return -EFAULT;
-	}
-
-    return 0;
+	_mali_osk_errcode_t err;
+
+	/* If the job was started successfully, 0 is returned.  If there was an error, but the job
+	 * was started, we return -ENOENT.  For anything else returned, the job was not started. */
+
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
+
+	err = _mali_ukk_gp_start_job(session_data, uargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+
+	return 0;
 }
 
 int gp_get_core_version_wrapper(struct mali_session_data *session_data, _mali_uk_get_gp_core_version_s __user *uargs)
 {
-    _mali_uk_get_gp_core_version_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_get_gp_core_version_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    kargs.ctx = session_data;
-    err =  _mali_ukk_get_gp_core_version(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
+	err =  _mali_ukk_get_gp_core_version(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
 	/* no known transactions to roll-back */
 
-    if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
+	if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
 
-    return 0;
+	return 0;
 }
 
 int gp_suspend_response_wrapper(struct mali_session_data *session_data, _mali_uk_gp_suspend_response_s __user *uargs)
 {
-    _mali_uk_gp_suspend_response_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_gp_suspend_response_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_gp_suspend_response_s))) return -EFAULT;
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_gp_suspend_response_s))) return -EFAULT;
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_gp_suspend_response(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
+	err = _mali_ukk_gp_suspend_response(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-    if (0 != put_user(kargs.cookie, &uargs->cookie)) return -EFAULT;
+	if (0 != put_user(kargs.cookie, &uargs->cookie)) return -EFAULT;
 
-    /* no known transactions to roll-back */
-    return 0;
+	/* no known transactions to roll-back */
+	return 0;
 }
 
 int gp_get_number_of_cores_wrapper(struct mali_session_data *session_data, _mali_uk_get_gp_number_of_cores_s __user *uargs)
 {
-    _mali_uk_get_gp_number_of_cores_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_get_gp_number_of_cores_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_get_gp_number_of_cores(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
+	err = _mali_ukk_get_gp_number_of_cores(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
 	/* no known transactions to roll-back */
 
-    if (0 != put_user(kargs.number_of_cores, &uargs->number_of_cores)) return -EFAULT;
+	if (0 != put_user(kargs.number_of_cores, &uargs->number_of_cores)) return -EFAULT;
 
-    return 0;
+	return 0;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_mem.c b/drivers/gpu/mali/mali/linux/mali_ukk_mem.c
old mode 100644
new mode 100755
index 3951831..623e5aa
--- a/drivers/gpu/mali/mali/linux/mali_ukk_mem.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_mem.c
@@ -1,15 +1,14 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
 #include <linux/fs.h>       /* file system operations */
 #include <asm/uaccess.h>    /* user space access */
-#include <plat/memory.h>
 
 #include "mali_ukk.h"
 #include "mali_osk.h"
@@ -17,245 +16,222 @@
 #include "mali_session.h"
 #include "mali_ukk_wrappers.h"
 
-int mem_init_wrapper(struct mali_session_data *session_data, _mali_uk_init_mem_s __user *uargs)
+int mem_write_safe_wrapper(struct mali_session_data *session_data, _mali_uk_mem_write_safe_s __user *uargs)
 {
-    _mali_uk_init_mem_s kargs;
-    _mali_osk_errcode_t err;
-
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-
-    kargs.ctx = session_data;
-    err = _mali_ukk_init_mem(&kargs);
-    if (_MALI_OSK_ERR_OK != err)
-    {
-        return map_errcode(err);
-    }
-
-    if (0 != put_user(kargs.mali_address_base, &uargs->mali_address_base)) goto mem_init_rollback;
-    if (0 != put_user(kargs.memory_size, &uargs->memory_size)) goto mem_init_rollback;
-
-    return 0;
-
-mem_init_rollback:
-	{
-		_mali_uk_term_mem_s kargs;
-		kargs.ctx = session_data;
-		err = _mali_ukk_term_mem(&kargs);
-		if (_MALI_OSK_ERR_OK != err)
-		{
-			MALI_DEBUG_PRINT(4, ("reverting _mali_ukk_init_mem, as a result of failing put_user(), failed\n"));
-		}
+	_mali_uk_mem_write_safe_s kargs;
+	_mali_osk_errcode_t err;
+
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
+
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_mem_write_safe_s))) {
+		return -EFAULT;
 	}
-    return -EFAULT;
-}
 
-int mem_term_wrapper(struct mali_session_data *session_data, _mali_uk_term_mem_s __user *uargs)
-{
-    _mali_uk_term_mem_s kargs;
-    _mali_osk_errcode_t err;
+	kargs.ctx = session_data;
+
+	/* Check if we can access the buffers */
+	if (!access_ok(VERIFY_WRITE, kargs.dest, kargs.size)
+	    || !access_ok(VERIFY_READ, kargs.src, kargs.size)) {
+		return -EINVAL;
+	}
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	/* Check if size wraps */
+	if ((kargs.size + kargs.dest) <= kargs.dest
+	    || (kargs.size + kargs.src) <= kargs.src) {
+		return -EINVAL;
+	}
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_term_mem(&kargs);
-    if (_MALI_OSK_ERR_OK != err)
-    {
-        return map_errcode(err);
-    }
+	err = _mali_ukk_mem_write_safe(&kargs);
+	if (_MALI_OSK_ERR_OK != err) {
+		return map_errcode(err);
+	}
 
-    return 0;
+	if (0 != put_user(kargs.size, &uargs->size)) {
+		return -EFAULT;
+	}
+
+	return 0;
 }
 
-int mem_map_ext_wrapper(struct mali_session_data *session_data, _mali_uk_map_external_mem_s __user * argument)
+int mem_map_ext_wrapper(struct mali_session_data *session_data, _mali_uk_map_external_mem_s __user *argument)
 {
 	_mali_uk_map_external_mem_s uk_args;
 	_mali_osk_errcode_t err_code;
 
 	/* validate input */
 	/* the session_data pointer was validated by caller */
-    MALI_CHECK_NON_NULL( argument, -EINVAL);
+	MALI_CHECK_NON_NULL(argument, -EINVAL);
 
 	/* get call arguments from user space. copy_from_user returns how many bytes which where NOT copied */
-	if ( 0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_map_external_mem_s)) )
-	{
+	if (0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_map_external_mem_s))) {
 		return -EFAULT;
 	}
 
 	uk_args.ctx = session_data;
+	err_code = _mali_ukk_map_external_mem(&uk_args);
+
+	if (0 != put_user(uk_args.cookie, &argument->cookie)) {
+		if (_MALI_OSK_ERR_OK == err_code) {
+			/* Rollback */
+			_mali_uk_unmap_external_mem_s uk_args_unmap;
+
+			uk_args_unmap.ctx = session_data;
+			uk_args_unmap.cookie = uk_args.cookie;
+			err_code = _mali_ukk_unmap_external_mem(&uk_args_unmap);
+			if (_MALI_OSK_ERR_OK != err_code) {
+				MALI_DEBUG_PRINT(4, ("reverting _mali_ukk_unmap_external_mem, as a result of failing put_user(), failed\n"));
+			}
+		}
+		return -EFAULT;
+	}
 
-	err_code = _mali_ukk_map_external_mem( &uk_args );
-
-	if (0 != put_user(uk_args.cookie, &argument->cookie))
-	{
-        if (_MALI_OSK_ERR_OK == err_code)
-        {
-            /* Rollback */
-           	_mali_uk_unmap_external_mem_s uk_args_unmap;
-
-            uk_args_unmap.ctx = session_data;
-            uk_args_unmap.cookie = uk_args.cookie;
-            err_code = _mali_ukk_unmap_external_mem( &uk_args_unmap );
-            if (_MALI_OSK_ERR_OK != err_code)
-            {
-                MALI_DEBUG_PRINT(4, ("reverting _mali_ukk_unmap_external_mem, as a result of failing put_user(), failed\n"));
-            }
-        }
-        return -EFAULT;
-    }
-
-    /* Return the error that _mali_ukk_free_big_block produced */
+	/* Return the error that _mali_ukk_free_big_block produced */
 	return map_errcode(err_code);
 }
 
-int mem_unmap_ext_wrapper(struct mali_session_data *session_data, _mali_uk_unmap_external_mem_s __user * argument)
+int mem_unmap_ext_wrapper(struct mali_session_data *session_data, _mali_uk_unmap_external_mem_s __user *argument)
 {
 	_mali_uk_unmap_external_mem_s uk_args;
 	_mali_osk_errcode_t err_code;
 
 	/* validate input */
 	/* the session_data pointer was validated by caller */
-    MALI_CHECK_NON_NULL( argument, -EINVAL);
+	MALI_CHECK_NON_NULL(argument, -EINVAL);
 
 	/* get call arguments from user space. copy_from_user returns how many bytes which where NOT copied */
-	if ( 0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_unmap_external_mem_s)) )
-	{
+	if (0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_unmap_external_mem_s))) {
 		return -EFAULT;
 	}
 
-    uk_args.ctx = session_data;
-	err_code = _mali_ukk_unmap_external_mem( &uk_args );
+	uk_args.ctx = session_data;
+	err_code = _mali_ukk_unmap_external_mem(&uk_args);
 
 	/* Return the error that _mali_ukk_free_big_block produced */
 	return map_errcode(err_code);
 }
 
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-int mem_release_ump_wrapper(struct mali_session_data *session_data, _mali_uk_release_ump_mem_s __user * argument)
+#if defined(CONFIG_MALI400_UMP)
+int mem_release_ump_wrapper(struct mali_session_data *session_data, _mali_uk_release_ump_mem_s __user *argument)
 {
 	_mali_uk_release_ump_mem_s uk_args;
 	_mali_osk_errcode_t err_code;
 
 	/* validate input */
 	/* the session_data pointer was validated by caller */
-    MALI_CHECK_NON_NULL( argument, -EINVAL);
+	MALI_CHECK_NON_NULL(argument, -EINVAL);
 
 	/* get call arguments from user space. copy_from_user returns how many bytes which where NOT copied */
-	if ( 0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_release_ump_mem_s)) )
-	{
+	if (0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_release_ump_mem_s))) {
 		return -EFAULT;
 	}
 
-    uk_args.ctx = session_data;
-	err_code = _mali_ukk_release_ump_mem( &uk_args );
+	uk_args.ctx = session_data;
+	err_code = _mali_ukk_release_ump_mem(&uk_args);
 
 	/* Return the error that _mali_ukk_free_big_block produced */
 	return map_errcode(err_code);
 }
 
-int mem_attach_ump_wrapper(struct mali_session_data *session_data, _mali_uk_attach_ump_mem_s __user * argument)
+int mem_attach_ump_wrapper(struct mali_session_data *session_data, _mali_uk_attach_ump_mem_s __user *argument)
 {
 	_mali_uk_attach_ump_mem_s uk_args;
 	_mali_osk_errcode_t err_code;
 
 	/* validate input */
 	/* the session_data pointer was validated by caller */
-    MALI_CHECK_NON_NULL( argument, -EINVAL);
+	MALI_CHECK_NON_NULL(argument, -EINVAL);
 
 	/* get call arguments from user space. copy_from_user returns how many bytes which where NOT copied */
-	if ( 0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_attach_ump_mem_s)) )
-	{
+	if (0 != copy_from_user(&uk_args, (void __user *)argument, sizeof(_mali_uk_attach_ump_mem_s))) {
+		return -EFAULT;
+	}
+
+	uk_args.ctx = session_data;
+	err_code = _mali_ukk_attach_ump_mem(&uk_args);
+
+	if (0 != put_user(uk_args.cookie, &argument->cookie)) {
+		if (_MALI_OSK_ERR_OK == err_code) {
+			/* Rollback */
+			_mali_uk_release_ump_mem_s uk_args_unmap;
+
+			uk_args_unmap.ctx = session_data;
+			uk_args_unmap.cookie = uk_args.cookie;
+			err_code = _mali_ukk_release_ump_mem(&uk_args_unmap);
+			if (_MALI_OSK_ERR_OK != err_code) {
+				MALI_DEBUG_PRINT(4, ("reverting _mali_ukk_attach_mem, as a result of failing put_user(), failed\n"));
+			}
+		}
 		return -EFAULT;
 	}
 
-    uk_args.ctx = session_data;
-	err_code = _mali_ukk_attach_ump_mem( &uk_args );
-
-    if (0 != put_user(uk_args.cookie, &argument->cookie))
-    {
-        if (_MALI_OSK_ERR_OK == err_code)
-        {
-            /* Rollback */
-           	_mali_uk_release_ump_mem_s uk_args_unmap;
-
-            uk_args_unmap.ctx = session_data;
-            uk_args_unmap.cookie = uk_args.cookie;
-            err_code = _mali_ukk_release_ump_mem( &uk_args_unmap );
-            if (_MALI_OSK_ERR_OK != err_code)
-            {
-                MALI_DEBUG_PRINT(4, ("reverting _mali_ukk_attach_mem, as a result of failing put_user(), failed\n"));
-            }
-        }
-        return -EFAULT;
-    }
-
-    /* Return the error that _mali_ukk_map_external_ump_mem produced */
+	/* Return the error that _mali_ukk_map_external_ump_mem produced */
 	return map_errcode(err_code);
 }
-#endif /* MALI_USE_UNIFIED_MEMORY_PROVIDER */
+#endif /* CONFIG_MALI400_UMP */
 
-int mem_query_mmu_page_table_dump_size_wrapper(struct mali_session_data *session_data, _mali_uk_query_mmu_page_table_dump_size_s __user * uargs)
+int mem_query_mmu_page_table_dump_size_wrapper(struct mali_session_data *session_data, _mali_uk_query_mmu_page_table_dump_size_s __user *uargs)
 {
-    _mali_uk_query_mmu_page_table_dump_size_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_query_mmu_page_table_dump_size_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    kargs.ctx = session_data;
+	kargs.ctx = session_data;
 
-    err = _mali_ukk_query_mmu_page_table_dump_size(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	err = _mali_ukk_query_mmu_page_table_dump_size(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-    if (0 != put_user(kargs.size, &uargs->size)) return -EFAULT;
+	if (0 != put_user(kargs.size, &uargs->size)) return -EFAULT;
 
-    return 0;
+	return 0;
 }
 
-int mem_dump_mmu_page_table_wrapper(struct mali_session_data *session_data, _mali_uk_dump_mmu_page_table_s __user * uargs)
+int mem_dump_mmu_page_table_wrapper(struct mali_session_data *session_data, _mali_uk_dump_mmu_page_table_s __user *uargs)
 {
-    _mali_uk_dump_mmu_page_table_s kargs;
-    _mali_osk_errcode_t err;
-    void *buffer;
-    int rc = -EFAULT;
+	_mali_uk_dump_mmu_page_table_s kargs;
+	_mali_osk_errcode_t err;
+	void *buffer;
+	int rc = -EFAULT;
 
 	/* validate input */
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 	/* the session_data pointer was validated by caller */
 
-    kargs.buffer = NULL;
+	kargs.buffer = NULL;
 
-    /* get location of user buffer */
+	/* get location of user buffer */
 	if (0 != get_user(buffer, &uargs->buffer)) goto err_exit;
 	/* get size of mmu page table info buffer from user space */
-	if ( 0 != get_user(kargs.size, &uargs->size) ) goto err_exit;
-    /* verify we can access the whole of the user buffer */
-    if (!access_ok(VERIFY_WRITE, buffer, kargs.size)) goto err_exit;
-
-    /* allocate temporary buffer (kernel side) to store mmu page table info */
-    kargs.buffer = _mali_osk_valloc(kargs.size);
-    if (NULL == kargs.buffer)
-    {
-        rc = -ENOMEM;
-        goto err_exit;
-    }
-
-    kargs.ctx = session_data;
-    err = _mali_ukk_dump_mmu_page_table(&kargs);
-    if (_MALI_OSK_ERR_OK != err)
-    {
-        rc = map_errcode(err);
-        goto err_exit;
-    }
-
-    /* copy mmu page table info back to user space and update pointers */
-	if (0 != copy_to_user(uargs->buffer, kargs.buffer, kargs.size) ) goto err_exit;
-    if (0 != put_user((kargs.register_writes - (u32 *)kargs.buffer) + (u32 *)uargs->buffer, &uargs->register_writes)) goto err_exit;
-    if (0 != put_user((kargs.page_table_dump - (u32 *)kargs.buffer) + (u32 *)uargs->buffer, &uargs->page_table_dump)) goto err_exit;
-    if (0 != put_user(kargs.register_writes_size, &uargs->register_writes_size)) goto err_exit;
-    if (0 != put_user(kargs.page_table_dump_size, &uargs->page_table_dump_size)) goto err_exit;
-    rc = 0;
+	if (0 != get_user(kargs.size, &uargs->size)) goto err_exit;
+	/* verify we can access the whole of the user buffer */
+	if (!access_ok(VERIFY_WRITE, buffer, kargs.size)) goto err_exit;
+
+	/* allocate temporary buffer (kernel side) to store mmu page table info */
+	MALI_CHECK(kargs.size > 0, -ENOMEM);
+	kargs.buffer = _mali_osk_valloc(kargs.size);
+	if (NULL == kargs.buffer) {
+		rc = -ENOMEM;
+		goto err_exit;
+	}
+
+	kargs.ctx = session_data;
+	err = _mali_ukk_dump_mmu_page_table(&kargs);
+	if (_MALI_OSK_ERR_OK != err) {
+		rc = map_errcode(err);
+		goto err_exit;
+	}
+
+	/* copy mmu page table info back to user space and update pointers */
+	if (0 != copy_to_user(uargs->buffer, kargs.buffer, kargs.size)) goto err_exit;
+	if (0 != put_user((kargs.register_writes - (u32 *)kargs.buffer) + (u32 *)uargs->buffer, &uargs->register_writes)) goto err_exit;
+	if (0 != put_user((kargs.page_table_dump - (u32 *)kargs.buffer) + (u32 *)uargs->buffer, &uargs->page_table_dump)) goto err_exit;
+	if (0 != put_user(kargs.register_writes_size, &uargs->register_writes_size)) goto err_exit;
+	if (0 != put_user(kargs.page_table_dump_size, &uargs->page_table_dump_size)) goto err_exit;
+	rc = 0;
 
 err_exit:
-    if (kargs.buffer) _mali_osk_vfree(kargs.buffer);
-    return rc;
+	if (kargs.buffer) _mali_osk_vfree(kargs.buffer);
+	return rc;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_pp.c b/drivers/gpu/mali/mali/linux/mali_ukk_pp.c
old mode 100644
new mode 100755
index 43f49c6..9ed9acf
--- a/drivers/gpu/mali/mali/linux/mali_ukk_pp.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_pp.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,71 +18,88 @@
 
 int pp_start_job_wrapper(struct mali_session_data *session_data, _mali_uk_pp_start_job_s __user *uargs)
 {
-	_mali_uk_pp_start_job_s kargs;
 	_mali_osk_errcode_t err;
 
+	/* If the job was started successfully, 0 is returned.  If there was an error, but the job
+	 * was started, we return -ENOENT.  For anything else returned, the job was not started. */
+
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-	if (!access_ok(VERIFY_WRITE, uargs, sizeof(_mali_uk_pp_start_job_s)))
-	{
-		return -EFAULT;
-	}
+	err = _mali_ukk_pp_start_job(session_data, uargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_pp_start_job_s))) return -EFAULT;
+	return 0;
+}
 
-	kargs.ctx = session_data;
-	err = _mali_ukk_pp_start_job(&kargs);
+int pp_and_gp_start_job_wrapper(struct mali_session_data *session_data, _mali_uk_pp_and_gp_start_job_s __user *uargs)
+{
+	_mali_osk_errcode_t err;
+
+	/* If the jobs were started successfully, 0 is returned.  If there was an error, but the
+	 * jobs were started, we return -ENOENT.  For anything else returned, the jobs were not
+	 * started. */
+
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
+
+	err = _mali_ukk_pp_and_gp_start_job(session_data, uargs);
 	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-    return 0;
+	return 0;
 }
 
 int pp_get_number_of_cores_wrapper(struct mali_session_data *session_data, _mali_uk_get_pp_number_of_cores_s __user *uargs)
 {
-    _mali_uk_get_pp_number_of_cores_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_get_pp_number_of_cores_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_get_pp_number_of_cores(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
 
-    if (0 != put_user(kargs.number_of_cores, &uargs->number_of_cores)) return -EFAULT;
+	err = _mali_ukk_get_pp_number_of_cores(&kargs);
+	if (_MALI_OSK_ERR_OK != err) {
+		return map_errcode(err);
+	}
 
-    return 0;
+	kargs.ctx = NULL; /* prevent kernel address to be returned to user space */
+	if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_get_pp_number_of_cores_s))) {
+		return -EFAULT;
+	}
+
+	return 0;
 }
 
 int pp_get_core_version_wrapper(struct mali_session_data *session_data, _mali_uk_get_pp_core_version_s __user *uargs)
 {
-    _mali_uk_get_pp_core_version_s kargs;
-    _mali_osk_errcode_t err;
+	_mali_uk_get_pp_core_version_s kargs;
+	_mali_osk_errcode_t err;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    kargs.ctx = session_data;
-    err = _mali_ukk_get_pp_core_version(&kargs);
-    if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
+	kargs.ctx = session_data;
+	err = _mali_ukk_get_pp_core_version(&kargs);
+	if (_MALI_OSK_ERR_OK != err) return map_errcode(err);
 
-    if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
+	if (0 != put_user(kargs.version, &uargs->version)) return -EFAULT;
 
-    return 0;
+	return 0;
 }
 
 int pp_disable_wb_wrapper(struct mali_session_data *session_data, _mali_uk_pp_disable_wb_s __user *uargs)
 {
 	_mali_uk_pp_disable_wb_s kargs;
 
-    MALI_CHECK_NON_NULL(uargs, -EINVAL);
-    MALI_CHECK_NON_NULL(session_data, -EINVAL);
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
 
-    if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_pp_disable_wb_s))) return -EFAULT;
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_pp_disable_wb_s))) return -EFAULT;
 
-    kargs.ctx = session_data;
-    _mali_ukk_pp_job_disable_wb(&kargs);
+	kargs.ctx = session_data;
+	_mali_ukk_pp_job_disable_wb(&kargs);
 
-    return 0;
+	return 0;
 }
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_profiling.c b/drivers/gpu/mali/mali/linux/mali_ukk_profiling.c
old mode 100644
new mode 100755
index 4e6c745..e918032
--- a/drivers/gpu/mali/mali/linux/mali_ukk_profiling.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_profiling.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -24,20 +24,17 @@ int profiling_start_wrapper(struct mali_session_data *session_data, _mali_uk_pro
 
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_profiling_start_s)))
-	{
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_profiling_start_s))) {
 		return -EFAULT;
 	}
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_profiling_start(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
-	if (0 != put_user(kargs.limit, &uargs->limit))
-	{
+	if (0 != put_user(kargs.limit, &uargs->limit)) {
 		return -EFAULT;
 	}
 
@@ -51,15 +48,13 @@ int profiling_add_event_wrapper(struct mali_session_data *session_data, _mali_uk
 
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_profiling_add_event_s)))
-	{
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_profiling_add_event_s))) {
 		return -EFAULT;
 	}
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_profiling_add_event(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
@@ -75,13 +70,11 @@ int profiling_stop_wrapper(struct mali_session_data *session_data, _mali_uk_prof
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_profiling_stop(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
-	if (0 != put_user(kargs.count, &uargs->count))
-	{
+	if (0 != put_user(kargs.count, &uargs->count)) {
 		return -EFAULT;
 	}
 
@@ -95,22 +88,19 @@ int profiling_get_event_wrapper(struct mali_session_data *session_data, _mali_uk
 
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-	if (0 != get_user(kargs.index, &uargs->index))
-	{
+	if (0 != get_user(kargs.index, &uargs->index)) {
 		return -EFAULT;
 	}
 
 	kargs.ctx = session_data;
 
 	err = _mali_ukk_profiling_get_event(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
 	kargs.ctx = NULL; /* prevent kernel address to be returned to user space */
-	if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_profiling_get_event_s)))
-	{
+	if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_profiling_get_event_s))) {
 		return -EFAULT;
 	}
 
@@ -126,14 +116,35 @@ int profiling_clear_wrapper(struct mali_session_data *session_data, _mali_uk_pro
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_profiling_clear(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
 	return 0;
 }
 
+int profiling_memory_usage_get_wrapper(struct mali_session_data *session_data, _mali_uk_profiling_memory_usage_get_s __user *uargs)
+{
+	_mali_osk_errcode_t err;
+	_mali_uk_profiling_memory_usage_get_s kargs;
+
+	MALI_CHECK_NON_NULL(uargs, -EINVAL);
+	MALI_CHECK_NON_NULL(session_data, -EINVAL);
+
+	kargs.ctx = session_data;
+	err = _mali_ukk_profiling_memory_usage_get(&kargs);
+	if (_MALI_OSK_ERR_OK != err) {
+		return map_errcode(err);
+	}
+
+	kargs.ctx = NULL; /* prevent kernel address to be returned to user space */
+	if (0 != copy_to_user(uargs, &kargs, sizeof(_mali_uk_profiling_memory_usage_get_s))) {
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
 int profiling_report_sw_counters_wrapper(struct mali_session_data *session_data, _mali_uk_sw_counters_report_s __user *uargs)
 {
 	_mali_uk_sw_counters_report_s kargs;
@@ -142,8 +153,7 @@ int profiling_report_sw_counters_wrapper(struct mali_session_data *session_data,
 
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_sw_counters_report_s)))
-	{
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_sw_counters_report_s))) {
 		return -EFAULT;
 	}
 
@@ -153,14 +163,12 @@ int profiling_report_sw_counters_wrapper(struct mali_session_data *session_data,
 		return -EINVAL;
 	}
 
-	counter_buffer = (u32*)kmalloc(sizeof(u32) * kargs.num_counters, GFP_KERNEL);
-	if (NULL == counter_buffer)
-	{
+	counter_buffer = (u32 *)kmalloc(sizeof(u32) * kargs.num_counters, GFP_KERNEL);
+	if (NULL == counter_buffer) {
 		return -ENOMEM;
 	}
 
-	if (0 != copy_from_user(counter_buffer, kargs.counters, sizeof(u32) * kargs.num_counters))
-	{
+	if (0 != copy_from_user(counter_buffer, kargs.counters, sizeof(u32) * kargs.num_counters)) {
 		kfree(counter_buffer);
 		return -EFAULT;
 	}
@@ -172,10 +180,11 @@ int profiling_report_sw_counters_wrapper(struct mali_session_data *session_data,
 
 	kfree(counter_buffer);
 
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
 	return 0;
 }
+
+
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_vsync.c b/drivers/gpu/mali/mali/linux/mali_ukk_vsync.c
old mode 100644
new mode 100755
index 87d5aaf..bf5f357
--- a/drivers/gpu/mali/mali/linux/mali_ukk_vsync.c
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_vsync.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2011-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2011-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -24,17 +24,16 @@ int vsync_event_report_wrapper(struct mali_session_data *session_data, _mali_uk_
 
 	MALI_CHECK_NON_NULL(uargs, -EINVAL);
 
-	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_vsync_event_report_s)))
-	{
+	if (0 != copy_from_user(&kargs, uargs, sizeof(_mali_uk_vsync_event_report_s))) {
 		return -EFAULT;
 	}
 
 	kargs.ctx = session_data;
 	err = _mali_ukk_vsync_event_report(&kargs);
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		return map_errcode(err);
 	}
 
 	return 0;
 }
+
diff --git a/drivers/gpu/mali/mali/linux/mali_ukk_wrappers.h b/drivers/gpu/mali/mali/linux/mali_ukk_wrappers.h
old mode 100644
new mode 100755
index 0578be5..793393c
--- a/drivers/gpu/mali/mali/linux/mali_ukk_wrappers.h
+++ b/drivers/gpu/mali/mali/linux/mali_ukk_wrappers.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,29 +20,34 @@
 #include "mali_osk.h"
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
-int get_system_info_size_wrapper(struct mali_session_data *session_data, _mali_uk_get_system_info_size_s __user *uargs);
-int get_system_info_wrapper(struct mali_session_data *session_data, _mali_uk_get_system_info_s __user *uargs);
 int wait_for_notification_wrapper(struct mali_session_data *session_data, _mali_uk_wait_for_notification_s __user *uargs);
 int get_api_version_wrapper(struct mali_session_data *session_data, _mali_uk_get_api_version_s __user *uargs);
 int get_user_settings_wrapper(struct mali_session_data *session_data, _mali_uk_get_user_settings_s __user *uargs);
 int post_notification_wrapper(struct mali_session_data *session_data, _mali_uk_post_notification_s __user *uargs);
-int mem_init_wrapper(struct mali_session_data *session_data, _mali_uk_init_mem_s __user *uargs);
-int mem_term_wrapper(struct mali_session_data *session_data, _mali_uk_term_mem_s __user *uargs);
-int mem_map_ext_wrapper(struct mali_session_data *session_data, _mali_uk_map_external_mem_s __user * argument);
-int mem_unmap_ext_wrapper(struct mali_session_data *session_data, _mali_uk_unmap_external_mem_s __user * argument);
-int mem_query_mmu_page_table_dump_size_wrapper(struct mali_session_data *session_data, _mali_uk_query_mmu_page_table_dump_size_s __user * uargs);
-int mem_dump_mmu_page_table_wrapper(struct mali_session_data *session_data, _mali_uk_dump_mmu_page_table_s __user * uargs);
+int request_high_priority_wrapper(struct mali_session_data *session_data, _mali_uk_request_high_priority_s __user *uargs);
 
-#if MALI_USE_UNIFIED_MEMORY_PROVIDER != 0
-int mem_attach_ump_wrapper(struct mali_session_data *session_data, _mali_uk_attach_ump_mem_s __user * argument);
-int mem_release_ump_wrapper(struct mali_session_data *session_data, _mali_uk_release_ump_mem_s __user * argument);
-#endif /* MALI_USE_UNIFIED_MEMORY_PROVIDER */
+int mem_write_safe_wrapper(struct mali_session_data *session_data, _mali_uk_mem_write_safe_s __user *uargs);
+int mem_map_ext_wrapper(struct mali_session_data *session_data, _mali_uk_map_external_mem_s __user *argument);
+int mem_unmap_ext_wrapper(struct mali_session_data *session_data, _mali_uk_unmap_external_mem_s __user *argument);
+int mem_query_mmu_page_table_dump_size_wrapper(struct mali_session_data *session_data, _mali_uk_query_mmu_page_table_dump_size_s __user *uargs);
+int mem_dump_mmu_page_table_wrapper(struct mali_session_data *session_data, _mali_uk_dump_mmu_page_table_s __user *uargs);
+
+int timeline_get_latest_point_wrapper(struct mali_session_data *session, _mali_uk_timeline_get_latest_point_s __user *uargs);
+int timeline_wait_wrapper(struct mali_session_data *session, _mali_uk_timeline_wait_s __user *uargs);
+int timeline_create_sync_fence_wrapper(struct mali_session_data *session, _mali_uk_timeline_create_sync_fence_s __user *uargs);
+int soft_job_start_wrapper(struct mali_session_data *session, _mali_uk_soft_job_start_s __user *uargs);
+int soft_job_signal_wrapper(struct mali_session_data *session, _mali_uk_soft_job_signal_s __user *uargs);
+
+#if defined(CONFIG_MALI400_UMP)
+int mem_attach_ump_wrapper(struct mali_session_data *session_data, _mali_uk_attach_ump_mem_s __user *argument);
+int mem_release_ump_wrapper(struct mali_session_data *session_data, _mali_uk_release_ump_mem_s __user *argument);
+#endif
 
 int pp_start_job_wrapper(struct mali_session_data *session_data, _mali_uk_pp_start_job_s __user *uargs);
+int pp_and_gp_start_job_wrapper(struct mali_session_data *session_data, _mali_uk_pp_and_gp_start_job_s __user *uargs);
 int pp_get_number_of_cores_wrapper(struct mali_session_data *session_data, _mali_uk_get_pp_number_of_cores_s __user *uargs);
 int pp_get_core_version_wrapper(struct mali_session_data *session_data, _mali_uk_get_pp_core_version_s __user *uargs);
 int pp_disable_wb_wrapper(struct mali_session_data *session_data, _mali_uk_pp_disable_wb_s __user *uargs);
@@ -57,11 +62,12 @@ int profiling_stop_wrapper(struct mali_session_data *session_data, _mali_uk_prof
 int profiling_get_event_wrapper(struct mali_session_data *session_data, _mali_uk_profiling_get_event_s __user *uargs);
 int profiling_clear_wrapper(struct mali_session_data *session_data, _mali_uk_profiling_clear_s __user *uargs);
 int profiling_report_sw_counters_wrapper(struct mali_session_data *session_data, _mali_uk_sw_counters_report_s __user *uargs);
+int profiling_memory_usage_get_wrapper(struct mali_session_data *session_data, _mali_uk_profiling_memory_usage_get_s __user *uargs);
 
 int vsync_event_report_wrapper(struct mali_session_data *session_data, _mali_uk_vsync_event_report_s __user *uargs);
 
 
-int map_errcode( _mali_osk_errcode_t err );
+int map_errcode(_mali_osk_errcode_t err);
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/mali/regs/mali_200_regs.h b/drivers/gpu/mali/mali/regs/mali_200_regs.h
index d48d40d..22806db 100644
--- a/drivers/gpu/mali/mali/regs/mali_200_regs.h
+++ b/drivers/gpu/mali/mali/regs/mali_200_regs.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,8 +14,7 @@
 /**
  *  Enum for management register addresses.
  */
-enum mali200_mgmt_reg
-{
+enum mali200_mgmt_reg {
 	MALI200_REG_ADDR_MGMT_VERSION                              = 0x1000,
 	MALI200_REG_ADDR_MGMT_CURRENT_REND_LIST_ADDR               = 0x1004,
 	MALI200_REG_ADDR_MGMT_STATUS                               = 0x1008,
@@ -38,6 +37,9 @@ enum mali200_mgmt_reg
 	MALI200_REG_ADDR_MGMT_PERF_CNT_1_SRC                       = 0x10a4,
 	MALI200_REG_ADDR_MGMT_PERF_CNT_1_VALUE                     = 0x10ac,
 
+	MALI200_REG_ADDR_MGMT_PERFMON_CONTR                        = 0x10b0,
+	MALI200_REG_ADDR_MGMT_PERFMON_BASE                         = 0x10b4,
+
 	MALI200_REG_SIZEOF_REGISTER_BANK                           = 0x10f0
 
 };
@@ -45,123 +47,79 @@ enum mali200_mgmt_reg
 #define MALI200_REG_VAL_PERF_CNT_ENABLE 1
 
 enum mali200_mgmt_ctrl_mgmt {
-	MALI200_REG_VAL_CTRL_MGMT_STOP_BUS         = (1<<0),
-#if defined(USING_MALI200)
-	MALI200_REG_VAL_CTRL_MGMT_FLUSH_CACHES     = (1<<3),
-#endif
-	MALI200_REG_VAL_CTRL_MGMT_FORCE_RESET      = (1<<5),
-	MALI200_REG_VAL_CTRL_MGMT_START_RENDERING  = (1<<6),
-#if defined(USING_MALI400) || defined(USING_MALI450)
-	MALI400PP_REG_VAL_CTRL_MGMT_SOFT_RESET     = (1<<7),
-#endif
+	MALI200_REG_VAL_CTRL_MGMT_STOP_BUS         = (1 << 0),
+	MALI200_REG_VAL_CTRL_MGMT_FLUSH_CACHES     = (1 << 3),
+	MALI200_REG_VAL_CTRL_MGMT_FORCE_RESET      = (1 << 5),
+	MALI200_REG_VAL_CTRL_MGMT_START_RENDERING  = (1 << 6),
+	MALI400PP_REG_VAL_CTRL_MGMT_SOFT_RESET     = (1 << 7), /* Only valid for Mali-300 and later */
 };
 
 enum mali200_mgmt_irq {
-	MALI200_REG_VAL_IRQ_END_OF_FRAME          = (1<<0),
-	MALI200_REG_VAL_IRQ_END_OF_TILE           = (1<<1),
-	MALI200_REG_VAL_IRQ_HANG                  = (1<<2),
-	MALI200_REG_VAL_IRQ_FORCE_HANG            = (1<<3),
-	MALI200_REG_VAL_IRQ_BUS_ERROR             = (1<<4),
-	MALI200_REG_VAL_IRQ_BUS_STOP              = (1<<5),
-	MALI200_REG_VAL_IRQ_CNT_0_LIMIT           = (1<<6),
-	MALI200_REG_VAL_IRQ_CNT_1_LIMIT           = (1<<7),
-	MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR  = (1<<8),
-	MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND = (1<<9),
-	MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW  = (1<<10),
-	MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW   = (1<<11),
-	MALI400PP_REG_VAL_IRQ_RESET_COMPLETED       = (1<<12),
+	MALI200_REG_VAL_IRQ_END_OF_FRAME          = (1 << 0),
+	MALI200_REG_VAL_IRQ_END_OF_TILE           = (1 << 1),
+	MALI200_REG_VAL_IRQ_HANG                  = (1 << 2),
+	MALI200_REG_VAL_IRQ_FORCE_HANG            = (1 << 3),
+	MALI200_REG_VAL_IRQ_BUS_ERROR             = (1 << 4),
+	MALI200_REG_VAL_IRQ_BUS_STOP              = (1 << 5),
+	MALI200_REG_VAL_IRQ_CNT_0_LIMIT           = (1 << 6),
+	MALI200_REG_VAL_IRQ_CNT_1_LIMIT           = (1 << 7),
+	MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR  = (1 << 8),
+	MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND = (1 << 9),
+	MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW  = (1 << 10),
+	MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW   = (1 << 11),
+	MALI400PP_REG_VAL_IRQ_RESET_COMPLETED       = (1 << 12),
 };
 
-#if defined(USING_MALI200)
-#define MALI200_REG_VAL_IRQ_MASK_ALL  ((enum mali200_mgmt_irq) (\
-    MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
-    MALI200_REG_VAL_IRQ_END_OF_TILE                            |\
-    MALI200_REG_VAL_IRQ_HANG                                   |\
-    MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
-    MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
-    MALI200_REG_VAL_IRQ_BUS_STOP                               |\
-    MALI200_REG_VAL_IRQ_CNT_0_LIMIT                            |\
-    MALI200_REG_VAL_IRQ_CNT_1_LIMIT                            |\
-    MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR))
-#elif defined(USING_MALI400) || defined(USING_MALI450)
 #define MALI200_REG_VAL_IRQ_MASK_ALL  ((enum mali200_mgmt_irq) (\
-    MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
-    MALI200_REG_VAL_IRQ_END_OF_TILE                            |\
-    MALI200_REG_VAL_IRQ_HANG                                   |\
-    MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
-    MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
-    MALI200_REG_VAL_IRQ_BUS_STOP                               |\
-    MALI200_REG_VAL_IRQ_CNT_0_LIMIT                            |\
-    MALI200_REG_VAL_IRQ_CNT_1_LIMIT                            |\
-    MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR                   |\
-    MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND                  |\
-    MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW                   |\
-    MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW                    |\
-    MALI400PP_REG_VAL_IRQ_RESET_COMPLETED))
-#else
-#error "No supported mali core defined"
-#endif
-
-#if defined(USING_MALI200)
-#define MALI200_REG_VAL_IRQ_MASK_USED ((enum mali200_mgmt_irq) (\
-    MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
-    MALI200_REG_VAL_IRQ_HANG                                   |\
-    MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
-    MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
-    MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR))
-#elif defined(USING_MALI400) || defined(USING_MALI450)
+				       MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
+				       MALI200_REG_VAL_IRQ_END_OF_TILE                            |\
+				       MALI200_REG_VAL_IRQ_HANG                                   |\
+				       MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
+				       MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
+				       MALI200_REG_VAL_IRQ_BUS_STOP                               |\
+				       MALI200_REG_VAL_IRQ_CNT_0_LIMIT                            |\
+				       MALI200_REG_VAL_IRQ_CNT_1_LIMIT                            |\
+				       MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR                   |\
+				       MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND                  |\
+				       MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW                   |\
+				       MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW                    |\
+				       MALI400PP_REG_VAL_IRQ_RESET_COMPLETED))
+
 #define MALI200_REG_VAL_IRQ_MASK_USED ((enum mali200_mgmt_irq) (\
-    MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
-    MALI200_REG_VAL_IRQ_HANG                                   |\
-    MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
-    MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
-    MALI200_REG_VAL_IRQ_BUS_STOP                               |\
-    MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR                   |\
-    MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND                  |\
-    MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW                   |\
-    MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW))
-#else
-#error "No supported mali core defined"
-#endif
+				       MALI200_REG_VAL_IRQ_END_OF_FRAME                           |\
+				       MALI200_REG_VAL_IRQ_FORCE_HANG                             |\
+				       MALI200_REG_VAL_IRQ_BUS_ERROR                              |\
+				       MALI200_REG_VAL_IRQ_WRITE_BOUNDARY_ERROR                   |\
+				       MALI400PP_REG_VAL_IRQ_INVALID_PLIST_COMMAND                  |\
+				       MALI400PP_REG_VAL_IRQ_CALL_STACK_UNDERFLOW                   |\
+				       MALI400PP_REG_VAL_IRQ_CALL_STACK_OVERFLOW))
 
 #define MALI200_REG_VAL_IRQ_MASK_NONE ((enum mali200_mgmt_irq)(0))
 
 enum mali200_mgmt_status {
-	MALI200_REG_VAL_STATUS_RENDERING_ACTIVE     = (1<<0),
-	MALI200_REG_VAL_STATUS_BUS_STOPPED          = (1<<4),
+	MALI200_REG_VAL_STATUS_RENDERING_ACTIVE     = (1 << 0),
+	MALI200_REG_VAL_STATUS_BUS_STOPPED          = (1 << 4),
 };
 
-enum mali200_render_unit
-{
+enum mali200_render_unit {
 	MALI200_REG_ADDR_FRAME = 0x0000,
-	MALI200_REG_ADDR_STACK = 0x0030
+	MALI200_REG_ADDR_RSW   = 0x0004,
+	MALI200_REG_ADDR_STACK = 0x0030,
+	MALI200_REG_ADDR_STACK_SIZE = 0x0034,
+	MALI200_REG_ADDR_ORIGIN_OFFSET_X  = 0x0040
 };
 
-#if defined(USING_MALI200)
-#define MALI200_NUM_REGS_FRAME ((0x04C/4)+1)
-#elif defined(USING_MALI400)
-#define MALI200_NUM_REGS_FRAME ((0x058/4)+1)
-#elif defined(USING_MALI450)
-#define MALI200_NUM_REGS_FRAME ((0x058/4)+1)
-#else
-#error "No supported mali core defined"
-#endif
-
 enum mali200_wb_unit {
-    MALI200_REG_ADDR_WB0 = 0x0100,
-    MALI200_REG_ADDR_WB1 = 0x0200,
-    MALI200_REG_ADDR_WB2 = 0x0300
+	MALI200_REG_ADDR_WB0 = 0x0100,
+	MALI200_REG_ADDR_WB1 = 0x0200,
+	MALI200_REG_ADDR_WB2 = 0x0300
 };
 
 enum mali200_wb_unit_regs {
 	MALI200_REG_ADDR_WB_SOURCE_SELECT = 0x0000,
+	MALI200_REG_ADDR_WB_SOURCE_ADDR   = 0x0004,
 };
 
-/** The number of registers in one single writeback unit */
-#ifndef MALI200_NUM_REGS_WBx
-#define MALI200_NUM_REGS_WBx ((0x02C/4)+1)
-#endif
-
 /* This should be in the top 16 bit of the version register of Mali PP */
 #define MALI200_PP_PRODUCT_ID 0xC807
 #define MALI300_PP_PRODUCT_ID 0xCE07
diff --git a/drivers/gpu/mali/mali/regs/mali_gp_regs.h b/drivers/gpu/mali/mali/regs/mali_gp_regs.h
index a2006ea..7c9b5c8 100644
--- a/drivers/gpu/mali/mali/regs/mali_gp_regs.h
+++ b/drivers/gpu/mali/mali/regs/mali_gp_regs.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -52,17 +52,14 @@ typedef enum {
  * Commands to geometry processor.
  *  @see MALIGP2_CTRL_REG_CMD
  */
-typedef enum
-{
-	MALIGP2_REG_VAL_CMD_START_VS			= (1<< 0),
-	MALIGP2_REG_VAL_CMD_START_PLBU			= (1<< 1),
-	MALIGP2_REG_VAL_CMD_UPDATE_PLBU_ALLOC	= (1<< 4),
-	MALIGP2_REG_VAL_CMD_RESET				= (1<< 5),
-	MALIGP2_REG_VAL_CMD_FORCE_HANG			= (1<< 6),
-	MALIGP2_REG_VAL_CMD_STOP_BUS 			= (1<< 9),
-#if defined(USING_MALI400) || defined(USING_MALI450)
-	MALI400GP_REG_VAL_CMD_SOFT_RESET		= (1<<10),
-#endif
+typedef enum {
+	MALIGP2_REG_VAL_CMD_START_VS                    = (1 << 0),
+	MALIGP2_REG_VAL_CMD_START_PLBU                  = (1 << 1),
+	MALIGP2_REG_VAL_CMD_UPDATE_PLBU_ALLOC   = (1 << 4),
+	MALIGP2_REG_VAL_CMD_RESET                               = (1 << 5),
+	MALIGP2_REG_VAL_CMD_FORCE_HANG                  = (1 << 6),
+	MALIGP2_REG_VAL_CMD_STOP_BUS                    = (1 << 9),
+	MALI400GP_REG_VAL_CMD_SOFT_RESET                = (1 << 10), /* only valid for Mali-300 and later */
 } mgp_contr_reg_val_cmd;
 
 
@@ -84,7 +81,6 @@ typedef enum
 #define MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     (1 << 9)
 #define MALIGP2_REG_VAL_IRQ_SYNC_ERROR          (1 << 10)
 #define MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR       (1 << 11)
-#if defined(USING_MALI400) || defined(USING_MALI450)
 #define MALI400GP_REG_VAL_IRQ_AXI_BUS_STOPPED     (1 << 12)
 #define MALI400GP_REG_VAL_IRQ_VS_INVALID_CMD      (1 << 13)
 #define MALI400GP_REG_VAL_IRQ_PLB_INVALID_CMD     (1 << 14)
@@ -92,83 +88,45 @@ typedef enum
 #define MALI400GP_REG_VAL_IRQ_SEMAPHORE_UNDERFLOW (1 << 20)
 #define MALI400GP_REG_VAL_IRQ_SEMAPHORE_OVERFLOW  (1 << 21)
 #define MALI400GP_REG_VAL_IRQ_PTR_ARRAY_OUT_OF_BOUNDS  (1 << 22)
-#elif !defined USING_MALI200
-#error "No supported mali core defined"
-#endif
 
-/* Mask defining all IRQs in MaliGP2 */
-#if defined(USING_MALI200)
-#define MALIGP2_REG_VAL_IRQ_MASK_ALL \
-	(\
-		MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
-		MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
-		MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
-		MALIGP2_REG_VAL_IRQ_VS_SEM_IRQ          | \
-		MALIGP2_REG_VAL_IRQ_PLBU_SEM_IRQ        | \
-		MALIGP2_REG_VAL_IRQ_HANG                | \
-		MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
-		MALIGP2_REG_VAL_IRQ_PERF_CNT_0_LIMIT    | \
-		MALIGP2_REG_VAL_IRQ_PERF_CNT_1_LIMIT    | \
-		MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
-		MALIGP2_REG_VAL_IRQ_SYNC_ERROR          | \
-		MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR)
-#elif defined(USING_MALI400) || defined(USING_MALI450)
+/* Mask defining all IRQs in Mali GP */
 #define MALIGP2_REG_VAL_IRQ_MASK_ALL \
 	(\
-		MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
-		MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
-		MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
-		MALIGP2_REG_VAL_IRQ_VS_SEM_IRQ          | \
-		MALIGP2_REG_VAL_IRQ_PLBU_SEM_IRQ        | \
-		MALIGP2_REG_VAL_IRQ_HANG                | \
-		MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
-		MALIGP2_REG_VAL_IRQ_PERF_CNT_0_LIMIT    | \
-		MALIGP2_REG_VAL_IRQ_PERF_CNT_1_LIMIT    | \
-		MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
-		MALIGP2_REG_VAL_IRQ_SYNC_ERROR          | \
-		MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR       | \
-		MALI400GP_REG_VAL_IRQ_AXI_BUS_STOPPED     | \
-		MALI400GP_REG_VAL_IRQ_VS_INVALID_CMD      | \
-		MALI400GP_REG_VAL_IRQ_PLB_INVALID_CMD     | \
-		MALI400GP_REG_VAL_IRQ_RESET_COMPLETED     | \
-		MALI400GP_REG_VAL_IRQ_SEMAPHORE_UNDERFLOW | \
-		MALI400GP_REG_VAL_IRQ_SEMAPHORE_OVERFLOW  | \
-		MALI400GP_REG_VAL_IRQ_PTR_ARRAY_OUT_OF_BOUNDS)
-#else
-#error "No supported mali core defined"
-#endif
-
-/* Mask defining the IRQs in MaliGP2 which we use*/
-#if defined(USING_MALI200)
+	 MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
+	 MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
+	 MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
+	 MALIGP2_REG_VAL_IRQ_VS_SEM_IRQ          | \
+	 MALIGP2_REG_VAL_IRQ_PLBU_SEM_IRQ        | \
+	 MALIGP2_REG_VAL_IRQ_HANG                | \
+	 MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
+	 MALIGP2_REG_VAL_IRQ_PERF_CNT_0_LIMIT    | \
+	 MALIGP2_REG_VAL_IRQ_PERF_CNT_1_LIMIT    | \
+	 MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
+	 MALIGP2_REG_VAL_IRQ_SYNC_ERROR          | \
+	 MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR       | \
+	 MALI400GP_REG_VAL_IRQ_AXI_BUS_STOPPED     | \
+	 MALI400GP_REG_VAL_IRQ_VS_INVALID_CMD      | \
+	 MALI400GP_REG_VAL_IRQ_PLB_INVALID_CMD     | \
+	 MALI400GP_REG_VAL_IRQ_RESET_COMPLETED     | \
+	 MALI400GP_REG_VAL_IRQ_SEMAPHORE_UNDERFLOW | \
+	 MALI400GP_REG_VAL_IRQ_SEMAPHORE_OVERFLOW  | \
+	 MALI400GP_REG_VAL_IRQ_PTR_ARRAY_OUT_OF_BOUNDS)
+
+/* Mask defining the IRQs in Mali GP which we use */
 #define MALIGP2_REG_VAL_IRQ_MASK_USED \
 	(\
-		MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
-		MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
-		MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
-		MALIGP2_REG_VAL_IRQ_HANG                | \
-		MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
-		MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
-		MALIGP2_REG_VAL_IRQ_SYNC_ERROR 			| \
-		MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR)
-#elif defined(USING_MALI400) || defined(USING_MALI450)
-#define MALIGP2_REG_VAL_IRQ_MASK_USED \
-	(\
-		MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
-		MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
-		MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
-		MALIGP2_REG_VAL_IRQ_HANG                | \
-		MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
-		MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
-		MALIGP2_REG_VAL_IRQ_SYNC_ERROR 			| \
-		MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR       | \
-		MALI400GP_REG_VAL_IRQ_VS_INVALID_CMD      | \
-		MALI400GP_REG_VAL_IRQ_PLB_INVALID_CMD     | \
-		MALI400GP_REG_VAL_IRQ_SEMAPHORE_UNDERFLOW | \
-		MALI400GP_REG_VAL_IRQ_SEMAPHORE_OVERFLOW  | \
-		MALI400GP_REG_VAL_IRQ_PTR_ARRAY_OUT_OF_BOUNDS)
-#else
-#error "No supported mali core defined"
-#endif
+	 MALIGP2_REG_VAL_IRQ_VS_END_CMD_LST      | \
+	 MALIGP2_REG_VAL_IRQ_PLBU_END_CMD_LST    | \
+	 MALIGP2_REG_VAL_IRQ_PLBU_OUT_OF_MEM     | \
+	 MALIGP2_REG_VAL_IRQ_FORCE_HANG          | \
+	 MALIGP2_REG_VAL_IRQ_WRITE_BOUND_ERR     | \
+	 MALIGP2_REG_VAL_IRQ_SYNC_ERROR          | \
+	 MALIGP2_REG_VAL_IRQ_AXI_BUS_ERROR       | \
+	 MALI400GP_REG_VAL_IRQ_VS_INVALID_CMD      | \
+	 MALI400GP_REG_VAL_IRQ_PLB_INVALID_CMD     | \
+	 MALI400GP_REG_VAL_IRQ_SEMAPHORE_UNDERFLOW | \
+	 MALI400GP_REG_VAL_IRQ_SEMAPHORE_OVERFLOW  | \
+	 MALI400GP_REG_VAL_IRQ_PTR_ARRAY_OUT_OF_BOUNDS)
 
 /* Mask defining non IRQs on MaliGP2*/
 #define MALIGP2_REG_VAL_IRQ_MASK_NONE 0
@@ -188,13 +146,13 @@ typedef enum
 /** }@ defgroup MALIGP2_STATUS*/
 
 #define MALIGP2_REG_VAL_STATUS_MASK_ACTIVE (\
-	MALIGP2_REG_VAL_STATUS_VS_ACTIVE|\
-	MALIGP2_REG_VAL_STATUS_PLBU_ACTIVE)
+		MALIGP2_REG_VAL_STATUS_VS_ACTIVE|\
+		MALIGP2_REG_VAL_STATUS_PLBU_ACTIVE)
 
 
 #define MALIGP2_REG_VAL_STATUS_MASK_ERROR (\
-	MALIGP2_REG_VAL_STATUS_BUS_ERROR |\
-	MALIGP2_REG_VAL_STATUS_WRITE_BOUND_ERR )
+		MALIGP2_REG_VAL_STATUS_BUS_ERROR |\
+		MALIGP2_REG_VAL_STATUS_WRITE_BOUND_ERR )
 
 /* This should be in the top 16 bit of the version register of gp.*/
 #define MALI200_GP_PRODUCT_ID 0xA07
diff --git a/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.c b/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.c
index a8bd10c..d1c3e99 100644
--- a/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.c
+++ b/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.h b/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.h
index 14679df..f0bd599 100644
--- a/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.h
+++ b/drivers/gpu/mali/mali/timestamp-arm11-cc/mali_timestamp.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -19,18 +19,18 @@ MALI_STATIC_INLINE _mali_osk_errcode_t _mali_timestamp_reset(void)
 	 * reset counters and overflow flags
 	 */
 
-    u32 mask = (1 << 0) | /* enable all three counters */
-	           (0 << 1) | /* reset both Count Registers to 0x0 */
-	           (1 << 2) | /* reset the Cycle Counter Register to 0x0 */
-	           (0 << 3) | /* 1 = Cycle Counter Register counts every 64th processor clock cycle */
-	           (0 << 4) | /* Count Register 0 interrupt enable */
-	           (0 << 5) | /* Count Register 1 interrupt enable */
-	           (0 << 6) | /* Cycle Counter interrupt enable */
-	           (0 << 8) | /* Count Register 0 overflow flag (clear or write, flag on read) */
-	           (0 << 9) | /* Count Register 1 overflow flag (clear or write, flag on read) */
-	           (1 << 10); /* Cycle Counter Register overflow flag (clear or write, flag on read) */
+	u32 mask = (1 << 0) | /* enable all three counters */
+		   (0 << 1) | /* reset both Count Registers to 0x0 */
+		   (1 << 2) | /* reset the Cycle Counter Register to 0x0 */
+		   (0 << 3) | /* 1 = Cycle Counter Register counts every 64th processor clock cycle */
+		   (0 << 4) | /* Count Register 0 interrupt enable */
+		   (0 << 5) | /* Count Register 1 interrupt enable */
+		   (0 << 6) | /* Cycle Counter interrupt enable */
+		   (0 << 8) | /* Count Register 0 overflow flag (clear or write, flag on read) */
+		   (0 << 9) | /* Count Register 1 overflow flag (clear or write, flag on read) */
+		   (1 << 10); /* Cycle Counter Register overflow flag (clear or write, flag on read) */
 
-	__asm__ __volatile__ ("MCR    p15, 0, %0, c15, c12, 0" : : "r" (mask) );
+	__asm__ __volatile__("MCR    p15, 0, %0, c15, c12, 0" : : "r"(mask));
 
 	return _MALI_OSK_ERR_OK;
 }
@@ -40,7 +40,7 @@ MALI_STATIC_INLINE u64 _mali_timestamp_get(void)
 	u32 result;
 
 	/* this is for the clock cycles */
-	__asm__ __volatile__ ("MRC    p15, 0, %0, c15, c12, 1" : "=r" (result));
+	__asm__ __volatile__("MRC    p15, 0, %0, c15, c12, 1" : "=r"(result));
 
 	return (u64)result;
 }
diff --git a/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.c b/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.c
index a8bd10c..d1c3e99 100644
--- a/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.c
+++ b/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.h b/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.h
index cc67cf8..268ede5 100644
--- a/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.h
+++ b/drivers/gpu/mali/mali/timestamp-default/mali_timestamp.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/ump/Kbuild b/drivers/gpu/mali/ump/Kbuild
index 62380fa..ed65819 100644
--- a/drivers/gpu/mali/ump/Kbuild
+++ b/drivers/gpu/mali/ump/Kbuild
@@ -1,39 +1,74 @@
 #
 # Copyright (C) 2010-2012 ARM Limited. All rights reserved.
-#
+# 
 # This program is free software and is provided to you under the terms of the GNU General Public License version 2
 # as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
-#
+# 
 # A copy of the licence is included with the program, and can also be obtained from Free Software
 # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 #
 
 # Set default configuration to use, if Makefile didn't provide one.
 # Change this to use a different config.h
-CONFIG ?= os_memory_64m
+CONFIG ?= default
+
+# Validate selected config
+ifneq ($(shell [ -d $(src)/arch-$(CONFIG) ] && [ -f  $(src)/arch-$(CONFIG)/config.h ] && echo "OK"), OK)
+$(warning Current directory is $(src))
+$(error No configuration found for config $(CONFIG). Check that arch-$(CONFIG)/config.h exists)
+else
+# Link arch to the selected arch-config directory
+$(shell [ -L $(src)/arch ] && rm $(src)/arch)
+$(shell ln -sf arch-$(CONFIG) $(src)/arch)
+$(shell touch $(src)/arch/config.h)
+endif
 
-UDD_FILE_PREFIX = 
+UDD_FILE_PREFIX = ../mali/
 
-# set the SVN_REV to ${MALI_RELEASE_NAME} due to ARM using subversion
-SVN_REV := $(MALI_RELEASE_NAME)
+# Get subversion revision number, fall back to 0000 if no svn info is available
+SVN_INFO = (cd $(src); svn info 2>/dev/null)
 
-ccflags-y += -I$(srctree)/$(src)/arch-$(CONFIG)
+ifneq ($(shell $(SVN_INFO) 2>/dev/null),)
+# SVN detected
+SVN_REV := $(shell $(SVN_INFO) | grep '^Revision: '| sed -e 's/^Revision: //' 2>/dev/null)
+DRIVER_REV := $(MALI_RELEASE_NAME)-r$(SVN_REV)
+CHANGE_DATE := $(shell $(SVN_INFO) | grep '^Last Changed Date: ' | cut -d: -f2- | cut -b2-)
+CHANGED_REVISION := $(shell $(SVN_INFO) | grep '^Last Changed Rev: ' | cut -d: -f2- | cut -b2-)
+REPO_URL := $(shell $(SVN_INFO) | grep '^URL: ' | cut -d: -f2- | cut -b2-)
+
+else # SVN
+GIT_REV := $(shell cd $(src); git describe --always 2>/dev/null)
+ifneq ($(GIT_REV),)
+# Git detected
+DRIVER_REV := $(MALI_RELEASE_NAME)-$(GIT_REV)
+CHANGE_DATE := $(shell cd $(src); git log -1 --format="%ci")
+CHANGED_REVISION := $(GIT_REV)
+REPO_URL := $(shell cd $(src); git describe --all --always 2>/dev/null)
+
+else # Git
+# No Git or SVN detected
+DRIVER_REV := $(MALI_RELEASE_NAME)
+CHANGE_DATE := $(MALI_RELEASE_NAME)
+CHANGED_REVISION := $(MALI_RELEASE_NAME)
+endif
+endif
 
 ccflags-y += -DSVN_REV=$(SVN_REV)
-ccflags-y += -DSVN_REV_STRING=\"$(SVN_REV)\"
+ccflags-y += -DSVN_REV_STRING=\"$(DRIVER_REV)\"
 
-ccflags-y += -I$(src) -I$(src)/common -I$(src)/linux -I$(src)/../mali/common -I$(src)/../mali/linux -I$(src)/../ump/include/ump
+ccflags-y += -I$(src) -I$(src)/common -I$(src)/linux -I$(src)/../mali/common -I$(src)/../mali/linux -I$(src)/../../ump/include/ump
 ccflags-y += -DMALI_STATE_TRACKING=0
+ccflags-y += -DMALI_ENABLE_CPU_CYCLES=0
 ccflags-$(CONFIG_UMP_DEBUG) += -DDEBUG
 
 # For customer releases the Linux Device Drivers will be provided as ARM proprietary and GPL releases:
 # The ARM proprietary product will only include the license/proprietary directory
 # The GPL product will only include the license/gpl directory
 
-ifeq ($(wildcard $(srctree)/$(src)/linux/license/gpl/*),)
-ccflags-y += -I$(srctree)/$(src)/linux/license/proprietary
+ifeq ($(wildcard $(src)/linux/license/gpl/*),)
+ccflags-y += -I$(src)/linux/license/proprietary -I$(src)/../mali/linux/license/proprietary
 else
-ccflags-y += -I$(srctree)/$(src)/linux/license/gpl
+ccflags-y += -I$(src)/linux/license/gpl -I$(src)/../mali/linux/license/gpl
 endif
 
 ump-y = common/ump_kernel_common.o \
@@ -49,6 +84,7 @@ ump-y = common/ump_kernel_common.o \
 	linux/ump_osk_atomics.o \
 	linux/ump_osk_low_level_mem.o \
 	linux/ump_osk_misc.o \
+	linux/ump_kernel_random_mapping.o \
 	$(UDD_FILE_PREFIX)linux/mali_osk_atomics.o \
 	$(UDD_FILE_PREFIX)linux/mali_osk_locks.o \
 	$(UDD_FILE_PREFIX)linux/mali_osk_memory.o \
@@ -56,3 +92,4 @@ ump-y = common/ump_kernel_common.o \
 	$(UDD_FILE_PREFIX)linux/mali_osk_misc.o
 
 obj-$(CONFIG_UMP) := ump.o
+
diff --git a/drivers/gpu/mali/ump/Kconfig b/drivers/gpu/mali/ump/Kconfig
index 2277a53..3ae316c 100644
--- a/drivers/gpu/mali/ump/Kconfig
+++ b/drivers/gpu/mali/ump/Kconfig
@@ -1,6 +1,6 @@
 config UMP
 	tristate "UMP support"
-	depends on ARM && MALI400
+	depends on ARM
 	---help---
 	  This enables support for the UMP memory allocation and sharing API.
 
@@ -13,3 +13,4 @@ config UMP_DEBUG
 	default y
 	---help---
 	  This enabled extra debug checks and messages in UMP.
+
diff --git a/drivers/gpu/mali/ump/Makefile b/drivers/gpu/mali/ump/Makefile
index 56137ea..e2ad949 100644
--- a/drivers/gpu/mali/ump/Makefile
+++ b/drivers/gpu/mali/ump/Makefile
@@ -1,9 +1,9 @@
 #
-# Copyright (C) 2010-2012 ARM Limited. All rights reserved.
-#
+# Copyright (C) 2010-2012, 2014 ARM Limited. All rights reserved.
+# 
 # This program is free software and is provided to you under the terms of the GNU General Public License version 2
 # as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
-#
+# 
 # A copy of the licence is included with the program, and can also be obtained from Free Software
 # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 #
@@ -13,9 +13,17 @@
 export ARCH ?= arm
 BUILD ?= debug
 
+check_cc2 = \
+	$(shell if $(1) -S -o /dev/null -xc /dev/null > /dev/null 2>&1; \
+	then \
+		echo "$(2)"; \
+	else \
+		echo "$(3)"; \
+	fi ;)
+
 # Check that required parameters are supplied.
 ifeq ($(CONFIG),)
-$(error "CONFIG must be specified.")
+CONFIG := default
 endif
 ifeq ($(CPU)$(KDIR),)
 $(error "KDIR or CPU must be specified.")
@@ -28,8 +36,8 @@ endif
 KDIR-$(shell uname -m):=/lib/modules/$(shell uname -r)/build
 
 ifeq ($(ARCH), arm)
-	# when compiling for ARM we're cross compiling
-	export CROSS_COMPILE ?= arm-none-linux-gnueabi-
+# when compiling for ARM we're cross compiling
+export CROSS_COMPILE ?= $(call check_cc2, arm-linux-gnueabi-gcc, arm-linux-gnueabi-, arm-none-linux-gnueabi-)
 endif
 
 # look up KDIR based om CPU selection
diff --git a/drivers/gpu/mali/ump/Makefile.common b/drivers/gpu/mali/ump/Makefile.common
index de820ae..9bd2583 100644
--- a/drivers/gpu/mali/ump/Makefile.common
+++ b/drivers/gpu/mali/ump/Makefile.common
@@ -1,9 +1,9 @@
 #
-# Copyright (C) 2010-2011 ARM Limited. All rights reserved.
-#
+# Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+# 
 # This program is free software and is provided to you under the terms of the GNU General Public License version 2
 # as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
-#
+# 
 # A copy of the licence is included with the program, and can also be obtained from Free Software
 # Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 #
@@ -13,8 +13,8 @@ SRC = $(UMP_FILE_PREFIX)common/ump_kernel_common.c \
 	$(UMP_FILE_PREFIX)common/ump_kernel_api.c \
 	$(UMP_FILE_PREFIX)common/ump_kernel_ref_drv.c
 
-# set the SVN_REV to ${MALI_RELEASE_NAME} due to ARM using subversion
-SVN_REV := $(MALI_RELEASE_NAME)
+# Get subversion revision number, fall back to 0000 if no svn info is available
+SVN_REV:=$(shell ((svnversion | grep -qv exported && echo -n 'Revision: ' && svnversion) || git svn info | sed -e 's/$$$$/M/' | grep '^Revision: ' || echo ${MALI_RELEASE_NAME}) 2>/dev/null | sed -e 's/^Revision: //')
 
 EXTRA_CFLAGS += -DSVN_REV=$(SVN_REV)
 EXTRA_CFLAGS += -DSVN_REV_STRING=\"$(SVN_REV)\"
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_api.c b/drivers/gpu/mali/ump/common/ump_kernel_api.c
index e86bc33..aa7e43f 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_api.c
+++ b/drivers/gpu/mali/ump/common/ump_kernel_api.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,6 +14,7 @@
 #include "ump_uk_types.h"
 #include "ump_kernel_interface.h"
 #include "ump_kernel_common.h"
+#include "ump_kernel_random_mapping.h"
 
 
 
@@ -23,7 +24,7 @@
 
 UMP_KERNEL_API_EXPORT ump_secure_id ump_dd_secure_id_get(ump_dd_handle memh)
 {
-	ump_dd_mem * mem = (ump_dd_mem *)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
@@ -36,21 +37,16 @@ UMP_KERNEL_API_EXPORT ump_secure_id ump_dd_secure_id_get(ump_dd_handle memh)
 
 UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_secure_id(ump_secure_id secure_id)
 {
-	ump_dd_mem * mem;
-
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	ump_dd_mem *mem;
 
 	DBG_MSG(5, ("Getting handle from secure ID. ID: %u\n", secure_id));
-	if (0 != ump_descriptor_mapping_get(device.secure_id_map, (int)secure_id, (void**)&mem))
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	mem = ump_random_mapping_get(device.secure_id_map, (int)secure_id);
+	if (NULL == mem) {
 		DBG_MSG(1, ("Secure ID not found. ID: %u\n", secure_id));
 		return UMP_DD_HANDLE_INVALID;
 	}
 
-	ump_dd_reference_add(mem);
-
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	/* Keep the reference taken in ump_random_mapping_get() */
 
 	return (ump_dd_handle)mem;
 }
@@ -59,7 +55,7 @@ UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_secure_id(ump_secu
 
 UMP_KERNEL_API_EXPORT unsigned long ump_dd_phys_block_count_get(ump_dd_handle memh)
 {
-	ump_dd_mem * mem = (ump_dd_mem*) memh;
+	ump_dd_mem *mem = (ump_dd_mem *) memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
@@ -68,20 +64,18 @@ UMP_KERNEL_API_EXPORT unsigned long ump_dd_phys_block_count_get(ump_dd_handle me
 
 
 
-UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_blocks_get(ump_dd_handle memh, ump_dd_physical_block * blocks, unsigned long num_blocks)
+UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_blocks_get(ump_dd_handle memh, ump_dd_physical_block *blocks, unsigned long num_blocks)
 {
-	ump_dd_mem * mem = (ump_dd_mem *)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
-	if (blocks == NULL)
-	{
+	if (blocks == NULL) {
 		DBG_MSG(1, ("NULL parameter in ump_dd_phys_blocks_get()\n"));
 		return UMP_DD_INVALID;
 	}
 
-	if (mem->nr_blocks != num_blocks)
-	{
+	if (mem->nr_blocks != num_blocks) {
 		DBG_MSG(1, ("Specified number of blocks do not match actual number of blocks\n"));
 		return UMP_DD_INVALID;
 	}
@@ -95,20 +89,18 @@ UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_blocks_get(ump_dd_handle me
 
 
 
-UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_block_get(ump_dd_handle memh, unsigned long index, ump_dd_physical_block * block)
+UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_block_get(ump_dd_handle memh, unsigned long index, ump_dd_physical_block *block)
 {
-	ump_dd_mem * mem = (ump_dd_mem *)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
-	if (block == NULL)
-	{
+	if (block == NULL) {
 		DBG_MSG(1, ("NULL parameter in ump_dd_phys_block_get()\n"));
 		return UMP_DD_INVALID;
 	}
 
-	if (index >= mem->nr_blocks)
-	{
+	if (index >= mem->nr_blocks) {
 		DBG_MSG(5, ("Invalid index specified in ump_dd_phys_block_get()\n"));
 		return UMP_DD_INVALID;
 	}
@@ -124,7 +116,7 @@ UMP_KERNEL_API_EXPORT ump_dd_status_code ump_dd_phys_block_get(ump_dd_handle mem
 
 UMP_KERNEL_API_EXPORT unsigned long ump_dd_size_get(ump_dd_handle memh)
 {
-	ump_dd_mem * mem = (ump_dd_mem*)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
@@ -137,7 +129,7 @@ UMP_KERNEL_API_EXPORT unsigned long ump_dd_size_get(ump_dd_handle memh)
 
 UMP_KERNEL_API_EXPORT void ump_dd_reference_add(ump_dd_handle memh)
 {
-	ump_dd_mem * mem = (ump_dd_mem*)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 	int new_ref;
 
 	DEBUG_ASSERT_POINTER(mem);
@@ -151,35 +143,11 @@ UMP_KERNEL_API_EXPORT void ump_dd_reference_add(ump_dd_handle memh)
 
 UMP_KERNEL_API_EXPORT void ump_dd_reference_release(ump_dd_handle memh)
 {
-	int new_ref;
-	ump_dd_mem * mem = (ump_dd_mem*)memh;
+	ump_dd_mem *mem = (ump_dd_mem *)memh;
 
 	DEBUG_ASSERT_POINTER(mem);
 
-	/* We must hold this mutex while doing the atomic_dec_and_read, to protect
-	that elements in the ump_descriptor_mapping table is always valid.  If they
-	are not, userspace may accidently map in this secure_ids right before its freed
-	giving a mapped backdoor into unallocated memory.*/
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-
-	new_ref = _ump_osk_atomic_dec_and_read(&mem->ref_count);
-
-	DBG_MSG(5, ("Memory reference decremented. ID: %u, new value: %d\n", mem->secure_id, new_ref));
-
-	if (0 == new_ref)
-	{
-		DBG_MSG(3, ("Final release of memory. ID: %u\n", mem->secure_id));
-
-		ump_descriptor_mapping_free(device.secure_id_map, (int)mem->secure_id);
-
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		mem->release_func(mem->ctx, mem);
-		_mali_osk_free(mem);
-	}
-	else
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	}
+	ump_random_mapping_put(mem);
 }
 
 
@@ -187,31 +155,24 @@ UMP_KERNEL_API_EXPORT void ump_dd_reference_release(ump_dd_handle memh)
 /* --------------- Handling of user space requests follows --------------- */
 
 
-_mali_osk_errcode_t _ump_uku_get_api_version( _ump_uk_api_version_s *args )
+_mali_osk_errcode_t _ump_uku_get_api_version(_ump_uk_api_version_s *args)
 {
-	ump_session_data * session_data;
+	ump_session_data *session_data;
 
-	DEBUG_ASSERT_POINTER( args );
-	DEBUG_ASSERT_POINTER( args->ctx );
+	DEBUG_ASSERT_POINTER(args);
+	DEBUG_ASSERT_POINTER(args->ctx);
 
 	session_data = (ump_session_data *)args->ctx;
 
 	/* check compatability */
-	if (args->version == UMP_IOCTL_API_VERSION)
-	{
-		DBG_MSG(3, ("API version set to newest %d (compatible)\n", GET_VERSION(args->version)));
-		args->compatible = 1;
-		session_data->api_version = args->version;
-	}
-	else if (args->version == MAKE_VERSION_ID(1))
-	{
-		DBG_MSG(2, ("API version set to depricated: %d (compatible)\n", GET_VERSION(args->version)));
+	if (args->version == UMP_IOCTL_API_VERSION) {
+		DBG_MSG(3, ("API version set to newest %d (compatible)\n",
+				GET_VERSION(args->version)));
 		args->compatible = 1;
 		session_data->api_version = args->version;
-	}
-	else
-	{
-		DBG_MSG(2, ("API version set to %d (incompatible with client version %d)\n", GET_VERSION(UMP_IOCTL_API_VERSION), GET_VERSION(args->version)));
+	} else {
+		DBG_MSG(2, ("API version set to %d (incompatible with client version %d)\n",
+				GET_VERSION(UMP_IOCTL_API_VERSION), GET_VERSION(args->version)));
 		args->compatible = 0;
 		args->version = UMP_IOCTL_API_VERSION; /* report our version */
 	}
@@ -220,19 +181,19 @@ _mali_osk_errcode_t _ump_uku_get_api_version( _ump_uk_api_version_s *args )
 }
 
 
-_mali_osk_errcode_t _ump_ukk_release( _ump_uk_release_s *release_info )
+_mali_osk_errcode_t _ump_ukk_release(_ump_uk_release_s *release_info)
 {
-	ump_session_memory_list_element * session_memory_element;
-	ump_session_memory_list_element * tmp;
-	ump_session_data * session_data;
+	ump_session_memory_list_element *session_memory_element;
+	ump_session_memory_list_element *tmp;
+	ump_session_data *session_data;
 	_mali_osk_errcode_t ret = _MALI_OSK_ERR_INVALID_FUNC;
 	int secure_id;
 
-	DEBUG_ASSERT_POINTER( release_info );
-	DEBUG_ASSERT_POINTER( release_info->ctx );
+	DEBUG_ASSERT_POINTER(release_info);
+	DEBUG_ASSERT_POINTER(release_info->ctx);
 
 	/* Retreive the session data */
-	session_data = (ump_session_data*)release_info->ctx;
+	session_data = (ump_session_data *)release_info->ctx;
 
 	/* If there are many items in the memory session list we
 	 * could be de-referencing this pointer a lot so keep a local copy
@@ -242,11 +203,9 @@ _mali_osk_errcode_t _ump_ukk_release( _ump_uk_release_s *release_info )
 	DBG_MSG(4, ("Releasing memory with IOCTL, ID: %u\n", secure_id));
 
 	/* Iterate through the memory list looking for the requested secure ID */
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
-	_MALI_OSK_LIST_FOREACHENTRY(session_memory_element, tmp, &session_data->list_head_session_memory_list, ump_session_memory_list_element, list)
-	{
-		if ( session_memory_element->mem->secure_id == secure_id)
-		{
+	_mali_osk_mutex_wait(session_data->lock);
+	_MALI_OSK_LIST_FOREACHENTRY(session_memory_element, tmp, &session_data->list_head_session_memory_list, ump_session_memory_list_element, list) {
+		if (session_memory_element->mem->secure_id == secure_id) {
 			ump_dd_mem *release_mem;
 
 			release_mem = session_memory_element->mem;
@@ -259,276 +218,238 @@ _mali_osk_errcode_t _ump_ukk_release( _ump_uk_release_s *release_info )
 		}
 	}
 
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
- 	DBG_MSG_IF(1, _MALI_OSK_ERR_OK != ret, ("UMP memory with ID %u does not belong to this session.\n", secure_id));
+	_mali_osk_mutex_signal(session_data->lock);
+	DBG_MSG_IF(1, _MALI_OSK_ERR_OK != ret, ("UMP memory with ID %u does not belong to this session.\n", secure_id));
 
 	DBG_MSG(4, ("_ump_ukk_release() returning 0x%x\n", ret));
 	return ret;
 }
 
-_mali_osk_errcode_t _ump_ukk_size_get( _ump_uk_size_get_s *user_interaction )
+_mali_osk_errcode_t _ump_ukk_size_get(_ump_uk_size_get_s *user_interaction)
 {
-	ump_dd_mem * mem;
+	ump_dd_mem *mem;
 	_mali_osk_errcode_t ret = _MALI_OSK_ERR_FAULT;
 
-	DEBUG_ASSERT_POINTER( user_interaction );
+	DEBUG_ASSERT_POINTER(user_interaction);
 
 	/* We lock the mappings so things don't get removed while we are looking for the memory */
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	if (0 == ump_descriptor_mapping_get(device.secure_id_map, (int)user_interaction->secure_id, (void**)&mem))
-	{
+	mem = ump_random_mapping_get(device.secure_id_map, user_interaction->secure_id);
+	if (NULL != mem) {
 		user_interaction->size = mem->size_bytes;
-		DBG_MSG(4, ("Returning size. ID: %u, size: %lu ", (ump_secure_id)user_interaction->secure_id, (unsigned long)user_interaction->size));
+		DBG_MSG(4, ("Returning size. ID: %u, size: %lu ",
+				(ump_secure_id)user_interaction->secure_id,
+				(unsigned long)user_interaction->size));
+		ump_random_mapping_put(mem);
 		ret = _MALI_OSK_ERR_OK;
-	}
-	else
-	{
-		 user_interaction->size = 0;
-		DBG_MSG(1, ("Failed to look up mapping in ump_ioctl_size_get(). ID: %u\n", (ump_secure_id)user_interaction->secure_id));
+	} else {
+		user_interaction->size = 0;
+		DBG_MSG(1, ("Failed to look up mapping in ump_ioctl_size_get(). ID: %u\n",
+					(ump_secure_id)user_interaction->secure_id));
 	}
 
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 	return ret;
 }
 
 
 
-void _ump_ukk_msync( _ump_uk_msync_s *args )
+void _ump_ukk_msync(_ump_uk_msync_s *args)
 {
-	ump_dd_mem * mem = NULL;
+	ump_dd_mem *mem = NULL;
 	void *virtual = NULL;
 	u32 size = 0;
 	u32 offset = 0;
 
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	ump_descriptor_mapping_get(device.secure_id_map, (int)args->secure_id, (void**)&mem);
-
-	if (NULL == mem)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_msync(). ID: %u\n", (ump_secure_id)args->secure_id));
+	mem = ump_random_mapping_get(device.secure_id_map, (int)args->secure_id);
+	if (NULL == mem) {
+		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_msync(). ID: %u\n",
+					(ump_secure_id)args->secure_id));
 		return;
 	}
-	/* Ensure the memory doesn't dissapear when we are flushing it. */
-	ump_dd_reference_add(mem);
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 
 	/* Returns the cache settings back to Userspace */
-	args->is_cached=mem->is_cached;
+	args->is_cached = mem->is_cached;
 
 	/* If this flag is the only one set, we should not do the actual flush, only the readout */
-	if ( _UMP_UK_MSYNC_READOUT_CACHE_ENABLED==args->op )
-	{
+	if (_UMP_UK_MSYNC_READOUT_CACHE_ENABLED == args->op) {
 		DBG_MSG(3, ("_ump_ukk_msync READOUT  ID: %u Enabled: %d\n", (ump_secure_id)args->secure_id, mem->is_cached));
 		goto msync_release_and_return;
 	}
 
 	/* Nothing to do if the memory is not caches */
-	if ( 0==mem->is_cached )
-	{
+	if (0 == mem->is_cached) {
 		DBG_MSG(3, ("_ump_ukk_msync IGNORING ID: %u Enabled: %d  OP: %d\n", (ump_secure_id)args->secure_id, mem->is_cached, args->op));
 		goto msync_release_and_return;
 	}
 	DBG_MSG(3, ("UMP[%02u] _ump_ukk_msync  Flush  OP: %d Address: 0x%08x Mapping: 0x%08x\n",
-	            (ump_secure_id)args->secure_id, args->op, args->address, args->mapping));
+		    (ump_secure_id)args->secure_id, args->op, args->address, args->mapping));
 
-	if ( args->address )
-	{
+	if (args->address) {
 		virtual = (void *)((u32)args->address);
 		offset = (u32)((args->address) - (args->mapping));
 	} else {
 		/* Flush entire mapping when no address is specified. */
 		virtual = args->mapping;
 	}
-	if ( args->size )
-	{
+	if (args->size) {
 		size = args->size;
 	} else {
 		/* Flush entire mapping when no size is specified. */
 		size = mem->size_bytes - offset;
 	}
 
-	if ( (offset + size) > mem->size_bytes )
-	{
+	if ((offset + size) > mem->size_bytes) {
 		DBG_MSG(1, ("Trying to flush more than the entire UMP allocation: offset: %u + size: %u > %u\n", offset, size, mem->size_bytes));
 		goto msync_release_and_return;
 	}
 
 	/* The actual cache flush - Implemented for each OS*/
-	_ump_osk_msync( mem, virtual, offset, size, args->op, NULL);
+	_ump_osk_msync(mem, virtual, offset, size, args->op, NULL);
 
 msync_release_and_return:
-	ump_dd_reference_release(mem);
+	ump_random_mapping_put(mem);
 	return;
 }
 
-void _ump_ukk_cache_operations_control(_ump_uk_cache_operations_control_s* args)
+void _ump_ukk_cache_operations_control(_ump_uk_cache_operations_control_s *args)
 {
-	ump_session_data * session_data;
+	ump_session_data *session_data;
 	ump_uk_cache_op_control op;
 
-	DEBUG_ASSERT_POINTER( args );
-	DEBUG_ASSERT_POINTER( args->ctx );
+	DEBUG_ASSERT_POINTER(args);
+	DEBUG_ASSERT_POINTER(args->ctx);
 
 	op = args->op;
 	session_data = (ump_session_data *)args->ctx;
 
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
-	if ( op== _UMP_UK_CACHE_OP_START )
-	{
+	_mali_osk_mutex_wait(session_data->lock);
+	if (op == _UMP_UK_CACHE_OP_START) {
 		session_data->cache_operations_ongoing++;
-		DBG_MSG(4, ("Cache ops start\n" ));
-		if ( session_data->cache_operations_ongoing != 1 )
-		{
-			DBG_MSG(2, ("UMP: Number of simultanious cache control ops: %d\n", session_data->cache_operations_ongoing) );
+		DBG_MSG(4, ("Cache ops start\n"));
+		if (session_data->cache_operations_ongoing != 1) {
+			DBG_MSG(2, ("UMP: Number of simultanious cache control ops: %d\n", session_data->cache_operations_ongoing));
 		}
-	}
-	else if ( op== _UMP_UK_CACHE_OP_FINISH )
-	{
+	} else if (op == _UMP_UK_CACHE_OP_FINISH) {
 		DBG_MSG(4, ("Cache ops finish\n"));
 		session_data->cache_operations_ongoing--;
-		#if 0
-		if ( session_data->has_pending_level1_cache_flush)
-		{
+#if 0
+		if (session_data->has_pending_level1_cache_flush) {
 			/* This function will set has_pending_level1_cache_flush=0 */
-			_ump_osk_msync( NULL, NULL, 0, 0, _UMP_UK_MSYNC_FLUSH_L1, session_data);
+			_ump_osk_msync(NULL, NULL, 0, 0, _UMP_UK_MSYNC_FLUSH_L1, session_data);
 		}
-		#endif
+#endif
 
 		/* to be on the safe side: always flush l1 cache when cache operations are done */
-		_ump_osk_msync( NULL, NULL, 0, 0, _UMP_UK_MSYNC_FLUSH_L1, session_data);
-		DBG_MSG(4, ("Cache ops finish end\n" ));
-	}
-	else
-	{
+		_ump_osk_msync(NULL, NULL, 0, 0, _UMP_UK_MSYNC_FLUSH_L1, session_data);
+		DBG_MSG(4, ("Cache ops finish end\n"));
+	} else {
 		DBG_MSG(1, ("Illegal call to %s at line %d\n", __FUNCTION__, __LINE__));
 	}
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_signal(session_data->lock);
 
 }
 
-void _ump_ukk_switch_hw_usage(_ump_uk_switch_hw_usage_s *args )
+void _ump_ukk_switch_hw_usage(_ump_uk_switch_hw_usage_s *args)
 {
-	ump_dd_mem * mem = NULL;
+	ump_dd_mem *mem = NULL;
 	ump_uk_user old_user;
 	ump_uk_msync_op cache_op = _UMP_UK_MSYNC_CLEAN_AND_INVALIDATE;
 	ump_session_data *session_data;
 
-	DEBUG_ASSERT_POINTER( args );
-	DEBUG_ASSERT_POINTER( args->ctx );
+	DEBUG_ASSERT_POINTER(args);
+	DEBUG_ASSERT_POINTER(args->ctx);
 
 	session_data = (ump_session_data *)args->ctx;
 
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	ump_descriptor_mapping_get(device.secure_id_map, (int)args->secure_id, (void**)&mem);
-
-	if (NULL == mem)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_switch_hw_usage(). ID: %u\n", (ump_secure_id)args->secure_id));
+	mem = ump_random_mapping_get(device.secure_id_map, (int)args->secure_id);
+	if (NULL == mem) {
+		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_switch_hw_usage(). ID: %u\n",
+					(ump_secure_id)args->secure_id));
 		return;
 	}
 
 	old_user = mem->hw_device;
 	mem->hw_device = args->new_user;
 
-	DBG_MSG(3, ("UMP[%02u] Switch usage  Start  New: %s  Prev: %s.\n", (ump_secure_id)args->secure_id, args->new_user?"MALI":"CPU",old_user?"MALI":"CPU"));
+	DBG_MSG(3, ("UMP[%02u] Switch usage  Start  New: %s  Prev: %s.\n",
+				(ump_secure_id)args->secure_id,
+				args->new_user ? "MALI" : "CPU",
+				old_user ? "MALI" : "CPU"));
 
-	if ( ! mem->is_cached )
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(3, ("UMP[%02u] Changing owner of uncached memory. Cache flushing not needed.\n", (ump_secure_id)args->secure_id));
-		return;
+	if (!mem->is_cached) {
+		DBG_MSG(3, ("UMP[%02u] Changing owner of uncached memory. Cache flushing not needed.\n",
+					(ump_secure_id)args->secure_id));
+		goto out;
 	}
 
-	if ( old_user == args->new_user)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(4, ("UMP[%02u] Setting the new_user equal to previous for. Cache flushing not needed.\n", (ump_secure_id)args->secure_id));
-		return;
+	if (old_user == args->new_user) {
+		DBG_MSG(4, ("UMP[%02u] Setting the new_user equal to previous for. Cache flushing not needed.\n",
+					(ump_secure_id)args->secure_id));
+		goto out;
 	}
 	if (
-		 /* Previous AND new is both different from CPU */
-		 (old_user != _UMP_UK_USED_BY_CPU) && (args->new_user != _UMP_UK_USED_BY_CPU  )
-	   )
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(4, ("UMP[%02u] Previous and new user is not CPU. Cache flushing not needed.\n", (ump_secure_id)args->secure_id));
-		return;
+		/* Previous AND new is both different from CPU */
+		(old_user != _UMP_UK_USED_BY_CPU) && (args->new_user != _UMP_UK_USED_BY_CPU)
+	) {
+		DBG_MSG(4, ("UMP[%02u] Previous and new user is not CPU. Cache flushing not needed.\n",
+					(ump_secure_id)args->secure_id));
+		goto out;
 	}
 
-	if ( (old_user != _UMP_UK_USED_BY_CPU ) && (args->new_user==_UMP_UK_USED_BY_CPU) )
-	{
-		cache_op =_UMP_UK_MSYNC_INVALIDATE;
+	if ((old_user != _UMP_UK_USED_BY_CPU) && (args->new_user == _UMP_UK_USED_BY_CPU)) {
+		cache_op = _UMP_UK_MSYNC_INVALIDATE;
 		DBG_MSG(4, ("UMP[%02u] Cache invalidation needed\n", (ump_secure_id)args->secure_id));
 #ifdef UMP_SKIP_INVALIDATION
 #error
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 		DBG_MSG(4, ("UMP[%02u] Performing Cache invalidation SKIPPED\n", (ump_secure_id)args->secure_id));
-		return;
+		goto out;
 #endif
 	}
-	/* Ensure the memory doesn't dissapear when we are flushing it. */
-	ump_dd_reference_add(mem);
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 
 	/* Take lock to protect: session->cache_operations_ongoing and session->has_pending_level1_cache_flush */
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_wait(session_data->lock);
 	/* Actual cache flush */
-	_ump_osk_msync( mem, NULL, 0, mem->size_bytes, cache_op, session_data);
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_ump_osk_msync(mem, NULL, 0, mem->size_bytes, cache_op, session_data);
+	_mali_osk_mutex_signal(session_data->lock);
 
-	ump_dd_reference_release(mem);
+out:
+	ump_random_mapping_put(mem);
 	DBG_MSG(4, ("UMP[%02u] Switch usage  Finish\n", (ump_secure_id)args->secure_id));
 	return;
 }
 
-void _ump_ukk_lock(_ump_uk_lock_s *args )
+void _ump_ukk_lock(_ump_uk_lock_s *args)
 {
-	ump_dd_mem * mem = NULL;
+	ump_dd_mem *mem = NULL;
 
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	ump_descriptor_mapping_get(device.secure_id_map, (int)args->secure_id, (void**)&mem);
-
-	if (NULL == mem)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(1, ("UMP[%02u] Failed to look up mapping in _ump_ukk_lock(). ID: %u\n", (ump_secure_id)args->secure_id));
+	mem = ump_random_mapping_get(device.secure_id_map, (int)args->secure_id);
+	if (NULL == mem) {
+		DBG_MSG(1, ("UMP[%02u] Failed to look up mapping in _ump_ukk_lock(). ID: %u\n",
+					(ump_secure_id)args->secure_id));
 		return;
 	}
-	ump_dd_reference_add(mem);
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 
-	DBG_MSG(1, ("UMP[%02u] Lock. New lock flag: %d. Old Lock flag:\n", (u32)args->secure_id, (u32)args->lock_usage, (u32) mem->lock_usage ));
+	DBG_MSG(1, ("UMP[%02u] Lock. New lock flag: %d. Old Lock flag:\n", (u32)args->secure_id, (u32)args->lock_usage, (u32) mem->lock_usage));
 
 	mem->lock_usage = (ump_lock_usage) args->lock_usage;
 
-	/** TODO: TAKE LOCK HERE */
-
-	ump_dd_reference_release(mem);
+	ump_random_mapping_put(mem);
 }
 
-void _ump_ukk_unlock(_ump_uk_unlock_s *args )
+void _ump_ukk_unlock(_ump_uk_unlock_s *args)
 {
-	ump_dd_mem * mem = NULL;
+	ump_dd_mem *mem = NULL;
 
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	ump_descriptor_mapping_get(device.secure_id_map, (int)args->secure_id, (void**)&mem);
-
-	if (NULL == mem)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_unlock(). ID: %u\n", (ump_secure_id)args->secure_id));
+	mem = ump_random_mapping_get(device.secure_id_map, (int)args->secure_id);
+	if (NULL == mem) {
+		DBG_MSG(1, ("Failed to look up mapping in _ump_ukk_unlock(). ID: %u\n",
+					(ump_secure_id)args->secure_id));
 		return;
 	}
-	ump_dd_reference_add(mem);
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
 
-	DBG_MSG(1, ("UMP[%02u] Unlocking. Old Lock flag:\n", (u32)args->secure_id, (u32) mem->lock_usage ));
+	DBG_MSG(1, ("UMP[%02u] Unlocking. Old Lock flag:\n",
+				(u32)args->secure_id, (u32) mem->lock_usage));
 
 	mem->lock_usage = (ump_lock_usage) UMP_NOT_LOCKED;
 
-	/** TODO: RELEASE LOCK HERE */
-
-	ump_dd_reference_release(mem);
+	ump_random_mapping_put(mem);
 }
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_common.c b/drivers/gpu/mali/ump/common/ump_kernel_common.c
index 7f15e30..e1d8b3a 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_common.c
+++ b/drivers/gpu/mali/ump/common/ump_kernel_common.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -45,38 +45,26 @@ _mali_osk_errcode_t ump_kernel_constructor(void)
 
 	/* Perform OS Specific initialization */
 	err = _ump_osk_init();
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("Failed to initiaze the UMP Device Driver"));
 		return err;
 	}
 
 	/* Init the global device */
-	_mali_osk_memset(&device, 0, sizeof(device) );
+	_mali_osk_memset(&device, 0, sizeof(device));
 
 	/* Create the descriptor map, which will be used for mapping secure ID to ump_dd_mem structs */
-	device.secure_id_map_lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0 , 0);
-	if (NULL == device.secure_id_map_lock)
-	{
-		MSG_ERR(("Failed to create OSK lock for secure id lookup table\n"));
-		return _MALI_OSK_ERR_NOMEM;
-	}
-
-	device.secure_id_map = ump_descriptor_mapping_create(UMP_SECURE_ID_TABLE_ENTRIES_INITIAL, UMP_SECURE_ID_TABLE_ENTRIES_MAXIMUM);
-	if (NULL == device.secure_id_map)
-	{
-		_mali_osk_lock_term(device.secure_id_map_lock);
+	device.secure_id_map = ump_random_mapping_create();
+	if (NULL == device.secure_id_map) {
 		MSG_ERR(("Failed to create secure id lookup table\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
 	/* Init memory backend */
 	device.backend = ump_memory_backend_create();
-	if (NULL == device.backend)
-	{
+	if (NULL == device.backend) {
 		MSG_ERR(("Failed to create memory backend\n"));
-		_mali_osk_lock_term(device.secure_id_map_lock);
-		ump_descriptor_mapping_destroy(device.secure_id_map);
+		ump_random_mapping_destroy(device.secure_id_map);
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
@@ -86,12 +74,8 @@ _mali_osk_errcode_t ump_kernel_constructor(void)
 void ump_kernel_destructor(void)
 {
 	DEBUG_ASSERT_POINTER(device.secure_id_map);
-	DEBUG_ASSERT_POINTER(device.secure_id_map_lock);
-
-	_mali_osk_lock_term(device.secure_id_map_lock);
-	device.secure_id_map_lock = NULL;
 
-	ump_descriptor_mapping_destroy(device.secure_id_map);
+	ump_random_mapping_destroy(device.secure_id_map);
 	device.secure_id_map = NULL;
 
 	device.backend->shutdown(device.backend);
@@ -104,34 +88,33 @@ void ump_kernel_destructor(void)
 
 /** Creates a new UMP session
  */
-_mali_osk_errcode_t _ump_ukk_open( void** context )
+_mali_osk_errcode_t _ump_ukk_open(void **context)
 {
-	struct ump_session_data * session_data;
+	struct ump_session_data *session_data;
 
 	/* allocated struct to track this session */
 	session_data = (struct ump_session_data *)_mali_osk_malloc(sizeof(struct ump_session_data));
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("Failed to allocate ump_session_data in ump_file_open()\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
-	session_data->lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE, 0, 0);
-	if( NULL == session_data->lock )
-	{
+	session_data->lock = _mali_osk_mutex_init(_MALI_OSK_LOCKFLAG_UNORDERED, 0);
+	if (NULL == session_data->lock) {
 		MSG_ERR(("Failed to initialize lock for ump_session_data in ump_file_open()\n"));
 		_mali_osk_free(session_data);
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
-	session_data->cookies_map = ump_descriptor_mapping_create( UMP_COOKIES_PER_SESSION_INITIAL, UMP_COOKIES_PER_SESSION_MAXIMUM );
+	session_data->cookies_map = ump_descriptor_mapping_create(
+				UMP_COOKIES_PER_SESSION_INITIAL,
+				UMP_COOKIES_PER_SESSION_MAXIMUM);
 
-	if ( NULL == session_data->cookies_map )
-	{
+	if (NULL == session_data->cookies_map) {
 		MSG_ERR(("Failed to create descriptor mapping for _ump_ukk_map_mem cookies\n"));
 
-		_mali_osk_lock_term( session_data->lock );
-		_mali_osk_free( session_data );
+		_mali_osk_mutex_term(session_data->lock);
+		_mali_osk_free(session_data);
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
@@ -145,7 +128,7 @@ _mali_osk_errcode_t _ump_ukk_open( void** context )
 	   to the correct one.*/
 	session_data->api_version = MAKE_VERSION_ID(1);
 
-	*context = (void*)session_data;
+	*context = (void *)session_data;
 
 	session_data->cache_operations_ongoing = 0 ;
 	session_data->has_pending_level1_cache_flush = 0;
@@ -155,59 +138,55 @@ _mali_osk_errcode_t _ump_ukk_open( void** context )
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t _ump_ukk_close( void** context )
+_mali_osk_errcode_t _ump_ukk_close(void **context)
 {
-	struct ump_session_data * session_data;
-	ump_session_memory_list_element * item;
-	ump_session_memory_list_element * tmp;
+	struct ump_session_data *session_data;
+	ump_session_memory_list_element *item;
+	ump_session_memory_list_element *tmp;
 
 	session_data = (struct ump_session_data *)*context;
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("Session data is NULL in _ump_ukk_close()\n"));
 		return _MALI_OSK_ERR_INVALID_ARGS;
 	}
 
 	/* Unmap any descriptors mapped in. */
-	if (0 == _mali_osk_list_empty(&session_data->list_head_session_memory_mappings_list))
-	{
+	if (0 == _mali_osk_list_empty(&session_data->list_head_session_memory_mappings_list)) {
 		ump_memory_allocation *descriptor;
 		ump_memory_allocation *temp;
 
 		DBG_MSG(1, ("Memory mappings found on session usage list during session termination\n"));
 
 		/* use the 'safe' list iterator, since freeing removes the active block from the list we're iterating */
-		_MALI_OSK_LIST_FOREACHENTRY(descriptor, temp, &session_data->list_head_session_memory_mappings_list, ump_memory_allocation, list)
-		{
+		_MALI_OSK_LIST_FOREACHENTRY(descriptor, temp, &session_data->list_head_session_memory_mappings_list, ump_memory_allocation, list) {
 			_ump_uk_unmap_mem_s unmap_args;
 			DBG_MSG(4, ("Freeing block with phys address 0x%x size 0x%x mapped in user space at 0x%x\n",
-			            descriptor->phys_addr, descriptor->size, descriptor->mapping));
-			unmap_args.ctx = (void*)session_data;
+				    descriptor->phys_addr, descriptor->size, descriptor->mapping));
+			unmap_args.ctx = (void *)session_data;
 			unmap_args.mapping = descriptor->mapping;
 			unmap_args.size = descriptor->size;
 			unmap_args._ukk_private = NULL; /* NOTE: unused */
 			unmap_args.cookie = descriptor->cookie;
 
 			/* NOTE: This modifies the list_head_session_memory_mappings_list */
-			_ump_ukk_unmap_mem( &unmap_args );
+			_ump_ukk_unmap_mem(&unmap_args);
 		}
 	}
 
 	/* ASSERT that we really did free everything, because _ump_ukk_unmap_mem()
 	 * can fail silently. */
-	DEBUG_ASSERT( _mali_osk_list_empty(&session_data->list_head_session_memory_mappings_list) );
+	DEBUG_ASSERT(_mali_osk_list_empty(&session_data->list_head_session_memory_mappings_list));
 
-	_MALI_OSK_LIST_FOREACHENTRY(item, tmp, &session_data->list_head_session_memory_list, ump_session_memory_list_element, list)
-	{
+	_MALI_OSK_LIST_FOREACHENTRY(item, tmp, &session_data->list_head_session_memory_list, ump_session_memory_list_element, list) {
 		_mali_osk_list_del(&item->list);
 		DBG_MSG(2, ("Releasing UMP memory %u as part of file close\n", item->mem->secure_id));
 		ump_dd_reference_release(item->mem);
 		_mali_osk_free(item);
 	}
 
-	ump_descriptor_mapping_destroy( session_data->cookies_map );
+	ump_descriptor_mapping_destroy(session_data->cookies_map);
 
-	_mali_osk_lock_term(session_data->lock);
+	_mali_osk_mutex_term(session_data->lock);
 	_mali_osk_free(session_data);
 
 	DBG_MSG(2, ("Session closed\n"));
@@ -215,54 +194,49 @@ _mali_osk_errcode_t _ump_ukk_close( void** context )
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t _ump_ukk_map_mem( _ump_uk_map_mem_s *args )
+_mali_osk_errcode_t _ump_ukk_map_mem(_ump_uk_map_mem_s *args)
 {
-	struct ump_session_data * session_data;
-	ump_memory_allocation * descriptor;  /* Describes current mapping of memory */
+	struct ump_session_data *session_data;
+	ump_memory_allocation *descriptor;   /* Describes current mapping of memory */
 	_mali_osk_errcode_t err;
 	unsigned long offset = 0;
 	unsigned long left;
 	ump_dd_handle handle;  /* The real UMP handle for this memory. Its real datatype is ump_dd_mem*  */
-	ump_dd_mem * mem;      /* The real UMP memory. It is equal to the handle, but with exposed struct */
+	ump_dd_mem *mem;       /* The real UMP memory. It is equal to the handle, but with exposed struct */
 	u32 block;
 	int map_id;
 
 	session_data = (ump_session_data *)args->ctx;
-	if( NULL == session_data )
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("Session data is NULL in _ump_ukk_map_mem()\n"));
 		return _MALI_OSK_ERR_INVALID_ARGS;
 	}
 
-	descriptor = (ump_memory_allocation*) _mali_osk_calloc( 1, sizeof(ump_memory_allocation));
-	if (NULL == descriptor)
-	{
+	descriptor = (ump_memory_allocation *) _mali_osk_calloc(1, sizeof(ump_memory_allocation));
+	if (NULL == descriptor) {
 		MSG_ERR(("ump_ukk_map_mem: descriptor allocation failed\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
 	handle = ump_dd_handle_create_from_secure_id(args->secure_id);
-	if ( UMP_DD_HANDLE_INVALID == handle)
-	{
+	if (UMP_DD_HANDLE_INVALID == handle) {
 		_mali_osk_free(descriptor);
 		DBG_MSG(1, ("Trying to map unknown secure ID %u\n", args->secure_id));
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	mem = (ump_dd_mem*)handle;
+	mem = (ump_dd_mem *)handle;
 	DEBUG_ASSERT(mem);
-	if (mem->size_bytes != args->size)
-	{
+	if (mem->size_bytes != args->size) {
 		_mali_osk_free(descriptor);
 		ump_dd_reference_release(handle);
 		DBG_MSG(1, ("Trying to map too much or little. ID: %u, virtual size=%lu, UMP size: %lu\n", args->secure_id, args->size, mem->size_bytes));
 		return _MALI_OSK_ERR_FAULT;
 	}
 
-	map_id = ump_descriptor_mapping_allocate_mapping( session_data->cookies_map, (void*) descriptor );
+	map_id = ump_descriptor_mapping_allocate_mapping(session_data->cookies_map, (void *) descriptor);
 
-	if (map_id < 0)
-	{
+	if (map_id < 0) {
 		_mali_osk_free(descriptor);
 		ump_dd_reference_release(handle);
 		DBG_MSG(1, ("ump_ukk_map_mem: unable to allocate a descriptor_mapping for return cookie\n"));
@@ -277,58 +251,49 @@ _mali_osk_errcode_t _ump_ukk_map_mem( _ump_uk_map_mem_s *args )
 	descriptor->ump_session = session_data;
 	descriptor->cookie = (u32)map_id;
 
-	if ( mem->is_cached )
-	{
+	if (mem->is_cached) {
 		descriptor->is_cached = 1;
 		args->is_cached       = 1;
 		DBG_MSG(3, ("Mapping UMP secure_id: %d as cached.\n", args->secure_id));
-	}
-	else
-	{
+	} else {
 		descriptor->is_cached = 0;
 		args->is_cached       = 0;
 		DBG_MSG(3, ("Mapping UMP secure_id: %d  as Uncached.\n", args->secure_id));
 	}
 
-	_mali_osk_list_init( &descriptor->list );
+	_mali_osk_list_init(&descriptor->list);
 
-	err = _ump_osk_mem_mapregion_init( descriptor );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	err = _ump_osk_mem_mapregion_init(descriptor);
+	if (_MALI_OSK_ERR_OK != err) {
 		DBG_MSG(1, ("Failed to initialize memory mapping in _ump_ukk_map_mem(). ID: %u\n", args->secure_id));
-		ump_descriptor_mapping_free( session_data->cookies_map, map_id );
+		ump_descriptor_mapping_free(session_data->cookies_map, map_id);
 		_mali_osk_free(descriptor);
 		ump_dd_reference_release(mem);
 		return err;
 	}
 
 	DBG_MSG(4, ("Mapping virtual to physical memory: ID: %u, size:%lu, first physical addr: 0x%08lx, number of regions: %lu\n",
-	        mem->secure_id,
-	        mem->size_bytes,
-	        ((NULL != mem->block_array) ? mem->block_array->addr : 0),
-	        mem->nr_blocks));
+		    mem->secure_id,
+		    mem->size_bytes,
+		    ((NULL != mem->block_array) ? mem->block_array->addr : 0),
+		    mem->nr_blocks));
 
 	left = descriptor->size;
 	/* loop over all blocks and map them in */
-	for (block = 0; block < mem->nr_blocks; block++)
-	{
+	for (block = 0; block < mem->nr_blocks; block++) {
 		unsigned long size_to_map;
 
-		if (left >  mem->block_array[block].size)
-		{
+		if (left >  mem->block_array[block].size) {
 			size_to_map = mem->block_array[block].size;
-		}
-		else
-		{
+		} else {
 			size_to_map = left;
 		}
 
-		if (_MALI_OSK_ERR_OK != _ump_osk_mem_mapregion_map(descriptor, offset, (u32 *)&(mem->block_array[block].addr), size_to_map ) )
-		{
+		if (_MALI_OSK_ERR_OK != _ump_osk_mem_mapregion_map(descriptor, offset, (u32 *) & (mem->block_array[block].addr), size_to_map)) {
 			DBG_MSG(1, ("WARNING: _ump_ukk_map_mem failed to map memory into userspace\n"));
-			ump_descriptor_mapping_free( session_data->cookies_map, map_id );
+			ump_descriptor_mapping_free(session_data->cookies_map, map_id);
 			ump_dd_reference_release(mem);
-			_ump_osk_mem_mapregion_term( descriptor );
+			_ump_osk_mem_mapregion_term(descriptor);
 			_mali_osk_free(descriptor);
 			return _MALI_OSK_ERR_FAULT;
 		}
@@ -337,9 +302,9 @@ _mali_osk_errcode_t _ump_ukk_map_mem( _ump_uk_map_mem_s *args )
 	}
 
 	/* Add to the ump_memory_allocation tracking list */
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
-	_mali_osk_list_add( &descriptor->list, &session_data->list_head_session_memory_mappings_list );
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_wait(session_data->lock);
+	_mali_osk_list_add(&descriptor->list, &session_data->list_head_session_memory_mappings_list);
+	_mali_osk_mutex_signal(session_data->lock);
 
 	args->mapping = descriptor->mapping;
 	args->cookie = descriptor->cookie;
@@ -347,51 +312,48 @@ _mali_osk_errcode_t _ump_ukk_map_mem( _ump_uk_map_mem_s *args )
 	return _MALI_OSK_ERR_OK;
 }
 
-void _ump_ukk_unmap_mem( _ump_uk_unmap_mem_s *args )
+void _ump_ukk_unmap_mem(_ump_uk_unmap_mem_s *args)
 {
-	struct ump_session_data * session_data;
-	ump_memory_allocation * descriptor;
+	struct ump_session_data *session_data;
+	ump_memory_allocation *descriptor;
 	ump_dd_handle handle;
 
 	session_data = (ump_session_data *)args->ctx;
 
-	if( NULL == session_data )
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("Session data is NULL in _ump_ukk_map_mem()\n"));
 		return;
 	}
 
-	if (0 != ump_descriptor_mapping_get( session_data->cookies_map, (int)args->cookie, (void**)&descriptor) )
-	{
-		MSG_ERR(("_ump_ukk_map_mem: cookie 0x%X not found for this session\n", args->cookie ));
+	if (0 != ump_descriptor_mapping_get(session_data->cookies_map, (int)args->cookie, (void **)&descriptor)) {
+		MSG_ERR(("_ump_ukk_map_mem: cookie 0x%X not found for this session\n", args->cookie));
 		return;
 	}
 
 	DEBUG_ASSERT_POINTER(descriptor);
 
 	handle = descriptor->handle;
-	if ( UMP_DD_HANDLE_INVALID == handle)
-	{
+	if (UMP_DD_HANDLE_INVALID == handle) {
 		DBG_MSG(1, ("WARNING: Trying to unmap unknown handle: UNKNOWN\n"));
 		return;
 	}
 
 	/* Remove the ump_memory_allocation from the list of tracked mappings */
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
-	_mali_osk_list_del( &descriptor->list );
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_wait(session_data->lock);
+	_mali_osk_list_del(&descriptor->list);
+	_mali_osk_mutex_signal(session_data->lock);
 
-	ump_descriptor_mapping_free( session_data->cookies_map, (int)args->cookie );
+	ump_descriptor_mapping_free(session_data->cookies_map, (int)args->cookie);
 
 	ump_dd_reference_release(handle);
 
-	_ump_osk_mem_mapregion_term( descriptor );
+	_ump_osk_mem_mapregion_term(descriptor);
 	_mali_osk_free(descriptor);
 }
 
-u32 _ump_ukk_report_memory_usage( void )
+u32 _ump_ukk_report_memory_usage(void)
 {
-	if(device.backend->stat)
+	if (device.backend->stat)
 		return device.backend->stat(device.backend);
 	else
 		return 0;
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_common.h b/drivers/gpu/mali/ump/common/ump_kernel_common.h
index 03d213d..efc6c3f 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_common.h
+++ b/drivers/gpu/mali/ump/common/ump_kernel_common.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,54 +14,55 @@
 #include "ump_kernel_types.h"
 #include "ump_kernel_interface.h"
 #include "ump_kernel_descriptor_mapping.h"
+#include "ump_kernel_random_mapping.h"
 #include "ump_kernel_memory_backend.h"
 
 
 #ifdef DEBUG
-	extern int ump_debug_level;
-	#define UMP_DEBUG_PRINT(args) _mali_osk_dbgmsg args
-	#define UMP_DEBUG_CODE(args) args
-	#define DBG_MSG(level,args)  do { /* args should be in brackets */ \
+extern int ump_debug_level;
+#define UMP_DEBUG_PRINT(args) _mali_osk_dbgmsg args
+#define UMP_DEBUG_CODE(args) args
+#define DBG_MSG(level,args)  do { /* args should be in brackets */ \
 		((level) <=  ump_debug_level)?\
 		UMP_DEBUG_PRINT(("UMP<" #level ">: ")), \
 		UMP_DEBUG_PRINT(args):0; \
-		} while (0)
+	} while (0)
 
-	#define DBG_MSG_IF(level,condition,args) /* args should be in brackets */ \
-		if((condition)&&((level) <=  ump_debug_level)) {\
+#define DBG_MSG_IF(level,condition,args) /* args should be in brackets */ \
+	if((condition)&&((level) <=  ump_debug_level)) {\
 		UMP_DEBUG_PRINT(("UMP<" #level ">: ")); \
 		UMP_DEBUG_PRINT(args); \
-		}
+	}
 
-	#define DBG_MSG_ELSE(level,args) /* args should be in brackets */ \
-		else if((level) <=  ump_debug_level) { \
+#define DBG_MSG_ELSE(level,args) /* args should be in brackets */ \
+	else if((level) <=  ump_debug_level) { \
 		UMP_DEBUG_PRINT(("UMP<" #level ">: ")); \
 		UMP_DEBUG_PRINT(args); \
-		}
+	}
 
-	#define DEBUG_ASSERT_POINTER(pointer) do  {if( (pointer)== NULL) MSG_ERR(("NULL pointer " #pointer)); } while(0)
-	#define DEBUG_ASSERT(condition) do  {if(!(condition)) MSG_ERR(("ASSERT failed: " #condition)); } while(0)
+#define DEBUG_ASSERT_POINTER(pointer) do  {if( (pointer)== NULL) MSG_ERR(("NULL pointer " #pointer)); } while(0)
+#define DEBUG_ASSERT(condition) do  {if(!(condition)) MSG_ERR(("ASSERT failed: " #condition)); } while(0)
 #else /* DEBUG */
-	#define UMP_DEBUG_PRINT(args) do {} while(0)
-	#define UMP_DEBUG_CODE(args)
-	#define DBG_MSG(level,args) do {} while(0)
-	#define DBG_MSG_IF(level,condition,args) do {} while(0)
-	#define DBG_MSG_ELSE(level,args) do {} while(0)
-	#define DEBUG_ASSERT(condition) do {} while(0)
-	#define DEBUG_ASSERT_POINTER(pointer) do  {} while(0)
+#define UMP_DEBUG_PRINT(args) do {} while(0)
+#define UMP_DEBUG_CODE(args)
+#define DBG_MSG(level,args) do {} while(0)
+#define DBG_MSG_IF(level,condition,args) do {} while(0)
+#define DBG_MSG_ELSE(level,args) do {} while(0)
+#define DEBUG_ASSERT(condition) do {} while(0)
+#define DEBUG_ASSERT_POINTER(pointer) do  {} while(0)
 #endif /* DEBUG */
 
 #define MSG_ERR(args) do{ /* args should be in brackets */ \
-	 _mali_osk_dbgmsg("UMP: ERR: %s\n" ,__FILE__); \
-	 _mali_osk_dbgmsg( "           %s()%4d\n", __FUNCTION__, __LINE__) ; \
-	 _mali_osk_dbgmsg args ; \
-	 _mali_osk_dbgmsg("\n"); \
+		_mali_osk_dbgmsg("UMP: ERR: %s\n" ,__FILE__); \
+		_mali_osk_dbgmsg( "           %s()%4d\n", __FUNCTION__, __LINE__) ; \
+		_mali_osk_dbgmsg args ; \
+		_mali_osk_dbgmsg("\n"); \
 	} while(0)
 
 #define MSG(args) do{ /* args should be in brackets */ \
-		 _mali_osk_dbgmsg("UMP: "); \
-		 _mali_osk_dbgmsg args; \
-		} while (0)
+		_mali_osk_dbgmsg("UMP: "); \
+		_mali_osk_dbgmsg args; \
+	} while (0)
 
 
 
@@ -70,13 +71,12 @@
  * A session is created when someone open() the device, and
  * closed when someone close() it or the user space application terminates.
  */
-typedef struct ump_session_data
-{
+typedef struct ump_session_data {
 	_mali_osk_list_t list_head_session_memory_list;  /**< List of ump allocations made by the process (elements are ump_session_memory_list_element) */
 	_mali_osk_list_t list_head_session_memory_mappings_list; /**< List of ump_memory_allocations mapped in */
 	int api_version;
-	_mali_osk_lock_t * lock;
-	ump_descriptor_mapping * cookies_map; /**< Secure mapping of cookies from _ump_ukk_map_mem() */
+	_mali_osk_mutex_t *lock;
+	ump_descriptor_mapping *cookies_map;  /**< Secure mapping of cookies from _ump_ukk_map_mem() */
 	int cache_operations_ongoing;
 	int has_pending_level1_cache_flush;
 } ump_session_data;
@@ -88,9 +88,8 @@ typedef struct ump_session_data
  * We need to track this in order to be able to clean up after user space processes
  * which don't do it themself (e.g. due to a crash or premature termination).
  */
-typedef struct ump_session_memory_list_element
-{
-	struct ump_dd_mem * mem;
+typedef struct ump_session_memory_list_element {
+	struct ump_dd_mem *mem;
 	_mali_osk_list_t list;
 } ump_session_memory_list_element;
 
@@ -99,11 +98,9 @@ typedef struct ump_session_memory_list_element
 /*
  * Device specific data, created when device driver is loaded, and then kept as the global variable device.
  */
-typedef struct ump_dev
-{
-	_mali_osk_lock_t * secure_id_map_lock;
-	ump_descriptor_mapping * secure_id_map;
-	ump_memory_backend * backend;
+typedef struct ump_dev {
+	ump_random_mapping *secure_id_map;
+	ump_memory_backend *backend;
 } ump_dev;
 
 
@@ -113,7 +110,7 @@ extern struct ump_dev device;
 
 _mali_osk_errcode_t ump_kernel_constructor(void);
 void ump_kernel_destructor(void);
-int map_errcode( _mali_osk_errcode_t err );
+int map_errcode(_mali_osk_errcode_t err);
 
 /**
  * variables from user space cannot be dereferenced from kernel space; tagging them
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.c b/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.c
index c3a5af5..c89324e 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.c
+++ b/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -21,29 +21,26 @@
  * @param count Number of mappings in the table
  * @return Pointer to a new table, NULL on error
  */
-static ump_descriptor_table * descriptor_table_alloc(int count);
+static ump_descriptor_table *descriptor_table_alloc(int count);
 
 /**
  * Free a descriptor table
  * @param table The table to free
  */
-static void descriptor_table_free(ump_descriptor_table * table);
+static void descriptor_table_free(ump_descriptor_table *table);
 
-ump_descriptor_mapping * ump_descriptor_mapping_create(int init_entries, int max_entries)
+ump_descriptor_mapping *ump_descriptor_mapping_create(int init_entries, int max_entries)
 {
-	ump_descriptor_mapping * map = _mali_osk_calloc(1, sizeof(ump_descriptor_mapping) );
+	ump_descriptor_mapping *map = _mali_osk_calloc(1, sizeof(ump_descriptor_mapping));
 
 	init_entries = MALI_PAD_INT(init_entries);
 	max_entries = MALI_PAD_INT(max_entries);
 
-	if (NULL != map)
-	{
+	if (NULL != map) {
 		map->table = descriptor_table_alloc(init_entries);
-		if (NULL != map->table)
-		{
-			map->lock = _mali_osk_lock_init(_MALI_OSK_LOCKFLAG_NONINTERRUPTABLE | _MALI_OSK_LOCKFLAG_READERWRITER, 0 , 0);
-			if ( NULL != map->lock )
-			{
+		if (NULL != map->table) {
+			map->lock = _mali_osk_mutex_rw_init(_MALI_OSK_LOCKFLAG_UNORDERED, 0);
+			if (NULL != map->lock) {
 				_mali_osk_set_nonatomic_bit(0, map->table->usage); /* reserve bit 0 to prevent NULL/zero logic to kick in */
 				map->max_nr_mappings_allowed = max_entries;
 				map->current_nr_mappings = init_entries;
@@ -56,41 +53,38 @@ ump_descriptor_mapping * ump_descriptor_mapping_create(int init_entries, int max
 	return NULL;
 }
 
-void ump_descriptor_mapping_destroy(ump_descriptor_mapping * map)
+void ump_descriptor_mapping_destroy(ump_descriptor_mapping *map)
 {
 	descriptor_table_free(map->table);
-	_mali_osk_lock_term( map->lock );
+	_mali_osk_mutex_rw_term(map->lock);
 	_mali_osk_free(map);
 }
 
-int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping * map, void * target)
+int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping *map, void *target)
 {
- 	int descriptor = -1;/*-EFAULT;*/
- 	_mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
- 	descriptor = _mali_osk_find_first_zero_bit(map->table->usage, map->current_nr_mappings);
-	if (descriptor == map->current_nr_mappings)
-	{
+	int descriptor = -1;/*-EFAULT;*/
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
+	descriptor = _mali_osk_find_first_zero_bit(map->table->usage, map->current_nr_mappings);
+	if (descriptor == map->current_nr_mappings) {
 		int nr_mappings_new;
 		/* no free descriptor, try to expand the table */
-		ump_descriptor_table * new_table;
-		ump_descriptor_table * old_table = map->table;
-		nr_mappings_new= map->current_nr_mappings *2;
+		ump_descriptor_table *new_table;
+		ump_descriptor_table *old_table = map->table;
+		nr_mappings_new = map->current_nr_mappings * 2;
 
-		if (map->current_nr_mappings >= map->max_nr_mappings_allowed)
-		{
+		if (map->current_nr_mappings >= map->max_nr_mappings_allowed) {
 			descriptor = -1;
 			goto unlock_and_exit;
 		}
 
 		new_table = descriptor_table_alloc(nr_mappings_new);
-		if (NULL == new_table)
-		{
+		if (NULL == new_table) {
 			descriptor = -1;
 			goto unlock_and_exit;
 		}
 
- 		_mali_osk_memcpy(new_table->usage, old_table->usage, (sizeof(unsigned long)*map->current_nr_mappings) / BITS_PER_LONG);
- 		_mali_osk_memcpy(new_table->mappings, old_table->mappings, map->current_nr_mappings * sizeof(void*));
+		_mali_osk_memcpy(new_table->usage, old_table->usage, (sizeof(unsigned long)*map->current_nr_mappings) / BITS_PER_LONG);
+		_mali_osk_memcpy(new_table->mappings, old_table->mappings, map->current_nr_mappings * sizeof(void *));
 		map->table = new_table;
 		map->current_nr_mappings = nr_mappings_new;
 		descriptor_table_free(old_table);
@@ -101,65 +95,60 @@ int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping * map, void *
 	map->table->mappings[descriptor] = target;
 
 unlock_and_exit:
-	_mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
 	return descriptor;
 }
 
-int ump_descriptor_mapping_get(ump_descriptor_mapping * map, int descriptor, void** target)
+int ump_descriptor_mapping_get(ump_descriptor_mapping *map, int descriptor, void **target)
 {
- 	int result = -1;/*-EFAULT;*/
- 	DEBUG_ASSERT(map);
- 	_mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
- 	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	int result = -1;/*-EFAULT;*/
+	DEBUG_ASSERT(map);
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
+	if ((descriptor > 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		*target = map->table->mappings[descriptor];
 		result = 0;
-	}
-	else *target = NULL;
-	_mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
+	} else *target = NULL;
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
 	return result;
 }
 
-int ump_descriptor_mapping_set(ump_descriptor_mapping * map, int descriptor, void * target)
+int ump_descriptor_mapping_set(ump_descriptor_mapping *map, int descriptor, void *target)
 {
- 	int result = -1;/*-EFAULT;*/
- 	_mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
- 	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	int result = -1;/*-EFAULT;*/
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RO);
+	if ((descriptor > 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		map->table->mappings[descriptor] = target;
 		result = 0;
 	}
-	_mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RO);
 	return result;
 }
 
-void ump_descriptor_mapping_free(ump_descriptor_mapping * map, int descriptor)
+void ump_descriptor_mapping_free(ump_descriptor_mapping *map, int descriptor)
 {
- 	_mali_osk_lock_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
- 	if ( (descriptor >= 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage) )
-	{
+	_mali_osk_mutex_rw_wait(map->lock, _MALI_OSK_LOCKMODE_RW);
+	if ((descriptor > 0) && (descriptor < map->current_nr_mappings) && _mali_osk_test_bit(descriptor, map->table->usage)) {
 		map->table->mappings[descriptor] = NULL;
 		_mali_osk_clear_nonatomic_bit(descriptor, map->table->usage);
 	}
-	_mali_osk_lock_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_rw_signal(map->lock, _MALI_OSK_LOCKMODE_RW);
 }
 
-static ump_descriptor_table * descriptor_table_alloc(int count)
+static ump_descriptor_table *descriptor_table_alloc(int count)
 {
-	ump_descriptor_table * table;
+	ump_descriptor_table *table;
 
-	table = _mali_osk_calloc(1, sizeof(ump_descriptor_table) + ((sizeof(unsigned long) * count)/BITS_PER_LONG) + (sizeof(void*) * count) );
+	table = _mali_osk_calloc(1, sizeof(ump_descriptor_table) + ((sizeof(unsigned long) * count) / BITS_PER_LONG) + (sizeof(void *) * count));
 
-	if (NULL != table)
-	{
-		table->usage = (u32*)((u8*)table + sizeof(ump_descriptor_table));
-		table->mappings = (void**)((u8*)table + sizeof(ump_descriptor_table) + ((sizeof(unsigned long) * count)/BITS_PER_LONG));
+	if (NULL != table) {
+		table->usage = (u32 *)((u8 *)table + sizeof(ump_descriptor_table));
+		table->mappings = (void **)((u8 *)table + sizeof(ump_descriptor_table) + ((sizeof(unsigned long) * count) / BITS_PER_LONG));
 	}
 
 	return table;
 }
 
-static void descriptor_table_free(ump_descriptor_table * table)
+static void descriptor_table_free(ump_descriptor_table *table)
 {
 	_mali_osk_free(table);
 }
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.h b/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.h
index 06543ee..160e20e 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.h
+++ b/drivers/gpu/mali/ump/common/ump_kernel_descriptor_mapping.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,22 +20,20 @@
 /**
  * The actual descriptor mapping table, never directly accessed by clients
  */
-typedef struct ump_descriptor_table
-{
-	u32 * usage; /**< Pointer to bitpattern indicating if a descriptor is valid/used or not */
-	void** mappings; /**< Array of the pointers the descriptors map to */
+typedef struct ump_descriptor_table {
+	u32 *usage;  /**< Pointer to bitpattern indicating if a descriptor is valid/used or not */
+	void **mappings; /**< Array of the pointers the descriptors map to */
 } ump_descriptor_table;
 
 /**
  * The descriptor mapping object
  * Provides a separate namespace where we can map an integer to a pointer
  */
-typedef struct ump_descriptor_mapping
-{
-	_mali_osk_lock_t *lock; /**< Lock protecting access to the mapping object */
+typedef struct ump_descriptor_mapping {
+	_mali_osk_mutex_rw_t *lock; /**< Lock protecting access to the mapping object */
 	int max_nr_mappings_allowed; /**< Max number of mappings to support in this namespace */
 	int current_nr_mappings; /**< Current number of possible mappings */
-	ump_descriptor_table * table; /**< Pointer to the current mapping table */
+	ump_descriptor_table *table;  /**< Pointer to the current mapping table */
 } ump_descriptor_mapping;
 
 /**
@@ -45,13 +43,13 @@ typedef struct ump_descriptor_mapping
  * @param max_entries Number of entries to max support
  * @return Pointer to a descriptor mapping object, NULL on failure
  */
-ump_descriptor_mapping * ump_descriptor_mapping_create(int init_entries, int max_entries);
+ump_descriptor_mapping *ump_descriptor_mapping_create(int init_entries, int max_entries);
 
 /**
  * Destroy a descriptor mapping object
  * @param map The map to free
  */
-void ump_descriptor_mapping_destroy(ump_descriptor_mapping * map);
+void ump_descriptor_mapping_destroy(ump_descriptor_mapping *map);
 
 /**
  * Allocate a new mapping entry (descriptor ID)
@@ -60,7 +58,7 @@ void ump_descriptor_mapping_destroy(ump_descriptor_mapping * map);
  * @param target The value to map to
  * @return The descriptor allocated, a negative value on error
  */
-int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping * map, void * target);
+int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping *map, void *target);
 
 /**
  * Get the value mapped to by a descriptor ID
@@ -69,7 +67,7 @@ int ump_descriptor_mapping_allocate_mapping(ump_descriptor_mapping * map, void *
  * @param target Pointer to a pointer which will receive the stored value
  * @return 0 on successful lookup, negative on error
  */
-int ump_descriptor_mapping_get(ump_descriptor_mapping * map, int descriptor, void** target);
+int ump_descriptor_mapping_get(ump_descriptor_mapping *map, int descriptor, void **target);
 
 /**
  * Set the value mapped to by a descriptor ID
@@ -78,7 +76,7 @@ int ump_descriptor_mapping_get(ump_descriptor_mapping * map, int descriptor, voi
  * @param target Pointer to replace the current value with
  * @return 0 on successful lookup, negative on error
  */
-int ump_descriptor_mapping_set(ump_descriptor_mapping * map, int descriptor, void * target);
+int ump_descriptor_mapping_set(ump_descriptor_mapping *map, int descriptor, void *target);
 
 /**
  * Free the descriptor ID
@@ -86,6 +84,6 @@ int ump_descriptor_mapping_set(ump_descriptor_mapping * map, int descriptor, voi
  * @param map The map to free the descriptor from
  * @param descriptor The descriptor ID to free
  */
-void ump_descriptor_mapping_free(ump_descriptor_mapping * map, int descriptor);
+void ump_descriptor_mapping_free(ump_descriptor_mapping *map, int descriptor);
 
 #endif /* __UMP_KERNEL_DESCRIPTOR_MAPPING_H__ */
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_memory_backend.h b/drivers/gpu/mali/ump/common/ump_kernel_memory_backend.h
index 529afa6..4fa4bda 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_memory_backend.h
+++ b/drivers/gpu/mali/ump/common/ump_kernel_memory_backend.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -19,32 +19,30 @@
 #include "ump_kernel_types.h"
 
 
-typedef struct ump_memory_allocation
-{
-	void                    * phys_addr;
-	void                    * mapping;
+typedef struct ump_memory_allocation {
+	void                     *phys_addr;
+	void                     *mapping;
 	unsigned long             size;
 	ump_dd_handle             handle;
-	void                    * process_mapping_info;
+	void                     *process_mapping_info;
 	u32                       cookie;               /**< necessary on some U/K interface implementations */
-	struct ump_session_data * ump_session;          /**< Session that this allocation belongs to */
+	struct ump_session_data *ump_session;           /**< Session that this allocation belongs to */
 	_mali_osk_list_t          list;                 /**< List for linking together memory allocations into the session's memory head */
 	u32 is_cached;
 } ump_memory_allocation;
 
-typedef struct ump_memory_backend
-{
-	int  (*allocate)(void* ctx, ump_dd_mem * descriptor);
-	void (*release)(void* ctx, ump_dd_mem * descriptor);
-	void (*shutdown)(struct ump_memory_backend * backend);
-	u32  (*stat)(struct ump_memory_backend *backend);
-	int  (*pre_allocate_physical_check)(void *ctx, u32 size);
-	u32  (*adjust_to_mali_phys)(void *ctx, u32 cpu_phys);
-	void * ctx;
+typedef struct ump_memory_backend {
+	int (*allocate)(void *ctx, ump_dd_mem *descriptor);
+	void (*release)(void *ctx, ump_dd_mem *descriptor);
+	void (*shutdown)(struct ump_memory_backend *backend);
+	u32(*stat)(struct ump_memory_backend *backend);
+	int (*pre_allocate_physical_check)(void *ctx, u32 size);
+	u32(*adjust_to_mali_phys)(void *ctx, u32 cpu_phys);
+	void *ctx;
 } ump_memory_backend;
 
-ump_memory_backend * ump_memory_backend_create ( void );
-void ump_memory_backend_destroy( void );
+ump_memory_backend *ump_memory_backend_create(void);
+void ump_memory_backend_destroy(void);
 
 #endif /*__UMP_KERNEL_MEMORY_BACKEND_H__ */
 
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_ref_drv.c b/drivers/gpu/mali/ump/common/ump_kernel_ref_drv.c
index daf20a6..3898218 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_ref_drv.c
+++ b/drivers/gpu/mali/ump/common/ump_kernel_ref_drv.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -21,32 +21,29 @@
 #define UMP_MINIMUM_SIZE_MASK    (~(UMP_MINIMUM_SIZE-1))
 #define UMP_SIZE_ALIGN(x)        (((x)+UMP_MINIMUM_SIZE-1)&UMP_MINIMUM_SIZE_MASK)
 #define UMP_ADDR_ALIGN_OFFSET(x) ((x)&(UMP_MINIMUM_SIZE-1))
-static void phys_blocks_release(void * ctx, struct ump_dd_mem * descriptor);
+static void phys_blocks_release(void *ctx, struct ump_dd_mem *descriptor);
 
-UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_phys_blocks(ump_dd_physical_block * blocks, unsigned long num_blocks)
+UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_phys_blocks(ump_dd_physical_block *blocks, unsigned long num_blocks)
 {
-	ump_dd_mem * mem;
+	ump_dd_mem *mem;
 	unsigned long size_total = 0;
-	int map_id;
+	int ret;
 	u32 i;
 
 	/* Go through the input blocks and verify that they are sane */
-	for (i=0; i < num_blocks; i++)
-	{
+	for (i = 0; i < num_blocks; i++) {
 		unsigned long addr = blocks[i].addr;
 		unsigned long size = blocks[i].size;
 
 		DBG_MSG(5, ("Adding physical memory to new handle. Address: 0x%08lx, size: %lu\n", addr, size));
 		size_total += blocks[i].size;
 
-		if (0 != UMP_ADDR_ALIGN_OFFSET(addr))
-		{
+		if (0 != UMP_ADDR_ALIGN_OFFSET(addr)) {
 			MSG_ERR(("Trying to create UMP memory from unaligned physical address. Address: 0x%08lx\n", addr));
 			return UMP_DD_HANDLE_INVALID;
 		}
 
-		if (0 != UMP_ADDR_ALIGN_OFFSET(size))
-		{
+		if (0 != UMP_ADDR_ALIGN_OFFSET(size)) {
 			MSG_ERR(("Trying to create UMP memory with unaligned size. Size: %lu\n", size));
 			return UMP_DD_HANDLE_INVALID;
 		}
@@ -54,30 +51,14 @@ UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_phys_blocks(ump_dd
 
 	/* Allocate the ump_dd_mem struct for this allocation */
 	mem = _mali_osk_malloc(sizeof(*mem));
-	if (NULL == mem)
-	{
+	if (NULL == mem) {
 		DBG_MSG(1, ("Could not allocate ump_dd_mem in ump_dd_handle_create_from_phys_blocks()\n"));
 		return UMP_DD_HANDLE_INVALID;
 	}
 
-	/* Find a secure ID for this allocation */
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	map_id = ump_descriptor_mapping_allocate_mapping(device.secure_id_map, (void*) mem);
-
-	if (map_id < 0)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		_mali_osk_free(mem);
-		DBG_MSG(1, ("Failed to allocate secure ID in ump_dd_handle_create_from_phys_blocks()\n"));
-		return UMP_DD_HANDLE_INVALID;
-	}
-
 	/* Now, make a copy of the block information supplied by the user */
-	mem->block_array = _mali_osk_malloc(sizeof(ump_dd_physical_block)* num_blocks);
-	if (NULL == mem->block_array)
-	{
-		ump_descriptor_mapping_free(device.secure_id_map, map_id);
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	mem->block_array = _mali_osk_malloc(sizeof(ump_dd_physical_block) * num_blocks);
+	if (NULL == mem->block_array) {
 		_mali_osk_free(mem);
 		DBG_MSG(1, ("Could not allocate a mem handle for function ump_dd_handle_create_from_phys_blocks().\n"));
 		return UMP_DD_HANDLE_INVALID;
@@ -87,7 +68,6 @@ UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_phys_blocks(ump_dd
 
 	/* And setup the rest of the ump_dd_mem struct */
 	_mali_osk_atomic_init(&mem->ref_count, 1);
-	mem->secure_id = (ump_secure_id)map_id;
 	mem->size_bytes = size_total;
 	mem->nr_blocks = num_blocks;
 	mem->backend_info = NULL;
@@ -98,81 +78,75 @@ UMP_KERNEL_API_EXPORT ump_dd_handle ump_dd_handle_create_from_phys_blocks(ump_dd
 	mem->hw_device = _UMP_UK_USED_BY_CPU;
 	mem->lock_usage = UMP_NOT_LOCKED;
 
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	/* Find a secure ID for this allocation */
+	ret = ump_random_mapping_insert(device.secure_id_map, mem);
+	if (unlikely(ret)) {
+		_mali_osk_free(mem->block_array);
+		_mali_osk_free(mem);
+		DBG_MSG(1, ("Failed to allocate secure ID in ump_dd_handle_create_from_phys_blocks()\n"));
+		return UMP_DD_HANDLE_INVALID;
+	}
+
 	DBG_MSG(3, ("UMP memory created. ID: %u, size: %lu\n", mem->secure_id, mem->size_bytes));
 
 	return (ump_dd_handle)mem;
 }
 
-static void phys_blocks_release(void * ctx, struct ump_dd_mem * descriptor)
+static void phys_blocks_release(void *ctx, struct ump_dd_mem *descriptor)
 {
 	_mali_osk_free(descriptor->block_array);
 	descriptor->block_array = NULL;
 }
 
-_mali_osk_errcode_t _ump_ukk_allocate( _ump_uk_allocate_s *user_interaction )
+_mali_osk_errcode_t _ump_ukk_allocate(_ump_uk_allocate_s *user_interaction)
 {
-	ump_session_data * session_data = NULL;
+	ump_session_data *session_data = NULL;
 	ump_dd_mem *new_allocation = NULL;
-	ump_session_memory_list_element * session_memory_element = NULL;
-	int map_id;
+	ump_session_memory_list_element *session_memory_element = NULL;
+	int ret;
 
-	DEBUG_ASSERT_POINTER( user_interaction );
-	DEBUG_ASSERT_POINTER( user_interaction->ctx );
+	DEBUG_ASSERT_POINTER(user_interaction);
+	DEBUG_ASSERT_POINTER(user_interaction->ctx);
 
 	session_data = (ump_session_data *) user_interaction->ctx;
 
-	session_memory_element = _mali_osk_calloc( 1, sizeof(ump_session_memory_list_element));
-	if (NULL == session_memory_element)
-	{
+	session_memory_element = _mali_osk_calloc(1, sizeof(ump_session_memory_list_element));
+	if (NULL == session_memory_element) {
 		DBG_MSG(1, ("Failed to allocate ump_session_memory_list_element in ump_ioctl_allocate()\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
 
-	new_allocation = _mali_osk_calloc( 1, sizeof(ump_dd_mem));
-	if (NULL==new_allocation)
-	{
+	new_allocation = _mali_osk_calloc(1, sizeof(ump_dd_mem));
+	if (NULL == new_allocation) {
 		_mali_osk_free(session_memory_element);
 		DBG_MSG(1, ("Failed to allocate ump_dd_mem in _ump_ukk_allocate()\n"));
 		return _MALI_OSK_ERR_NOMEM;
 	}
 
-	/* Create a secure ID for this allocation */
-	_mali_osk_lock_wait(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-	map_id = ump_descriptor_mapping_allocate_mapping(device.secure_id_map, (void*)new_allocation);
-
-	if (map_id < 0)
-	{
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-		_mali_osk_free(session_memory_element);
-		_mali_osk_free(new_allocation);
-		DBG_MSG(1, ("Failed to allocate secure ID in ump_ioctl_allocate()\n"));
-		return - _MALI_OSK_ERR_INVALID_FUNC;
-	}
-
 	/* Initialize the part of the new_allocation that we know so for */
-	new_allocation->secure_id = (ump_secure_id)map_id;
-	_mali_osk_atomic_init(&new_allocation->ref_count,1);
-	if ( 0==(UMP_REF_DRV_UK_CONSTRAINT_USE_CACHE & user_interaction->constraints) )
-		 new_allocation->is_cached = 0;
+	_mali_osk_atomic_init(&new_allocation->ref_count, 1);
+	if (0 == (UMP_REF_DRV_UK_CONSTRAINT_USE_CACHE & user_interaction->constraints))
+		new_allocation->is_cached = 0;
 	else new_allocation->is_cached = 1;
 
-	/* special case a size of 0, we should try to emulate what malloc does in this case, which is to return a valid pointer that must be freed, but can't be dereferences */
-	if (0 == user_interaction->size)
-	{
-		user_interaction->size = 1; /* emulate by actually allocating the minimum block size */
+	/* Special case a size of 0, we should try to emulate what malloc does
+	 * in this case, which is to return a valid pointer that must be freed,
+	 * but can't be dereferenced */
+	if (0 == user_interaction->size) {
+		/* Emulate by actually allocating the minimum block size */
+		user_interaction->size = 1;
 	}
 
-	new_allocation->size_bytes = UMP_SIZE_ALIGN(user_interaction->size); /* Page align the size */
+	/* Page align the size */
+	new_allocation->size_bytes = UMP_SIZE_ALIGN(user_interaction->size);
 	new_allocation->lock_usage = UMP_NOT_LOCKED;
 
 	/* Now, ask the active memory backend to do the actual memory allocation */
-	if (!device.backend->allocate( device.backend->ctx, new_allocation ) )
-	{
-		DBG_MSG(3, ("OOM: No more UMP memory left. Failed to allocate memory in ump_ioctl_allocate(). Size: %lu, requested size: %lu\n", new_allocation->size_bytes, (unsigned long)user_interaction->size));
-		ump_descriptor_mapping_free(device.secure_id_map, map_id);
-		_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
+	if (!device.backend->allocate(device.backend->ctx, new_allocation)) {
+		DBG_MSG(3, ("OOM: No more UMP memory left. Failed to allocate memory in ump_ioctl_allocate(). Size: %lu, requested size: %lu\n",
+					new_allocation->size_bytes,
+					(unsigned long)user_interaction->size));
 		_mali_osk_free(new_allocation);
 		_mali_osk_free(session_memory_element);
 		return _MALI_OSK_ERR_INVALID_FUNC;
@@ -181,17 +155,27 @@ _mali_osk_errcode_t _ump_ukk_allocate( _ump_uk_allocate_s *user_interaction )
 	new_allocation->ctx = device.backend->ctx;
 	new_allocation->release_func = device.backend->release;
 
-	_mali_osk_lock_signal(device.secure_id_map_lock, _MALI_OSK_LOCKMODE_RW);
-
 	/* Initialize the session_memory_element, and add it to the session object */
 	session_memory_element->mem = new_allocation;
-	_mali_osk_lock_wait(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_wait(session_data->lock);
 	_mali_osk_list_add(&(session_memory_element->list), &(session_data->list_head_session_memory_list));
-	_mali_osk_lock_signal(session_data->lock, _MALI_OSK_LOCKMODE_RW);
+	_mali_osk_mutex_signal(session_data->lock);
+
+	/* Create a secure ID for this allocation */
+	ret = ump_random_mapping_insert(device.secure_id_map, new_allocation);
+	if (unlikely(ret)) {
+		new_allocation->release_func(new_allocation->ctx, new_allocation);
+		_mali_osk_free(session_memory_element);
+		_mali_osk_free(new_allocation);
+		DBG_MSG(1, ("Failed to allocate secure ID in ump_ioctl_allocate()\n"));
+		return _MALI_OSK_ERR_INVALID_FUNC;
+	}
 
 	user_interaction->secure_id = new_allocation->secure_id;
 	user_interaction->size = new_allocation->size_bytes;
-	DBG_MSG(3, ("UMP memory allocated. ID: %u, size: %lu\n", new_allocation->secure_id, new_allocation->size_bytes));
+	DBG_MSG(3, ("UMP memory allocated. ID: %u, size: %lu\n",
+				new_allocation->secure_id,
+				new_allocation->size_bytes));
 
 	return _MALI_OSK_ERR_OK;
 }
diff --git a/drivers/gpu/mali/ump/common/ump_kernel_types.h b/drivers/gpu/mali/ump/common/ump_kernel_types.h
index fdacd86..7718956 100644
--- a/drivers/gpu/mali/ump/common/ump_kernel_types.h
+++ b/drivers/gpu/mali/ump/common/ump_kernel_types.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -14,35 +14,33 @@
 #include "ump_kernel_interface.h"
 #include "mali_osk.h"
 
+#include <linux/rbtree.h>
 
-typedef enum
-{
+typedef enum {
 	UMP_USED_BY_CPU = 0,
 	UMP_USED_BY_MALI = 1,
-	UMP_USED_BY_UNKNOWN_DEVICE= 100,
+	UMP_USED_BY_UNKNOWN_DEVICE = 100,
 } ump_hw_usage;
 
-typedef enum
-{
+typedef enum {
 	UMP_NOT_LOCKED = 0,
 	UMP_READ = 1,
 	UMP_READ_WRITE = 3,
 } ump_lock_usage;
 
-
 /*
  * This struct is what is "behind" a ump_dd_handle
  */
-typedef struct ump_dd_mem
-{
+typedef struct ump_dd_mem {
+	struct rb_node node;
 	ump_secure_id secure_id;
 	_mali_osk_atomic_t ref_count;
 	unsigned long size_bytes;
 	unsigned long nr_blocks;
-	ump_dd_physical_block * block_array;
-	void (*release_func)(void * ctx, struct ump_dd_mem * descriptor);
-	void * ctx;
-	void * backend_info;
+	ump_dd_physical_block *block_array;
+	void (*release_func)(void *ctx, struct ump_dd_mem *descriptor);
+	void *ctx;
+	void *backend_info;
 	int is_cached;
 	ump_hw_usage hw_device;
 	ump_lock_usage lock_usage;
diff --git a/drivers/gpu/mali/ump/common/ump_osk.h b/drivers/gpu/mali/ump/common/ump_osk.h
index 0ea7c45..5759ddb 100644
--- a/drivers/gpu/mali/ump/common/ump_osk.h
+++ b/drivers/gpu/mali/ump/common/ump_osk.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -22,25 +22,24 @@
 #include "ump_kernel_common.h"
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
-_mali_osk_errcode_t _ump_osk_init( void );
+_mali_osk_errcode_t _ump_osk_init(void);
 
-_mali_osk_errcode_t _ump_osk_term( void );
+_mali_osk_errcode_t _ump_osk_term(void);
 
-int _ump_osk_atomic_inc_and_read( _mali_osk_atomic_t *atom );
+int _ump_osk_atomic_inc_and_read(_mali_osk_atomic_t *atom);
 
-int _ump_osk_atomic_dec_and_read( _mali_osk_atomic_t *atom );
+int _ump_osk_atomic_dec_and_read(_mali_osk_atomic_t *atom);
 
-_mali_osk_errcode_t _ump_osk_mem_mapregion_init( ump_memory_allocation *descriptor );
+_mali_osk_errcode_t _ump_osk_mem_mapregion_init(ump_memory_allocation *descriptor);
 
-_mali_osk_errcode_t _ump_osk_mem_mapregion_map( ump_memory_allocation * descriptor, u32 offset, u32 * phys_addr, unsigned long size );
+_mali_osk_errcode_t _ump_osk_mem_mapregion_map(ump_memory_allocation *descriptor, u32 offset, u32 *phys_addr, unsigned long size);
 
-void _ump_osk_mem_mapregion_term( ump_memory_allocation * descriptor );
+void _ump_osk_mem_mapregion_term(ump_memory_allocation *descriptor);
 
-void _ump_osk_msync( ump_dd_mem * mem, void * virt, u32 offset, u32 size, ump_uk_msync_op op, ump_session_data * session_data );
+void _ump_osk_msync(ump_dd_mem *mem, void *virt, u32 offset, u32 size, ump_uk_msync_op op, ump_session_data *session_data);
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/ump/common/ump_uk_types.h b/drivers/gpu/mali/ump/common/ump_uk_types.h
index 24f4596..48b588f 100644
--- a/drivers/gpu/mali/ump/common/ump_uk_types.h
+++ b/drivers/gpu/mali/ump/common/ump_uk_types.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,8 +17,7 @@
 #define __UMP_UK_TYPES_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 /* Helpers for API version handling */
@@ -34,7 +33,7 @@ extern "C"
  * The 16bit integer is stored twice in a 32bit integer
  * So for version 1 the value would be 0x00010001
  */
-#define UMP_IOCTL_API_VERSION MAKE_VERSION_ID(2)
+#define UMP_IOCTL_API_VERSION MAKE_VERSION_ID(3)
 
 typedef enum
 {
@@ -49,7 +48,7 @@ typedef enum
 	_UMP_IOC_SWITCH_HW_USAGE,
 	_UMP_IOC_LOCK,
 	_UMP_IOC_UNLOCK,
-}_ump_uk_functions;
+} _ump_uk_functions;
 
 typedef enum
 {
@@ -83,7 +82,7 @@ typedef enum
 {
 	_UMP_UK_USED_BY_CPU = 0,
 	_UMP_UK_USED_BY_MALI = 1,
-	_UMP_UK_USED_BY_UNKNOWN_DEVICE= 100,
+	_UMP_UK_USED_BY_UNKNOWN_DEVICE = 100,
 } ump_uk_user;
 
 /**
@@ -133,7 +132,7 @@ typedef struct _ump_uk_map_mem_s
 	void *phys_addr;                /**< [in] physical address */
 	unsigned long size;             /**< [in] size */
 	u32 secure_id;                  /**< [in] secure_id to assign to mapping */
-	void * _ukk_private;            /**< Only used inside linux port between kernel frontend and common part to store vma */
+	void *_ukk_private;             /**< Only used inside linux port between kernel frontend and common part to store vma */
 	u32 cookie;
 	u32 is_cached;            /**< [in,out] caching of CPU mappings */
 } _ump_uk_map_mem_s;
@@ -143,7 +142,7 @@ typedef struct _ump_uk_unmap_mem_s
 	void *ctx;            /**< [in,out] user-kernel context (trashed on output) */
 	void *mapping;
 	u32 size;
-	void * _ukk_private;
+	void *_ukk_private;
 	u32 cookie;
 } _ump_uk_unmap_mem_s;
 
diff --git a/drivers/gpu/mali/ump/common/ump_ukk.h b/drivers/gpu/mali/ump/common/ump_ukk.h
index 4e6bb86..da7917a 100644
--- a/drivers/gpu/mali/ump/common/ump_ukk.h
+++ b/drivers/gpu/mali/ump/common/ump_ukk.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -21,38 +21,37 @@
 
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 
-_mali_osk_errcode_t _ump_ukk_open( void** context );
+_mali_osk_errcode_t _ump_ukk_open(void **context);
 
-_mali_osk_errcode_t _ump_ukk_close( void** context );
+_mali_osk_errcode_t _ump_ukk_close(void **context);
 
-_mali_osk_errcode_t _ump_ukk_allocate( _ump_uk_allocate_s *user_interaction );
+_mali_osk_errcode_t _ump_ukk_allocate(_ump_uk_allocate_s *user_interaction);
 
-_mali_osk_errcode_t _ump_ukk_release( _ump_uk_release_s *release_info );
+_mali_osk_errcode_t _ump_ukk_release(_ump_uk_release_s *release_info);
 
-_mali_osk_errcode_t _ump_ukk_size_get( _ump_uk_size_get_s *user_interaction );
+_mali_osk_errcode_t _ump_ukk_size_get(_ump_uk_size_get_s *user_interaction);
 
-_mali_osk_errcode_t _ump_ukk_map_mem( _ump_uk_map_mem_s *args );
+_mali_osk_errcode_t _ump_ukk_map_mem(_ump_uk_map_mem_s *args);
 
-_mali_osk_errcode_t _ump_uku_get_api_version( _ump_uk_api_version_s *args );
+_mali_osk_errcode_t _ump_uku_get_api_version(_ump_uk_api_version_s *args);
 
-void _ump_ukk_unmap_mem( _ump_uk_unmap_mem_s *args );
+void _ump_ukk_unmap_mem(_ump_uk_unmap_mem_s *args);
 
-void _ump_ukk_msync( _ump_uk_msync_s *args );
+void _ump_ukk_msync(_ump_uk_msync_s *args);
 
-void _ump_ukk_cache_operations_control(_ump_uk_cache_operations_control_s* args);
+void _ump_ukk_cache_operations_control(_ump_uk_cache_operations_control_s *args);
 
-void _ump_ukk_switch_hw_usage(_ump_uk_switch_hw_usage_s *args );
+void _ump_ukk_switch_hw_usage(_ump_uk_switch_hw_usage_s *args);
 
-void _ump_ukk_lock(_ump_uk_lock_s *args );
+void _ump_ukk_lock(_ump_uk_lock_s *args);
 
-void _ump_ukk_unlock(_ump_uk_unlock_s *args );
+void _ump_ukk_unlock(_ump_uk_unlock_s *args);
 
-u32 _ump_ukk_report_memory_usage( void );
+u32 _ump_ukk_report_memory_usage(void);
 
 #ifdef __cplusplus
 }
diff --git a/drivers/gpu/mali/ump/linux/license/gpl/ump_kernel_license.h b/drivers/gpu/mali/ump/linux/license/gpl/ump_kernel_license.h
index 34884dc..567d803 100644
--- a/drivers/gpu/mali/ump/linux/license/gpl/ump_kernel_license.h
+++ b/drivers/gpu/mali/ump/linux/license/gpl/ump_kernel_license.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,8 +17,7 @@
 #define __UMP_KERNEL_LICENSE_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 #define UMP_KERNEL_LINUX_LICENSE     "GPL"
diff --git a/drivers/gpu/mali/ump/linux/ump_ioctl.h b/drivers/gpu/mali/ump/linux/ump_ioctl.h
index 675e36e..239e8ab 100644
--- a/drivers/gpu/mali/ump/linux/ump_ioctl.h
+++ b/drivers/gpu/mali/ump/linux/ump_ioctl.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -12,8 +12,7 @@
 #define __UMP_IOCTL_H__
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 #include <linux/types.h>
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_linux.c b/drivers/gpu/mali/ump/linux/ump_kernel_linux.c
index 40514fe..c99caa6 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_linux.c
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_linux.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -18,7 +18,7 @@
 #include <linux/device.h>
 #include <linux/debugfs.h>
 
-#include "config.h"             /* Configuration for current platform. The symlinc for arch is set by Makefile */
+#include "arch/config.h"             /* Configuration for current platform. The symlinc for arch is set by Makefile */
 #include "ump_ioctl.h"
 #include "ump_kernel_common.h"
 #include "ump_kernel_interface.h"
@@ -59,17 +59,15 @@ static struct dentry *ump_debugfs_dir = NULL;
  * Each memory mapping has a reference to the UMP memory it maps.
  * We release this reference when the last memory mapping is unmapped.
  */
-typedef struct ump_vma_usage_tracker
-{
+typedef struct ump_vma_usage_tracker {
 	int references;
 	ump_dd_handle handle;
 } ump_vma_usage_tracker;
 
-struct ump_device
-{
+struct ump_device {
 	struct cdev cdev;
 #if UMP_LICENSE_IS_GPL
-	struct class * ump_class;
+	struct class *ump_class;
 #endif
 };
 
@@ -85,12 +83,11 @@ static long ump_file_ioctl(struct file *filp, unsigned int cmd, unsigned long ar
 #else
 static int ump_file_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg);
 #endif
-static int ump_file_mmap(struct file * filp, struct vm_area_struct * vma);
+static int ump_file_mmap(struct file *filp, struct vm_area_struct *vma);
 
 
 /* This variable defines the file operations this UMP device driver offer */
-static struct file_operations ump_fops =
-{
+static struct file_operations ump_fops = {
 	.owner   = THIS_MODULE,
 	.open    = ump_file_open,
 	.release = ump_file_release,
@@ -113,8 +110,7 @@ static int ump_initialize_module(void)
 	DBG_MSG(2, ("Inserting UMP device driver. Compiled: %s, time: %s\n", __DATE__, __TIME__));
 
 	err = ump_kernel_constructor();
-	if (_MALI_OSK_ERR_OK != err)
-	{
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("UMP device driver init failed\n"));
 		return map_errcode(err);
 	}
@@ -140,17 +136,17 @@ static void ump_cleanup_module(void)
 
 static ssize_t ump_memory_used_read(struct file *filp, char __user *ubuf, size_t cnt, loff_t *ppos)
 {
-        char buf[64];
-        size_t r;
-        u32 mem = _ump_ukk_report_memory_usage();
+	char buf[64];
+	size_t r;
+	u32 mem = _ump_ukk_report_memory_usage();
 
-        r = snprintf(buf, 64, "%u\n", mem);
-        return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
+	r = snprintf(buf, 64, "%u\n", mem);
+	return simple_read_from_buffer(ubuf, cnt, ppos, buf, r);
 }
 
 static const struct file_operations ump_memory_usage_fops = {
-        .owner = THIS_MODULE,
-        .read = ump_memory_used_read,
+	.owner = THIS_MODULE,
+	.read = ump_memory_used_read,
 };
 
 /*
@@ -162,31 +158,24 @@ int ump_kernel_device_initialize(void)
 	dev_t dev = 0;
 #if UMP_LICENSE_IS_GPL
 	ump_debugfs_dir = debugfs_create_dir(ump_dev_name, NULL);
-	if (ERR_PTR(-ENODEV) == ump_debugfs_dir)
-	{
-			ump_debugfs_dir = NULL;
-	}
-	else
-	{
+	if (ERR_PTR(-ENODEV) == ump_debugfs_dir) {
+		ump_debugfs_dir = NULL;
+	} else {
 		debugfs_create_file("memory_usage", 0400, ump_debugfs_dir, NULL, &ump_memory_usage_fops);
 	}
 #endif
 
-	if (0 == ump_major)
-	{
+	if (0 == ump_major) {
 		/* auto select a major */
 		err = alloc_chrdev_region(&dev, 0, 1, ump_dev_name);
 		ump_major = MAJOR(dev);
-	}
-	else
-	{
+	} else {
 		/* use load time defined major number */
 		dev = MKDEV(ump_major, 0);
 		err = register_chrdev_region(dev, 1, ump_dev_name);
 	}
 
-	if (0 == err)
-	{
+	if (0 == err) {
 		memset(&ump_device, 0, sizeof(ump_device));
 
 		/* initialize our char dev data */
@@ -196,21 +185,16 @@ int ump_kernel_device_initialize(void)
 
 		/* register char dev with the kernel */
 		err = cdev_add(&ump_device.cdev, dev, 1/*count*/);
-		if (0 == err)
-		{
+		if (0 == err) {
 
 #if UMP_LICENSE_IS_GPL
 			ump_device.ump_class = class_create(THIS_MODULE, ump_dev_name);
-			if (IS_ERR(ump_device.ump_class))
-			{
+			if (IS_ERR(ump_device.ump_class)) {
 				err = PTR_ERR(ump_device.ump_class);
-			}
-			else
-			{
-				struct device * mdev;
+			} else {
+				struct device *mdev;
 				mdev = device_create(ump_device.ump_class, NULL, dev, NULL, ump_dev_name);
-				if (!IS_ERR(mdev))
-				{
+				if (!IS_ERR(mdev)) {
 					return 0;
 				}
 
@@ -249,7 +233,7 @@ void ump_kernel_device_terminate(void)
 	unregister_chrdev_region(dev, 1);
 
 #if UMP_LICENSE_IS_GPL
-	if(ump_debugfs_dir)
+	if (ump_debugfs_dir)
 		debugfs_remove_recursive(ump_debugfs_dir);
 #endif
 }
@@ -259,25 +243,23 @@ void ump_kernel_device_terminate(void)
  */
 static int ump_file_open(struct inode *inode, struct file *filp)
 {
-	struct ump_session_data * session_data;
+	struct ump_session_data *session_data;
 	_mali_osk_errcode_t err;
 
 	/* input validation */
-	if (0 != MINOR(inode->i_rdev))
-	{
+	if (0 != MINOR(inode->i_rdev)) {
 		MSG_ERR(("Minor not zero in ump_file_open()\n"));
 		return -ENODEV;
 	}
 
 	/* Call the OS-Independent UMP Open function */
-	err = _ump_ukk_open((void**) &session_data );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	err = _ump_ukk_open((void **) &session_data);
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("Ump failed to open a new session\n"));
-		return map_errcode( err );
+		return map_errcode(err);
 	}
 
-	filp->private_data = (void*)session_data;
+	filp->private_data = (void *)session_data;
 	filp->f_pos = 0;
 
 	return 0; /* success */
@@ -292,10 +274,9 @@ static int ump_file_release(struct inode *inode, struct file *filp)
 {
 	_mali_osk_errcode_t err;
 
-	err = _ump_ukk_close((void**) &filp->private_data );
-	if( _MALI_OSK_ERR_OK != err )
-	{
-		return map_errcode( err );
+	err = _ump_ukk_close((void **) &filp->private_data);
+	if (_MALI_OSK_ERR_OK != err) {
+		return map_errcode(err);
 	}
 
 	return 0;  /* success */
@@ -313,16 +294,15 @@ static int ump_file_ioctl(struct inode *inode, struct file *filp, unsigned int c
 #endif
 {
 	int err = -ENOTTY;
-	void __user * argument;
-	struct ump_session_data * session_data;
+	void __user *argument;
+	struct ump_session_data *session_data;
 
 #ifndef HAVE_UNLOCKED_IOCTL
 	(void)inode; /* inode not used */
 #endif
 
 	session_data = (struct ump_session_data *)filp->private_data;
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("No session data attached to file object\n"));
 		return -ENOTTY;
 	}
@@ -330,82 +310,88 @@ static int ump_file_ioctl(struct inode *inode, struct file *filp, unsigned int c
 	/* interpret the argument as a user pointer to something */
 	argument = (void __user *)arg;
 
-	switch (cmd)
-	{
-		case UMP_IOC_QUERY_API_VERSION:
-			err = ump_get_api_version_wrapper((u32 __user *)argument, session_data);
-			break;
+	switch (cmd) {
+	case UMP_IOC_QUERY_API_VERSION:
+		err = ump_get_api_version_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_ALLOCATE :
-			err = ump_allocate_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_ALLOCATE :
+		err = ump_allocate_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_RELEASE:
-			err = ump_release_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_RELEASE:
+		err = ump_release_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_SIZE_GET:
-			err = ump_size_get_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_SIZE_GET:
+		err = ump_size_get_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_MSYNC:
-			err = ump_msync_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_MSYNC:
+		err = ump_msync_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_CACHE_OPERATIONS_CONTROL:
-			err = ump_cache_operations_control_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_CACHE_OPERATIONS_CONTROL:
+		err = ump_cache_operations_control_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_SWITCH_HW_USAGE:
-			err = ump_switch_hw_usage_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_SWITCH_HW_USAGE:
+		err = ump_switch_hw_usage_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_LOCK:
-			err = ump_lock_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_LOCK:
+		err = ump_lock_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		case UMP_IOC_UNLOCK:
-			err = ump_unlock_wrapper((u32 __user *)argument, session_data);
-			break;
+	case UMP_IOC_UNLOCK:
+		err = ump_unlock_wrapper((u32 __user *)argument, session_data);
+		break;
 
-		default:
-			DBG_MSG(1, ("No handler for IOCTL. cmd: 0x%08x, arg: 0x%08lx\n", cmd, arg));
-			err = -EFAULT;
-			break;
+	default:
+		DBG_MSG(1, ("No handler for IOCTL. cmd: 0x%08x, arg: 0x%08lx\n", cmd, arg));
+		err = -EFAULT;
+		break;
 	}
 
 	return err;
 }
 
-int map_errcode( _mali_osk_errcode_t err )
+int map_errcode(_mali_osk_errcode_t err)
 {
-    switch(err)
-    {
-        case _MALI_OSK_ERR_OK : return 0;
-        case _MALI_OSK_ERR_FAULT: return -EFAULT;
-        case _MALI_OSK_ERR_INVALID_FUNC: return -ENOTTY;
-        case _MALI_OSK_ERR_INVALID_ARGS: return -EINVAL;
-        case _MALI_OSK_ERR_NOMEM: return -ENOMEM;
-        case _MALI_OSK_ERR_TIMEOUT: return -ETIMEDOUT;
-        case _MALI_OSK_ERR_RESTARTSYSCALL: return -ERESTARTSYS;
-        case _MALI_OSK_ERR_ITEM_NOT_FOUND: return -ENOENT;
-        default: return -EFAULT;
-    }
+	switch (err) {
+	case _MALI_OSK_ERR_OK :
+		return 0;
+	case _MALI_OSK_ERR_FAULT:
+		return -EFAULT;
+	case _MALI_OSK_ERR_INVALID_FUNC:
+		return -ENOTTY;
+	case _MALI_OSK_ERR_INVALID_ARGS:
+		return -EINVAL;
+	case _MALI_OSK_ERR_NOMEM:
+		return -ENOMEM;
+	case _MALI_OSK_ERR_TIMEOUT:
+		return -ETIMEDOUT;
+	case _MALI_OSK_ERR_RESTARTSYSCALL:
+		return -ERESTARTSYS;
+	case _MALI_OSK_ERR_ITEM_NOT_FOUND:
+		return -ENOENT;
+	default:
+		return -EFAULT;
+	}
 }
 
 /*
  * Handle from OS to map specified virtual memory to specified UMP memory.
  */
-static int ump_file_mmap(struct file * filp, struct vm_area_struct * vma)
+static int ump_file_mmap(struct file *filp, struct vm_area_struct *vma)
 {
 	_ump_uk_map_mem_s args;
 	_mali_osk_errcode_t err;
-	struct ump_session_data * session_data;
+	struct ump_session_data *session_data;
 
 	/* Validate the session data */
 	session_data = (struct ump_session_data *)filp->private_data;
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("mmap() called without any session data available\n"));
 		return -EFAULT;
 	}
@@ -418,8 +404,7 @@ static int ump_file_mmap(struct file * filp, struct vm_area_struct * vma)
 	args.secure_id = vma->vm_pgoff;
 	args.is_cached = 0;
 
-	if (!(vma->vm_flags & VM_SHARED))
-	{
+	if (!(vma->vm_flags & VM_SHARED)) {
 		args.is_cached = 1;
 		vma->vm_flags = vma->vm_flags | VM_SHARED | VM_MAYSHARE  ;
 		DBG_MSG(3, ("UMP Map function: Forcing the CPU to use cache\n"));
@@ -427,14 +412,13 @@ static int ump_file_mmap(struct file * filp, struct vm_area_struct * vma)
 	/* By setting this flag, during a process fork; the child process will not have the parent UMP mappings */
 	vma->vm_flags |= VM_DONTCOPY;
 
-	DBG_MSG(4, ("UMP vma->flags: %x\n", vma->vm_flags ));
+	DBG_MSG(4, ("UMP vma->flags: %x\n", vma->vm_flags));
 
 	/* Call the common mmap handler */
-	err = _ump_ukk_map_mem( &args );
-	if ( _MALI_OSK_ERR_OK != err)
-	{
+	err = _ump_ukk_map_mem(&args);
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("_ump_ukk_map_mem() failed in function ump_file_mmap()"));
-		return map_errcode( err );
+		return map_errcode(err);
 	}
 
 	return 0; /* success */
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_linux.h b/drivers/gpu/mali/ump/linux/ump_kernel_linux.h
index f67275e..c071b77 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_linux.h
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_linux.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.c b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.c
index 9850053..32ea8b0 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.c
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -30,28 +30,26 @@
 
 
 
-typedef struct block_info
-{
-	struct block_info * next;
+typedef struct block_info {
+	struct block_info *next;
 } block_info;
 
 
 
-typedef struct block_allocator
-{
+typedef struct block_allocator {
 	struct semaphore mutex;
-	block_info * all_blocks;
-	block_info * first_free;
+	block_info *all_blocks;
+	block_info *first_free;
 	u32 base;
 	u32 num_blocks;
 	u32 num_free;
 } block_allocator;
 
 
-static void block_allocator_shutdown(ump_memory_backend * backend);
-static int block_allocator_allocate(void* ctx, ump_dd_mem * mem);
-static void block_allocator_release(void * ctx, ump_dd_mem * handle);
-static inline u32 get_phys(block_allocator * allocator, block_info * block);
+static void block_allocator_shutdown(ump_memory_backend *backend);
+static int block_allocator_allocate(void *ctx, ump_dd_mem *mem);
+static void block_allocator_release(void *ctx, ump_dd_mem *handle);
+static inline u32 get_phys(block_allocator *allocator, block_info *block);
 static u32 block_allocator_stat(struct ump_memory_backend *backend);
 
 
@@ -59,18 +57,17 @@ static u32 block_allocator_stat(struct ump_memory_backend *backend);
 /*
  * Create dedicated memory backend
  */
-ump_memory_backend * ump_block_allocator_create(u32 base_address, u32 size)
+ump_memory_backend *ump_block_allocator_create(u32 base_address, u32 size)
 {
-	ump_memory_backend * backend;
-	block_allocator * allocator;
+	ump_memory_backend *backend;
+	block_allocator *allocator;
 	u32 usable_size;
 	u32 num_blocks;
 
 	usable_size = (size + UMP_BLOCK_SIZE - 1) & ~(UMP_BLOCK_SIZE - 1);
 	num_blocks = usable_size / UMP_BLOCK_SIZE;
 
-	if (0 == usable_size)
-	{
+	if (0 == usable_size) {
 		DBG_MSG(1, ("Memory block of size %u is unusable\n", size));
 		return NULL;
 	}
@@ -79,14 +76,11 @@ ump_memory_backend * ump_block_allocator_create(u32 base_address, u32 size)
 	DBG_MSG(6, ("%u usable bytes which becomes %u blocks\n", usable_size, num_blocks));
 
 	backend = kzalloc(sizeof(ump_memory_backend), GFP_KERNEL);
-	if (NULL != backend)
-	{
+	if (NULL != backend) {
 		allocator = kmalloc(sizeof(block_allocator), GFP_KERNEL);
-		if (NULL != allocator)
-		{
-			allocator->all_blocks = kmalloc(sizeof(block_allocator) * num_blocks, GFP_KERNEL);
-			if (NULL != allocator->all_blocks)
-			{
+		if (NULL != allocator) {
+			allocator->all_blocks = kmalloc(sizeof(block_info) * num_blocks, GFP_KERNEL);
+			if (NULL != allocator->all_blocks) {
 				int i;
 
 				allocator->first_free = NULL;
@@ -95,8 +89,7 @@ ump_memory_backend * ump_block_allocator_create(u32 base_address, u32 size)
 				allocator->base = base_address;
 				sema_init(&allocator->mutex, 1);
 
-				for (i = 0; i < num_blocks; i++)
-				{
+				for (i = 0; i < num_blocks; i++) {
 					allocator->all_blocks[i].next = allocator->first_free;
 					allocator->first_free = &allocator->all_blocks[i];
 				}
@@ -124,14 +117,14 @@ ump_memory_backend * ump_block_allocator_create(u32 base_address, u32 size)
 /*
  * Destroy specified dedicated memory backend
  */
-static void block_allocator_shutdown(ump_memory_backend * backend)
+static void block_allocator_shutdown(ump_memory_backend *backend)
 {
-	block_allocator * allocator;
+	block_allocator *allocator;
 
 	BUG_ON(!backend);
 	BUG_ON(!backend->ctx);
 
-	allocator = (block_allocator*)backend->ctx;
+	allocator = (block_allocator *)backend->ctx;
 
 	DBG_MSG_IF(1, allocator->num_free != allocator->num_blocks, ("%u blocks still in use during shutdown\n", allocator->num_blocks - allocator->num_free));
 
@@ -142,41 +135,38 @@ static void block_allocator_shutdown(ump_memory_backend * backend)
 
 
 
-static int block_allocator_allocate(void* ctx, ump_dd_mem * mem)
+static int block_allocator_allocate(void *ctx, ump_dd_mem *mem)
 {
-	block_allocator * allocator;
+	block_allocator *allocator;
 	u32 left;
-	block_info * last_allocated = NULL;
+	block_info *last_allocated = NULL;
 	int i = 0;
 
 	BUG_ON(!ctx);
 	BUG_ON(!mem);
 
-	allocator = (block_allocator*)ctx;
+	allocator = (block_allocator *)ctx;
 	left = mem->size_bytes;
 
 	BUG_ON(!left);
 	BUG_ON(!&allocator->mutex);
 
 	mem->nr_blocks = ((left + UMP_BLOCK_SIZE - 1) & ~(UMP_BLOCK_SIZE - 1)) / UMP_BLOCK_SIZE;
-	mem->block_array = (ump_dd_physical_block*)vmalloc(sizeof(ump_dd_physical_block) * mem->nr_blocks);
-	if (NULL == mem->block_array)
-	{
+	mem->block_array = (ump_dd_physical_block *)vmalloc(sizeof(ump_dd_physical_block) * mem->nr_blocks);
+	if (NULL == mem->block_array) {
 		MSG_ERR(("Failed to allocate block array\n"));
 		return 0;
 	}
 
-	if (down_interruptible(&allocator->mutex))
-	{
+	if (down_interruptible(&allocator->mutex)) {
 		MSG_ERR(("Could not get mutex to do block_allocate\n"));
 		return 0;
 	}
 
 	mem->size_bytes = 0;
 
-	while ((left > 0) && (allocator->first_free))
-	{
-		block_info * block;
+	while ((left > 0) && (allocator->first_free)) {
+		block_info *block;
 
 		block = allocator->first_free;
 		allocator->first_free = allocator->first_free->next;
@@ -194,12 +184,10 @@ static int block_allocator_allocate(void* ctx, ump_dd_mem * mem)
 		else left -= UMP_BLOCK_SIZE;
 	}
 
-	if (left)
-	{
-		block_info * block;
+	if (left) {
+		block_info *block;
 		/* release all memory back to the pool */
-		while (last_allocated)
-		{
+		while (last_allocated) {
 			block = last_allocated->next;
 			last_allocated->next = allocator->first_free;
 			allocator->first_free = last_allocated;
@@ -220,36 +208,34 @@ static int block_allocator_allocate(void* ctx, ump_dd_mem * mem)
 	mem->backend_info = last_allocated;
 
 	up(&allocator->mutex);
-	mem->is_cached=0;
+	mem->is_cached = 0;
 
 	return 1;
 }
 
 
 
-static void block_allocator_release(void * ctx, ump_dd_mem * handle)
+static void block_allocator_release(void *ctx, ump_dd_mem *handle)
 {
-	block_allocator * allocator;
-	block_info * block, * next;
+	block_allocator *allocator;
+	block_info *block, * next;
 
 	BUG_ON(!ctx);
 	BUG_ON(!handle);
 
-	allocator = (block_allocator*)ctx;
-	block = (block_info*)handle->backend_info;
+	allocator = (block_allocator *)ctx;
+	block = (block_info *)handle->backend_info;
 	BUG_ON(!block);
 
-	if (down_interruptible(&allocator->mutex))
-	{
+	if (down_interruptible(&allocator->mutex)) {
 		MSG_ERR(("Allocator release: Failed to get mutex - memory leak\n"));
 		return;
 	}
 
-	while (block)
-	{
+	while (block) {
 		next = block->next;
 
-		BUG_ON( (block < allocator->all_blocks) || (block > (allocator->all_blocks + allocator->num_blocks)));
+		BUG_ON((block < allocator->all_blocks) || (block > (allocator->all_blocks + allocator->num_blocks)));
 
 		block->next = allocator->first_free;
 		allocator->first_free = block;
@@ -269,7 +255,7 @@ static void block_allocator_release(void * ctx, ump_dd_mem * handle)
 /*
  * Helper function for calculating the physical base adderss of a memory block
  */
-static inline u32 get_phys(block_allocator * allocator, block_info * block)
+static inline u32 get_phys(block_allocator *allocator, block_info *block)
 {
 	return allocator->base + ((block - allocator->all_blocks) * UMP_BLOCK_SIZE);
 }
@@ -278,8 +264,8 @@ static u32 block_allocator_stat(struct ump_memory_backend *backend)
 {
 	block_allocator *allocator;
 	BUG_ON(!backend);
-	allocator = (block_allocator*)backend->ctx;
+	allocator = (block_allocator *)backend->ctx;
 	BUG_ON(!allocator);
 
-	return (allocator->num_blocks - allocator->num_free)* UMP_BLOCK_SIZE;
+	return (allocator->num_blocks - allocator->num_free) * UMP_BLOCK_SIZE;
 }
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.h b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.h
index b338df2..5a5a4a3 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.h
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_dedicated.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,7 +17,7 @@
 
 #include "ump_kernel_memory_backend.h"
 
-ump_memory_backend * ump_block_allocator_create(u32 base_address, u32 size);
+ump_memory_backend *ump_block_allocator_create(u32 base_address, u32 size);
 
 #endif /* __UMP_KERNEL_MEMORY_BACKEND_DEDICATED_H__ */
 
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.c b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.c
index 48905b1..86a8132 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.c
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2011 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2011, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -28,8 +28,7 @@
 
 
 
-typedef struct os_allocator
-{
+typedef struct os_allocator {
 	struct semaphore mutex;
 	u32 num_pages_max;       /**< Maximum number of pages to allocate from the OS */
 	u32 num_pages_allocated; /**< Number of pages allocated from the OS */
@@ -37,9 +36,9 @@ typedef struct os_allocator
 
 
 
-static void os_free(void* ctx, ump_dd_mem * descriptor);
-static int os_allocate(void* ctx, ump_dd_mem * descriptor);
-static void os_memory_backend_destroy(ump_memory_backend * backend);
+static void os_free(void *ctx, ump_dd_mem *descriptor);
+static int os_allocate(void *ctx, ump_dd_mem *descriptor);
+static void os_memory_backend_destroy(ump_memory_backend *backend);
 static u32 os_stat(struct ump_memory_backend *backend);
 
 
@@ -47,14 +46,13 @@ static u32 os_stat(struct ump_memory_backend *backend);
 /*
  * Create OS memory backend
  */
-ump_memory_backend * ump_os_memory_backend_create(const int max_allocation)
+ump_memory_backend *ump_os_memory_backend_create(const int max_allocation)
 {
-	ump_memory_backend * backend;
-	os_allocator * info;
+	ump_memory_backend *backend;
+	os_allocator *info;
 
 	info = kmalloc(sizeof(os_allocator), GFP_KERNEL);
-	if (NULL == info)
-	{
+	if (NULL == info) {
 		return NULL;
 	}
 
@@ -64,8 +62,7 @@ ump_memory_backend * ump_os_memory_backend_create(const int max_allocation)
 	sema_init(&info->mutex, 1);
 
 	backend = kmalloc(sizeof(ump_memory_backend), GFP_KERNEL);
-	if (NULL == backend)
-	{
+	if (NULL == backend) {
 		kfree(info);
 		return NULL;
 	}
@@ -86,9 +83,9 @@ ump_memory_backend * ump_os_memory_backend_create(const int max_allocation)
 /*
  * Destroy specified OS memory backend
  */
-static void os_memory_backend_destroy(ump_memory_backend * backend)
+static void os_memory_backend_destroy(ump_memory_backend *backend)
 {
-	os_allocator * info = (os_allocator*)backend->ctx;
+	os_allocator *info = (os_allocator *)backend->ctx;
 
 	DBG_MSG_IF(1, 0 != info->num_pages_allocated, ("%d pages still in use during shutdown\n", info->num_pages_allocated));
 
@@ -101,22 +98,21 @@ static void os_memory_backend_destroy(ump_memory_backend * backend)
 /*
  * Allocate UMP memory
  */
-static int os_allocate(void* ctx, ump_dd_mem * descriptor)
+static int os_allocate(void *ctx, ump_dd_mem *descriptor)
 {
 	u32 left;
-	os_allocator * info;
+	os_allocator *info;
 	int pages_allocated = 0;
 	int is_cached;
 
 	BUG_ON(!descriptor);
 	BUG_ON(!ctx);
 
-	info = (os_allocator*)ctx;
+	info = (os_allocator *)ctx;
 	left = descriptor->size_bytes;
 	is_cached = descriptor->is_cached;
 
-	if (down_interruptible(&info->mutex))
-	{
+	if (down_interruptible(&info->mutex)) {
 		DBG_MSG(1, ("Failed to get mutex in os_free\n"));
 		return 0; /* failure */
 	}
@@ -127,48 +123,38 @@ static int os_allocate(void* ctx, ump_dd_mem * descriptor)
 	DBG_MSG(5, ("Allocating page array. Size: %lu\n", descriptor->nr_blocks * sizeof(ump_dd_physical_block)));
 
 	descriptor->block_array = (ump_dd_physical_block *)vmalloc(sizeof(ump_dd_physical_block) * descriptor->nr_blocks);
-	if (NULL == descriptor->block_array)
-	{
+	if (NULL == descriptor->block_array) {
 		up(&info->mutex);
 		DBG_MSG(1, ("Block array could not be allocated\n"));
 		return 0; /* failure */
 	}
 
-	while (left > 0 && ((info->num_pages_allocated + pages_allocated) < info->num_pages_max))
-	{
-		struct page * new_page;
+	while (left > 0 && ((info->num_pages_allocated + pages_allocated) < info->num_pages_max)) {
+		struct page *new_page;
 
-		if (is_cached)
-		{
+		if (is_cached) {
 			new_page = alloc_page(GFP_HIGHUSER | __GFP_ZERO | __GFP_REPEAT | __GFP_NOWARN);
-		} else
-		{
+		} else {
 			new_page = alloc_page(GFP_HIGHUSER | __GFP_ZERO | __GFP_REPEAT | __GFP_NOWARN | __GFP_COLD);
 		}
-		if (NULL == new_page)
-		{
+		if (NULL == new_page) {
 			break;
 		}
 
 		/* Ensure page caches are flushed. */
-		if ( is_cached )
-		{
+		if (is_cached) {
 			descriptor->block_array[pages_allocated].addr = page_to_phys(new_page);
 			descriptor->block_array[pages_allocated].size = PAGE_SIZE;
-		} else
-		{
-			descriptor->block_array[pages_allocated].addr = dma_map_page(NULL, new_page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL );
+		} else {
+			descriptor->block_array[pages_allocated].addr = dma_map_page(NULL, new_page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
 			descriptor->block_array[pages_allocated].size = PAGE_SIZE;
 		}
 
 		DBG_MSG(5, ("Allocated page 0x%08lx cached: %d\n", descriptor->block_array[pages_allocated].addr, is_cached));
 
-		if (left < PAGE_SIZE)
-		{
+		if (left < PAGE_SIZE) {
 			left = 0;
-		}
-		else
-		{
+		} else {
 			left -= PAGE_SIZE;
 		}
 
@@ -177,18 +163,15 @@ static int os_allocate(void* ctx, ump_dd_mem * descriptor)
 
 	DBG_MSG(5, ("Alloce for ID:%2d got %d pages, cached: %d\n", descriptor->secure_id,  pages_allocated));
 
-	if (left)
-	{
+	if (left) {
 		DBG_MSG(1, ("Failed to allocate needed pages\n"));
 
-		while(pages_allocated)
-		{
+		while (pages_allocated) {
 			pages_allocated--;
-			if ( !is_cached )
-			{
+			if (!is_cached) {
 				dma_unmap_page(NULL, descriptor->block_array[pages_allocated].addr, PAGE_SIZE, DMA_BIDIRECTIONAL);
 			}
-			__free_page(pfn_to_page(descriptor->block_array[pages_allocated].addr >> PAGE_SHIFT) );
+			__free_page(pfn_to_page(descriptor->block_array[pages_allocated].addr >> PAGE_SHIFT));
 		}
 
 		up(&info->mutex);
@@ -209,20 +192,19 @@ static int os_allocate(void* ctx, ump_dd_mem * descriptor)
 /*
  * Free specified UMP memory
  */
-static void os_free(void* ctx, ump_dd_mem * descriptor)
+static void os_free(void *ctx, ump_dd_mem *descriptor)
 {
-	os_allocator * info;
+	os_allocator *info;
 	int i;
 
 	BUG_ON(!ctx);
 	BUG_ON(!descriptor);
 
-	info = (os_allocator*)ctx;
+	info = (os_allocator *)ctx;
 
 	BUG_ON(descriptor->nr_blocks > info->num_pages_allocated);
 
-	if (down_interruptible(&info->mutex))
-	{
+	if (down_interruptible(&info->mutex)) {
 		DBG_MSG(1, ("Failed to get mutex in os_free\n"));
 		return;
 	}
@@ -233,14 +215,12 @@ static void os_free(void* ctx, ump_dd_mem * descriptor)
 
 	up(&info->mutex);
 
-	for ( i = 0; i < descriptor->nr_blocks; i++)
-	{
+	for (i = 0; i < descriptor->nr_blocks; i++) {
 		DBG_MSG(6, ("Freeing physical page. Address: 0x%08lx\n", descriptor->block_array[i].addr));
-		if ( ! descriptor->is_cached)
-		{
+		if (! descriptor->is_cached) {
 			dma_unmap_page(NULL, descriptor->block_array[i].addr, PAGE_SIZE, DMA_BIDIRECTIONAL);
 		}
-		__free_page(pfn_to_page(descriptor->block_array[i].addr>>PAGE_SHIFT) );
+		__free_page(pfn_to_page(descriptor->block_array[i].addr >> PAGE_SHIFT));
 	}
 
 	vfree(descriptor->block_array);
@@ -250,6 +230,6 @@ static void os_free(void* ctx, ump_dd_mem * descriptor)
 static u32 os_stat(struct ump_memory_backend *backend)
 {
 	os_allocator *info;
-	info = (os_allocator*)backend->ctx;
+	info = (os_allocator *)backend->ctx;
 	return info->num_pages_allocated * _MALI_OSK_MALI_PAGE_SIZE;
 }
diff --git a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.h b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.h
index a156791..9ac3cb7 100644
--- a/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.h
+++ b/drivers/gpu/mali/ump/linux/ump_kernel_memory_backend_os.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -17,7 +17,7 @@
 
 #include "ump_kernel_memory_backend.h"
 
-ump_memory_backend * ump_os_memory_backend_create(const int max_allocation);
+ump_memory_backend *ump_os_memory_backend_create(const int max_allocation);
 
 #endif /* __UMP_KERNEL_MEMORY_BACKEND_OS_H__ */
 
diff --git a/drivers/gpu/mali/ump/linux/ump_memory_backend.c b/drivers/gpu/mali/ump/linux/ump_memory_backend.c
index 9242819..b091543 100644
--- a/drivers/gpu/mali/ump/linux/ump_memory_backend.c
+++ b/drivers/gpu/mali/ump/linux/ump_memory_backend.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -11,7 +11,7 @@
 #include <linux/module.h>            /* kernel module definitions */
 #include <linux/ioport.h>            /* request_mem_region */
 
-#include "config.h"             /* Configuration for current platform. The symlink for arch is set by Makefile */
+#include "arch/config.h"             /* Configuration for current platform. The symlink for arch is set by Makefile */
 
 #include "ump_osk.h"
 #include "ump_kernel_common.h"
@@ -33,26 +33,22 @@ unsigned int ump_memory_size = ARCH_UMP_MEMORY_SIZE_DEFAULT;
 module_param(ump_memory_size, uint, S_IRUGO); /* r--r--r-- */
 MODULE_PARM_DESC(ump_memory_size, "The size of fixed memory to map in the dedicated memory backend");
 
-ump_memory_backend* ump_memory_backend_create ( void )
+ump_memory_backend *ump_memory_backend_create(void)
 {
-	ump_memory_backend * backend = NULL;
+	ump_memory_backend *backend = NULL;
 
 	/* Create the dynamic memory allocator backend */
-	if (0 == ump_backend)
-	{
+	if (0 == ump_backend) {
 		DBG_MSG(2, ("Using dedicated memory backend\n"));
 
 		DBG_MSG(2, ("Requesting dedicated memory: 0x%08x, size: %u\n", ump_memory_address, ump_memory_size));
 		/* Ask the OS if we can use the specified physical memory */
-		if (NULL == request_mem_region(ump_memory_address, ump_memory_size, "UMP Memory"))
-		{
+		if (NULL == request_mem_region(ump_memory_address, ump_memory_size, "UMP Memory")) {
 			MSG_ERR(("Failed to request memory region (0x%08X - 0x%08X). Is Mali DD already loaded?\n", ump_memory_address, ump_memory_address + ump_memory_size - 1));
 			return NULL;
 		}
 		backend = ump_block_allocator_create(ump_memory_address, ump_memory_size);
-	}
-	else if (1 == ump_backend)
-	{
+	} else if (1 == ump_backend) {
 		DBG_MSG(2, ("Using OS memory backend, allocation limit: %d\n", ump_memory_size));
 		backend = ump_os_memory_backend_create(ump_memory_size);
 	}
@@ -60,10 +56,9 @@ ump_memory_backend* ump_memory_backend_create ( void )
 	return backend;
 }
 
-void ump_memory_backend_destroy( void )
+void ump_memory_backend_destroy(void)
 {
-	if (0 == ump_backend)
-	{
+	if (0 == ump_backend) {
 		DBG_MSG(2, ("Releasing dedicated memory: 0x%08x\n", ump_memory_address));
 		release_mem_region(ump_memory_address, ump_memory_size);
 	}
diff --git a/drivers/gpu/mali/ump/linux/ump_osk_atomics.c b/drivers/gpu/mali/ump/linux/ump_osk_atomics.c
index 87d1f31..0493423 100644
--- a/drivers/gpu/mali/ump/linux/ump_osk_atomics.c
+++ b/drivers/gpu/mali/ump/linux/ump_osk_atomics.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -16,12 +16,12 @@
 #include "ump_osk.h"
 #include <asm/atomic.h>
 
-int _ump_osk_atomic_dec_and_read( _mali_osk_atomic_t *atom )
+int _ump_osk_atomic_dec_and_read(_mali_osk_atomic_t *atom)
 {
 	return atomic_dec_return((atomic_t *)&atom->u.val);
 }
 
-int _ump_osk_atomic_inc_and_read( _mali_osk_atomic_t *atom )
+int _ump_osk_atomic_inc_and_read(_mali_osk_atomic_t *atom)
 {
 	return atomic_inc_return((atomic_t *)&atom->u.val);
 }
diff --git a/drivers/gpu/mali/ump/linux/ump_osk_low_level_mem.c b/drivers/gpu/mali/ump/linux/ump_osk_low_level_mem.c
index e87ff45..3cd429a 100644
--- a/drivers/gpu/mali/ump/linux/ump_osk_low_level_mem.c
+++ b/drivers/gpu/mali/ump/linux/ump_osk_low_level_mem.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -26,26 +26,24 @@
 #include <linux/slab.h>
 
 #include <asm/memory.h>
-#include <asm/uaccess.h>			/* to verify pointers from user space */
+#include <asm/uaccess.h>                        /* to verify pointers from user space */
 #include <asm/cacheflush.h>
 #include <linux/dma-mapping.h>
 
-typedef struct ump_vma_usage_tracker
-{
+typedef struct ump_vma_usage_tracker {
 	atomic_t references;
 	ump_memory_allocation *descriptor;
 } ump_vma_usage_tracker;
 
-static void ump_vma_open(struct vm_area_struct * vma);
-static void ump_vma_close(struct vm_area_struct * vma);
+static void ump_vma_open(struct vm_area_struct *vma);
+static void ump_vma_close(struct vm_area_struct *vma);
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
 static int ump_cpu_page_fault_handler(struct vm_area_struct *vma, struct vm_fault *vmf);
 #else
-static unsigned long ump_cpu_page_fault_handler(struct vm_area_struct * vma, unsigned long address);
+static unsigned long ump_cpu_page_fault_handler(struct vm_area_struct *vma, unsigned long address);
 #endif
 
-static struct vm_operations_struct ump_vm_ops =
-{
+static struct vm_operations_struct ump_vm_ops = {
 	.open = ump_vma_open,
 	.close = ump_vma_close,
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
@@ -62,11 +60,11 @@ static struct vm_operations_struct ump_vm_ops =
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
 static int ump_cpu_page_fault_handler(struct vm_area_struct *vma, struct vm_fault *vmf)
 #else
-static unsigned long ump_cpu_page_fault_handler(struct vm_area_struct * vma, unsigned long address)
+static unsigned long ump_cpu_page_fault_handler(struct vm_area_struct *vma, unsigned long address)
 #endif
 {
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
-	void __user * address;
+	void __user *address;
 	address = vmf->virtual_address;
 #endif
 	MSG_ERR(("Page-fault in UMP memory region caused by the CPU\n"));
@@ -79,12 +77,12 @@ static unsigned long ump_cpu_page_fault_handler(struct vm_area_struct * vma, uns
 #endif
 }
 
-static void ump_vma_open(struct vm_area_struct * vma)
+static void ump_vma_open(struct vm_area_struct *vma)
 {
-	ump_vma_usage_tracker * vma_usage_tracker;
+	ump_vma_usage_tracker *vma_usage_tracker;
 	int new_val;
 
-	vma_usage_tracker = (ump_vma_usage_tracker*)vma->vm_private_data;
+	vma_usage_tracker = (ump_vma_usage_tracker *)vma->vm_private_data;
 	BUG_ON(NULL == vma_usage_tracker);
 
 	new_val = atomic_inc_return(&vma_usage_tracker->references);
@@ -92,22 +90,21 @@ static void ump_vma_open(struct vm_area_struct * vma)
 	DBG_MSG(4, ("VMA open, VMA reference count incremented. VMA: 0x%08lx, reference count: %d\n", (unsigned long)vma, new_val));
 }
 
-static void ump_vma_close(struct vm_area_struct * vma)
+static void ump_vma_close(struct vm_area_struct *vma)
 {
-	ump_vma_usage_tracker * vma_usage_tracker;
+	ump_vma_usage_tracker *vma_usage_tracker;
 	_ump_uk_unmap_mem_s args;
 	int new_val;
 
-	vma_usage_tracker = (ump_vma_usage_tracker*)vma->vm_private_data;
+	vma_usage_tracker = (ump_vma_usage_tracker *)vma->vm_private_data;
 	BUG_ON(NULL == vma_usage_tracker);
 
 	new_val = atomic_dec_return(&vma_usage_tracker->references);
 
 	DBG_MSG(4, ("VMA close, VMA reference count decremented. VMA: 0x%08lx, reference count: %d\n", (unsigned long)vma, new_val));
 
-	if (0 == new_val)
-	{
-		ump_memory_allocation * descriptor;
+	if (0 == new_val) {
+		ump_memory_allocation *descriptor;
 
 		descriptor = vma_usage_tracker->descriptor;
 
@@ -119,48 +116,52 @@ static void ump_vma_close(struct vm_area_struct * vma)
 		args._ukk_private = NULL; /** @note unused */
 
 		DBG_MSG(4, ("No more VMA references left, releasing UMP memory\n"));
-		_ump_ukk_unmap_mem( & args );
+		_ump_ukk_unmap_mem(& args);
 
 		/* vma_usage_tracker is free()d by _ump_osk_mem_mapregion_term() */
 	}
 }
 
-_mali_osk_errcode_t _ump_osk_mem_mapregion_init( ump_memory_allocation * descriptor )
+_mali_osk_errcode_t _ump_osk_mem_mapregion_init(ump_memory_allocation *descriptor)
 {
-	ump_vma_usage_tracker * vma_usage_tracker;
+	ump_vma_usage_tracker *vma_usage_tracker;
 	struct vm_area_struct *vma;
 
 	if (NULL == descriptor) return _MALI_OSK_ERR_FAULT;
 
 	vma_usage_tracker = kmalloc(sizeof(ump_vma_usage_tracker), GFP_KERNEL);
-	if (NULL == vma_usage_tracker)
-	{
+	if (NULL == vma_usage_tracker) {
 		DBG_MSG(1, ("Failed to allocate memory for ump_vma_usage_tracker in _mali_osk_mem_mapregion_init\n"));
 		return -_MALI_OSK_ERR_FAULT;
 	}
 
-	vma = (struct vm_area_struct*)descriptor->process_mapping_info;
-	if (NULL == vma )
-	{
+	vma = (struct vm_area_struct *)descriptor->process_mapping_info;
+	if (NULL == vma) {
 		kfree(vma_usage_tracker);
 		return _MALI_OSK_ERR_FAULT;
 	}
 
 	vma->vm_private_data = vma_usage_tracker;
 	vma->vm_flags |= VM_IO;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,7,0)
 	vma->vm_flags |= VM_RESERVED;
+#else
+	vma->vm_flags |= VM_DONTDUMP;
+	vma->vm_flags |= VM_DONTEXPAND;
+	vma->vm_flags |= VM_PFNMAP;
+#endif
+
 
-	if (0==descriptor->is_cached)
-	{
+	if (0 == descriptor->is_cached) {
 		vma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);
 	}
-	DBG_MSG(3, ("Mapping with page_prot: 0x%x\n", vma->vm_page_prot ));
+	DBG_MSG(3, ("Mapping with page_prot: 0x%x\n", vma->vm_page_prot));
 
 	/* Setup the functions which handle further VMA handling */
 	vma->vm_ops = &ump_vm_ops;
 
 	/* Do the va range allocation - in this case, it was done earlier, so we copy in that information */
-	descriptor->mapping = (void __user*)vma->vm_start;
+	descriptor->mapping = (void __user *)vma->vm_start;
 
 	atomic_set(&vma_usage_tracker->references, 1); /*this can later be increased if process is forked, see ump_vma_open() */
 	vma_usage_tracker->descriptor = descriptor;
@@ -168,16 +169,16 @@ _mali_osk_errcode_t _ump_osk_mem_mapregion_init( ump_memory_allocation * descrip
 	return _MALI_OSK_ERR_OK;
 }
 
-void _ump_osk_mem_mapregion_term( ump_memory_allocation * descriptor )
+void _ump_osk_mem_mapregion_term(ump_memory_allocation *descriptor)
 {
-	struct vm_area_struct* vma;
-	ump_vma_usage_tracker * vma_usage_tracker;
+	struct vm_area_struct *vma;
+	ump_vma_usage_tracker *vma_usage_tracker;
 
 	if (NULL == descriptor) return;
 
 	/* Linux does the right thing as part of munmap to remove the mapping
 	 * All that remains is that we remove the vma_usage_tracker setup in init() */
-	vma = (struct vm_area_struct*)descriptor->process_mapping_info;
+	vma = (struct vm_area_struct *)descriptor->process_mapping_info;
 
 	vma_usage_tracker = vma->vm_private_data;
 
@@ -186,26 +187,26 @@ void _ump_osk_mem_mapregion_term( ump_memory_allocation * descriptor )
 	return;
 }
 
-_mali_osk_errcode_t _ump_osk_mem_mapregion_map( ump_memory_allocation * descriptor, u32 offset, u32 * phys_addr, unsigned long size )
+_mali_osk_errcode_t _ump_osk_mem_mapregion_map(ump_memory_allocation *descriptor, u32 offset, u32 *phys_addr, unsigned long size)
 {
 	struct vm_area_struct *vma;
 	_mali_osk_errcode_t retval;
 
 	if (NULL == descriptor) return _MALI_OSK_ERR_FAULT;
 
-	vma = (struct vm_area_struct*)descriptor->process_mapping_info;
+	vma = (struct vm_area_struct *)descriptor->process_mapping_info;
 
-	if (NULL == vma ) return _MALI_OSK_ERR_FAULT;
+	if (NULL == vma) return _MALI_OSK_ERR_FAULT;
 
-	retval = remap_pfn_range( vma, ((u32)descriptor->mapping) + offset, (*phys_addr) >> PAGE_SHIFT, size, vma->vm_page_prot) ? _MALI_OSK_ERR_FAULT : _MALI_OSK_ERR_OK;;
+	retval = remap_pfn_range(vma, ((u32)descriptor->mapping) + offset, (*phys_addr) >> PAGE_SHIFT, size, vma->vm_page_prot) ? _MALI_OSK_ERR_FAULT : _MALI_OSK_ERR_OK;;
 
-		DBG_MSG(4, ("Mapping virtual to physical memory. ID: %u, vma: 0x%08lx, virtual addr:0x%08lx, physical addr: 0x%08lx, size:%lu, prot:0x%x, vm_flags:0x%x RETVAL: 0x%x\n",
-		        ump_dd_secure_id_get(descriptor->handle),
-		        (unsigned long)vma,
-		        (unsigned long)(vma->vm_start + offset),
-		        (unsigned long)*phys_addr,
-		        size,
-		        (unsigned int)vma->vm_page_prot, vma->vm_flags, retval));
+	DBG_MSG(4, ("Mapping virtual to physical memory. ID: %u, vma: 0x%08lx, virtual addr:0x%08lx, physical addr: 0x%08lx, size:%lu, prot:0x%x, vm_flags:0x%x RETVAL: 0x%x\n",
+		    ump_dd_secure_id_get(descriptor->handle),
+		    (unsigned long)vma,
+		    (unsigned long)(vma->vm_start + offset),
+		    (unsigned long)*phys_addr,
+		    size,
+		    (unsigned int)vma->vm_page_prot, vma->vm_flags, retval));
 
 	return retval;
 }
@@ -216,127 +217,94 @@ static void level1_cache_flush_all(void)
 	__cpuc_flush_kern_all();
 }
 
-void _ump_osk_msync( ump_dd_mem * mem, void * virt, u32 offset, u32 size, ump_uk_msync_op op, ump_session_data * session_data )
+void _ump_osk_msync(ump_dd_mem *mem, void *virt, u32 offset, u32 size, ump_uk_msync_op op, ump_session_data *session_data)
 {
 	int i;
-	const void *start_v, *end_v;
 
 	/* Flush L1 using virtual address, the entire range in one go.
 	 * Only flush if user space process has a valid write mapping on given address. */
-	if( (mem) && (virt!=NULL) && (access_ok(VERIFY_WRITE, virt, size)) )
-	{
-		start_v = (void *)virt;
-		end_v   = (void *)(start_v + size - 1);
-		/*  There is no dmac_clean_range, so the L1 is always flushed,
-		 *  also for UMP_MSYNC_CLEAN. */
-		dmac_flush_range(start_v, end_v);
-		DBG_MSG(3, ("UMP[%02u] Flushing CPU L1 Cache. Cpu address: %x-%x\n", mem->secure_id, start_v,end_v));
-	}
-	else
-	{
-		if (session_data)
-		{
-			if (op == _UMP_UK_MSYNC_FLUSH_L1  )
-			{
+	if ((mem) && (virt != NULL) && (access_ok(VERIFY_WRITE, virt, size))) {
+		__cpuc_flush_dcache_area(virt, size);
+		DBG_MSG(3, ("UMP[%02u] Flushing CPU L1 Cache. CPU address: %x, size: %x\n", mem->secure_id, virt, size));
+	} else {
+		if (session_data) {
+			if (op == _UMP_UK_MSYNC_FLUSH_L1) {
 				DBG_MSG(4, ("UMP Pending L1 cache flushes: %d\n", session_data->has_pending_level1_cache_flush));
 				session_data->has_pending_level1_cache_flush = 0;
 				level1_cache_flush_all();
 				return;
-			}
-			else
-			{
-				if (session_data->cache_operations_ongoing)
-				{
+			} else {
+				if (session_data->cache_operations_ongoing) {
 					session_data->has_pending_level1_cache_flush++;
-					DBG_MSG(4, ("UMP[%02u] Defering the L1 flush. Nr pending:%d\n", mem->secure_id, session_data->has_pending_level1_cache_flush) );
-				}
-				else
-				{
+					DBG_MSG(4, ("UMP[%02u] Defering the L1 flush. Nr pending:%d\n", mem->secure_id, session_data->has_pending_level1_cache_flush));
+				} else {
 					/* Flushing the L1 cache for each switch_user() if ump_cache_operations_control(START) is not called */
 					level1_cache_flush_all();
 				}
 			}
-		}
-		else
-		{
+		} else {
 			DBG_MSG(4, ("Unkown state %s %d\n", __FUNCTION__, __LINE__));
 			level1_cache_flush_all();
 		}
 	}
 
-	if ( NULL == mem ) return;
+	if (NULL == mem) return;
 
-	if ( mem->size_bytes==size)
-	{
-		DBG_MSG(3, ("UMP[%02u] Flushing CPU L2 Cache\n",mem->secure_id));
-	}
-	else
-	{
+	if (mem->size_bytes == size) {
+		DBG_MSG(3, ("UMP[%02u] Flushing CPU L2 Cache\n", mem->secure_id));
+	} else {
 		DBG_MSG(3, ("UMP[%02u] Flushing CPU L2 Cache. Blocks:%u, TotalSize:%u. FlushSize:%u Offset:0x%x FirstPaddr:0x%08x\n",
-	            mem->secure_id, mem->nr_blocks, mem->size_bytes, size, offset, mem->block_array[0].addr));
+			    mem->secure_id, mem->nr_blocks, mem->size_bytes, size, offset, mem->block_array[0].addr));
 	}
 
 
 	/* Flush L2 using physical addresses, block for block. */
-	for (i=0 ; i < mem->nr_blocks; i++)
-	{
+	for (i = 0 ; i < mem->nr_blocks; i++) {
 		u32 start_p, end_p;
 		ump_dd_physical_block *block;
 		block = &mem->block_array[i];
 
-		if(offset >= block->size)
-		{
+		if (offset >= block->size) {
 			offset -= block->size;
 			continue;
 		}
 
-		if(offset)
-		{
+		if (offset) {
 			start_p = (u32)block->addr + offset;
 			/* We'll zero the offset later, after using it to calculate end_p. */
-		}
-		else
-		{
+		} else {
 			start_p = (u32)block->addr;
 		}
 
-		if(size < block->size - offset)
-		{
+		if (size < block->size - offset) {
 			end_p = start_p + size - 1;
 			size = 0;
-		}
-		else
-		{
-			if(offset)
-			{
+		} else {
+			if (offset) {
 				end_p = start_p + (block->size - offset - 1);
 				size -= block->size - offset;
 				offset = 0;
-			}
-			else
-			{
+			} else {
 				end_p = start_p + block->size - 1;
 				size -= block->size;
 			}
 		}
 
-		switch(op)
-		{
-				case _UMP_UK_MSYNC_CLEAN:
-						outer_clean_range(start_p, end_p);
-						break;
-				case _UMP_UK_MSYNC_CLEAN_AND_INVALIDATE:
-						outer_flush_range(start_p, end_p);
-						break;
-				case _UMP_UK_MSYNC_INVALIDATE:
-						outer_inv_range(start_p, end_p);
-						break;
-				default:
-						break;
+		switch (op) {
+		case _UMP_UK_MSYNC_CLEAN:
+			outer_clean_range(start_p, end_p);
+			break;
+		case _UMP_UK_MSYNC_CLEAN_AND_INVALIDATE:
+			outer_flush_range(start_p, end_p);
+			break;
+		case _UMP_UK_MSYNC_INVALIDATE:
+			outer_inv_range(start_p, end_p);
+			break;
+		default:
+			break;
 		}
 
-		if(0 == size)
-		{
+		if (0 == size) {
 			/* Nothing left to flush. */
 			break;
 		}
diff --git a/drivers/gpu/mali/ump/linux/ump_osk_misc.c b/drivers/gpu/mali/ump/linux/ump_osk_misc.c
index aeed946..0f6829d 100644
--- a/drivers/gpu/mali/ump/linux/ump_osk_misc.c
+++ b/drivers/gpu/mali/ump/linux/ump_osk_misc.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,17 +20,16 @@
 #include "ump_kernel_linux.h"
 
 /* is called from ump_kernel_constructor in common code */
-_mali_osk_errcode_t _ump_osk_init( void )
+_mali_osk_errcode_t _ump_osk_init(void)
 {
-	if (0 != ump_kernel_device_initialize())
-	{
+	if (0 != ump_kernel_device_initialize()) {
 		return _MALI_OSK_ERR_FAULT;
 	}
 
 	return _MALI_OSK_ERR_OK;
 }
 
-_mali_osk_errcode_t _ump_osk_term( void )
+_mali_osk_errcode_t _ump_osk_term(void)
 {
 	ump_kernel_device_terminate();
 	return _MALI_OSK_ERR_OK;
diff --git a/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.c b/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.c
index d5e27ae..ed14987 100644
--- a/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.c
+++ b/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -24,37 +24,33 @@
 /*
  * IOCTL operation; Allocate UMP memory
  */
-int ump_allocate_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_allocate_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_allocate_s user_interaction;
 	_mali_osk_errcode_t err;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_allocate()\n"));
 		return -ENOTTY;
 	}
 
 	/* Copy the user space memory to kernel space (so we safely can read it) */
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_allocate()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	err = _ump_ukk_allocate( &user_interaction );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	err = _ump_ukk_allocate(&user_interaction);
+	if (_MALI_OSK_ERR_OK != err) {
 		DBG_MSG(1, ("_ump_ukk_allocate() failed in ump_ioctl_allocate()\n"));
 		return map_errcode(err);
 	}
 	user_interaction.ctx = NULL;
 
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		/* If the copy fails then we should release the memory. We can use the IOCTL release to accomplish this */
 		_ump_uk_release_s release_args;
 
@@ -63,9 +59,8 @@ int ump_allocate_wrapper(u32 __user * argument, struct ump_session_data  * sessi
 		release_args.ctx = (void *) session_data;
 		release_args.secure_id = user_interaction.secure_id;
 
-		err = _ump_ukk_release( &release_args );
-		if(_MALI_OSK_ERR_OK != err)
-		{
+		err = _ump_ukk_release(&release_args);
+		if (_MALI_OSK_ERR_OK != err) {
 			MSG_ERR(("_ump_ukk_release() also failed when trying to release newly allocated memory in ump_ioctl_allocate()\n"));
 		}
 
diff --git a/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.h b/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.h
index 59ed860..c88b666 100644
--- a/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.h
+++ b/drivers/gpu/mali/ump/linux/ump_ukk_ref_wrappers.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2013-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,12 +20,11 @@
 #include "ump_kernel_common.h"
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 
-int ump_allocate_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
+int ump_allocate_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
 
 
 #ifdef __cplusplus
diff --git a/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.c b/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.c
index e5c5903..49d58d7 100644
--- a/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.c
+++ b/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.c
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010-2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -23,29 +23,26 @@
 /*
  * IOCTL operation; Negotiate version of IOCTL API
  */
-int ump_get_api_version_wrapper(u32 __user * argument, struct ump_session_data * session_data)
+int ump_get_api_version_wrapper(u32 __user *argument, struct ump_session_data *session_data)
 {
 	_ump_uk_api_version_s version_info;
 	_mali_osk_errcode_t err;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_get_api_version()\n"));
 		return -ENOTTY;
 	}
 
 	/* Copy the user space memory to kernel space (so we safely can read it) */
-	if (0 != copy_from_user(&version_info, argument, sizeof(version_info)))
-	{
+	if (0 != copy_from_user(&version_info, argument, sizeof(version_info))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_get_api_version()\n"));
 		return -EFAULT;
 	}
 
-	version_info.ctx = (void*) session_data;
-	err = _ump_uku_get_api_version( &version_info );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	version_info.ctx = (void *) session_data;
+	err = _ump_uku_get_api_version(&version_info);
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("_ump_uku_get_api_version() failed in ump_ioctl_get_api_version()\n"));
 		return map_errcode(err);
 	}
@@ -53,8 +50,7 @@ int ump_get_api_version_wrapper(u32 __user * argument, struct ump_session_data *
 	version_info.ctx = NULL;
 
 	/* Copy ouput data back to user space */
-	if (0 != copy_to_user(argument, &version_info, sizeof(version_info)))
-	{
+	if (0 != copy_to_user(argument, &version_info, sizeof(version_info))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_get_api_version()\n"));
 		return -EFAULT;
 	}
@@ -66,29 +62,26 @@ int ump_get_api_version_wrapper(u32 __user * argument, struct ump_session_data *
 /*
  * IOCTL operation; Release reference to specified UMP memory.
  */
-int ump_release_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_release_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_release_s release_args;
 	_mali_osk_errcode_t err;
 
 	/* Sanity check input parameters */
-	if (NULL == session_data)
-	{
+	if (NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_release()\n"));
 		return -ENOTTY;
 	}
 
 	/* Copy the user space memory to kernel space (so we safely can read it) */
-	if (0 != copy_from_user(&release_args, argument, sizeof(release_args)))
-	{
+	if (0 != copy_from_user(&release_args, argument, sizeof(release_args))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_get_api_version()\n"));
 		return -EFAULT;
 	}
 
-	release_args.ctx = (void*) session_data;
-	err = _ump_ukk_release( &release_args );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	release_args.ctx = (void *) session_data;
+	err = _ump_ukk_release(&release_args);
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("_ump_ukk_release() failed in ump_ioctl_release()\n"));
 		return map_errcode(err);
 	}
@@ -100,36 +93,32 @@ int ump_release_wrapper(u32 __user * argument, struct ump_session_data  * sessio
 /*
  * IOCTL operation; Return size for specified UMP memory.
  */
-int ump_size_get_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_size_get_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_size_get_s user_interaction;
 	_mali_osk_errcode_t err;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_size_get()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
-	err = _ump_ukk_size_get( &user_interaction );
-	if( _MALI_OSK_ERR_OK != err )
-	{
+	err = _ump_ukk_size_get(&user_interaction);
+	if (_MALI_OSK_ERR_OK != err) {
 		MSG_ERR(("_ump_ukk_size_get() failed in ump_ioctl_size_get()\n"));
 		return map_errcode(err);
 	}
 
 	user_interaction.ctx = NULL;
 
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_size_get()\n"));
 		return -EFAULT;
 	}
@@ -140,63 +129,57 @@ int ump_size_get_wrapper(u32 __user * argument, struct ump_session_data  * sessi
 /*
  * IOCTL operation; Do cache maintenance on specified UMP memory.
  */
-int ump_msync_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_msync_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_msync_s user_interaction;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_msync()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	_ump_ukk_msync( &user_interaction );
+	_ump_ukk_msync(&user_interaction);
 
 	user_interaction.ctx = NULL;
 
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_msync()\n"));
 		return -EFAULT;
 	}
 
 	return 0; /* success */
 }
-int ump_cache_operations_control_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_cache_operations_control_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_cache_operations_control_s user_interaction;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_cache_operations_control()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	_ump_ukk_cache_operations_control((_ump_uk_cache_operations_control_s*) &user_interaction );
+	_ump_ukk_cache_operations_control((_ump_uk_cache_operations_control_s *) &user_interaction);
 
 	user_interaction.ctx = NULL;
 
 #if 0  /* No data to copy back */
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_cache_operations_control()\n"));
 		return -EFAULT;
 	}
@@ -204,32 +187,29 @@ int ump_cache_operations_control_wrapper(u32 __user * argument, struct ump_sessi
 	return 0; /* success */
 }
 
-int ump_switch_hw_usage_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_switch_hw_usage_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_switch_hw_usage_s user_interaction;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	_ump_ukk_switch_hw_usage( &user_interaction );
+	_ump_ukk_switch_hw_usage(&user_interaction);
 
 	user_interaction.ctx = NULL;
 
 #if 0  /* No data to copy back */
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
@@ -237,32 +217,29 @@ int ump_switch_hw_usage_wrapper(u32 __user * argument, struct ump_session_data
 	return 0; /* success */
 }
 
-int ump_lock_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_lock_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_lock_s user_interaction;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	_ump_ukk_lock( &user_interaction );
+	_ump_ukk_lock(&user_interaction);
 
 	user_interaction.ctx = NULL;
 
 #if 0  /* No data to copy back */
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
@@ -271,32 +248,29 @@ int ump_lock_wrapper(u32 __user * argument, struct ump_session_data  * session_d
 	return 0; /* success */
 }
 
-int ump_unlock_wrapper(u32 __user * argument, struct ump_session_data  * session_data)
+int ump_unlock_wrapper(u32 __user *argument, struct ump_session_data   *session_data)
 {
 	_ump_uk_unlock_s user_interaction;
 
 	/* Sanity check input parameters */
-	if (NULL == argument || NULL == session_data)
-	{
+	if (NULL == argument || NULL == session_data) {
 		MSG_ERR(("NULL parameter in ump_ioctl_size_get()\n"));
 		return -ENOTTY;
 	}
 
-	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction)))
-	{
+	if (0 != copy_from_user(&user_interaction, argument, sizeof(user_interaction))) {
 		MSG_ERR(("copy_from_user() in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
 
 	user_interaction.ctx = (void *) session_data;
 
-	_ump_ukk_unlock( &user_interaction );
+	_ump_ukk_unlock(&user_interaction);
 
 	user_interaction.ctx = NULL;
 
 #if 0  /* No data to copy back */
-	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction)))
-	{
+	if (0 != copy_to_user(argument, &user_interaction, sizeof(user_interaction))) {
 		MSG_ERR(("copy_to_user() failed in ump_ioctl_switch_hw_usage()\n"));
 		return -EFAULT;
 	}
diff --git a/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.h b/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.h
index 1cbacf7..e9110b7 100644
--- a/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.h
+++ b/drivers/gpu/mali/ump/linux/ump_ukk_wrappers.h
@@ -1,9 +1,9 @@
 /*
- * Copyright (C) 2010, 2012 ARM Limited. All rights reserved.
- *
+ * Copyright (C) 2010, 2012-2014 ARM Limited. All rights reserved.
+ * 
  * This program is free software and is provided to you under the terms of the GNU General Public License version 2
  * as published by the Free Software Foundation, and any use by you of this program is subject to the terms of such GNU licence.
- *
+ * 
  * A copy of the licence is included with the program, and can also be obtained from Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
  */
@@ -20,20 +20,19 @@
 #include "ump_kernel_common.h"
 
 #ifdef __cplusplus
-extern "C"
-{
+extern "C" {
 #endif
 
 
 
-int ump_get_api_version_wrapper(u32 __user * argument, struct ump_session_data * session_data);
-int ump_release_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_size_get_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_msync_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_cache_operations_control_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_switch_hw_usage_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_lock_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
-int ump_unlock_wrapper(u32 __user * argument, struct ump_session_data  * session_data);
+int ump_get_api_version_wrapper(u32 __user *argument, struct ump_session_data *session_data);
+int ump_release_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_size_get_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_msync_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_cache_operations_control_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_switch_hw_usage_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_lock_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
+int ump_unlock_wrapper(u32 __user *argument, struct ump_session_data   *session_data);
 
 
 
-- 
1.7.10.4

